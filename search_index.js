const raw_index={documents:[{
name:"advent_of_code_2018_5.html",
text:"Getting started with Scheme by solving an Advent of Code 2018 challenge\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2019-09-05\nGetting started with Scheme by solving an Advent of Code 2018 challenge\nLisp\nScheme\nC\nAdvent of Code\nTable of contents\nThe problem\nWorking with the REPL to iteratively close in on a solution\nA small detour: pattern matching\nUsing pattern matching to solve our problem\nThe final solution\nConclusion\nDiscussions:\n/r/scheme\nI started learning\nScheme\nvery recently.\nChicken Scheme\nis a wonderful small and\nperformant implementation of Scheme, a programming language in the family of\nLISPs.\nSince I learn by doing, let\'s solve the\nAdvent of Code 2018 day 5 challenge\nwith a tiny Scheme program.\nI encourage you to check out\nAdvent of\nCode\nand try to solve the challenges yourself.\nMany people have the feeling that LISPs are slow and cryptic with all those\nparentheses. I hope to show that it is in fact very approachable, easy to work\nwith, and even fast to run!\nI will not go through installing Chicken Scheme and learning the basics, because\nit was\nalready done better than I can\n.\nThe problem\nWe have a string looking like this:\nAabcdZZqQ\nwhich represents a chain of\nchemical units. Adjacent units of the same type (i.e letter) and opposite\npolarity (i.e casing) react together and disappear.\nIt means we want to remove adjacent characters which are the same letter and have opposite casing, e.g\nAa\nand\nqQ\ndisappear while\nbc\nand\nZZ\nremain. Once we are finished, we have:\nbcdZZ\n.\nThe final output is the number of characters in the final string, i.e,\n5\n.\nWorking with the REPL to iteratively close in on a solution\nFirst, let\'s define our input, which is a string:\n(define input &quot;aAbxXBctTCz&quot;)\nLater, we will read our input string from a file, but for now it is simpler to\njust hard-code it.\nMost functions in Scheme are immutable, meaning they do not\nmodify their arguments, they instead return a new item which is slightly different.\nWe could work with strings, but it turns out it is simpler to work with lists\ninstead in our case. We do not want to keep track of indices, risking doing off-by-one mistakes.\nAlso, LISPs are good at handling lists (LISP stands for LISt Processor), and\nwe\'ll that we can use pattern matching to make the code very concise. I am not\naware of pattern matching capabilities on string, so let\'s use lists:\n(string-&gt;list input)\nHere, the\nstring-&gt;list\nfunction just returns a list of characters for a string (in other\nlanguages it is usually named\nsplit\n).\nNow, we need to detect if two characters are the same latter, with opposite casing.\nLet\'s write a\nchar-opposite-casing?\nfunction to do just that. It will take 2\narguments, the letters we are inspecting, and will return a boolean.\nFor now, let\'s just make it always return true:\n(define (char-opposite-casing? a b) #\\t)\nWe only deal with ASCII, so it is safe to compare ASCII codes to detect casing.\nWhat is the ASCII code of\nA\n? Let\'s try it by using the function\nchar-&gt;integer\n:\n(char-&gt;integer #\\A) \nWhat about\na\n?\n(char-&gt;integer #\\a)\nSo there is a difference of\n32\nbetween the same ASCII letter in lowercase and\nuppercase. Peeking at\nman ascii\nin the terminal confirms this hunch for all\nletters of the alphabet.\nSo, time to implement\nchar-opposite-casing?\n:\n(define (char-case-opposite-casing? a b)\n  (let* ((a-code (char-&gt;integer a))\n         (b-code (char-&gt;integer b))\n         (diff (- a-code b-code)))\n    (= (* 32 32) (* diff diff))))\nLet\'s try it with\na\nand\nA\n:\n(char-case-opposite-casing? #\\a #\\A) \nAnd flipped:\n(char-case-opposite-casing? #\\A #\\a)\nAnd\nA\nand\nb\n:\n(char-case-opposite-casing? #\\A #\\b)\nlet*\nis used to define local bindings which are only visible in this function.\nIt evaluates each binding in order which means we can define\ndiff\nin terms of\na\nand\nb\n(contrary to\nlet\n).\nWe could have done without it but it makes the function more readable.\nThe only hurdle is not caring\nabout the sign of the difference: if the difference is\n32\nor\n-32\n, it is the\nsame. We could compare the absolute value, but I (arbitrarily) chose to implement it without\nbranches, by comparing the squared values (which swallows the signs).\nNow let\'s work on the central problem: how to remove\ncharacters in a list, in a functional, immutable way?\nThe idea is to write a recursive function taking two arguments: an accumulator\n(let\'s call it\nacc\nfrom now on),\nwhich will be eventually the end result, and the input list (\ninput\n), from which we\ngradually remove items until it is empty. We can view the first list as the work\nwe have done, and the second list as the work to do.\nLet\'s first define the function. For now, it just returns the empty list:\n(define (chem-react acc input)\n  \'())\nAt first, the accumulator is the empty list, so we will always call our function like\nthis:\n(chem-react \'() (string-&gt;list input))\nIt is import to know that most list functions do not work on the empty list in\nChicken Scheme. For example, to get the first element of a list, we use the\ncar\nfunction:\n(define my-list (list 1 2 3))\n\n;; Note that this doest **not** mutate `my-list`\n(car my-list)\nBut it won\'t work on the empty list:\n(define my-list \'())\n\n(car my-list)\nSo we need to treat the case of the empty list (both for the first and the\nsecond argument) explicitly. We could do that by using lots of\nif\n, but it is\nmore readable and concise to use pattern matching.\nA small detour: pattern matching\nScheme has a minimalist core, so we do not get pattern matching out of\nthe box, but we can easily add it with the package\nmatchable\n. Let\'s install\nit in the terminal:\n$ chicken-install matchable\nNow we can import it at the top of our code:\n(import matchable)\n\n;; At this point we can refer to any function in this module `matchable`.\n;; No need to prefix them either with `matchable`.\nLet\'s try to match the empty list in our function, and return (as an example) a\nnumber, e.g\n42\n. We also want to match the case of both lists containing one\nelement, and returning the sum of those 2 elements:\n(define (chem-react acc input)\n  (match (list acc input)\n    [(_ ()) 42]\n    [((a) (b)) (+ a b)]))\n\n(chem-react \'() \'()) ;; =&gt; 42\n\n(chem-react (list 2) (list 3)) ;; =&gt; 5\nA few interesting things here:\n_\nallows us to match anything, so the first\ncase is equivalent to checking if the second list is\nempty. Additionally, we can bind variables to our patterns: we do that in the\nsecond case, binding the first element of the first list to\na\n, and the fist\nelement of the second list to\nb\n, and summing the two.\nNote that not all possible cases are covered here, and we will get a (runtime)\nerror if we trigger one of them, for example with a list containing several numbers:\n(chem-react (list 1 2) (list 3)) ;; =&gt; Error: (match) &quot;no matching pattern&quot;: ()\nLet\'s go ahead and match the case of a list of one or more elements (\n(a . arest)\n) to avoid that:\n(define (chem-react acc input)\n  (match (list acc input)\n    [(_ ()) 42]\n    [((a) (b)) (+ a b)]\n    [((a . arest) (b . brest)) (* a b)]))\n\n(chem-react (list 2 3) (list 4)) ;; =&gt; 8\nHere we choose to (arbitrarily) return the product of the first elements of both\nlist, to show that pattern matching is also a way to do destructuring.\nUsing pattern matching to solve our problem\nIf the second list (the input) is empty, it means we are\nfinished, so we return the first list (\nacc\n):\n(define (chem-react acc input)\n  (match (list acc input)\n    [(_ ()) acc]))\nOur recursion will work as follows: we look at the first element of the second\nlist (\ninput\n, which is the work to do), let\'s call it\nb\n, and the first element of the first\nlist (\nacc\n, the work done), let\'s call it\na\n.\nIf\na\nand\nb\nare the same letter of opposite casing, we \'drop\' the two. Otherwise, we\nadd\nb\nto the first list, and \'continue\'. \'drop\' and \'continue\' are put in\nquotes because that is vocabulary from imperative languages such as C; we\'ll see\nin a minute how we implement it in a functional way.\nIf the first list is empty, this is our starting case: the only thing we can do\nis mark\nb\nas \'processed\', i.e add it to the first list, and call ourselves\nwith the remainder of\ninput\n. Indeed, we can only work with two characters, so\nif we only have one, we cannot do much.\nIt\'s time to learn about a new function:\ncons\n.\ncons\njust adds an item to a list, and\nreturns the new list with the added item:\n(define my-list (list 2 3))\n\n;; Note: `my-list` is **not** modified\n(cons 1 my-list) \nWe can now use\ncons\nto implement the new case:\n(define (chem-react acc input)\n  (match (list acc input)\n    [(_ ()) acc]\n    [(() (b . brest)) (chem-react (cons b acc) brest)]))\n\n\n(chem-react \'() \'(#\\A)) ;; =&gt; (#\\A)\nThis new pattern is required for the recursion to\nwork, but it also covers the trivial case of an input string of only one character.\nNow, let\'s treat the main case: we have at least an element\na\nin\nacc\nand at\nleast an element\nb\nin\ninput\n. If they are the same letters of opposite casing, we\ncall ourselves with the remainder of\nacc\nand the remainder of\ninput\n, which\nis equivalent to \'drop\'\na\nand\nb\n. Otherwise, we add\nb\nto\nacc\n, and we call\nourselves with the remainder of\ninput\n, which is the equivalent of \'continuing\':\n(define (chem-react acc input)\n  (match (list acc input)\n    [(_ ()) acc]\n    [(() (b . brest)) (chem-react (cons b acc) brest)]\n    [((a . arest) (b . brest)) (if (char-case-opposite-casing? a b)\n                                   (chem-react arest brest)\n                                   (chem-react (cons b acc) brest))]))\n\n\n(chem-react \'() (list #\\A #\\a #\\b)) ;; =&gt; (#\\b)\n(chem-react \'() (string-&gt;list &quot;aAbxXBctTCz&quot;)) ;; =&gt; (#\\z)\nBut wait a minute...Doesn\'t it look familiar? Yes, what we are doing here is a\nfold (sometimes called reduce)!\nLet\'s replace our custom recursion by\nfold\n.\nchem-react\nbecomes the reduction\nfunction. It becomes simpler because\nfold\nwill not call it on the empty list,\nso we only need to patter match\nacc\n(which is the empty list at the beginning):\n(define (chem-react acc x)\n  (match acc\n    [() (cons x acc)]\n    [(a . arest) (if (char-case-opposite-casing? a x)\n                     arest\n                     (cons x acc))]))\n\n\n(foldl chem-react \'() input) ;; =&gt; (#\\z)\nMy experience writing code in a LISP is that I usually find a solution that is\nrelatively big, and I start replacing parts of it with standard functions such\nas\nfold\nand it ends up very small.\nHow do I read the input from a file?\nIt\'s quite simple: we use the modules\nchicken.file.posix\nand\nchicken.io\n:\n(import chicken.file.posix\n        chicken.io)\n\n(read-line (open-input-file &quot;/Users/pgaultier/Downloads/aoc5.txt&quot;)) ;; =&gt; &quot;a big string...&quot;\nThe final solution\nHere I use the package\nclojurian\n(\nchicken-install clojurian\n) to have access\nto the\n-&gt;&gt;\nmacro which makes code more readable. It works like the pipe in the\nshell. Instead of writing:\n(foo (bar &quot;foo&quot; (baz 1 2)))\nWe write:\n(-&gt;&gt; (baz 1 2)\n     (bar &quot;foo&quot;)\n     (foo))\nThe macro reorders the functions calls to make it flat and avoid nesting.\nIt is not strictly required, but I like that my code looks like a\npipeline of data transformations.\nThe final code:\n(import matchable\n        clojurian.syntax\n        chicken.file.posix\n        chicken.io)\n\n(define (char-case-opposite-casing? a b)\n  (let* ((a-code (char-&gt;integer a))\n         (b-code (char-&gt;integer b))\n         (diff (- a-code b-code)))\n    (= (* 32 32) (* diff diff))))\n\n(define (chem-react acc x)\n  (match acc\n    [() (cons x acc)]\n    [(a . arest) (if (char-case-opposite-casing? a x)\n                     arest\n                     (cons x acc))]))\n\n(-&gt;&gt; (open-input-file &quot;/Users/pgaultier/Downloads/aoc5.txt&quot;)\n     (read-line)\n     (string-&gt;list)\n     (foldl chem-react \'())\n     (length)\n     (print))\nBut we will get a stack overflow on a big input!\nScheme has a nice requirement for all implementations: they must implement\ntail-call optimization, which is to say that the compiler can transform our function into an\nequivalent for-loop. So we won\'t get a stack overflow, and it will be quite\nefficient in terms of memory and time.\nBut we are making thousands of copies, it will be slow as hell!\nLet\'s benchmark it on the real input (50 000 characters), with\n-O3\nto enable optimizations:\nNote 1: The real output of the program is not shown to avoid spoiling the final result\nNote 2: This is a simplistic way to do benchmarking. A more correct way would\nbe: warming up the file cache, making many runs, averaging the results, etc.\nI did exactly that and it did not change the results in a significant manner.\n$ csc aoc5.scm -o aoc5 -O3 &amp;&amp; time ./aoc5\n./aoc5  0.01s user 0.00s system 82% cpu 0.021 total\nIt takes 21 milliseconds. Not too bad for a garbage collected, functional,\nimmutable program.\nHere is a hand-written C version which only does one allocation and removes\nletters in place:\n#include &lt;errno.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n  int fd = open(&quot;/home/pg/Downloads/aoc2020_5.txt&quot;, O_RDONLY);\n  if (fd == -1)\n    return errno;\n\n  struct stat st = {0};\n  if (stat(&quot;/home/pg/Downloads/aoc2020_5.txt&quot;, &amp;st) == -1)\n    return errno;\n\n  int64_t input_len = st.st_size;\n  char *const input = calloc(input_len, 1);\n\n  if (read(fd, input, input_len) != input_len)\n    return errno;\n\n  while (input[input_len - 1] == \'\\n\' || input[input_len - 1] == \' \')\n    input_len--;\n\n  int64_t i = 0;\n  while (i &lt; input_len) {\n    if (abs(input[i] - input[i + 1]) == 32) {\n      memmove(input + i, input + i + 2, input_len - i - 2);\n      input_len -= 2;\n      i = i &gt; 0 ? i - 1 : 0;\n    } else\n      i++;\n  }\n\n  printf(&quot;`%zu`\\n&quot;, input_len);\n}\nLet\'s benchmark it on the same input:\n$ cc -std=c99 -O3 -Weverything aoc5.c -march=native &amp;&amp; time ./a.out\n./a.out  0.01s user 0.00s system 86% cpu 0.012 total\nIt took 12 milliseconds. So the scheme version is very close, and takes an\nacceptable amount of time.\nCan\'t we use strings and not lists?\nYes, of course. However we need to be careful about how strings are implemented\nand what we we do with those. Most runtimes (e.g the JVM) use immutable strings,\nmeaning we could end up allocating thousands of big strings, and being quite slow.\nConclusion\nThat\'s it, we solved the fifth Advent of Code challenge in Scheme. The solution\nis under 30 lines of code, is (hopefully) simple and readable, and has a\nperformance close to C, while having memory safety (I had several segfaults\nwhile doing the C version).\nBut more than that, I think the real value in LISPs is\ninteractive programming, instead of the classical write-compile-execute-repeat,\nwhich is much more time consuming. It is really important to get feedback as\nearly as possible, and LISPs give us that.\nI hope it gave you a glance at what Scheme can do, and stay tuned for more blog\nposts about programming. I intend to post more solutions to other coding\nchallenges, solved with a variety of programming languages.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2580162644-the-problem",
"#3898953298-working-with-the-repl-to-iteratively-close-in-on-a-solution",
"#3881950255-a-small-detour-pattern-matching",
"#1617151895-using-pattern-matching-to-solve-our-problem",
"#405744868-the-final-solution",
"#3796851539-conclusion",
],
title_text_offsets:[
1154,1627,5448,7282,10745,14489,],
},
{
name:"compile_ziglang_from_source_on_alpine_2020_9.html",
text:"How to compile LLVM, Clang, LLD, and Ziglang from source on Alpine Linux\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2020-09-07\nHow to compile LLVM, Clang, LLD, and Ziglang from source on Alpine Linux\nLLVM\nZig\nAlpine\nThis article is now outdated but remains for historical reasons.\nZiglang\n, or\nZig\nfor short, is an ambitious programming language addressing important flaws of mainstream languages such as failing to handle memory allocation failures or forgetting to handle an error condition in general.\nIt is also fast moving so for most, the latest (HEAD) version will be needed, and most package managers will not have it, so we will compile it from source.\nSince the official Zig compiler is (currently) written in C++ and using the LLVM libraries at a specific version, we will need them as well, and once again, some package managers will not have the exact version you want (10.0.0).\nI find it more reliable to compile LLVM, Clang, LLD, and Zig from source and that is what we will do here. I have found that the official LLVM and Zig instructions differed somewhat, were presenting too many options, and I wanted to have one place to centralize them for my future self.\nIncidentally, if you are a lost C++ developer trying to compile LLVM from source, without having ever heard of Zig, well you have stumbled on the right page, you can simply skip the final block about Zig.\nNote that those instructions should work just the same on any Unix system. Feel free to pick the directories you want when cloning the git repositories.\n# The only Alpine specific bit. build-base mainly installs make and a C++ compiler. Python 3 is required by LLVM for some reason.\n$ apk add build-base cmake git python3\n\n$ git clone https://github.com/llvm/llvm-project.git --branch llvmorg-10.0.0  --depth 1\n$ cd llvm-project/\n$ mkdir build\n$ cd build/\n# The flag LLVM_ENABLE_PROJECTS is crucial, otherwise only llvm will be built, without clang or lld,\n# and we need all three with the exact same version since C++ does not have a stable ABI.\n$ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=&quot;AVR&quot; -DLLVM_ENABLE_LIBXML2=OFF -DLLVM_ENABLE_TERMINFO=OFF -DLLVM_ENABLE_PROJECTS=&quot;clang;lld&quot; ../llvm\n\n# nproc is Linux only but you can set the number of threads manually\n$ make -j$(nproc)\n$ sudo make install\n\n$ cd ~\n$ git clone https://github.com/ziglang/zig.git --depth 1\n$ cd zig\n$ mkdir build\n$ cd build\n$ cmake .. -DCMAKE_BUILD_TYPE=Release -DZIG_STATIC=ON\n# nproc is Linux only but you can set the number of threads manually\n$ make -j$(nproc)\n$ sudo make install\nYou will now have a\nzig\nexecutable in the PATH as well as the zig standard library. You can verify you have now the latest version by doing:\n$ zig version\n0.6.0+749417a\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"speed_up_your_ci.html",
text:"Adventures in CI land, or how to speed up your CI\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2020-09-21\nAdventures in CI land, or how to speed up your CI\nCI\nOptimization\nTable of contents\nReduce the size of everything\nBe lazy: Don\'t do things you don\'t need to do\nMiscellenaous tricks\nA note on security\nI am a DevOps Engineer, what can I do?\nClosing words\nEvery project has a Continuous Integration (CI) pipeline and every one of them complains its CI is too slow. It is more important than you might think; this can be the root cause of many problems, including lackluster productivity, low morale, high barrier of entry for newcomers, and overall suboptimal quality.\nBut this need not be. I have compiled here a lengthy list of various ways you can simplify your CI and make it faster, based on my experience on open-source projects and my work experience. I sure wish you will find something in here worth your time.\nAnd finally, I hope you will realize this endeavour is not unlike optimizing a program: it requires some time and dedication but you will get tremendous results. Also, almost incidentally, it will be more secure and easier to audit.\nLastly, remember to measure and profile your changes. If a change has made no improvements, it should be reverted.\nThis article assumes you are running a POSIX system. Windows developers, this is not the article you are looking for.\nReduce the size of everything\nAlmost certainly, your CI pipeline has to download \'something\', be it a base docker image, a virtual machine image, some packages, maybe a few company wide scripts. The thing is, you are downloading those every time it runs, 24/7, every day of the year. Even a small size reduction can yield big speed ups. Remember, the network is usually the bottleneck.\nIn no particular order:\nOnly fetch required git objects. That means running\ngit clone my-repo.git --depth 1 --branch shiny-feature\n, instead of cloning the whole repository every time, along with every branch and that one class file that your coworker accidentally committed once.\nAxe duplicate tools.\ncurl\nand\nwget\nare equivalent, given the right command line options. Settle on using only one and stick to it. All my pipelines use:\ncurl --sSL --retry 5\n. You can customize further, but that\'s the gist of it. Other examples:\nmake\nand\nninja\n,\ngcc\nand\nclang\n, etc.\nUse POSIX tools. They are already present on whatever system you are using. When purely checking that a tool or an API returned \'OK\', simply use\ngrep\nand\nawk\n, no need for\nripgrep\n. Prefer\nsh\nover\nbash\nfor simple scripts,\nmake\nover\nrake\nfor builds, etc. It\'s most likely faster, more stable, and more documented, too.\nPay attention to the base image you are using. Prefer a small image where you install only what you need. I have seen docker base images over 1 Gb big. You will spend more time downloading it, uncompressing it, and checksumming it, than running your pipeline. Alpine Linux is great. Debian and Ubuntu are fine. When in doubt, inspect the content of the image. Look for stuff that should not be here. E.g.:\nX11\n, man pages, etc.\nDon\'t install documentation. It\'s obvious but most people do it. While you are at it, don\'t install\nman\n,\napropos\n,\ninfo\n, etc. Alpine Linux gets it right by splitting almost all packages between the package itself and its documentation. E.g.:\ncmake\nand\ncmake-doc\n.\nOn the same vein: don\'t install shell autocompletions. Same idea. Again, on Alpine they are not part of the main package. E.g.:\ncmake\nand\ncmake-bash-completion\n.\nStay away from aggregate packages (or meta-packages)! Those are for convenience only when developing. E.g.:\nbuild-base\non Alpine is a meta-package gathering\nmake\n,\nfile\n,\ngcc\n, etc. It will bring lots of things you do not need. Cherry-pick only what you really required and steer clear of those packages.\nLearn how Docker image layers work: avoid doing\nRUN rm archive.tar\n, since it simply creates a new layer without removing the file from the previous layer. Prefer:\nRUN curl -sSL --retry 5 foo.com/archive.tar &amp;&amp; tar -xf archive.tar &amp;&amp; rm archive.tar\nwhich will not add the tar archive to the Docker image.\nUse multi-stage Docker builds. It is old advice at this point but it bears repeating.\nWhen using multi-stage: Only copy files you need from a previous stage instead of globbing wildly, thus defeating the purpose of multi-stages.\nTell apart the development and the release variant of a package. For example: on Ubuntu, when using the SDL2 library, it comes in two flavors:\nlibsdl2-dev\nand\nlibsdl2-2.0\n. The former is the development variant which you only need when building code that needs the headers and the libraries of the SDL2, while the latter is only useful with software needing the dynamic libraries at runtime. The development packages are usually bigger in size. You can astutely use multi-stage Docker builds to have first a build stage using the development packages, and then a final stage which only has the non-development packages. In CI, you almost never need both variants installed at the same time.\nOpt-out of \'recommended\' packages. Aptitude on Debian/Ubuntu is the culprit here:\napt-get install foo\nwill install much more than\nfoo\n. It will also install recommended packages that most of the time are completely unrelated. Always use\napt-get install --no-install-recommends foo\n.\nDon\'t create unnecessary files: you use use heredoc and shell pipelines to avoid creating intermediary files.\nBe lazy: Don\'t do things you don\'t need to do\nSome features you are not using are enabled by default. Be explicit instead of relying on obscure, ever changing defaults. Example:\nCGO_ENABLED=0 go build ...\nbecause it is (at the time of writing) enabled by default. The Gradle build system also has the annoying habit to run stuff behind your back. Use\ngradle foo -x baz\nto run\nfoo\nand not\nbaz\n.\nDon\'t run tests from your dependencies. This can happen if you are using git submodules or vendoring dependencies in some way. You generally always want to build them, but not run their tests. Again,\ngradle\nis the culprit here. If you are storing your git submodules in a\nsubmodules/\ndirectory for example, you can run only your project tests with:\ngradle test -x submodules:test\n.\nDisable the generation of reports files. They frequently come in the form of HTML or XML form, and once again,\ngradle\ngets out of his way to clutter your filesystem with those. Of debatable usefulness locally, they are downright wasteful in CI. And it takes some precious time, too! Disable it with:\ntasks.withType&lt;Test&gt; {\n     useJUnitPlatform()\n     reports.html.isEnabled = false\n     reports.junitXml.isEnabled = false\n }\nCheck alternative repositories for a dependency instead of building it from source. It can happen that a certain dependency you need is not in the main repositories of the package manager of your system. You can however inspect other repositories before falling back to building it yourself. On Alpine, you can simply add the URL of the repository to\n/etc/apk/repositories\n. For example, in the main Alpine Docker image, the repository\nhttps://&lt;mirror-server&gt;/alpine/edge/testing\nis not enabled. More information\nhere\n. Other example: on OpenBSD or FreeBSD, you can opt-in to use the\ncurrent\nbranch to get the newest and latest changes, and along them the newest dependencies.\nDon\'t build the static and dynamic variants of the same library (in C or C++). You probably only want one, preferably the static one. Otherwise, you are doing twice the work!\nFetch statically built binaries instead of building them from source. Go, and sometimes Rust, are great for this. As long as the OS and the architecture are the same, of course. E.g.: you can simply fetch\nkubectl\nwhich is a Go static binary instead of installing lots of Kubernetes packages, if you simply need to talk to a Kubernetes cluster. Naturally, the same goes for single file, dependency-less script: shell, awk, python, lua, perl, and ruby, assuming the interpreter is the right one. But this case is rarer and you might as well vendor the script at this point.\nGroom your \'ignore\' files.\n.gitignore\nis the mainstream one, but were you aware Docker has the mechanism in the form of a\n.dockerignore\nfile? My advice: whitelist the files you need, e.g.:\n**/*\n!**/*.js\nThis can have a huge impact on performance since Docker will copy all the files inside the Docker context directory inside the container (or virtual machine on macOS) and it can be a lot. You don\'t want to copy build artifacts, images, and so on each time which your image does not need.\nUse an empty Docker context if possible: you sometimes want to build an image which does not need any local files. In that case you can completely bypass copying any files into the image with the command:\ndocker build . -f - &lt; Dockerfile\n.\nDon\'t update the package manager cache: you typically need to start your Dockerfile by updating the package manager cache, otherwise it will complain the dependencies you want to install are not found. E.g.:\nRUN apk update &amp;&amp; apk add curl\n. But did you know it is not always required? You can simply do:\nRUN apk --no-cache add curl\nwhen you know the package exists and you can bypass the cache.\nSilence the tools: most command line applications accept the\n-q\nflag which reduces their verbosity. Most of their output is likely to be useless, some CI systems will struggle storing big pipeline logs, and you might be bottlenecked on stdout! Also, it will simplify troubleshooting\nyour\nbuild if it is not swamped in thousands of unrelated logs.\nMiscellenaous tricks\nUse\nsed\nto quickly edit big files in place. E.g.: you want to insert a line at the top of a Javascript file to skip linter warnings. Instead of doing:\nprintf \'/* eslint-disable */\\n\\n\' | cat - foo.js &gt; foo_tmp &amp;&amp; mv foo_tmp foo.js\nwhich involves reading the whole file, copying it, and renaming it, we can do:\nsed -i \'1s#^#/* eslint-disable */ #\' foo.js\nwhich is simpler.\nFavor static linking and LTO. This will simplify much of your pipeline because you\'ll have to deal with fewer files, ideally one statically built executable.\nUse only one Gitlab CI job. That is because the startup time of a job is very high, in the order of minutes. You can achieve task parallelism with other means such as\nparallel\nor\nmake -j\n.\nParallelize all the things! Some tools do not run tasks in parallel by default, e.g.\nmake\nand\ngradle\n. Make sure you are always using a CI instance with multiple cores and are passing\n--parallel\nto Gradle and\n-j$(nproc)\nto make. In rare instances you might have to tweak the exact level of parallelism to your particular task for maximum performance. Also,\nparallel\nis great for parallelizing tasks.\nAvoid network accesses: you should minimize the amount of things you are downloading from external sources in your CI because it is both slow and a source of flakiness. Some tools will unfortunately always try to \'call home\' even if all of your dependencies are present. You should disable this behavior explicitly, e.g. with Gradle:\ngradle build --offline\n.\nIn some rare cases, you will be bottlenecked on a slow running script. Consider using a faster interpreter: for shell scripts, there is\nash\nand\ndash\nwhich are said to be much faster than\nbash\n. For\nawk\nthere is\ngawk\nand\nmawk\n. For Lua there is\nLuaJIT\n.\nAvoid building inside Docker if you can. Building locally, and then copying the artifacts into the image, is always faster. It only works under certain constraints, of course:\nsame OS and architecture, or\na portable artifact format such as\njar\n, and not using native dependencies, or\nyour toolchain supports cross-compilation\nA note on security\nAlways use https\nChecksum files you fetched from third-parties with\nshasum\n.\nFavor official package repositories, docker images, and third-parties over those of individuals.\nNever bypass certificate checks (such as\ncurl -k\n)\nI am a DevOps Engineer, what can I do?\nMost of the above rules can be automated with a script, assuming the definition of a CI pipeline is in a text format (e.g. Gitlab CI). I would suggest starting here, and teaching developers about these simple tips than really make a difference.\nI would also suggest considering adding strict firewall rules inside CI pipelines, and making sure the setup/teardown of CI runners is very fast. Additionally, I would do everything to avoid a situation where no CI runner is available, preventing developers from working and deploying.\nFinally, I would recommend leading by example with the pipelines for the tools made by DevOps Engineers in your organization.\nClosing words\nI wish you well on your journey towards a fast, reliable and simple CI pipeline.\nI noticed in my numerous projects with different tech stacks that some are friendlier than others towards CI pipelines than others (I am looking at you, Gradle!). If you have the luxury of choosing your technical stack, do consider how it will play out with your pipeline. I believe this is a much more important factor than discussing whether $LANG has semicolons or not because I am convinced it can completely decide the outcome of your project.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2959153544-reduce-the-size-of-everything",
"#1630662642-be-lazy-don-t-do-things-you-don-t-need-to-do",
"#618219166-miscellenaous-tricks",
"#3119426742-a-note-on-security",
"#2259479887-i-am-a-devops-engineer-what-can-i-do",
"#3019505966-closing-words",
],
title_text_offsets:[
1435,5499,9621,11710,11954,12650,],
},
{
name:"x11_x64.html",
text:"Learn x86-64 assembly by writing a GUI from scratch\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-05-31\nLearn x86-64 assembly by writing a GUI from scratch\nGUI\nx86_64\nX11\nOptimization\nTable of contents\nWhat do we need?\nX11 basics\nMain in x64 assembly\nA stack primer\nA small stack example\nOpening a socket\nConnecting to the server\nSending data over the socket\nGenerating ids\nOpening a font\nCreating a graphical context\nCreating the window\nMapping the window\nPolling for server messages\nDrawing text\nThe end\nAddendum: the full code\nDiscussions:\nHacker News\n,\nr/programming\n,\nLobsters\n.\nMost people think assembly is only to be used to write toy programs for learning purposes, or to write a highly optimized version of a specific function inside a codebase written in a high-level language.\nWell, what if we wrote a whole program in assembly that opens a GUI window? It will be the hello world of the GUI world, but that still counts. Here is what we are working towards:\nI wanted to expand my knowledge of assembly and by doing something fun and motivating. It all originated from the observation that so many program binaries today are very big, often over 30 Mib (!), and I asked myself: How small a binary can be for a (very simplistic) GUI? Well, it turns out, very little. Spoiler alert: around 1 KiB!\nI am by no means an expert in assembly or in X11. I just hope to provide an entertaining, approachable article, something a beginner can understand. Something I wished I had found when I was learning those topics. If you spot an error, please open a\nGithub issue\n!\nNote: Authentication is optional in the X11 protocol, but some X11 servers e.g. XWayland require it. Authentication is skipped here and is handled in a separate\narticle\n.\nWhat do we need?\nI will be using the\nnasm\nassembler which is simple, cross-platform, fast, and has quite a readable syntax.\nFor the GUI, I will be using X11 since I am based on Linux and it has some interesting properties that make it easy to do without external libraries. If you are running Wayland, it should work with XWayland out of the box (\nEDIT: After testing it, I can confirm it does work\n), and perhaps also on macOS with XQuartz, but I have not tested those (for macOS, remember to tell\nnasm\nto use the\nmacho64\nformat, since macOS does not use the ELF format! Also, the stock linker on macOS does not support\n-static\n.).\nNote that the only difference between *nix operating systems in the context of this program is the system call values. Since I am based on Linux I will be using the Linux system call values, but \'porting\' this program to, say, FreeBSD, would only require to change those values, possibly using the\nnasm\nmacros:\n%ifdef linux\n  %define SYSCALL_EXIT 60\n%elifdef freebsd\n  %define SYSCALL_EXIT 1\n%endif\n%define\nand its variants are part of the macro system in\nnasm\n, which is powerful but we will only use it here to define constants, just like in C:\n#define FOO 3\n.\nNo need for additional tooling to cross-compile, issues with dynamic libraries, libc differences, etc. Just compile on Linux by defining the right variable on the command line, send the binary to your friend on FreeBSD, and it just works(tm). That\'s refreshing.\nSome readers have rightfully pointed out that Linux is the only mainstream operating system that officially provides a stable userland ABI, other OSes often break their ABI from (major) version to version and recommend all programs to link to a library (e.g.\nlibSystem\nin the case of macOS). That layer guarantees API stability, and acts as a insulation layer from breaking changes in the ABI. In practice, for common system calls such as the ones we use here, they very rarely break, but doing more exotic things may break in the future. That actually happened to the Go project in the past on macOS! The solution if that happens is to simply recompile the program on the new version of the OS.\nSo let\'s dive in!\nX11 basics\nX11 is a server accessible over the network that handles windowing and rendering inside those windows. A client opens a socket, connects to the server, and sends commands in a specific format to open a window, draw shapes, text, etc. The server sends message about errors or events to the client.\nMost applications will want to use\nlibX11\nor\nlibxcb\nwhich offer a C API, but we want to do that ourselves.\nWhere the server lives is actually not relevant for a client, it might run on the same machine or in a data center far far away. Of course, in the context of a desktop computer in 2023, it will be running on the same machine, but that\'s a detail.\nThe\nofficial documentation\nis pretty good, so when in doubt we can refer to it.\nMain in x64 assembly\nLet\'s start slow with minimal program that simply exits with 0, and build from there.\nFirst, we tell nasm we are writing a 64 bit program and that we target x86_64. Then, we need a main function, which we call\n_start\nand needs to be visible since this is the entry point of our program (hence the\nglobal\nkeyword):\n; Comments start with a semicolon!\nBITS 64 ; 64 bits.\nCPU X64 ; Target the x86_64 family of CPUs.\n\nsection .text\nglobal _start\n_start:\n  xor rax, rax ; Set rax to 0. Not actually needed, it\'s just to avoid having an empty body.\nsection .text\nis telling\nnasm\nand the linker, that what follows is code that should be placed in the text section of the executable.\nWe will soon have a\nsection .data\nfor our global variables.\nNote that those section usually get mapped by the OS to different pages in memory with different permissions (visible with\nreadelf -l\n) so that the text section is not writable and the data section is not executable, but that varies from OS to OS.\nThe\n_start\nfunction has a body that does nothing for now, but not for long. The actual name of the main function is actually up to us, it\'s just that\nstart\nor\n_start\nis usual.\nWe build and run our little program like this:\n$ nasm -f elf64 -g main.nasm &amp;&amp; ld main.o -static -o main\nnasm\nactually only produces an object file, so to get an executable out of it, we need to invoke the linker\nld\n. The flag\n-g\nis telling\nnasm\nto produce debugging information which is immensely useful when writing raw assembly, since firing the debugger is often our only recourse in face of a bug.\nTo remove the debugging information, we can pass\n-s\nto the linker, for example when we are about to ship our program and want to save a few KiB.\nWe finally have an executable:\n$ file ./main\nmain: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped\nWe can see the different sections with\nreadelf -a ./main\n, and it tells us that the\n.text\nsection, which contains our code, is only 3 bytes long.\nNow, if we try to run our program, it will segfault. That\'s because we are expected by the operating system to exit (using the exit system call) ourselves (otherwise the CPU will keep executing whatever comes after our entry point until it hits an unmapped page, triggering a segfault). That\'s what libc does for us in C programs, so let\'s handle that:\n%define SYSCALL_EXIT 60\n\nglobal _start:\n_start:\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\nnasm\nuses the Intel syntax:\n&lt;instruction&gt; &lt;destination&gt;, &lt;source&gt;\n, so\nmov rdi, 0\nputs 0 into the register\nrdi\n. Other assemblers use the AT&amp;T syntax which swaps the source and destination. My advice: pick one syntax and one assembler and stick to it, both syntaxes are fine and most tools have some support for both.\nFollowing the System V ABI, which is required on Linux and other Unices for system calls, invoking a system call requires us to put the system call code in the register\nrax\n, the parameters to the syscall (up to 6) in the registers\nrdi\n,\nrsi\n,\nrdx\n,\nrcx\n,\nr8\n,\nr9\n, and additional parameters, if any, on the stack (which will not happen in this program so we can forget about it).\nWe then use the instruction\nsyscall\nand check\nrax\nfor the return value,\n0\nusually meaning: no error.\nNote that Linux (and perhaps other Unices?) has a \'fun\' difference, which is that the fourth parameter of a system call is actually passed using the register\nr10\n.\nAstute readers have pointed out that this is the case across all OSes and documented in the x86_64 architecture supplement of the System V ABI. The more you know! That\'s only for system calls, though, regular functions still use\nrcx\nfor the fourth parameter.\nNote that the System V ABI is required when making system calls and when interfacing with C but we are free to use whatever conventions we want in our own assembly code. For a long time, Go was using a different calling convention than the System V ABI, for example, when calling functions (passing arguments on the stack). Most tools (debuggers, profilers) expect the System V ABI though, so I recommend sticking to it.\nBack to our program: when we run it, we see...nothing. That\'s because everything went well, true to the UNIX philosophy!\nWe can check the exit code:\n$ ./main; echo $?\n0\nChanging\nmov rdi, 0\nto\nmov rdi, 8\nwill now result in:\n$ ./main; echo $?\n8\nAnother way to observe system calls made by a program is with\nstrace\n, which will also prove very useful when troubleshooting. On some BSD, its equivalent is\ntruss\nor\ndtruss\n.\n$ strace ./main\nexecve(&quot;./main&quot;, [&quot;./main&quot;], 0x7ffc60e6bf10 /* 60 vars */) = 0\nexit(8)                                 = ?\n+++ exited with 8 +++\nLet\'s change it back to 0 and continue.\nA stack primer\nBefore we can continue, we need to know the basics of how the stack works in assembly since we have no friendly compiler to do that for us.\nThe three most important things about the stack are:\nIt grows downwards: to reserve more space on the stack, we decrease the value of\nrsp\nA function must restore the stack pointer to its original value before the function returns, meaning, either remember the original value and set\nrsp\nto this, or, match every decrement by an increment of the same value.\nBefore a function call, the stack pointer needs to be 16 bytes aligned, according to the System V ABI. Also, at the very beginning of a function, the stack pointer value is:\n16*N + 8\n. That\'s because before the function call, its value was 16 byte aligned, i.e.\n16*N\n, and the\ncall\ninstruction pushes on the stack the current location (the register\nrip\n, which is 8 bytes long), to know where to jump when the called function returns.\nNot abiding by those rules will result in nasty crashes, so be warned. That\'s because the location of where to jump when the function returns will be likely overwritten and the program will jump to the wrong location. That, or the stack content will be overwritten and the program will operate on wrong values. Bad either way.\nA small stack example\nLet\'s write a function that prints\nhello\nto the standard out, using the stack, to learn the ropes. An easier way would be to store this static string in the\n.rodata\nsection, but that would not teach us anything about the stack.\nWe need to reserve (at least) 5 bytes on the stack, since that\'s the length in bytes of\nhello\n.\nThe stack looks like this:\n...\nrbp\no\nl\nl\ne\nh\nAnd\nrsp\npoints to the bottom of it.\nHere\'s how we access each element:\nMemory location (example)\nAssembly code\nStack element\n0x1016\n...\n0x1015\nrsp + 5\nrbp\n0x1014\nrsp + 4\no\n0x1013\nrsp + 3\nl\n0x1012\nrsp + 2\nl\n0x1011\nrsp + 1\ne\n0x1010\nrsp + 0\nh\nWe then pass the address on the stack of the beginning of the string to the\nwrite\nsyscall, as well as its length:\n%define SYSCALL_WRITE 1\n%define STDOUT 1\n\nprint_hello:\n  push rbp ; Save rbp on the stack to be able to restore it at the end of the function.\n  mov rbp, rsp ; Set rbp to rsp\n\n  sub rsp, 5 ; Reserve 5 bytes of space on the stack.\n  mov BYTE [rsp + 0], \'h\' ; Set each byte on the stack to a string character.\n  mov BYTE [rsp + 1], \'e\'\n  mov BYTE [rsp + 2], \'l\'\n  mov BYTE [rsp + 3], \'l\'\n  mov BYTE [rsp + 4], \'o\'\n\n  ; Make the write syscall\n  mov rax, SYSCALL_WRITE\n  mov rdi, STDOUT ; Write to stdout.\n  lea rsi, [rsp] ; Address on the stack of the string.\n  mov rdx, 5 ; Pass the length of the string which is 5.\n  syscall\n\n  add rsp, 5 ; Restore the stack to its original value.\n\n  pop rbp ; Restore rbp\n  ret\nlea destination, source\nloads the effective address of the source into the destination, which is how C pointers are implemented. To dereference a memory location we use square brackets. So, assuming we just have loaded an address into\nrdi\nwith\nlea\n, e.g.\nlea rdi, [hello_world]\n, and we want to store the value at the address into\nrax\n, we do:\nmov rax, [rdi]\n. We usually have to tell\nnasm\nhow many bytes to dereference with\nBYTE\n,\nWORD\n,\nDWORD\n,\nQWORD\nso:\nmov rax, DWORD [rdi]\n, because\nnasm\ndoes not keep track of the sizes of each variable. That\'s also what the C compiler does when we dereference a\nint8_t\n,\nint16_t\n,\nint32_t\n, and\nint64_t\npointer, respectively.\nThere is a lot to unpack here.\nFirst, what is\nrbp\n? That\'s a register like any other. But, you can choose to follow the convention of not using this register like the other registers, to store arbitrary values, and instead, use it to store a linked list of call frames. That\'s a lot of words.\nBasically, at the very beginning of a function, the value of\nrbp\nis stored on the stack (that\'s\npush rbp\n). Since\nrbp\nstores an address (the address of the frame that\'s called us), we are storing on the stack the address of the caller in a known location.\nImmediately after that, we set\nrbp\nto\nrsp\n, that is, to the stack pointer at the beginning of the function.\npush rbp\nand\nmov rbp, rsp\nare thus usually referred to as the function prolog.\nFor the rest of the function body, we treat\nrbp\nas a constant and only decrease\nrsp\nif we need to reserve space on the stack.\nSo if function A calls function B which in turn calls function C, and each function stores on the stack the address of the caller frame, we know where to find on the stack the address of each. Thus, we can print a stack trace in any location of our program simply by inspecting the stack. Pretty nifty. That\'s already very useful to profilers and other similar tools.\nWe must not forget of course, just before we exit the function, to restore\nrbp\nto its original value (which is still on the stack at that point): that\'s\npop rbp\n. This is also known as the function epilog. Another way to look at it is that we remove the last element of the linked list of call frames, since we are exiting the leaf function.\nDon\'t worry if you have not fully understood everything, just remember to always have the function epilogs and prologs and you\'ll be fine:\nmy_function:\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, N\n\n  [...]\n\n\n  add rsp, N\n  pop rbp\n  ret\nNote\n: There is an optimization method that uses\nrbp\nas a standard register (with a C compiler, that\'s the flag\n-fomit-frame-pointer\n), which means we lose the information about the call stack. My advice is: never do this, it is no worth it.\nWait, but didn\'t you say the stack needs to be 16 byte aligned (that is, a multiple of 16)? Last time I checked, 5 is not really a multiple of 16!\nGood catch! The only reason why this program works, is that\nprint_hello\nis a leaf function, meaning it does not call another function. Remember, the stack needs to be 16 bytes aligned when we do a\ncall\n!\nSo the correct way would be:\nprint_hello:\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 16\n  mov BYTE [rsp + 0], \'h\'\n  mov BYTE [rsp + 1], \'e\'\n  mov BYTE [rsp + 2], \'l\'\n  mov BYTE [rsp + 3], \'l\'\n  mov BYTE [rsp + 4], \'o\'\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, STDOUT\n  lea rsi, [rsp]\n  mov rdx, 5\n  syscall\n\n  call print_world\n\n  add rsp, 16\n\n  pop rbp\n  ret\nSince when we enter the function, the value of\nrsp\nis\n16*N+8\n, and pushing\nrbp\nincreases it by 8, the stack pointer is 16 bytes aligned at the point of\nsub rsp, 16\n. Decrementing it by 16 (or a multiple of 16) keeps it 16 bytes aligned.\nWe now can safely call another function from within\nprint_hello\n:\nprint_world:\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 16\n  mov BYTE [rsp + 0], \' \'\n  mov BYTE [rsp + 1], \'w\'\n  mov BYTE [rsp + 2], \'o\'\n  mov BYTE [rsp + 3], \'r\'\n  mov BYTE [rsp + 4], \'l\'\n  mov BYTE [rsp + 5], \'d\'\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, STDOUT\n  lea rsi, [rsp]\n  mov rdx, 6\n  syscall\n\n  add rsp, 16\n\n  pop rbp\n  ret\n\nprint_hello:\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 16\n  mov BYTE [rsp + 0], \'h\'\n  mov BYTE [rsp + 1], \'e\'\n  mov BYTE [rsp + 2], \'l\'\n  mov BYTE [rsp + 3], \'l\'\n  mov BYTE [rsp + 4], \'o\'\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, STDOUT\n  lea rsi, [rsp]\n  mov rdx, 5\n  syscall\n\n  call print_world\n\n  add rsp, 16\n\n  pop rbp\n  ret\nAnd we get\nhello world\nas an output.\nNow, try to do\nsub rsp, 5\nin\nprint_hello\n, and your program\nmay\ncrash. There is no guarantee, that\'s what makes it hard to track down.\nMy advice is:\nAlways use the standard function prologs and epilogs\nAlways increment/decrement\nrsp\nby (a multiple of) 16\nAddress items on the stack relative to\nrsp\n, i.e.\nmov BYTE [rsp + 4], \'o\'\nIf you have to decrement\nrsp\nby a value that\'s unknown at compile time (similar to how\nalloca()\nworks in C), you can\nand rsp, -16\nto 16 bytes align it.\nAnd you\'ll be safe.\nThe last point is interesting, see for yourself:\n(gdb) p -100 &amp; -16\n$1 = -112\n(gdb) p -112 &amp; -16\n$2 = -112\nWhich translates in assembly to:\nsub rsp, 100\nand rsp, -16\nFinally, following those conventions means that our assembly functions can be safely called from C or other languages following the\nSystem V ABI\n, without any modification, which is great.\nI have not talked about the red zone which is a 128 byte region at the bottom of the stack which our program is free to use as it pleases without having to change the stack pointer. In my opinion, it is not helpful and creates hard to track bugs, so I do not recommend to use it. To disable it entirely, run:\nnasm -f elf64 -g main.nasm &amp;&amp; cc main.o -static -o main -mno-red-zone -nostdlib\n.\nOpening a socket\nWe now are ready to open a socket with the\nsocket(2)\nsyscall, so we add a few constants, taken from the libc headers (\nnote that those values might actually be different on a different Unix, I have not checked. Again, a few\n%ifdef\ncan easily remedy this discrepancy\n):\n%define AF_UNIX 1\n%define SOCK_STREAM 1\n\n%define SYSCALL_SOCKET 41\nThe\nAF_UNIX\nconstant means we want a Unix domain socket, and\nSOCK_STREAM\nmeans\nstream-oriented\n. We use a domain socket since we now that our server is running on the same machine and it should be faster, but we could change it to\nAF_INET\nto connect to a remote IPv4 address for example.\nWe then fill the relevant registers with those values and invoke the system call:\nmov rax, SYSCALL_SOCKET\n  mov rdi, AF_UNIX ; Unix socket.\n  mov rsi, SOCK_STREAM ; Stream oriented.\n  mov rdx, 0 ; Automatic protocol.\n  syscall\nThe C equivalent would be:\nsocket(AF_UNIX, SOCK_STREAM, 0);\n. So you see that if we fill the registers in the same order as the C function parameters, we stay close to what C code would do.\nThe whole program now looks like this:\nBITS 64 ; 64 bits.\nCPU X64 ; Target the x86_64 family of CPUs.\n\nsection .text\n\n%define AF_UNIX 1\n%define SOCK_STREAM 1\n\n%define SYSCALL_SOCKET 41\n%define SYSCALL_EXIT 60\n\nglobal _start:\n_start:\n  ; open a unix socket.\n  mov rax, SYSCALL_SOCKET\n  mov rdi, AF_UNIX ; Unix socket.\n  mov rsi, SOCK_STREAM ; Stream oriented.\n  mov rdx, 0 ; automatic protocol.\n  syscall\n\n\n  ; The end.\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\nBuilding and running it under\nstrace\nshows that it works and we get a socket with the file descriptor\n3\n(in this case, it might be different for you if you are following at home):\n$ nasm -f elf64 -g main.nasm &amp;&amp; ld main.o -static -o main \n$ strace ./main\nexecve(&quot;./main&quot;, [&quot;./main&quot;], 0x7ffe54dfe550 /* 60 vars */) = 0\nsocket(AF_UNIX, SOCK_STREAM, 0)         = 3\nexit(0)                                 = ?\n+++ exited with 0 +++\nConnecting to the server\nNow that we have created a socket, we can connect to the server with the\nconnect(2)\nsystem call.\nIt\'s a good time to extract that logic in its own little function, just like in any other high-level language.\nx11_connect_to_server:\n  ; TODO\nIn assembly, a function is simply a label we can jump to. But for clarity, both for readers of the code and tools, we can add a hint that this is a real function we can call, like this:\ncall x11_connect_to_server\n. This will improve the call stack for example when using\nstrace -k\n. This hint has the form (in\nnasm\n):\nstatic &lt;name of the function&gt;:function\n.\nOf course, we also need to add our standard function prolog and epilog:\nx11_connect_to_server:\nstatic x11_connect_to_server:function\n  push rbp\n  mov rbp, rsp\n  \n  pop rbp\n  ret\nAn additional help when reading functions in assembly code is adding comments describing what parameters they accept and what is the return value, if any. Since there is no language level feature for this, we resort to comments:\n; Create a UNIX domain socket and connect to the X11 server.\n; @returns The socket file descriptor.\nx11_connect_to_server:\nstatic x11_connect_to_server:function\n  push rbp\n  mov rbp, rsp\n  \n  pop rbp\n  ret\nFirst, let\'s move the socket creation logic to our function and call it in the program:\n; Create a UNIX domain socket and connect to the X11 server.\n; @returns The socket file descriptor.\nx11_connect_to_server:\nstatic x11_connect_to_server:function\n  push rbp\n  mov rbp, rsp\n  \n  ; Open a Unix socket: socket(2).\n  mov rax, SYSCALL_SOCKET\n  mov rdi, AF_UNIX ; Unix socket.\n  mov rsi, SOCK_STREAM ; Stream oriented.\n  mov rdx, 0 ; Automatic protocol.\n  syscall\n\n  cmp rax, 0\n  jle die\n\n  mov rdi, rax ; Store socket fd in `rdi` for the remainder of the function.\n\n  pop rbp\n  ret\n\ndie:\n  mov rax, SYSCALL_EXIT\n  mov rdi, 1\n  syscall\n\n_start:\nglobal _start:function\n  call x11_connect_to_server\n  \n  ; The end.\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\nThe error checking is very simplistic: we only check that the return value of the system call (in\nrax\n) is what we expect, otherwise we exit the program with a non-zero code by jumping to the\ndie\nsection.\njle\nis a conditional jump, which inspects global flags, hopefully set just before with\ncmp\nor\ntest\n, and jumps to a label if the condition is true. Here, we compare the returned value with 0, and if it is lower or equal to 0, we jump to the error label. That\'s how we implement conditionals and loops.\nOk, we can finally connect to the server now. The\nconnect(2)\nsystem call takes the address of a\nsockaddr_un\nstructure as the second argument. This structure is too big to fit in a register.\nThis is the first syscall we encounter that needs to be passed a pointer, in other words, the address of a region in memory. That region can be on the stack or on the heap, or even be our own executable mapped in memory. That\'s assembly, we get to do whatever we want.\nSince we want to keep things simple and fast, we will store everything in this program on the stack. And since we have 8 MiB of it (according to\nlimit\n, on my machine, that is), it\'ll be plenty enough. Actually, the most space we will need on the stack in this program will be 32 KiB.\nThe size of the\nsockaddr_un\nstructure is 110 bytes, so we reserve 112 to align\nrsp\nto 16 bytes.\nNasm does have structs, but they are rather a way to define offsets with a name, than structures like in C with a specific syntax to address a specific field. For the sake of simplicity, I\'ll use the manual way, without\nnasm\nstructs.\nWe set the first 2 bytes of this structure to\nAF_UNIX\nsince this is a domain socket. Then comes the path of the Unix domain socket which X11 expects to be in a certain format. We want to display our window on the first monitor starting at 0, so the string is:\n/tmp/.X11-unix/X0\n.\nIn C, we would do:\nconst sockaddr_un addr = {.sun_family = AF_UNIX,\n                            .sun_path = &quot;/tmp/.X11-unix/X0&quot;};\n  const int res =\n      connect(x11_socket_fd, (const struct sockaddr *)&amp;addr, sizeof(addr));\nHow do we translate that to assembly, especially the string part?\nWe could set each byte to each character of the string in the structure, on the stack, manually, one by one. Another\nway\nto do it is to use the\nrep movsb\nidiom, which instructs the CPU to copy a character from a string A to another string B, N times. This is exactly what we need!\nThe way it works is:\nWe put the string in the\n.rodata\nsection (same as the data section but read-only)\nWe load its address in\nrsi\n(it\'s the source)\nWe load the address of the string in the structure on the stack in\nrdi\n(it\'s the destination)\nWe set\nrcx\nto the number of bytes to be copied\nWe use\ncld\nto clear the\nDF\nflag to ensure the copy is done forwards (since it can also be done backwards)\nWe call\nrep movsb\nand voila\nIt\'s basically\nmemcpy\nfrom C.\nThis is a interesting case: we can see that some instructions expect some of their operands to be in certain registers and there is no way around it.  So, we have to plan ahead and expect those registers to be overwritten. If we need to keep their original values around, we have to store those values elsewhere, for example on the stack (that\'s called spilling) or in other registers. This is a broader topic of register allocation which is NP-hard! In small functions, it\'s manageable though.\nFirst, the\n.rodata\nsection:\nsection .rodata\n\nsun_path: db &quot;/tmp/.X11-unix/X0&quot;, 0\nstatic sun_path:data\nThen we copy the string:\nmov WORD [rsp], AF_UNIX ; Set sockaddr_un.sun_family to AF_UNIX\n  ; Fill sockaddr_un.sun_path with: &quot;/tmp/.X11-unix/X0&quot;.\n  lea rsi, sun_path\n  mov r12, rdi ; Save the socket file descriptor in `rdi` in `r12`.\n  lea rdi, [rsp + 2]\n  cld ; Move forward\n  mov ecx, 19 ; Length is 19 with the null terminator.\n  rep movsb ; Copy.\necx\nis the 32 bit form of the register\nrcx\n, meaning we only set here the lower 32 bits of the 64 bit register.\nThis handy table\nlists all of the forms for all of the registers. But be cautious of the pitfall case of only setting a value in part of a register, and then using the whole register later. The rest of the bits that have not been set will contain some past value, which is hard to troubleshoot. The solution is to use\nmovzx\nto zero extend, meaning setting the rest of the bits to 0. A good way to visualize this is to use\ninfo registers\nwithin gdb, and that will display for each register the value for each of its forms, e.g. for\nrcx\n, it will display the value for\nrcx\n,\necx\n,\ncx\n,\nch\n,\ncl\n.\nThen, we do the syscall, check the returned value, exit the program if the value is not 0, and finally return the socket file descriptor, which will be used every time in the rest of the program when talking to the X11 server.\nEverything together, it looks like:\n; Create a UNIX domain socket and connect to the X11 server.\n; @returns The socket file descriptor.\nx11_connect_to_server:\nstatic x11_connect_to_server:function\n  push rbp\n  mov rbp, rsp \n\n  ; Open a Unix socket: socket(2).\n  mov rax, SYSCALL_SOCKET\n  mov rdi, AF_UNIX ; Unix socket.\n  mov rsi, SOCK_STREAM ; Stream oriented.\n  mov rdx, 0 ; Automatic protocol.\n  syscall\n\n  cmp rax, 0\n  jle die\n\n  mov rdi, rax ; Store socket fd in `rdi` for the remainder of the function.\n\n  sub rsp, 112 ; Store struct sockaddr_un on the stack.\n\n  mov WORD [rsp], AF_UNIX ; Set sockaddr_un.sun_family to AF_UNIX\n  ; Fill sockaddr_un.sun_path with: &quot;/tmp/.X11-unix/X0&quot;.\n  lea rsi, sun_path\n  mov r12, rdi ; Save the socket file descriptor in `rdi` in `r12`.\n  lea rdi, [rsp + 2]\n  cld ; Move forward\n  mov ecx, 19 ; Length is 19 with the null terminator.\n  rep movsb ; Copy.\n\n  ; Connect to the server: connect(2).\n  mov rax, SYSCALL_CONNECT\n  mov rdi, r12\n  lea rsi, [rsp]\n  %define SIZEOF_SOCKADDR_UN 2+108\n  mov rdx, SIZEOF_SOCKADDR_UN\n  syscall\n\n  cmp rax, 0\n  jne die\n\n  mov rax, rdi ; Return the socket fd.\n\n  add rsp, 112\n  pop rbp\n  ret\nWe are ready to talk to the X11 server!\nSending data over the socket\nThere is the\nsend(2)\nsyscall to do this, but we can keep it simple and use the generic\nwrite(2)\nsyscall instead. Either way works.\n%define SYSCALL_WRITE 1\nThe C structure for the handshake in the case of success looks like this:\ntypedef struct {\n  u8 order;\n  u8 pad1;\n  u16 major, minor;\n  u16 auth_proto_len, auth_data_len;\n  u16 pad2;\n  // Optionally, authorization information follow, if `auth_proto_len` and `auth_data_len` are  not 0.\n} x11_connection_req_t;\npad*\nfields can be ignored since they are padding and their value is not read by the server.\nFor our handshake, we need to set the\norder\nto be\nl\n, that is, little-endian, since X11 can be told to interpret message as big or little endian. Since x64 is little-endian, we do not want to have a endianness translation layer and so we stick to little-endian.\nWe also need to set the\nmajor\nfield, which is the version, to\n11\n. I\'ll leave it to the reader to guess why.\nIn C, we would do:\nx11_connection_req_t req = {.order = \'l\', .major = 11};\nThis structure is only 12 bytes long, since we do not use authorization (we leave all subsequent fields after the\nminor_version\nas 0).\nBut since we will have to read the response from the server which is quite big (around 14 KiB during my testing), we will right away reserve a lot of space on the stack, 32 KiB, to be safe:\nsub rsp, 1&lt;&lt;15\n  mov BYTE [rsp + 0], \'l\' ; Set order to \'l\'.\n  mov WORD [rsp + 2], 11 ; Set major version to 11.\nThen we send it to the server:\n; Send the handshake to the server: write(2).\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 12\n  syscall\n\n  cmp rax, 12 ; Check that all bytes were written.\n  jnz die\nAfter that, we read the server response, which should be at first 8 bytes:\n; Read the server response: read(2).\n  ; Use the stack for the read buffer.\n  ; The X11 server first replies with 8 bytes. Once these are read, it replies with a much bigger message.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 8\n  syscall\n\n  cmp rax, 8 ; Check that the server replied with 8 bytes.\n  jnz die\n\n  cmp BYTE [rsp], 1 ; Check that the server sent \'success\' (first byte is 1).\n  jnz die\nThe first byte in the server response is\n0\nfor failure and\n1\nfor success (and\n2\nfor authentication but we will not need it here).\nThe server sends a big message with a lot of general information, which we will need for later, so we store certain fields in global variables located in the data section.\nFirst we add those variables, each 4 bytes big:\nsection .data\n\nid: dd 0\nstatic id:data\n\nid_base: dd 0\nstatic id_base:data\n\nid_mask: dd 0\nstatic id_mask:data\n\nroot_visual_id: dd 0\nstatic root_visual_id:data\nThen we read the server response, and skip over the parts we are not interested in. This boils down to incrementing a pointer by a dynamic value, a few times. Note that since we do not do any checks here, that would be a great attack vector to trigger a stack overflow or such in our program.\n; Read the rest of the server response: read(2).\n  ; Use the stack for the read buffer.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 1&lt;&lt;15\n  syscall\n\n  cmp rax, 0 ; Check that the server replied with something.\n  jle die\n\n  ; Set id_base globally.\n  mov edx, DWORD [rsp + 4]\n  mov DWORD [id_base], edx\n\n  ; Set id_mask globally.\n  mov edx, DWORD [rsp + 8]\n  mov DWORD [id_mask], edx\n\n  ; Read the information we need, skip over the rest.\n  lea rdi, [rsp] ; Pointer that will skip over some data.\n  \n  mov cx, WORD [rsp + 16] ; Vendor length (v).\n  movzx rcx, cx\n\n  mov al, BYTE [rsp + 21]; Number of formats (n).\n  movzx rax, al ; Fill the rest of the register with zeroes to avoid garbage values.\n  imul rax, 8 ; sizeof(format) == 8\n\n  add rdi, 32 ; Skip the connection setup\n  add rdi, rcx ; Skip over the vendor information (v).\n\n  ; Skip over padding.\n  add rdi, 3\n  and rdi, -4\n\n  add rdi, rax ; Skip over the format information (n*8).\n\n  mov eax, DWORD [rdi] ; Store (and return) the window root id.\n\n  ; Set the root_visual_id globally.\n  mov edx, DWORD [rdi + 32]\n  mov DWORD [root_visual_id], edx\nA small aside about padding,\nthanks to a perspicacious reader\n:\nHow we skip padding is the only bit of smartness we allow ourselves: some fields in the X11 protocol have a variable length. But the X11 protocol counts everything in units of \'4 bytes\'.\nMeaning, if a field is only 5 bytes long, per the protocol, there will be 3 bytes of padding (which should be skipped over by the application), so that the field occupies 2 units of 4 bytes (it is 4 bytes-aligned).\nHow do we do that then? The specification uses some division and modulo operations, but those are annoying to do in assembly. We can do better.\nlibX11\nuses this macro:\n#define ROUNDUP(nbytes, pad) (((nbytes) + ((pad)-1)) &amp; ~(long)((pad)-1))\nAnd it should be used so:\nassert(ROUNDUP(0, 4) == 0);\nassert(ROUNDUP(1, 4) == 4);\nassert(ROUNDUP(2, 4) == 4);\nassert(ROUNDUP(3, 4) == 4);\nassert(ROUNDUP(4, 4) == 4);\nassert(ROUNDUP(5, 4) == 8);\n// etc\nThis works, but is kind of complex. If we look at this output when compiling this code, we see that\ngcc\nsmartly optimizes this macro down to:\nadd     eax, 3\n  and     eax, -4\nSo we use this form.\nAll together:\n; Send the handshake to the X11 server and read the returned system information.\n; @param rdi The socket file descriptor\n; @returns The window root id (uint32_t) in rax.\nx11_send_handshake:\nstatic x11_send_handshake:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 1&lt;&lt;15\n  mov BYTE [rsp + 0], \'l\' ; Set order to \'l\'.\n  mov WORD [rsp + 2], 11 ; Set major version to 11.\n\n  ; Send the handshake to the server: write(2).\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 12\n  syscall\n\n  cmp rax, 12 ; Check that all bytes were written.\n  jnz die\n\n  ; Read the server response: read(2).\n  ; Use the stack for the read buffer.\n  ; The X11 server first replies with 8 bytes. Once these are read, it replies with a much bigger message.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 8\n  syscall\n\n  cmp rax, 8 ; Check that the server replied with 8 bytes.\n  jnz die\n\n  cmp BYTE [rsp], 1 ; Check that the server sent \'success\' (first byte is 1).\n  jnz die\n\n  ; Read the rest of the server response: read(2).\n  ; Use the stack for the read buffer.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 1&lt;&lt;15\n  syscall\n\n  cmp rax, 0 ; Check that the server replied with something.\n  jle die\n\n  ; Set id_base globally.\n  mov edx, DWORD [rsp + 4]\n  mov DWORD [id_base], edx\n\n  ; Set id_mask globally.\n  mov edx, DWORD [rsp + 8]\n  mov DWORD [id_mask], edx\n\n  ; Read the information we need, skip over the rest.\n  lea rdi, [rsp] ; Pointer that will skip over some data.\n  \n  mov cx, WORD [rsp + 16] ; Vendor length (v).\n  movzx rcx, cx\n\n  mov al, BYTE [rsp + 21]; Number of formats (n).\n  movzx rax, al ; Fill the rest of the register with zeroes to avoid garbage values.\n  imul rax, 8 ; sizeof(format) == 8\n\n  add rdi, 32 ; Skip the connection setup\n  add rdi, rcx ; Skip over the vendor information (v).\n\n  ; Skip over padding.\n  add rdi, 3\n  and rdi, -4\n\n  add rdi, rax ; Skip over the format information (n*8).\n\n  mov eax, DWORD [rdi] ; Store (and return) the window root id.\n\n  ; Set the root_visual_id globally.\n  mov edx, DWORD [rdi + 32]\n  mov DWORD [root_visual_id], edx\n\n  add rsp, 1&lt;&lt;15\n  pop rbp\n  ret\nFrom this point on, I will assume you are familiar with the basics of assembly and X11 and will not go as much into details.\nGenerating ids\nWhen creating resources on the server-side, we usually first generate an id on the client side, and send that id to the server when creating the resource.\nWe store the current id in a global variable and increment it each time a new id is generated.\nThis is how we do it:\n; Increment the global id.\n; @return The new id.\nx11_next_id:\nstatic x11_next_id:function\n  push rbp\n  mov rbp, rsp\n\n  mov eax, DWORD [id] ; Load global id.\n\n  mov edi, DWORD [id_base] ; Load global id_base.\n  mov edx, DWORD [id_mask] ; Load global id_mask.\n\n  ; Return: id_mask &amp; (id) | id_base\n  and eax, edx\n  or eax, edi\n\n  add DWORD [id], 1 ; Increment id.\n\n  pop rbp\n  ret\nOpening a font\nTo open a font, which is a prerequisite to draw text, we send a message to the server specifying (part of) the name of the font we want, and the server will select a matching font.\nTo play with another font, you can use\nxfontsel\nwhich displays all the font names that the X11 server knows about.\nFirst, we generate an id for the font locally, and then we send it alongside the font name.\n; Open the font on the server side.\n; @param rdi The socket file descriptor.\n; @param esi The font id.\nx11_open_font:\nstatic x11_open_font:function\n  push rbp\n  mov rbp, rsp\n\n  %define OPEN_FONT_NAME_BYTE_COUNT 5\n  %define OPEN_FONT_PADDING ((4 - (OPEN_FONT_NAME_BYTE_COUNT % 4)) % 4)\n  %define OPEN_FONT_PACKET_U32_COUNT (3 + (OPEN_FONT_NAME_BYTE_COUNT + OPEN_FONT_PADDING) / 4)\n  %define X11_OP_REQ_OPEN_FONT 0x2d\n\n  sub rsp, 6*8\n  mov DWORD [rsp + 0*4], X11_OP_REQ_OPEN_FONT | (OPEN_FONT_NAME_BYTE_COUNT &lt;&lt; 16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], OPEN_FONT_NAME_BYTE_COUNT\n  mov BYTE [rsp + 3*4 + 0], \'f\'\n  mov BYTE [rsp + 3*4 + 1], \'i\'\n  mov BYTE [rsp + 3*4 + 2], \'x\'\n  mov BYTE [rsp + 3*4 + 3], \'e\'\n  mov BYTE [rsp + 3*4 + 4], \'d\'\n\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, OPEN_FONT_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, OPEN_FONT_PACKET_U32_COUNT*4\n  jnz die\n\n  add rsp, 6*8\n\n  pop rbp\n  ret\nCreating a graphical context\nSince an application in X11 can have multiple windows, we first need to create a graphical context containing the general information. When we create a window, we refer to this graphical context by id.\nAgain, we need to generate an id for the graphical context to be.\nX11 stores a hierarchy of windows, so when creating the graphical context, we also need to give it the root window id (i.e. the parent id).\n; Create a X11 graphical context.\n; @param rdi The socket file descriptor.\n; @param esi The graphical context id.\n; @param edx The window root id.\n; @param ecx The font id.\nx11_create_gc:\nstatic x11_create_gc:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 8*8\n\n%define X11_OP_REQ_CREATE_GC 0x37\n%define X11_FLAG_GC_BG 0x00000004\n%define X11_FLAG_GC_FG 0x00000008\n%define X11_FLAG_GC_FONT 0x00004000\n%define X11_FLAG_GC_EXPOSE 0x00010000\n\n%define CREATE_GC_FLAGS X11_FLAG_GC_BG | X11_FLAG_GC_FG | X11_FLAG_GC_FONT\n%define CREATE_GC_PACKET_FLAG_COUNT 3\n%define CREATE_GC_PACKET_U32_COUNT (4 + CREATE_GC_PACKET_FLAG_COUNT)\n%define MY_COLOR_RGB 0x0000ffff\n\n  mov DWORD [rsp + 0*4], X11_OP_REQ_CREATE_GC | (CREATE_GC_PACKET_U32_COUNT&lt;&lt;16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], edx\n  mov DWORD [rsp + 3*4], CREATE_GC_FLAGS\n  mov DWORD [rsp + 4*4], MY_COLOR_RGB\n  mov DWORD [rsp + 5*4], 0\n  mov DWORD [rsp + 6*4], ecx\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, CREATE_GC_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, CREATE_GC_PACKET_U32_COUNT*4\n  jnz die\n  \n  add rsp, 8*8\n\n  pop rbp\n  ret\nCreating the window\nWe can now create the window, which refers to the freshly created graphical context.\nWe also provide the desired x and y coordinates of the window, as well as the desired dimensions (width and height).\nNote that those are simply hints and the resulting window may well have different coordinates and dimensions, for example when using a tiling window manager, or when resizing the window.\n; Create the X11 window.\n; @param rdi The socket file descriptor.\n; @param esi The new window id.\n; @param edx The window root id.\n; @param ecx The root visual id.\n; @param r8d Packed x and y.\n; @param r9d Packed w and h.\nx11_create_window:\nstatic x11_create_window:function\n  push rbp\n  mov rbp, rsp\n\n  %define X11_OP_REQ_CREATE_WINDOW 0x01\n  %define X11_FLAG_WIN_BG_COLOR 0x00000002\n  %define X11_EVENT_FLAG_KEY_RELEASE 0x0002\n  %define X11_EVENT_FLAG_EXPOSURE 0x8000\n  %define X11_FLAG_WIN_EVENT 0x00000800\n  \n  %define CREATE_WINDOW_FLAG_COUNT 2\n  %define CREATE_WINDOW_PACKET_U32_COUNT (8 + CREATE_WINDOW_FLAG_COUNT)\n  %define CREATE_WINDOW_BORDER 1\n  %define CREATE_WINDOW_GROUP 1\n\n  sub rsp, 12*8\n\n  mov DWORD [rsp + 0*4], X11_OP_REQ_CREATE_WINDOW | (CREATE_WINDOW_PACKET_U32_COUNT &lt;&lt; 16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], edx\n  mov DWORD [rsp + 3*4], r8d\n  mov DWORD [rsp + 4*4], r9d\n  mov DWORD [rsp + 5*4], CREATE_WINDOW_GROUP | (CREATE_WINDOW_BORDER &lt;&lt; 16)\n  mov DWORD [rsp + 6*4], ecx\n  mov DWORD [rsp + 7*4], X11_FLAG_WIN_BG_COLOR | X11_FLAG_WIN_EVENT\n  mov DWORD [rsp + 8*4], 0\n  mov DWORD [rsp + 9*4], X11_EVENT_FLAG_KEY_RELEASE | X11_EVENT_FLAG_EXPOSURE\n\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, CREATE_WINDOW_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, CREATE_WINDOW_PACKET_U32_COUNT*4\n  jnz die\n\n  add rsp, 12*8\n\n  pop rbp\n  ret\nMapping the window\nIf you are following along at home, and just ran the program, you have realized nothing is displayed.\nThat is because X11 does not show the window until we have mapped it. This is a simple message to send:\n; Map a X11 window.\n; @param rdi The socket file descriptor.\n; @param esi The window id.\nx11_map_window:\nstatic x11_map_window:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 16\n\n  %define X11_OP_REQ_MAP_WINDOW 0x08\n  mov DWORD [rsp + 0*4], X11_OP_REQ_MAP_WINDOW | (2&lt;&lt;16)\n  mov DWORD [rsp + 1*4], esi\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 2*4\n  syscall\n\n  cmp rax, 2*4\n  jnz die\n\n  add rsp, 16\n\n  pop rbp\n  ret\nWe now have a black window:\nYay!\nPolling for server messages\nWe would like to draw text in the window now, but we have to wait for the\nExpose\nevent to be sent to us, which means that the window is visible, to be able to start drawing on it.\nWe want to listen for all server messages actually, be it errors or events, for example when the user presses a key on the keyboard.\nIf we do a simple blocking\nread(2)\n, but the server sends nothing, the program will appear not responding. Not good.\nThe solution is to use the\npoll(2)\nsystem call to be awoken by the operating system whenever there is data to be read on the socket, a la NodeJS or Nginx.\nAn shrewd reader has pointed out that we could simply\nread\nfrom the socket in a loop, since we only have one, possibly with a timeout. Linux, and perhaps others, support setting a read timeout on a socket with\nsetsockopt(2)\n. But I will keep this version in this article since this is the original one. Feel free to experiment with the alternative at home!\nFirst, we need to mark the socket as \'non-blocking\' since it is by default in blocking mode:\n; Set a file descriptor in non-blocking mode.\n; @param rdi The file descriptor.\nset_fd_non_blocking:\nstatic set_fd_non_blocking:function\n  push rbp\n  mov rbp, rsp\n\n  mov rax, SYSCALL_FCNTL\n  mov rdi, rdi \n  mov rsi, F_GETFL\n  mov rdx, 0\n  syscall\n\n  cmp rax, 0\n  jl die\n\n  ; `or` the current file status flag with O_NONBLOCK.\n  mov rdx, rax\n  or rdx, O_NONBLOCK\n\n  mov rax, SYSCALL_FCNTL\n  mov rdi, rdi \n  mov rsi, F_SETFL\n  mov rdx, rdx\n  syscall\n\n  cmp rax, 0\n  jl die\n\n  pop rbp\n  ret\nThen, we write a small function to read data on the socket. For simplicity, we only read 32 bytes of data, because most messages from X11 are of this size. We also return the first byte which contains the event type.\n; Read the X11 server reply.\n; @return The message code in al.\nx11_read_reply:\nstatic x11_read_reply:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n  \n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 32\n  syscall\n\n  cmp rax, 1\n  jle die\n\n  mov al, BYTE [rsp]\n\n  add rsp, 32\n\n  pop rbp\n  ret\nWe now can poll. If an error occurs or the other side has closed their end of the socket, we exit the program.\n; Poll indefinitely messages from the X11 server with poll(2).\n; @param rdi The socket file descriptor.\n; @param esi The window id.\n; @param edx The gc id.\npoll_messages:\nstatic poll_messages:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n\n  %define POLLIN 0x001\n  %define POLLPRI 0x002\n  %define POLLOUT 0x004\n  %define POLLERR  0x008\n  %define POLLHUP  0x010\n  %define POLLNVAL 0x020\n\n  mov DWORD [rsp + 0*4], edi\n  mov DWORD [rsp + 1*4], POLLIN\n\n  mov DWORD [rsp + 16], esi ; window id\n  mov DWORD [rsp + 20], edx ; gc id\n\n  .loop:\n    mov rax, SYSCALL_POLL\n    lea rdi, [rsp]\n    mov rsi, 1\n    mov rdx, -1\n    syscall\n\n    cmp rax, 0\n    jle die\n\n    cmp DWORD [rsp + 2*4], POLLERR  \n    je die\n\n    cmp DWORD [rsp + 2*4], POLLHUP  \n    je die\n\n    mov rdi, [rsp + 0*4]\n    call x11_read_reply\n\n    jmp .loop\n\n  add rsp, 32\n  pop rbp\n  ret\nDrawing text\nAt last, we can draw text. The small difficulty here is that the text is of unknown length in the general case, so we have to compute the size of the X11 message, including the padding at the end. So far, we only had messages of fixed size.\nThe official documentation has formulas to compute those values.\n; Draw text in a X11 window with server-side text rendering.\n; @param rdi The socket file descriptor.\n; @param rsi The text string.\n; @param edx The text string length in bytes.\n; @param ecx The window id.\n; @param r8d The gc id.\n; @param r9d Packed x and y.\nx11_draw_text:\nstatic x11_draw_text:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 1024\n\n  mov DWORD [rsp + 1*4], ecx ; Store the window id directly in the packet data on the stack.\n  mov DWORD [rsp + 2*4], r8d ; Store the gc id directly in the packet data on the stack.\n  mov DWORD [rsp + 3*4], r9d ; Store x, y directly in the packet data on the stack.\n\n  mov r8d, edx ; Store the string length in r8 since edx will be overwritten next.\n  mov QWORD [rsp + 1024 - 8], rdi ; Store the socket file descriptor on the stack to free the register.\n\n  ; Compute padding and packet u32 count with division and modulo 4.\n  mov eax, edx ; Put dividend in eax.\n  mov ecx, 4 ; Put divisor in ecx.\n  cdq ; Sign extend.\n  idiv ecx ; Compute eax / ecx, and put the remainder (i.e. modulo) in edx.\n  ; LLVM optimizer magic: `(4-x)%4 == -x &amp; 3`, for some reason.\n  neg edx\n  and edx, 3\n  mov r9d, edx ; Store padding in r9.\n\n  mov eax, r8d \n  add eax, r9d\n  shr eax, 2 ; Compute: eax /= 4\n  add eax, 4 ; eax now contains the packet u32 count.\n\n\n  %define X11_OP_REQ_IMAGE_TEXT8 0x4c\n  mov DWORD [rsp + 0*4], r8d\n  shl DWORD [rsp + 0*4], 8\n  or DWORD [rsp + 0*4], X11_OP_REQ_IMAGE_TEXT8\n  mov ecx, eax\n  shl ecx, 16\n  or [rsp + 0*4], ecx\n\n  ; Copy the text string into the packet data on the stack.\n  mov rsi, rsi ; Source string in rsi.\n  lea rdi, [rsp + 4*4] ; Destination\n  cld ; Move forward\n  mov ecx, r8d ; String length.\n  rep movsb ; Copy.\n\n  mov rdx, rax ; packet u32 count\n  imul rdx, 4\n  mov rax, SYSCALL_WRITE\n  mov rdi, QWORD [rsp + 1024 - 8] ; fd\n  lea rsi, [rsp]\n  syscall\n\n  cmp rax, rdx\n  jnz die\n\n  add rsp, 1024\n\n  pop rbp\n  ret\nWe then call this function inside the polling loop, and we store the \'exposed\' state in a boolean on the stack to know whether we should render the text or not:\n%define X11_EVENT_EXPOSURE 0xc\n    cmp eax, X11_EVENT_EXPOSURE\n    jnz .received_other_event\n\n    .received_exposed_event:\n    mov BYTE [rsp + 24], 1 ; Mark as exposed.\n\n    .received_other_event:\n\n    cmp BYTE [rsp + 24], 1 ; exposed?\n    jnz .loop\n\n    .draw_text:\n      mov rdi, [rsp + 0*4] ; socket fd\n      lea rsi, [hello_world] ; string\n      mov edx, 13 ; length\n      mov ecx, [rsp + 16] ; window id\n      mov r8d, [rsp + 20] ; gc id\n      mov r9d, 100 ; x\n      shl r9d, 16\n      or r9d, 100 ; y\n      call x11_draw_text\nFinally, we see our\nHello, world!\ntext displayed inside the window:\nThe end\nWow, that was a lot. But we did it! We wrote a (albeit simplistic) GUI program in pure assembly, no dependencies, and that\'s just 600 lines of code in the end.\nHow did we fare on the executable size part?\nWith debug information: 10744 bytes (10 KiB)\nWithout debug information (stripped): 8592 bytes (8 KiB)\nStripped and\nOMAGIC\n(\n--omagic\nlinker flag, from the man page:\nSet the text and data sections to be readable and writable.  Also, do not page-align the data segment\n): 1776 bytes (1 KiB)\nNot too shabby, a GUI program in 1 KiB.\nWhere to go from there?\nWe could move text rendering client-side. Doing it server-side has lots of limitations.\nWe could add shape rendering, such as quads and circles\nWe could listen to keyboard and mouse events (the polling loop is easy to extend to do that)\nI hope that you had as much fun as I did!\nAddendum: the full code\nThe full code\n; Build with: nasm -f elf64 -g main.nasm &amp;&amp; ld main.o -static -o main \n\nBITS 64 ; 64 bits.\nCPU X64 ; Target the x86_64 family of CPUs.\n\nsection .rodata\n\nsun_path: db &quot;/tmp/.X11-unix/X0&quot;, 0\nstatic sun_path:data\n\nhello_world: db &quot;Hello, world!&quot;\nstatic hello_world:data\n\nsection .data\n\nid: dd 0\nstatic id:data\n\nid_base: dd 0\nstatic id_base:data\n\nid_mask: dd 0\nstatic id_mask:data\n\nroot_visual_id: dd 0\nstatic root_visual_id:data\n\n\nsection .text\n\n%define AF_UNIX 1\n%define SOCK_STREAM 1\n\n%define SYSCALL_READ 0\n%define SYSCALL_WRITE 1\n%define SYSCALL_POLL 7\n%define SYSCALL_SOCKET 41\n%define SYSCALL_CONNECT 42\n%define SYSCALL_EXIT 60\n%define SYSCALL_FCNTL 72\n\n; Create a UNIX domain socket and connect to the X11 server.\n; @returns The socket file descriptor.\nx11_connect_to_server:\nstatic x11_connect_to_server:function\n  push rbp\n  mov rbp, rsp \n\n  ; Open a Unix socket: socket(2).\n  mov rax, SYSCALL_SOCKET\n  mov rdi, AF_UNIX ; Unix socket.\n  mov rsi, SOCK_STREAM ; Stream oriented.\n  mov rdx, 0 ; Automatic protocol.\n  syscall\n\n  cmp rax, 0\n  jle die\n\n  mov rdi, rax ; Store socket fd in `rdi` for the remainder of the function.\n\n  sub rsp, 112 ; Store struct sockaddr_un on the stack.\n\n  mov WORD [rsp], AF_UNIX ; Set sockaddr_un.sun_family to AF_UNIX\n  ; Fill sockaddr_un.sun_path with: &quot;/tmp/.X11-unix/X0&quot;.\n  lea rsi, sun_path\n  mov r12, rdi ; Save the socket file descriptor in `rdi` in `r12`.\n  lea rdi, [rsp + 2]\n  cld ; Move forward\n  mov ecx, 19 ; Length is 19 with the null terminator.\n  rep movsb ; Copy.\n\n  ; Connect to the server: connect(2).\n  mov rax, SYSCALL_CONNECT\n  mov rdi, r12\n  lea rsi, [rsp]\n  %define SIZEOF_SOCKADDR_UN 2+108\n  mov rdx, SIZEOF_SOCKADDR_UN\n  syscall\n\n  cmp rax, 0\n  jne die\n\n  mov rax, rdi ; Return the socket fd.\n\n  add rsp, 112\n  pop rbp\n  ret\n\n; Send the handshake to the X11 server and read the returned system information.\n; @param rdi The socket file descriptor\n; @returns The window root id (uint32_t) in rax.\nx11_send_handshake:\nstatic x11_send_handshake:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 1&lt;&lt;15\n  mov BYTE [rsp + 0], \'l\' ; Set order to \'l\'.\n  mov WORD [rsp + 2], 11 ; Set major version to 11.\n\n  ; Send the handshake to the server: write(2).\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 12\n  syscall\n\n  cmp rax, 12 ; Check that all bytes were written.\n  jnz die\n\n  ; Read the server response: read(2).\n  ; Use the stack for the read buffer.\n  ; The X11 server first replies with 8 bytes. Once these are read, it replies with a much bigger message.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 8\n  syscall\n\n  cmp rax, 8 ; Check that the server replied with 8 bytes.\n  jnz die\n\n  cmp BYTE [rsp], 1 ; Check that the server sent \'success\' (first byte is 1).\n  jnz die\n\n  ; Read the rest of the server response: read(2).\n  ; Use the stack for the read buffer.\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 1&lt;&lt;15\n  syscall\n\n  cmp rax, 0 ; Check that the server replied with something.\n  jle die\n\n  ; Set id_base globally.\n  mov edx, DWORD [rsp + 4]\n  mov DWORD [id_base], edx\n\n  ; Set id_mask globally.\n  mov edx, DWORD [rsp + 8]\n  mov DWORD [id_mask], edx\n\n  ; Read the information we need, skip over the rest.\n  lea rdi, [rsp] ; Pointer that will skip over some data.\n  \n  mov cx, WORD [rsp + 16] ; Vendor length (v).\n  movzx rcx, cx\n\n  mov al, BYTE [rsp + 21]; Number of formats (n).\n  movzx rax, al ; Fill the rest of the register with zeroes to avoid garbage values.\n  imul rax, 8 ; sizeof(format) == 8\n\n  add rdi, 32 ; Skip the connection setup\n\n  ; Skip over padding.\n  add rdi, 3\n  and rdi, -4\n\n  add rdi, rcx ; Skip over the vendor information (v).\n  add rdi, rax ; Skip over the format information (n*8).\n\n  mov eax, DWORD [rdi] ; Store (and return) the window root id.\n\n  ; Set the root_visual_id globally.\n  mov edx, DWORD [rdi + 32]\n  mov DWORD [root_visual_id], edx\n\n  add rsp, 1&lt;&lt;15\n  pop rbp\n  ret\n\n; Increment the global id.\n; @return The new id.\nx11_next_id:\nstatic x11_next_id:function\n  push rbp\n  mov rbp, rsp\n\n  mov eax, DWORD [id] ; Load global id.\n\n  mov edi, DWORD [id_base] ; Load global id_base.\n  mov edx, DWORD [id_mask] ; Load global id_mask.\n\n  ; Return: id_mask &amp; (id) | id_base\n  and eax, edx\n  or eax, edi\n\n  add DWORD [id], 1 ; Increment id.\n\n  pop rbp\n  ret\n\n; Open the font on the server side.\n; @param rdi The socket file descriptor.\n; @param esi The font id.\nx11_open_font:\nstatic x11_open_font:function\n  push rbp\n  mov rbp, rsp\n\n  %define OPEN_FONT_NAME_BYTE_COUNT 5\n  %define OPEN_FONT_PADDING ((4 - (OPEN_FONT_NAME_BYTE_COUNT % 4)) % 4)\n  %define OPEN_FONT_PACKET_U32_COUNT (3 + (OPEN_FONT_NAME_BYTE_COUNT + OPEN_FONT_PADDING) / 4)\n  %define X11_OP_REQ_OPEN_FONT 0x2d\n\n  sub rsp, 6*8\n  mov DWORD [rsp + 0*4], X11_OP_REQ_OPEN_FONT | (OPEN_FONT_NAME_BYTE_COUNT &lt;&lt; 16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], OPEN_FONT_NAME_BYTE_COUNT\n  mov BYTE [rsp + 3*4 + 0], \'f\'\n  mov BYTE [rsp + 3*4 + 1], \'i\'\n  mov BYTE [rsp + 3*4 + 2], \'x\'\n  mov BYTE [rsp + 3*4 + 3], \'e\'\n  mov BYTE [rsp + 3*4 + 4], \'d\'\n\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, OPEN_FONT_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, OPEN_FONT_PACKET_U32_COUNT*4\n  jnz die\n\n  add rsp, 6*8\n\n  pop rbp\n  ret\n\n; Create a X11 graphical context.\n; @param rdi The socket file descriptor.\n; @param esi The graphical context id.\n; @param edx The window root id.\n; @param ecx The font id.\nx11_create_gc:\nstatic x11_create_gc:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 8*8\n\n%define X11_OP_REQ_CREATE_GC 0x37\n%define X11_FLAG_GC_BG 0x00000004\n%define X11_FLAG_GC_FG 0x00000008\n%define X11_FLAG_GC_FONT 0x00004000\n%define X11_FLAG_GC_EXPOSE 0x00010000\n\n%define CREATE_GC_FLAGS X11_FLAG_GC_BG | X11_FLAG_GC_FG | X11_FLAG_GC_FONT\n%define CREATE_GC_PACKET_FLAG_COUNT 3\n%define CREATE_GC_PACKET_U32_COUNT (4 + CREATE_GC_PACKET_FLAG_COUNT)\n%define MY_COLOR_RGB 0x0000ffff\n\n  mov DWORD [rsp + 0*4], X11_OP_REQ_CREATE_GC | (CREATE_GC_PACKET_U32_COUNT&lt;&lt;16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], edx\n  mov DWORD [rsp + 3*4], CREATE_GC_FLAGS\n  mov DWORD [rsp + 4*4], MY_COLOR_RGB\n  mov DWORD [rsp + 5*4], 0\n  mov DWORD [rsp + 6*4], ecx\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, CREATE_GC_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, CREATE_GC_PACKET_U32_COUNT*4\n  jnz die\n  \n  add rsp, 8*8\n\n  pop rbp\n  ret\n\n; Create the X11 window.\n; @param rdi The socket file descriptor.\n; @param esi The new window id.\n; @param edx The window root id.\n; @param ecx The root visual id.\n; @param r8d Packed x and y.\n; @param r9d Packed w and h.\nx11_create_window:\nstatic x11_create_window:function\n  push rbp\n  mov rbp, rsp\n\n  %define X11_OP_REQ_CREATE_WINDOW 0x01\n  %define X11_FLAG_WIN_BG_COLOR 0x00000002\n  %define X11_EVENT_FLAG_KEY_RELEASE 0x0002\n  %define X11_EVENT_FLAG_EXPOSURE 0x8000\n  %define X11_FLAG_WIN_EVENT 0x00000800\n  \n  %define CREATE_WINDOW_FLAG_COUNT 2\n  %define CREATE_WINDOW_PACKET_U32_COUNT (8 + CREATE_WINDOW_FLAG_COUNT)\n  %define CREATE_WINDOW_BORDER 1\n  %define CREATE_WINDOW_GROUP 1\n\n  sub rsp, 12*8\n\n  mov DWORD [rsp + 0*4], X11_OP_REQ_CREATE_WINDOW | (CREATE_WINDOW_PACKET_U32_COUNT &lt;&lt; 16)\n  mov DWORD [rsp + 1*4], esi\n  mov DWORD [rsp + 2*4], edx\n  mov DWORD [rsp + 3*4], r8d\n  mov DWORD [rsp + 4*4], r9d\n  mov DWORD [rsp + 5*4], CREATE_WINDOW_GROUP | (CREATE_WINDOW_BORDER &lt;&lt; 16)\n  mov DWORD [rsp + 6*4], ecx\n  mov DWORD [rsp + 7*4], X11_FLAG_WIN_BG_COLOR | X11_FLAG_WIN_EVENT\n  mov DWORD [rsp + 8*4], 0\n  mov DWORD [rsp + 9*4], X11_EVENT_FLAG_KEY_RELEASE | X11_EVENT_FLAG_EXPOSURE\n\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, CREATE_WINDOW_PACKET_U32_COUNT*4\n  syscall\n\n  cmp rax, CREATE_WINDOW_PACKET_U32_COUNT*4\n  jnz die\n\n  add rsp, 12*8\n\n  pop rbp\n  ret\n\n; Map a X11 window.\n; @param rdi The socket file descriptor.\n; @param esi The window id.\nx11_map_window:\nstatic x11_map_window:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 16\n\n  %define X11_OP_REQ_MAP_WINDOW 0x08\n  mov DWORD [rsp + 0*4], X11_OP_REQ_MAP_WINDOW | (2&lt;&lt;16)\n  mov DWORD [rsp + 1*4], esi\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 2*4\n  syscall\n\n  cmp rax, 2*4\n  jnz die\n\n  add rsp, 16\n\n  pop rbp\n  ret\n\n; Read the X11 server reply.\n; @return The message code in al.\nx11_read_reply:\nstatic x11_read_reply:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n\n  mov rax, SYSCALL_READ\n  mov rdi, rdi\n  lea rsi, [rsp]\n  mov rdx, 32\n  syscall\n\n  cmp rax, 1\n  jle die\n\n  mov al, BYTE [rsp]\n\n  add rsp, 32\n\n  pop rbp\n  ret\n\ndie:\n  mov rax, SYSCALL_EXIT\n  mov rdi, 1\n  syscall\n\n\n; Set a file descriptor in non-blocking mode.\n; @param rdi The file descriptor.\nset_fd_non_blocking:\nstatic set_fd_non_blocking:function\n  push rbp\n  mov rbp, rsp\n\n  %define F_GETFL 3\n  %define F_SETFL 4\n\n  %define O_NONBLOCK 2048\n\n  mov rax, SYSCALL_FCNTL\n  mov rdi, rdi \n  mov rsi, F_GETFL\n  mov rdx, 0\n  syscall\n\n  cmp rax, 0\n  jl die\n\n  ; `or` the current file status flag with O_NONBLOCK.\n  mov rdx, rax\n  or rdx, O_NONBLOCK\n\n  mov rax, SYSCALL_FCNTL\n  mov rdi, rdi \n  mov rsi, F_SETFL\n  mov rdx, rdx\n  syscall\n\n  cmp rax, 0\n  jl die\n\n  pop rbp\n  ret\n\n; Poll indefinitely messages from the X11 server with poll(2).\n; @param rdi The socket file descriptor.\n; @param esi The window id.\n; @param edx The gc id.\npoll_messages:\nstatic poll_messages:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n\n  %define POLLIN 0x001\n  %define POLLPRI 0x002\n  %define POLLOUT 0x004\n  %define POLLERR  0x008\n  %define POLLHUP  0x010\n  %define POLLNVAL 0x020\n\n  mov DWORD [rsp + 0*4], edi\n  mov DWORD [rsp + 1*4], POLLIN\n\n  mov DWORD [rsp + 16], esi ; window id\n  mov DWORD [rsp + 20], edx ; gc id\n  mov BYTE [rsp + 24], 0 ; exposed? (boolean)\n\n  .loop:\n    mov rax, SYSCALL_POLL\n    lea rdi, [rsp]\n    mov rsi, 1\n    mov rdx, -1\n    syscall\n\n    cmp rax, 0\n    jle die\n\n    cmp DWORD [rsp + 2*4], POLLERR  \n    je die\n\n    cmp DWORD [rsp + 2*4], POLLHUP  \n    je die\n\n    mov rdi, [rsp + 0*4]\n    call x11_read_reply\n\n    %define X11_EVENT_EXPOSURE 0xc\n    cmp eax, X11_EVENT_EXPOSURE\n    jnz .received_other_event\n\n    .received_exposed_event:\n    mov BYTE [rsp + 24], 1 ; Mark as exposed.\n\n    .received_other_event:\n\n    cmp BYTE [rsp + 24], 1 ; exposed?\n    jnz .loop\n\n    .draw_text:\n      mov rdi, [rsp + 0*4] ; socket fd\n      lea rsi, [hello_world] ; string\n      mov edx, 13 ; length\n      mov ecx, [rsp + 16] ; window id\n      mov r8d, [rsp + 20] ; gc id\n      mov r9d, 100 ; x\n      shl r9d, 16\n      or r9d, 100 ; y\n      call x11_draw_text\n\n\n    jmp .loop\n\n\n  add rsp, 32\n  pop rbp\n  ret\n\n; Draw text in a X11 window with server-side text rendering.\n; @param rdi The socket file descriptor.\n; @param rsi The text string.\n; @param edx The text string length in bytes.\n; @param ecx The window id.\n; @param r8d The gc id.\n; @param r9d Packed x and y.\nx11_draw_text:\nstatic x11_draw_text:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 1024\n\n  mov DWORD [rsp + 1*4], ecx ; Store the window id directly in the packet data on the stack.\n  mov DWORD [rsp + 2*4], r8d ; Store the gc id directly in the packet data on the stack.\n  mov DWORD [rsp + 3*4], r9d ; Store x, y directly in the packet data on the stack.\n\n  mov r8d, edx ; Store the string length in r8 since edx will be overwritten next.\n  mov QWORD [rsp + 1024 - 8], rdi ; Store the socket file descriptor on the stack to free the register.\n\n  ; Compute padding and packet u32 count with division and modulo 4.\n  mov eax, edx ; Put dividend in eax.\n  mov ecx, 4 ; Put divisor in ecx.\n  cdq ; Sign extend.\n  idiv ecx ; Compute eax / ecx, and put the remainder (i.e. modulo) in edx.\n  ; LLVM optimizer magic: `(4-x)%4 == -x &amp; 3`, for some reason.\n  neg edx\n  and edx, 3\n  mov r9d, edx ; Store padding in r9.\n\n  mov eax, r8d \n  add eax, r9d\n  shr eax, 2 ; Compute: eax /= 4\n  add eax, 4 ; eax now contains the packet u32 count.\n\n\n  %define X11_OP_REQ_IMAGE_TEXT8 0x4c\n  mov DWORD [rsp + 0*4], r8d\n  shl DWORD [rsp + 0*4], 8\n  or DWORD [rsp + 0*4], X11_OP_REQ_IMAGE_TEXT8\n  mov ecx, eax\n  shl ecx, 16\n  or [rsp + 0*4], ecx\n\n  ; Copy the text string into the packet data on the stack.\n  mov rsi, rsi ; Source string in rsi.\n  lea rdi, [rsp + 4*4] ; Destination\n  cld ; Move forward\n  mov ecx, r8d ; String length.\n  rep movsb ; Copy.\n\n  mov rdx, rax ; packet u32 count\n  imul rdx, 4\n  mov rax, SYSCALL_WRITE\n  mov rdi, QWORD [rsp + 1024 - 8] ; fd\n  lea rsi, [rsp]\n  syscall\n\n  cmp rax, rdx\n  jnz die\n\n  add rsp, 1024\n\n  pop rbp\n  ret\n\n_start:\nglobal _start:function\n  call x11_connect_to_server\n  mov r15, rax ; Store the socket file descriptor in r15.\n\n  mov rdi, rax\n  call x11_send_handshake\n\n  mov r12d, eax ; Store the window root id in r12.\n\n  call x11_next_id\n  mov r13d, eax ; Store the gc_id in r13.\n\n  call x11_next_id\n  mov r14d, eax ; Store the font_id in r14.\n\n  mov rdi, r15\n  mov esi, r14d\n  call x11_open_font\n\n\n  mov rdi, r15\n  mov esi, r13d\n  mov edx, r12d\n  mov ecx, r14d\n  call x11_create_gc\n\n  call x11_next_id\n  \n  mov ebx, eax ; Store the window id in ebx.\n\n  mov rdi, r15 ; socket fd\n  mov esi, eax\n  mov edx, r12d\n  mov ecx, [root_visual_id]\n  mov r8d, 200 | (200 &lt;&lt; 16) ; x and y are 200\n  %define WINDOW_W 800\n  %define WINDOW_H 600\n  mov r9d, WINDOW_W | (WINDOW_H &lt;&lt; 16)\n  call x11_create_window\n\n  mov rdi, r15 ; socket fd\n  mov esi, ebx\n  call x11_map_window\n\n  mov rdi, r15 ; socket fd\n  call set_fd_non_blocking\n\n  mov rdi, r15 ; socket fd\n  mov esi, ebx ; window id\n  mov edx, r13d ; gc id\n  call poll_messages\n\n  ; The end.\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3018859686-what-do-we-need",
"#2049729589-x11-basics",
"#1992549332-main-in-x64-assembly",
"#2732446636-a-stack-primer",
"#657479577-a-small-stack-example",
"#4163415294-opening-a-socket",
"#2750592591-connecting-to-the-server",
"#484246098-sending-data-over-the-socket",
"#1309822244-generating-ids",
"#4134081642-opening-a-font",
"#3515439192-creating-a-graphical-context",
"#2863200396-creating-the-window",
"#577694983-mapping-the-window",
"#677275119-polling-for-server-messages",
"#3433791877-drawing-text",
"#1770781618-the-end",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
1792,3964,4706,9479,10753,17873,19853,27867,35408,36078,37434,38998,40811,41517,44556,47529,48374,],
},
{
name:"kahns_algorithm.html",
text:"Cycle detection in graphs does not have to be hard: A lesser known, simple way with Kahn&#39;s algorithm\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-06-03\nCycle detection in graphs does not have to be hard: A lesser known, simple way with Kahn\'s algorithm\nGraph\nAlgorithm\nJavaScript\nSQL\nTable of contents\nIntroduction\nThe database\nTopological sort\nHow to store the graph in memory\nKahn\'s algorithm\nImplementation\nHelpers\nThe algorithm\nInserting entries in the database\nDetecting cycles\nDetecting multiple roots\nPlaying with the database\nClosing thoughts\nAddendum: the full code\nIntroduction\nGraphs are everywhere in Software Engineering, or so we are told by Computer Science teachers and interviewers. But sometimes, they do show up in real problems.\nNot too long ago, I was tasked to create a Web API to create and update a company\'s hierarchy of employee, and display that on a web page. Basically, who reports to whom.\nIn the simple case, it\'s a tree, when an employee reports to exactly one manager.\nHere\'s the tree of employees in an organization. An employee reports to a manager, and this forms a tree. The root is the CEO since they report to no one and so they have no outgoing edge.\nAn arrow (or \'edge\') between two nodes means\n&lt;source&gt; reports to &lt;destination&gt;\n, for example:\nJane the CFO reports to Ellen the CEO\n.\nBut here is the twist: our API receives a list of\nemployee -&gt; manager\nlinks, in any order:\nJane -&gt; Ellen\nAngela -&gt; Ellen\nZoe -&gt; Jane\nZoe -&gt; Angela\nBella -&gt; Angela\nMiranda -&gt; Angela\nIt opens the door to various invalid inputs: links that form a graph (an employee has multiple managers), multiple roots (e.g. multiple CEOs) or cycles.\nWe have to detect those and reject them, such as this one:\nThe database\nSo how do we store all of those people in the database?\nCREATE TABLE IF NOT EXISTS people(name TEXT NOT NULL UNIQUE, manager BIGINT REFERENCES people)\nEach employee has a optional reference to a manager.\nThis is not a novel idea, actually this is one of the examples in the official\nSQLite documentation\n.\nFor example, to save\nEllen, CEO\ninside the database, we do:\nINSERT INTO people VALUES(\'Ellen, CEO\', NULL)\nAnd to save\nJane, CFO\nin the database:\nINSERT INTO people VALUES(\'Jane, CFO\', 1)\nWhere\nEllen, CEO\n, Jane\'s boss, which we just inserted before, has the id\n1\n.\nImmediately, we notice that to insert an employee, their manager needs to already by in the database, by virtue of the self-referential foreign key\nmanager BIGINT REFERENCES people\n.\nSo we need a way to sort the big list of\nemployee -&gt; manager\nlinks (or \'edges\' in graph parlance), to insert them in the right order. First we insert the CEO, who reports to no one. Then we insert the employees directly reporting to the CEO. Then the employees reporting to those. Etc.\nAnd that\'s called a topological sort.\nA big benefit is that we hit three birds with one stone:\nWe detect cycles\nWe have the nodes in an convenient order to insert them in the database\nSince the algorithm for the topological sort takes as input an adjacency matrix (more on this later), we can easily detect the invalid case of a node having more than one outgoing edge (i.e. more than one manager, i.e. multiple roots).\nFrom now one, I will use the graph of employees (where\nZoe\nhas two managers) as example since that\'s a possible input to our API and we need to detect this case.\nTopological sort\nFrom Wikipedia:\nA topological sort or topological ordering of a directed graph is a linear ordering of its vertices such that for every directed edge uv from vertex u to vertex v, u comes before v in the ordering. For instance, the vertices of the graph may represent tasks to be performed, and the edges may represent constraints that one task must be performed before another; in this application, a topological ordering is just a valid sequence for the tasks\nThat\'s a mouthful but it\'s not too hard.\nA useful command line utility that\'s already on your (Unix) machine is\ntsort\n, which takes a list of edges as input, and outputs a topological sort. Here is the input in a text file (\npeople.txt\n):\nJane Ellen\nAngela Ellen\nZoe Jane\nZoe Angela\nBella Angela\nMiranda Angela\ntsort\nuses a simple way of defining each edge\nA -&gt; B\non its own line with the syntax:\nA B\n. The order of the lines does not matter.\nAnd here\'s the\ntsort\noutput:\n$ tsort &lt; people.txt\nBella\nMiranda\nZoe\nAngela\nJane\nEllen\nThe first 3 elements are the ones with no incoming edge, the Software Engineers, since no one reports to them. Then come their respective managers, Angela and Jane. Finally comes their manager,\nEllen\n.\nSo to insert all those people in our\npeople\nSQL table, we go through that list in reverse order: We can first insert\nEllen\n, then\nJane\n, etc, until we finally insert\nBella\n.\nAlso,\ntsort\ndetects cycles, for example if we add the line:\nEllen Zoe\nat the end of\npeople.txt\n, we get:\n$ tsort &lt; people.txt\nBella\nMiranda\ntsort: -: input contains a loop:\ntsort: Jane\ntsort: Ellen\ntsort: Zoe\nJane\ntsort: -: input contains a loop:\ntsort: Angela\ntsort: Ellen\ntsort: Zoe\nAngela\nEllen\nZoe\nSo, how can we implement something like\ntsort\nfor our problem at hand? That\'s where\nKahn\'s algorithm\ncomes in to do exactly that: find cycles in the graph and output a topological sort.\nNote that that\'s not the only solution and there are ways to detect cycles without creating a topological sort, but this algorithm seems relatively unknown and does not come up often on the Internet, so let\'s discover how it works and implement it. I promise, it\'s not complex.\nHow to store the graph in memory\nThere are many ways to do so, and Kahn\'s algorithm does not dictate which one to use.\nWe\'ll use an\nadjacency matrix\n, because it\'s simple conceptually, maps well to Kahn\'s algorithm, and can be optimized if needed.\nIt\'s just a 2D square table of size\nn x n\n(where\nn\nis the number of nodes), where the cell at row\ni\nand column\nj\nis 1 if there is an edge from the node\ni\nto the node\nj\n, and otherwise,\n0\n.\nThe order of the nodes is arbitrary, I\'ll use the alphabetical order because again, it\'s simple to do:\nAngela\nBella\nEllen\nJane\nMiranda\nZoe\nHere,\nAngela\nis the node\n0\nand\nZoe\nis the node\n5\n.\nSince there is an edge from\nZoe\nto\nAngela\n, i.e. from the node\n5\nto the node\n0\n, the cell at the position\n(5, 0)\nis set to\n1\n.\nThe full adjacency matrix for the employee graph in the example above looks like:\nAngela\nBella\nEllen\nJane\nMiranda\nZoe\nAngela\n0\n0\n1\n0\n0\n0\nBella\n1\n0\n0\n0\n0\n0\nEllen\n0\n0\n0\n0\n0\n0\nJane\n0\n0\n1\n0\n0\n0\nMiranda\n1\n0\n0\n0\n0\n0\nZoe\n1\n0\n0\n1\n0\n0\nThe way to read this table is:\nFor a given row, all the\n1\n\'s indicate outgoing edges\nFor a given column, all the\n1\n\'s indicate incoming edges\nIf there is a\n1\non the diagonal, it means there is an edge going out of a node and going to the same node.\nThere are a lot of zeroes in this table. Some may think this is horribly inefficient, which it is, but it really depends on number of nodes, i.e. the number of employees in the organization.\nBut note that this adjacency matrix is a concept, it shows what information is present, but not how it is stored.\nFor this article, we will store it the naive way, in a 2D array. Here are two optimization ideas I considered but have not had time to experiment with:\nMake this a bitarray. We are already only storing zeroes and ones, so it maps perfectly to this format.\nSince there are a ton of zeroes (in the valid case, a regular employee\'s row only has one\n1\nand the CEO\'s row is only zeroes), it is very compressible. An easy way would be to use run-length encoding, meaning, instead of\n0 0 0 0\n, we just store the number of times the number occurs:\n4 0\n. Easy to implement, easy to understand. A row compresses to just a few bytes. And this size would be constant, whatever the size of the organization (i.e. number of employees) is.\nWikipedia lists others if you are interested, it\'s a well-known problem.\nAlright, now that we know how our graph is represented, on to the algorithm.\nKahn\'s algorithm\nKahn\'s algorithm\nkeeps track of nodes with no incoming edge, and mutates the graph (in our case the adjacency matrix), by removing one edge at a time, until there are no more edges, and builds a list of nodes in the right order, which is the output.\nHere\'s the pseudo-code:\nL \u{2190} Empty list that will contain the sorted elements\nS \u{2190} Set of all nodes with no incoming edge\n\nwhile S is not empty do\n    remove a node n from S\n    add n to L\n    for each node m with an edge e from n to m do\n        remove edge e from the graph\n        if m has no other incoming edges then\n            insert m into S\n\nif graph has edges then\n    return error   (graph has at least one cycle)\nelse \n    return L   (a topologically sorted order)\nAnd in plain English:\nLine 1: The result of this algorithm is the list of nodes in the desired order (topological). It starts empty, and we add nodes one-by one during the algorithm. We can simply use an array in our implementation.\nLine 2: We first collect all nodes with no incoming edge. In terms of adjacency matrix, it means picking columns with only zeroes. The algorithm calls it a set, but we are free in our implementation to use whatever data structure we see fit. It just means a given node appears at most once in it. In our example, this set is:\n[Zoe, Bella, Miranda]\n. During the algorithm course, we will add further nodes to this set. Note that this is a working set, not the final result. Also, the order does not matter.\nLine 4: Self-explanatory, we continue until the working set is empty and there is no more work to do.\nLine 5: We first pick a node with no incoming edge (it does not matter which one). For example,\nZoe\n, and remove it from\nS\n.\nS\nis now:\n[Bella, Miranda]\n.\nLine 6: We add this node to the list of topologically sorted nodes,\nL\n. It now is:\n[Zoe]\n.\nLine 7: We then inspect each node that\nZoe\nhas an edge to. That means\nJane\nand\nAngela\n. In terms of adjacency matrix, we simply read\nZoe\'s\nrow, and inspect cells with a\n1\nin it.\nLine 8: We remove such an edge, for example,\nZoe -&gt; Jane\n. In terms of adjacency matrix, it means setting the cell on the row\nZoe\nand column\nJane\nto\n0\n. At this point, the graph looks like this:\nLine 9: If\nJane\ndoes not have another incoming edge, we add it to the set of all nodes with no incoming edge. That\'s the case here, so\nS\nnow looks like:\n[Bella, Miranda, Jane]\n. We now loop to line 7 and handle the node\nAngela\nsince\nJane\nis taken care of.\nLine 7-10: We are now handling the node\nAngela\n. We remove the edge\nZoe -&gt; Angela\n. We check whether the node\nAngela\nhas incoming edges. It does, so we do\nnot\nadd it to\nS\n. The graph is now:\n.\nWe are now done with the line 7 for loop, so go back to line 5 and pick this time\nBella\n. And so on. The graph would now, to the algorithm, look like:\nAnd here are the next steps in images:\nLine 12-15: Once the loop at line 4 is finished, we inspect our graph. If there are no more edges, we are done. If there is still an edge, it means there was a cycle in the graph, and we return an error.\nNote that this algorithm is not capable by itself to point out which cycle there was exactly, only that there was one. That\'s because we mutated the graph by removing edges. If this information was important, we could keep track of which edges we removed in order, and re-add them back, or perhaps apply the algorithm to a copy of the graph (the adjacency matrix is trivial to clone).\nThis algorithm is loose concerning the order of some operations, for example, picking a node with no incoming edge, or in which order the nodes in\nS\nare stored. That gives room for an implementation to use certain data structures or orders that are faster, but in some cases we want the order to be always the same to solve ties in the stable way and to be reproducible. In order to do that, we simply use the alphabetical order. So in our example above, at line 5, we picked\nZoe\nout of\n[Zoe, Bella, Miranda]\n. Using this method, we would keep the working set\nS\nsorted alphabetically and pick\nBella\nout of\n[Bella, Miranda, Zoe]\n.\nImplementation\nI implemented this at the time in Go, but I will use for this article the lingua franca of the 2010s, Javascript.\nI don\'t write Javascript these days, I stopped many years ago, so apologies in advance if I am not using all the bells and whistles of \'Modern Javascript\', or if the code is not quite idiomatic.\nFirst, we define our adjacency matrix and the list of nodes. This is the naive format. We would get the nodes and edges in some format, for example JSON, in the API, and build the adjacency matrix, which is trivial. Let\'s take the very first example, the (valid) tree  of employees:\nconst adjacencyMatrix = [\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0],\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 1, 0, 0],\n];\n\nconst nodes = [&quot;Angela&quot;, &quot;Bella&quot;, &quot;Ellen&quot;, &quot;Jane&quot;, &quot;Miranda&quot;, &quot;Zoe&quot;];\nHelpers\nWe need a helper function to check if a node has no incoming edge (line 9 in the algorithm):\nfunction hasNodeNoIncomingEdge(adjacencyMatrix, nodeIndex) {\n  const column = nodeIndex;\n\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    const cell = adjacencyMatrix[row][column];\n    if (cell != 0) {\n      return false;\n    }\n  }\n\n  return true;\n}\nThen, using this helper, we can define a second helper to initially collect all the nodes with no incoming edge (line 2 in the algorithm):\nfunction getNodesWithNoIncomingEdge(adjacencyMatrix, nodes) {\n  return nodes.filter((_, i) =&gt; hasNodeNoIncomingEdge(adjacencyMatrix, i));\n}\nWe can try it:\nconsole.log(getNodesWithNoIncomingEdge(adjacencyMatrix, nodes));\nAnd it outputs:\n[ \'Bella\', \'Miranda\', \'Zoe\' ]\nWe need one final helper, to determine if the graph has edges (line 12), which is straightforward:\nfunction graphHasEdges(adjacencyMatrix) {\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    for (let column = 0; column &lt; adjacencyMatrix.length; column += 1) {\n      if (adjacencyMatrix[row][column] == 1) return true;\n    }\n  }\n\n  return false;\n}\nThe algorithm\nWe are finally ready to implement the algorithm. It\'s a straightforward, line by line, translation of the pseudo-code:\nfunction topologicalSort(adjacencyMatrix) {\n  const L = [];\n  const S = getNodesWithNoIncomingEdge(adjacencyMatrix, nodes);\n\n  while (S.length &gt; 0) {\n    const node = S.pop();\n    L.push(node);\n    const nodeIndex = nodes.indexOf(node);\n\n    for (let mIndex = 0; mIndex &lt; nodes.length; mIndex += 1) {\n      const hasEdgeFromNtoM = adjacencyMatrix[nodeIndex][mIndex];\n      if (!hasEdgeFromNtoM) continue;\n\n      adjacencyMatrix[nodeIndex][mIndex] = 0;\n\n      if (hasNodeNoIncomingEdge(adjacencyMatrix, mIndex)) {\n        const m = nodes[mIndex];\n        S.push(m);\n      }\n    }\n  }\n\n  if (graphHasEdges(adjacencyMatrix)) {\n    throw new Error(&quot;Graph has at least one cycle&quot;);\n  }\n\n  return L;\n}\nLet\'s try it:\nconsole.log(topologicalSort(adjacencyMatrix, nodes));\nWe get:\n[ \'Zoe\', \'Jane\', \'Miranda\', \'Bella\', \'Angela\', \'Ellen\' ]\nInterestingly, it is not the same order as\ntsort\n, but it is indeed a valid topological ordering. That\'s because there are ties between some nodes and we do not resolve those ties the exact same way\ntsort\ndoes.\nBut in our specific case, we just want a valid insertion order in the database, and so this is enough.\nInserting entries in the database\nNow, we can produce the SQL code to insert our entries. We operate on a clone of the adjacency matrix for convenience because we later need to know what is the outgoing edge for a given node.\nWe handle the special case of the root first, which is the last element, and then we go through the topologically sorted list of employees in reverse order, and insert each one. We use a one liner to get the manager id by name when inserting to avoid many round trips to the database:\nconst employeesTopologicallySorted = topologicalSort(structuredClone(adjacencyMatrix), nodes)\n\nconst root = employeesTopologicallySorted[employeesTopologicallySorted.length - 1];\nconsole.log(`INSERT INTO people VALUES(&quot;${root}&quot;, NULL)`);\n\nfor (let i = employeesTopologicallySorted.length - 2; i &gt;= 0; i -= 1) {\n  const employee = employeesTopologicallySorted[i];\n  const employeeIndex = nodes.indexOf(employee);\n\n  const managerIndex = adjacencyMatrix[employeeIndex].indexOf(1);\n  const manager = nodes[managerIndex];\n  console.log(\n    `INSERT INTO people SELECT &quot;${employee}&quot;, rowid FROM people WHERE name = &quot;${manager}&quot; LIMIT 1;`,\n  );\n}\nWhich outputs:\nINSERT INTO people VALUES(&quot;Ellen&quot;, NULL);\nINSERT INTO people SELECT &quot;Angela&quot;, rowid FROM people WHERE name = &quot;Ellen&quot; LIMIT 1;\nINSERT INTO people SELECT &quot;Bella&quot;, rowid FROM people WHERE name = &quot;Angela&quot; LIMIT 1;\nINSERT INTO people SELECT &quot;Miranda&quot;, rowid FROM people WHERE name = &quot;Angela&quot; LIMIT 1;\nINSERT INTO people SELECT &quot;Jane&quot;, rowid FROM people WHERE name = &quot;Ellen&quot; LIMIT 1;\nINSERT INTO people SELECT &quot;Zoe&quot;, rowid FROM people WHERE name = &quot;Jane&quot; LIMIT 1;\nDetecting cycles\nAs we said earlier, we get that for free, so let\'s check our implementation against this invalid example:\nWe add the edge\nEllen -&gt; Zoe\nto create a cycle:\nconst adjacencyMatrix = [\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 1], // =&gt; We change the last element of this row (Ellen\'s row, Zoe\'s column) from 0 to 1.\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 1, 0, 0],\n];\n\nconst nodes = [&quot;Angela&quot;, &quot;Bella&quot;, &quot;Ellen&quot;, &quot;Jane&quot;, &quot;Miranda&quot;, &quot;Zoe&quot;];\n\nconst employeesTopologicallySorted = topologicalSort(structuredClone(adjacencyMatrix), nodes);\nAnd we get an error as expected:\n/home/pg/my-code/blog/kahns_algorithm.js:63\n    throw new Error(&quot;Graph has at least one cycle&quot;);\n    ^\n\nError: Graph has at least one cycle\nDetecting multiple roots\nOne thing that topological sorting does not do for us is to detect the case of multiple roots in the graph, for example:\nTo do this, we simply scan the adjacency matrix and verify that there is only one row with only zeroes, that is, only one node that has no outgoing edges:\nfunction hasMultipleRoots(adjacencyMatrix) {\n  let countOfRowsWithOnlyZeroes = 0;\n\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    let rowHasOnlyZeroes = true;\n    for (let column = 0; column &lt; adjacencyMatrix.length; column += 1) {\n      if (adjacencyMatrix[row][column] != 0) {\n        rowHasOnlyZeroes = false;\n        break;\n      }\n    }\n    if (rowHasOnlyZeroes) countOfRowsWithOnlyZeroes += 1;\n  }\n\n  return countOfRowsWithOnlyZeroes &gt; 1;\n}\nLet\'s try it with our invalid example from above:\nconst adjacencyMatrix = [\n  [0, 0, 1, 0, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 1, 0, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 1, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0],\n];\n\nconst nodes = [&quot;Angela&quot;, &quot;Bella&quot;, &quot;Ellen&quot;, &quot;Jane&quot;, &quot;Miranda&quot;, &quot;Zoe&quot;, &quot;Kelly&quot;];\n\n\nconsole.log(hasMultipleRoots(adjacencyMatrix));\nAnd we get:\ntrue\n. With our previous (valid) example, we get:\nfalse\n.\nPlaying with the database\nWe can query each employee along with their manager name so:\nSELECT a.name as employee_name, COALESCE(b.name, \'\') as manager_name FROM people a LEFT JOIN people b ON a.manager = b.rowid;\nTo query the manager (N+1) and the manager\'s manager (N+2) of an employee:\nSELECT COALESCE(n_plus_1.name, \'\'), COALESCE(n_plus_2.name, \'\')\nFROM people employee\nLEFT JOIN people n_plus_1 ON employee.manager = n_plus_1.rowid\nLEFT JOIN people n_plus_2 ON n_plus_1.manager = n_plus_2.rowid\nWHERE employee.name = ?\nWe can also do this with hairy recursive Common Table Expression (CTE) but I\'ll leave that to the reader.\nClosing thoughts\nGraphs and algorithms operating on them do not have to be complicated. Using an adjacency matrix and Kahn\'s algorithm, we can achieve a lot with little and it remains simple.\nThere are many ways to optimize the code in this article; the point was not to write the most efficient code, but to showcase in the clearest, simplest way possible to detect cycles and store a graph/tree in memory and in a database.\nIf you want to play with the code here and try to make it faster, go at it!\nAddendum: the full code\nThe full code\nconst adjacencyMatrix = [\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0],\n  [0, 0, 1, 0, 0, 0],\n  [1, 0, 0, 0, 0, 0],\n  [0, 0, 0, 1, 0, 0],\n];\n\nconst nodes = [&quot;Angela&quot;, &quot;Bella&quot;, &quot;Ellen&quot;, &quot;Jane&quot;, &quot;Miranda&quot;, &quot;Zoe&quot;];\n\nfunction hasNodeNoIncomingEdge(adjacencyMatrix, nodeIndex) {\n  const column = nodeIndex;\n\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    const cell = adjacencyMatrix[row][column];\n\n    if (cell != 0) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction getNodesWithNoIncomingEdge(adjacencyMatrix, nodes) {\n  return nodes.filter((_, i) =&gt; hasNodeNoIncomingEdge(adjacencyMatrix, i));\n}\n\nfunction graphHasEdges(adjacencyMatrix) {\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    for (let column = 0; column &lt; adjacencyMatrix.length; column += 1) {\n      if (adjacencyMatrix[row][column] == 1) return true;\n    }\n  }\n\n  return false;\n}\n\nfunction topologicalSort(adjacencyMatrix) {\n  const L = [];\n  const S = getNodesWithNoIncomingEdge(adjacencyMatrix, nodes);\n\n  while (S.length &gt; 0) {\n    const node = S.pop();\n    L.push(node);\n    const nodeIndex = nodes.indexOf(node);\n\n    for (let mIndex = 0; mIndex &lt; nodes.length; mIndex += 1) {\n      const hasEdgeFromNtoM = adjacencyMatrix[nodeIndex][mIndex];\n      if (!hasEdgeFromNtoM) continue;\n\n      adjacencyMatrix[nodeIndex][mIndex] = 0;\n\n      if (hasNodeNoIncomingEdge(adjacencyMatrix, mIndex)) {\n        const m = nodes[mIndex];\n        S.push(m);\n      }\n    }\n  }\n\n  if (graphHasEdges(adjacencyMatrix)) {\n    throw new Error(&quot;Graph has at least one cycle&quot;);\n  }\n\n  return L;\n}\n\nfunction hasMultipleRoots(adjacencyMatrix) {\n  let countOfRowsWithOnlyZeroes = 0;\n\n  for (let row = 0; row &lt; adjacencyMatrix.length; row += 1) {\n    let rowHasOnlyZeroes = true;\n    for (let column = 0; column &lt; adjacencyMatrix.length; column += 1) {\n      if (adjacencyMatrix[row][column] != 0) {\n        rowHasOnlyZeroes = false;\n        break;\n      }\n    }\n    if (rowHasOnlyZeroes) countOfRowsWithOnlyZeroes += 1;\n  }\n\n  return countOfRowsWithOnlyZeroes &gt; 1;\n}\n\nconsole.log(hasMultipleRoots(adjacencyMatrix));\nconst employeesTopologicallySorted = topologicalSort(structuredClone(adjacencyMatrix), nodes);\nconsole.log(employeesTopologicallySorted);\n\nconst root = employeesTopologicallySorted[employeesTopologicallySorted.length - 1];\nconsole.log(`INSERT INTO people VALUES(&quot;${root}&quot;, NULL)`);\n\nfor (let i = employeesTopologicallySorted.length - 2; i &gt;= 0; i -= 1) {\n  const employee = employeesTopologicallySorted[i];\n  const employeeIndex = nodes.indexOf(employee);\n\n  const managerIndex = adjacencyMatrix[employeeIndex].indexOf(1);\n  const manager = nodes[managerIndex];\n  console.log(\n    `INSERT INTO people SELECT &quot;${employee}&quot;, rowid FROM people WHERE name = &quot;${manager}&quot; LIMIT 1;`,\n  );\n}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#4275806978-introduction",
"#3658996082-the-database",
"#3448959225-topological-sort",
"#1273712339-how-to-store-the-graph-in-memory",
"#1475551869-kahn-s-algorithm",
"#3410597752-implementation",
"#3667958886-helpers",
"#1391191453-the-algorithm",
"#266987965-inserting-entries-in-the-database",
"#1211708065-detecting-cycles",
"#2939355639-detecting-multiple-roots",
"#782257250-playing-with-the-database",
"#3440295979-closing-thoughts",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
630,1806,3444,5603,8012,12081,12980,14129,15421,17189,18023,19323,19952,20454,],
},
{
name:"advent_of_code_2018_5_revisited.html",
text:"Optimizing an Advent of Code solution in assembly\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-10-05\nOptimizing an Advent of Code solution in assembly\nx86_64\nAdvent of Code\nOptimization\nAlgorithm\nC\nLisp\nScheme\nTable of contents\nThe new solution\nThe x86_64 implementation\nBenchmarking\nLearnings\nAppendix: The full code\nThe old C implementation\nThe x64 implementation\nA few days ago I was tweaking the appearance of this blog and I stumbled upon my\nfirst article\nwhich is about solving a simple problem from Advent of Code. Here it is again:\nWe have a string looking like this:\nAabcdZZqQ\nwhich represents a chain of\nchemical units. Adjacent units of the same type (i.e letter) and opposite\npolarity (i.e casing) react together and disappear.\nIt means we want to remove adjacent characters which are the same letter and have opposite casing, e.g\nAa\nand\nqQ\ndisappear while\nbc\nand\nZZ\nremain. Once we are finished, we have:\nbcdZZ\n.\nThe final output is the number of characters in the final string, i.e,\n5\n.\nImmediately, I thought I could do better than my past self:\nIn the Lisp solution, there are lots of allocations and the code is not straightforward.\nIn the Lisp solution, we use multiple external dependencies, which usually turn out to be problematic in the long run.\nIn the C solution, there is no allocation apart from the input but we do a lot of unnecessary work.\nIn the C solution, we use\nabs(x) == 32\nwhich we could avoid by doing\nx*x == 32*32\n.\nThis coincided with me listening to an interview from the VLC developers saying they wrote hundred of thousand of lines of (multi platform!) Assembly code by hand in their new AV1 decoder. I thought that was intriguing, who still writes assembly by hand in 2023? Well these guys are no idiots so I should try it as well.\nThe new solution\nI came up with a new algorithm, which on paper does less work. It\'s one linear pass on the input, and does not allocate.\nSince the result we care about is the number of remaining characters, we simply keep track of the count as we sift through the input.\nWe maintain two pointers,\ncurrent\nand\nnext\n, which we compare to decide whether we should merge the characters they point to. \'Merging\' means setting the two characters to\n0\n(it\'s basically a tombstone) and lower the count.\nnext\nis always incremented by one in each loop iteration, that\'s the easy one.\ncurrent\nis always pointing to a character before\ncurrent\n, but not always directly adjacent, because there may be tombstones, i.e. zeroes, in-between.\nIn pseudo-code:\nremaining_count = len(input)\nend = input + len(input)\ncurrent = &amp;input[0]\nnext = &amp;input[1]\n\nwhile next != end:\n    diff = *next - *current\n\n    if diff*diff == 32*32:\n      *current = 0\n      *next = 0\n      remaining_count -= 2\n\n      current -= 1\n      while current == 0:\n        current -= 1\n      endwhile\n    else:\n      current = next\n    endif\n\n next += 1\n    \nendwhile\n\nprint(remaining_count)\nThe easy case is when there is no need to merge:\ncurrent\nsimply becomes\nnext\n(and\nnext\nis incremented at the end of the loop iteration).\nThe \'hard\' case is merging: we set the two tombstones, lower the count, and now we are in a pickle:\ncurrent\nneeds to go backwards, but we do not know to where. There might be an arbitrary number of zeroes preceding the character\ncurrent\npoints to: the data on the left of\nnext\nis sparse, the data on the right of\nnext\nis not.\n[...] 0 0 A 0 0 0 0 B 0 0 0 0 C D E F [...]\n          ^         ^         ^\n          |         |         |\n          target    |         |\n                    current   |\n                              next\nSo we have to do a backwards search to find the first non zero character.\nWe could memoize this location, but that would basically come down to the Scheme solution, having an output array of the same size as the input.\nAstute readers might have noticed a potential issue with the backwards search: We may underflow the\ninput\nand go out of bounds! To avoid that, we could clamp\ncurrent\n, but the branch misprediction is costly (an earlier implementation of mine did this and that was almost twice as slow!), and we can simplify the code as well as improve the performance by simply prefixing the\ninput\nwith a non-zero value that has no chance of being merged with the rest of the input, say,\n1\n.\nLet\'s implement it in x86_64 assembly!\nThe x86_64 implementation\nFor a gentle introduction to x64 assembly, go read an\nearlier article\nof mine.\nBITS 64\nCPU X64\n\n%define SYSCALL_EXIT 60\n%define SYSCALL_WRITE 1\n\nsection .data\n\n\nprefix: db 1\ninput: db &quot;xPGgpXlvVLLP...&quot; ; Truncated for readability\nstatic input:data\n\n%define input_len 50000\n\nsection .text\n\nexit:\nstatic exit:function\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\n\nsolve:\nstatic solve:function\n  push rbp\n  mov rbp, rsp\n\n  ; TODO\n\n  pop rbp\n  ret\n\nglobal _start\n_start:\n  call solve\n  call exit\nWe circumvent reading the input from a file and embed it directly in our code, something many people having their hand at Advent of Code challenges do. It is in the\ndata\nsection and not in the\n.rodata\nsection because we are going to mutate it in place with the tombstones.\nWe also have to exit the program by ourselves since there is no libc, and we create a\nsolve\nfunction which will have our logic.\nWe compile and run it so (on Linux, other OSes will be similar but slightly different):\n$ nasm -f elf64 -g aoc2018_5.asm &amp;&amp; ld.lld aoc2018_5.o -static -g -o aoc2018_5\n$ ./aoc2020_5\nWhich outputs nothing for now, of course.\nWe will need to print the\nremaining_count\nto\nstdout\nat the end so we add a function to do so:\nwrite_int_to_stdout:\nstatic write_int:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n\n  %define ARG0 rdi\n  %define N rax\n  %define BUF rsi\n  %define BUF_LEN r10\n  %define BUF_END r9\n\n  lea BUF, [rsp+32]\n  mov BUF_LEN, 0\n  lea BUF_END, [rsp]\n  mov N, ARG0\n\n  .loop:\n    mov rcx, 10 ; Divisor.\n    mov rdx, 0 ; Reset rem.\n    div rcx ; rax /= rcx\n\n    add rdx, \'0\' ; Convert to ascii.\n\n    ; *(end--) = rem\n    dec BUF_END\n    mov [BUF_END], dl\n    \n    inc BUF_LEN\n\n    cmp N, 0\n    jnz .loop\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, 1\n  mov rsi, BUF_END\n  mov rdx, BUF_LEN\n  syscall\n\n\n  %undef ARG0\n  %undef N\n  %undef BUF\n  %undef BUF_LEN\n  %undef BUF_END\n\n  add rsp, 32\n  pop rbp\n  ret\nI am trying a new style of writing assembly which I saw notably the Go developers use: Since the biggest problem is that we have no named variables, we leverage the macro system from\nnasm\nto name the registers we work with in a human readable fashion.\nOur\nsolve\nfunction can now return a dummy number and we can print it out by passing the return value (in\nrax\n) of\nsolve\nas the first argument (in\nrdi\n) of\nwrite_int_to_stdout\n:\nsolve:\nstatic solve:function\n  push rbp\n  mov rbp, rsp\n\n  mov rax, 123\n\n  pop rbp\n  ret\n\nglobal _start\n_start:\n  call solve\n\n  mov rdi, rax\n  call write_int_to_stdout\n\n  call exit\nWe now can focus on implementing\nsolve\n. It\'s a one to one translation of the pseudo-code. We just have to judiciously choose which registers to use based on the x64 System V ABI to avoid bookkeeping work of saving and restoring registers. For example, we use\nrax\nto store\nremaining_count\nsince this will be the return value, so that we do not have to do anything special at the end of the function.\nAnother pitfall to be aware of is that since we are dealing with ASCII characters, we could use the 8 bit form of the registers. However, some opcode such as\nimul\nare not usable with these. We have to use the 16, 32, or 64 bit form. This does not compile:\nmov dl, 2\n  imul dl, dl\nBut this does:\nmov dx, 2\n  imul dx, dx\nAnd so we need to zero extend the 16 bit registers in some locations with\nmovzx\nto fill the remainder of the register with zeroes. Forgetting to do so will lead to very nasty, obscure bugs.\nFinally, we always write loops in the form of\ndo { ... } while(condition)\n. This is easier in our case; we assume (and know) the input is not empty, for example.\nHere we go. Note that this function does not need any stack space, since we modify the input in place, and the standard registers are enough to store the few values we keep track of:\nsolve:\nstatic solve:function\n  push rbp\n  mov rbp, rsp\n\n  %define INPUT_LEN r10\n  %define CURRENT r9\n  %define NEXT r11\n  %define REMAINING_COUNT rax\n  %define END r8\n\n  lea CURRENT, [input] \n  lea NEXT, [input + 1] \n  mov INPUT_LEN, input_len\n  mov REMAINING_COUNT, INPUT_LEN\n  lea END, [input]\n  add END, INPUT_LEN\n  \n\n.loop:\n  movzx dx, BYTE [CURRENT]\n  movzx cx, BYTE [NEXT]\n  sub dx, cx\n  imul dx, dx\n\n  mov rcx, 32*32\n\n  cmp rdx, rcx\n  jnz .else\n  .then:\n    mov BYTE [CURRENT], 0\n    mov BYTE [NEXT], 0\n\n    sub REMAINING_COUNT, 2\n\n    .reverse_search:\n    dec CURRENT\n    mov dl, [CURRENT]\n    cmp dl, 0\n    jz .reverse_search\n\n\n    jmp .endif\n  .else:\n    mov CURRENT, NEXT\n  .endif:\n\n  inc NEXT\n  cmp NEXT, END\n  jl .loop\n\n  %undef INPUT_LEN\n  %undef CURRENT\n  %undef NEXT\n  %undef REMAINING_COUNT\n  %undef END\n\n\n  pop rbp\n  ret\nBenchmarking\nSo, did it work? Is it fast? Let\'s compare the old C solution (also embedding the input data for a fair comparison) with our new Assembly one:\n$ clang -Ofast -g3 -march=native aoc2018_5.c -o aoc2018_5-c\n$ hyperfine --warmup 3 --shell=none ./aoc2018_5 ./aoc2018_5-c\n\nBenchmark 1: ./aoc2018_5\n  Time (mean \u{b1} \u{3c3}):       2.7 ms \u{b1}   1.0 ms    [User: 2.4 ms, System: 0.1 ms]\n  Range (min \u{2026} max):     1.2 ms \u{2026}   4.6 ms    1174 runs\n \nBenchmark 2: ./aoc2018_5-c\n  Time (mean \u{b1} \u{3c3}):       5.3 ms \u{b1}   1.4 ms    [User: 5.0 ms, System: 0.2 ms]\n  Range (min \u{2026} max):     4.1 ms \u{2026}  10.4 ms    442 runs\n \nSummary\n  \'./aoc2018_5\' ran\n    1.95 \u{b1} 0.86 times faster than \'./aoc2018_5-c\'\nYes, indeed, almost twice as fast!\nLearnings\nAssembly can absolutely be written by hand, although with (much) more effort and a harder time troubleshooting what goes wrong.\nSome tools (profilers, reverse-engineering tools) expect that the assembly they consume came from a C source file and will be confused when it\'s not the case.\nThere is no need to reach for esoteric, vendor specific instructions (such as SIMD or Intel string opcodes) to go fast and even beat a C implementation that does a bit more work than necessary.\nDoing less work is the most important thing when optimizing.\nAt the same time, doing a bit of work instead of memoizing can be fast(er), even though it seems counter-intuitive, due to memory latency and cache misses.\nHaving a clear idea in pseudo-code of the solution will simplify the implementation in any language.\nNaive assembly is very fast (your CPU is crazy fast when you do not abuse it with badly written interpreted languages, seriously!), but a good compiler will emit better assembly than you if you write C or similar. Unless you are an expert like the VLC guys.\nAppendix: The full code\nThe old C implementation\nThe full code\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n\nstatic char input[] =\n    &quot;xPGgpXlvVLLPplNSiIsWwaAEeMmJjyYfFWfFwpPqcCYvVySsAUuaCcDdHlLSshxKkMmXQnNKkr&quot;\n    &quot;RptBbTqQEevKkkKVsSmMmMvqFfGFSsfZzgQTtFLlfsSFBTtbfbBiIAHhzZaVNbBOonsfFSBYGg&quot;\n    &quot;RryvaAVTtbFfqaAEetqQUubBTyYAWwzZeENRrgGaAfFnNnpPJjulLEeUaQqnNJjQtTPTaqQAoO&quot;\n    &quot;EerRtnVaALlhDdPpHvvVrRsFVvfsMcCvkPZzpKbBOofZzyYFzZsAjJavGgkKRrVwWSYygFfGLr&quot;\n    &quot;RLlgGlVaAXZzHuULDpPdoOlhgGVoOKkVvaAhOoHIiBNnxsSXbBbvVFfvtTUvVlaALPptTGguPp&quot;\n    &quot;jJFmRrMqjJOOqQZzooQRVvrKkpVvPOopPKKbBkYykYQqPpPpoKkOihHIECcJjeyvsSVpbBPGKk&quot;\n    &quot;gfVvHhiIvGgViXxlLdDIgGKMCncCNcmfFDDdSsXxqQtTaAdenNdDVvPuUpVvtTZzEQqyoOvVTx&quot;\n    &quot;XtbBnDdcCZWwrRzNaeEAlDZzeEdJlelLEzZhHhOoHYyKkLjWwNnLAjJaiHhIvhHHhEhHeSsSKk&quot;\n    &quot;sXxVvzZEevVzpliIRPprLPcOHhsSoRSsTtrlLCiISsJjMmZvnNoOVclLCVzZMmKhHkqWufFmMS&quot;\n    &quot;mMkKsiFfoRrOIUozZyYNnSNnqQsTrRtSHhNniIbGgCcnNBxXSFYyWwfgFRrfaROorAsxXSGsSK&quot;\n    &quot;BbkspPIeoOHhEiXxVvpPUfFuyYypPynNYpPSskdDKjJCeErRtxXTHIzjJZihoOZvoOGfFWwgVz&quot;\n    &quot;CUuaXxAeEnBVvbNiIAaRdDxXrmMcgCyYceyYyYEEMmgWwGOoKkqQkeEVvGgrRJjrYyEeRKYyOP&quot;\n    &quot;ZzJjpooOcCrgGtTOoRNneHiIXxnNIQqzZiHhZgGZzyYeEuUOmMbZzUjaAJuPpBozZzlfFLiIph&quot;\n    &quot;HsvVSvVUTtuDdPhPVDdPpvYyvDgGCcdTSstaHhcCHhAJgGLOOoaARVCclgGLvrsSolAPpUuaXx&quot;\n    &quot;aAkoOPpeEzGgZcCjJHhKkKlYUuyMQIiqSiqQBbIsGLLGgvWwTtVlpyTtYgAaGPSeEfFsDdgGkV&quot;\n    &quot;bBNnvQrLlRqYWwyEqQLlsSSVvstTghHGeKkKQqhHHhmMoYyhsSAaHdDuUKkOMmDdMmgGgQqRnN&quot;\n    &quot;TtVvryYlDdrnNLlRUcCurRgGZuUWwMmbBTtjJzjJbBdDaAwWLjJKDpPpcCDdHhPRrhHRzjeEJZ&quot;\n    &quot;mMcNfVvlLvtTVSsxXFnVvTxtTKkjkAaKhzZxXfFHuBbkKTeEyrRcCYTtGgtuZDdjJzUUcSsCqQ&quot;\n    &quot;gGuUqUulLRrwWQeHOohSXxNnisSIWHhwiuUIfFVMxUaAuGdDgXmdHhDUuTFWwftbBvVKAakvrq&quot;\n    &quot;QAayYWwRCcIvVijJhHrSNnsDaAdBbHLlhRPpAqZzQSsaQmOpPozQLlqhHZIDdisdDSyFpPfEJj&quot;\n    &quot;eYowWhHrnNRRUuhHLeEdDlkKyYkKqQCcEexXifFIYfFqQyFzDdZcCorRgGzqQZDdzIiMmwWrRI&quot;\n    &quot;IjJihlLHoOyYDzrRuUKbBvMmeEKkFffFsSVcYJuUjQqMHEeeEhbBYyucCfFGDdqQRmMHhhHqWw&quot;\n    &quot;oOQTtrBhHxXCcbggGGpgGPgEecCYyEeEesSisSeOovVcwWCEIPJjnlLTtyYNLtfFHzZQCcqLly&quot;\n    &quot;xXYSqvGgVQzZsBvVDoOdlLbfFGxphHqQPHhmMdDGgHszjJZShXxXYysbBifrRFiIxcChIiHgGQ&quot;\n    &quot;qqvVbBEewWQxjJZmPpUuMzXlYyHhLXDvVBbdEsSexsSvtTrReEVnNmMTtXuKkjxXJMyYmZFfzU&quot;\n    &quot;MmyVvTtFfYdDExEeXvVooOOjJTtCcUrRSwWsbBbhHtTBGVvgNDdnQqukKGgJOYHFfhKfFkSnNk&quot;\n    &quot;KOoOohHsSnNsmmMMvVFGglHxXhLfFPsKkSpfyBbqQqaxXfpPZzbBCggGdDPlBbLaAZzKeEkYJi&quot;\n    &quot;IemMtYyTlLjJEjXxsSyLlXxCckKeEuUZzrqQlLxXafFeEVvAiRrIRpmiRrFfbBzZvHhVICcoOM&quot;\n    &quot;XxiWwNIinkkKBbgQqGPpLlKWhHwszZSQuUjKkfFJcZzCVvWeEYywtXxTjJzZkSsKfFeEcCrDhX&quot;\n    &quot;xMmrRjUuOoYyJQDdqHwWMmLlOodqQMmqGCcgwWpJjqMmQKkPMmpPBbxnNzZyYySscTcCFftwWO&quot;\n    &quot;eEoOobSsBSsOoaAGoOgRWwcQUWOokKwuTdUuDtYyYiJjYyIyquqaFfwWAQUZtKkTBbzndDXxjJ&quot;\n    &quot;LlJjyxWjJDdLlsSMmGgtiGgIqQpgGTtDdPClLAasyYFlLKoOkfMmFUuBEerRYyGflLFDdnNFfg&quot;\n    &quot;FLlXJjxWHhwDOoOodOokKPpMmfoOzZupPUvVjJSBRrbYLlyuUNTXxnNtUuvVVvpPQqQqUuaqQA&quot;\n    &quot;lLMBbHhxOfFozZJjXzZhHgqQEPpeVvSsEgGAaeUucCItTiLuUlGSsyYEeRrBbZiIAPpvRrhHzq&quot;\n    &quot;EeQqvVBbGgIhHRXxrishHSQNnyYZzxXZpdDPVWXxwMvVmmMByYcCaAEebxXVvKfFlLcCcCkZzz&quot;\n    &quot;QqGgFIifPpZNnjJMwsSWwRrWmvHosSOhVIibMmyYQqTtBMoOYOoSsZFKuUkKZzZzxXPpbqAanN&quot;\n    &quot;NnQyYsZzShHUuGgSiIsYgGyeeECcsAadGgDOojqQGgSstTPpJSQRrGgUunNqpkKdDZzPhHkSsr&quot;\n    &quot;RQwtTXyYxsSZzAaRcUgGvVufNSfFsnFCrXeogGWwQqlLOKbBuUkvWwzZUuEoOKkNneseECcwWw&quot;\n    &quot;zbBWiIwDQqdAawWiIwWNnLiQDdqIAatTEOdDoeVkOopPKvQmbBKkvVbyhHYBWwbzZrQqRZDdhp&quot;\n    &quot;CcOoXxnayYizZIFfANPKkeELKDdHhvyYVCckkvVKTAadDsSHhAjBbeQqEJpPaJjXxaAAFfXxRr&quot;\n    &quot;VpuFWwWwfFoOZRrzPpxHJjhIqQiXfrRkKkKkNnLlKqhhHLNWWKkwwZznvOIioMwWXxeEmYyzZX&quot;\n    &quot;cCxVZzmMUuPKYykKyYkpiIlSAaYcCyBCwDwWdWPpcbsghHnNbBsSMlLbBTpPtEeVuUZzfciICE&quot;\n    &quot;mMMfFmlLeuwWoOnNUgGJjiybBCJZziZzAaIjQqhHCcaAcnGgjUuPpQqpPhXxHUjJuuxNnXUYyJ&quot;\n    &quot;CcLOoImMilBbLlkKGkKPwWEeuUzZHoOqQjJFfGgCckBbKzlwKpQqsSsSViIIirRvbBiZzIZipl&quot;\n    &quot;xXLPTjnNJVpPyYvtDyYwqQWdYyarRxXDdALlIDdTtTcClZyYzvVRvVrLtmMkKvTDdxXtVqQlVv&quot;\n    &quot;LPNnpoaAdDeELUwWuwxXWlOxXGgiaAITtgGyYuUzZdDynNYGwzZPkqQOoKklLxBbdQqDGyYgXK&quot;\n    &quot;zHhRDhHdWzZwbBhvYyVHLHXxhlcaACIidDVbjJxeMmEXJBbtTjBVDdpPsNnSvrRbbBMmyoBbON&quot;\n    &quot;nwWJTtOoQqIiVhsSHLlQqHhXxAoOHhTjCcJwWLltFfetTEFWwtTIyYiYyzZvVzZTOobchHCBQS&quot;\n    &quot;iIsBbRDAamMJZzjoOJjyYIidHhQqOuUWwOovIiuUCcVoWPhHpwdDJjIvTufFUtWQqvVuUXxwtT&quot;\n    &quot;iIVisqyYQiISHLjJGkKcCBAabhHiIKkWCcwpPcChfFHCnNlLcZSBbfFbBgwWzWwZaAZIizGcCm&quot;\n    &quot;SsGxpNnPXQhHgGgGFfuJRraAjOouaUuTtAbRBbrjJlUtuUEeTCcwxXrROioZreOlnncKXxkCNK&quot;\n    &quot;ZzaAkpKkRcCrRVvrPNuULfCcxdZzDZvVCfFsUuSreFdDafFAfqQWPpTeINniEBArbBRaeJjEbZ&quot;\n    &quot;nNsSFflLzZztsPpEeBbwQqwWGgQqoOFfZzWnNSyYsXKkxWwKkkcCONnoNVvGgXxFuQqUkKfjJY&quot;\n    &quot;yFeGgEcCnNFfLldyikbiIBhHKjOoJaAIYpPIMmHLlhibBIaJjyrRYbBjJAaASsVvFuUfTMNTtn&quot;\n    &quot;nNmFfqQBbJOoCcXIhHgGCciTtSBMiImBYybxLgGlwWXNljuUJjJbBdDyYhHLQqxXmtTMwWqQnx&quot;\n    &quot;XWwzSsmMkBbJjeRrsSEDdTtGAagXxKeEJjwuUDdpPdDWTCcKktjmMJjlLXybBYnNMmwoOfTtix&quot;\n    &quot;XjJDduMmdzZJjclLqiIQciqQfjJvVFOJHhnNjUuoOoFfDdpkKPHbBhwWLYGvVgSXHsSFfxNnXh&quot;\n    &quot;pvVAaSsFZtTFfzXoOxfUJjuYyRrYyqQvVSslLPMbYyBmpIiCdkTtKDcDmiIoOQxXBfSsFHhVtT&quot;\n    &quot;vKcwWvVdDlOoHhuUQaTtAqLtTCkQXxEFfeoUunNHhtkKOobBEisSIetTWwTzrlLGgdDRiIelLm&quot;\n    &quot;cOoSsYyzOoZPpdgGZzDenNEnyYXbBoUuOwHOYyplLPSsoUuSECdvPpcCVmvVLdDlDdoOUuRpPU&quot;\n    &quot;YyurxXleKkeEEAaWwHhOoDrReXxEuULEelCNVvnjJIivVPpmwWeEAabBCcwZSwWsXxyxUuXYuU&quot;\n    &quot;dXxoOhHhHggGIPpkKiNQqnSsrReRrEGXxrRfFgQqYyAZLllLzaAxbBNnXRrtTNcyPUumMIipSs&quot;\n    &quot;TtYzOnNMmxXwVQsSvVqvJjVBbTtvoOQcCcCVvqWbmMBSkKsoOvVUCTtcuDxiTtIXxCcdlLDxXB&quot;\n    &quot;FbBfbpPNfFnfFHhdDBkKowWObUUuuxOrRoDUuQqQHhHhBbqrRdiNnUuFfoOINEenNOAzZakoOh&quot;\n    &quot;HJMhHmOoCcaAQIMmiqhHmDYwWdDjJXTtnNTnNpPtCcQqiInNnNXiYtWOYyNoOmRtVvlIiLIpiI&quot;\n    &quot;PigetuqQUPqaAUrRvVugGuUsCcYySQzToOwgDdGaiIAWdeAaFfuUtuUequUQZzBbEpbBhHvVFf&quot;\n    &quot;WpPXryoOYUcCASsauofnNFiHhInNKfFgGWwWVBSsbBbvMmWNnwQqDdnNDywWWNnwrveEVRgvVF&quot;\n    &quot;fGgGfJKkjRgEeYyXxWRrwfFWhHwPIKCcsytTYyYAazXxTtEHheCjJQqoODWwgGdVahHAvcZgdD&quot;\n    &quot;EhHuUSsYxXKkyXuGgUsGuUgLjJYRrsqJmMHhjQSfwWFrRaJKkRxXGglLrRDdHhIizZBYyJjbFf&quot;\n    &quot;eEmvRPprXxYDdFfyrRMdDQqaAnNKsLpPjJleEctfTtFonNOVENnpnNZAaPjJhrREeVvbBCctEe&quot;\n    &quot;IioOuKdDkXxYyJHfPpvVHlLAayaAYhVvZzFfFlWwBLlwWQqyYFPnNpPOopPoyYiIOpJpNiIJjk&quot;\n    &quot;KnTcCEuVvtTtSsStjVjpPTCcfFteEtTxJjnxlLgGlLdDwWtLlrRTyIiYMmMmXmdDMDDddHhNuU&quot;\n    &quot;vUuJjjJlLWAauUwmUppqQPAaHhtTUuwWJjYydXeELVNneuiqQkkaAaOoKtTkaQEyYeqAdDaTIi&quot;\n    &quot;KqQkwWcCGaAQqUuIigGiIRrTLDVvCcdbBJIijhnNHsyYcChHmMSqQcCiIiDkgcCGOomMDkGIiw&quot;\n    &quot;WSoOwdjJDLlsZYyzlLIkKivXxrRnNKkMmXmMPpkBrRoOIiHaAxbBXZrRoOzQqwWhXxbQHhqAoP&quot;\n    &quot;BbZzQqCcpzFfJcCaAjuUzZZUuzqiIQwGgWjJWwFdDfQaAtTHlLFgGfBbBMmycqQHhSyYdMmyYm&quot;\n    &quot;MgUuzZujJhvcnNCPpVPpHgiIGFHhOMmNnfFoGmMvIiHXzZDdnNZzxoiIBbIihUuDmMBbdXxXcC&quot;\n    &quot;KkatTAzZFfmCUucTtUuhHCNnjeEoOVIbBjJbBXxYDdXxJjyzZNnVvApPpxXPfFtxXYBbKRrkyT&quot;\n    &quot;jiQzOoEoOeSsLtTlZqyhxgGOqQTtOSaAskiWwqGlonNTtfVvvVFOLEegaXxAQRrJztTrROoQqZ&quot;\n    &quot;jZzZhHBHhbeXxYQqyxEEexXYYZzyFfDcKkWaAkKwwWOozZIiBuUTtxXoOAHhsSWLCcLlrSssPp&quot;\n    &quot;SIbBlkYyXOFCcfxXlfFLOoMmuUohHOmMoGCcgSsJWwjDdLlcpCcPidDwcOoCVvLbpPBEebmMSD&quot;\n    &quot;yYeEdnlcCHhPzZtOozZdDhkKHTWwZzwhHBbtDdinyYNjpPJccZzVvYyChHRrDGkKUuxXUuaDdw&quot;\n    &quot;QqKuUkLleSsERrRxXnNTxXggGGnNmMSsmpPBGgyYFyiYymMnNeTkKcIiCkKELleLmMgKkcClnF&quot;\n    &quot;fEeSsdKLmMlkHDdjJuUiPdoOLlBbXsSxbBojcCJmMOCcUxXnaikwMmMhcZYysiIHhRrCcZzxXn&quot;\n    &quot;NyYbQqAajJUurRQuUutTkKUnaAJsSjXRrpPeHJjoOhYyEoOeEUeOFCLAaRrloOFyoOYfWwwSrR&quot;\n    &quot;sWwWMiwWQqWwIlLmAaHhRriIOVvQvqQIiotTcCVChKcCsSbBkKkeEFfEePdUwWuDRSiIsCcJAb&quot;\n    &quot;HhBeFLlfjkKJqVZtiNnPpiNJjnvVxWwSsXpPINnKEyYpPpPjbnNTtaAWfFwBtTvVJrReOoEcOm&quot;\n    &quot;rNnRuUoUuLlnNcYdDMmcCDdLlAiBOoNnbcCZzbENneIiwWsSDgmMGkKwGgEeHxXhyMzZrMmRmn&quot;\n    &quot;epoOdDPENIMmiZzYfFVvAnLloONhHaFPKkpHhdjzZJNKkcmMCsSKkLWwKkRrdDlQqHobddDlUu&quot;\n    &quot;oajWwmhHMXxLLlnTpSsTtPtTtNeSNnsalLAEjBbGgatTAtTJjJDAnNkinmMNrRSsIkRrtZkKzB&quot;\n    &quot;bMmVQDdqvmMuBWkEeEexXKwwPpzZYydxXyYxmoONcCKkRWNnwZzrljJLCVPpvaAtlLwkKWTcbF&quot;\n    &quot;fBdrRguUVXdVMLlmvwWVMyeEYmHRuUOcAaCoGoOgyxiBbIXFfuUroAOaAcClLoaeEODdRVvrHC&quot;\n    &quot;ZUuzcDWdoOaAUuDOQquLOolUojJSsxXoGgOxMmiIDpPdGguUIidDIixXlLLlmVvpPHhQPaYyAk&quot;\n    &quot;KptTXxXjJwLlrRPpCcWwZzqodDPtToOXxPporRMmHdDsSmMsHjJlCxXdyYDzvbBPkKpVvLEekK&quot;\n    &quot;eEkSPpZzLlOVvHhCcosbBSJmsOoSNnNnPHhKkaVvZzoOoOaAeoOoAIiaUutTgVvGtTOhHGcCxO&quot;\n    &quot;oexXKjJLlkiJqQjDdtTeqdDzQqAaGgZoOMmDyYdIisnyYnuUNWrTvVgLSsllLGgkCcTtoUugGO&quot;\n    &quot;KGtCcZzKlLbAXUuWwrRxaexXEUuVqQvBYyYyrRzxXZvNNyYrsSRPpHhChpdDJjPIiKkHhrRHiI&quot;\n    &quot;SswCcWwXgKkcCGxUukaAKkKszfBbDdiICSsbBZzwicCjJIfqQbBFZzBbRrJVDoOdEevjuUyYTt&quot;\n    &quot;wGBoqQSjJsgGObtDdEeVrfkgGKFUuMmNJjWwHnNtFfTsDdtSsTZxXzWwSYmCcMIiyhnkPpsSOo&quot;\n    &quot;KNVwWGgvFUuOofSAHhlLaIiuUAVsSvcBbCVQficoOjJVvCBbUKkdDugGjJPkacCAgkMdDmEeLl&quot;\n    &quot;SsKBbKkXevVEZFfbHheTvpPRjJdGasrRSJjAgTJjoObBUurRcWwNnCMmFQquUvbqQBymMYVsOE&quot;\n    &quot;eozIiLlZkDSsZzEYyhDuCcxXUOUDduKjJgGzZhHkoddDsSjGzZggJcCSsbrqQReEBPKrRHhkeE&quot;\n    &quot;pjIioOowWOAaoOkKhHqGiIkKjJdMkjhalLAHaAlLxvaluLljJLlVvrQqrPwWwWzQqXxkwWXxKZ&quot;\n    &quot;tSsTfFuxQqdDfHhFXpPFEembBbEqQeERCcDdxXaAPpsStuBAabGHhgwzZPpxipvVkKeEfoOjtC&quot;\n    &quot;cFgGFfdnNoOKVvefFEBbHhkNTtKkrAaZzdDrbBRwwWyYMmdBbjbBfMInvVNEeGnNgiIdDDdRrU&quot;\n    &quot;ugxXTtScAaCsuJRrjHhpPUGKZPpzXjXxuWwUcdDCyfFCrRcoORrDQqDdBfSsscCaLliCgGPrai&quot;\n    &quot;vxXFfVIAJjRuUEDdepgGZyYzQNVzZvUkKZPxpPXGgRrpzwKsSlLkMmaalLmMDEelLcCTAuUfcC&quot;\n    &quot;FoNvVnCcNcbrRSsRTtIiqeEeENnTRrdDkLlJMmjoqhHqQqmMQWBbwEqFaJjIiWwAbzZzCtTgGc&quot;\n    &quot;qFtTfGgSswWAnhHNhaAHMKbByYKaAJEzmMdEbBeKkcjoOUTgGtuMmJNZznCvvTtQcCqVitFffF&quot;\n    &quot;yhTtTtpZAdDaXqQxWwCvJzaAQqAauUZwGgWjjJnNDMmDdgEUaAsSaeEMmAubBFRrgGHqlGgLyY&quot;\n    &quot;NnEiIrBbHhiIKktRrTRNgsIMmMZzmTtnWkKQOohHGgDdbBLlxXqwemjFvgGJjhDiINnHyeKeEm&quot;\n    &quot;MaAxXhqQQAaqrRHtTMkKLbBlFfFMmfXhLQqzZMmtKSskDiIbBcClLdpPBbWECUuqQceLRrgqVv&quot;\n    &quot;gGQezDdinJDdNPpRrAVvOoaZefsSsdDMmHGFCcfPsaoOAbBVePIgGYVaAOoAdDDTtdIiavAeeG&quot;\n    &quot;gGpSscwWCYlLeEyexXIiEPKkeEdDAxRrXaGgsJvxhHHxXllLLhdDPiIUQlLSsqVvflLFVEXsSo&quot;\n    &quot;JKkUWwukKjwWsNnrRsQqSStjJdDdDFfdcCAsvSsiMmIlLDfFuUIQIicCqtTRCnNcriVHKVvkhZ&quot;\n    &quot;edDERryYyYnNzSqQsTYiHhIXxiqiIgYyoIinQxOoXxiIXVvdDIwWmUuyyYAaJjYGgdDrRSsAZT&quot;\n    &quot;tzDdaNYyDXxdxgGgcqyYmMlVsSwnNWQTtTtqvnNqQbBqJZziHyYNnCyYIJjBbDdBDdTzZtuldD&quot;\n    &quot;LjbfrRQjJqFBUNnujmHhcIocVnNdDaAtTvCRrgaAGHhOBbsZoOPiIprRksSKLWwXxIioOdHiIG&quot;\n    &quot;gLExyYXmOoInNiZzMeGgfFyYIiEgGaAPpVvIYJjbncCNBTtyErRAkKasSeoZzOMUuAmNWwWFAa&quot;\n    &quot;YyiIfRxBboOQqeqQluUwzZTMmDHhNbBnzZcCHMmhPIsSiAapDNnqQcfXxxNnrRZzXTtCGmRrtK&quot;\n    &quot;kTMZOKknWyeNdJtlLyYgGEDdsSsYyCciTIgbBgGGstefzZZzZzhIijcrRCTtboDdOQqWwWmMSs&quot;\n    &quot;uuNkCcDdXxiIHoRMmrENneDdIiVvxUuohHUuOaOolGgYUuyJqQVKkVUGBbgMlLmTtwWWwYyTEd&quot;\n    &quot;DeaANnNnRrBAavRrVbHhhbBiFZzfIHtMQWwVXqvTtRrVksSjJDRrPMmhnNaApPtAaXxnNqsSKM&quot;\n    &quot;ZcCzYyEjJedDBdDIKtEepPKkQqXxNdDnocGSsgVsmMVveESfUUuuFSvVgGrVvxXvVaFfiaAIku&quot;\n    &quot;TtUqQjMmkwRrQqkbBKxZztPbmJSsXpGgHhPnNcJjpdYyDyqTJjeeEdrRJjDXYdDxXAaFxglLfF&quot;\n    &quot;mRreEvpPuUtBbUusSPfHhydDYfRrXxqVvQKkYsSyMSSssZbBMUuwBRrrRbiuURrRIxQqwpPKvV&quot;\n    &quot;kWfFEFgGpPlGqyEebUuBqZzWEuUYEQdDqLUhKkHRrXCoOwypPJjOoFfzGgaAAaZuFoYygGGgWD&quot;\n    &quot;IskKvDdwScGgXwPTwWthjhVAaAakKvnbrRXxysSiUXMmxiIxoOmMweoWyhrBbRVvHYvrcCiIkK&quot;\n    &quot;ZiIwVkKvZDdDCiutTUIoOIicdzkKzZhrRMmAaeQqkKBbSsOFfoVvEoOHGDmMKkdiJjuUUeTtim&quot;\n    &quot;wWTJoOfSsFjWTtxXwuUuqfFiIQUhmMGgtTHllaAZzpLVOzZHxvhHtTdNnNdPwWLMNnRruUwPpW&quot;\n    &quot;OogGVvDeEdnNzZkKkMmDdKnqQhFNYwWgGNqcYyZzRLlrpPkKsSLlLaAAaQsSVuVHhvjJUdVvDq&quot;\n    &quot;HiUpsPpSKkNnyZDdAJjaYyYnZzKYyCcvNneEVwWTtdDkNrRXxaInNuxBOUUuuZSPpsSVHhPpjN&quot;\n    &quot;nKjqQJuUCtTCcKuFfUNaAxMmgPpDdSEeszZGaAMrqQRvmONdDnpWwNnjJEePvGEewFwZzWjGgc&quot;\n    &quot;CIiDkKXxmMGgcCZzkKdCcdDGGSobBvNnVKvVVqQUznlLZzZqQCzZvVmMaLlGgCcJjFMmfvVFso&quot;\n    &quot;OSuCcyIzvVqQrCcRNQGDRFfYGJkoDdZzjJToNQqSNnsnDpPdqQTNMmvVfFcwWqTtCDdqaAQGgW&quot;\n    &quot;CctTxXCqeEFfVsSaAULrBblnNmMpxXZOozxXPRrSJfFqZzIiwWnYycClYfFrRSsjJyLRrnNFtC&quot;\n    &quot;czakYyrkKgGCkKtTcTtQqhwjJjJftYyqQJvVjTTtFOVwWAWwaPbVvyYdDWwrRBoOJjgGRKkUvM&quot;\n    &quot;mVurhHyYHuUBfySsYyYqrRwWQTtepmMQikZfFzrRIVwWjoOJhHPpuUawzZWbjqQJdiIDBfFAhS&quot;\n    &quot;gfFYlLLhoHhOZzmMoOgGDyYdpPFKkpPgGuUfkKEJrgGUuCEecRJbCcBEuUevmMSsVJwWCchdpP&quot;\n    &quot;DYyYtZPpNKIikSslLcCfGqQrRvVQYuUxYpPUUuzHhUuTfFxquRSsdEtlduUDtTMrjJRhHPvJjI&quot;\n    &quot;aAQqilbwKrRAaFnuUVvNfYhjcCckKcCcbBCaACmEehHgGQqHBbDdhpPHhnNqQHhcCIizZEespP&quot;\n    &quot;SyYtDIeBOorxBXxbJjXKkYyYegYyyCsHhEeSGkKgXxGdCOOOuUobBbnNBVvxXiIFjJxXjqnNkK&quot;\n    &quot;OojRrSsJQXxDdrRBRWJjFTyYtfZzTMGqQeEFfNnRrRDPpRrITWwWFdgGDfnBbyYfFBbReEhHfD&quot;\n    &quot;dUAaJjkKQvVzZcCquyYvzZRrMgsKWNnwkkKvVPpCcAaFcgRYyrGqfZzzZLlGqMPqQmbFxXaJkK&quot;\n    &quot;jFgDpuUbBXxPdGTyYqWwQBAaUtTucFfCACcSsakLMDdykdDfFUuRkKtTvQsKPRuUcFfkOoPpLl&quot;\n    &quot;WwmTtiIQqMbIiwWBPCmlLMqQVagGAZzaJsSUQqbXrRTtGOogxrRlJjnNxXBcCaAsSsvgxXGPpV&quot;\n    &quot;YyqtTxdixzZXGpNmrRMvHhEeVFzgBbGZBbnOgkIQqiKFfgAadDGBcoOEeCbWLlKkwXoRrcFfHh&quot;\n    &quot;YyfyYFGLIKkBeELNNnbnNBbBbztTZtTnNUuBSslcyYnTtEeNHhRrpmMPxWwXGwWokFYyomWwmx&quot;\n    &quot;XzZOxdmiTpemCcZzHZzyYetTleELEhjJHsSLlvMneElLBZFaejJxXEKRKkMmAatTrciXMvVUum&quot;\n    &quot;xByWwYVaArFiIsSSNSSIiPAgAaRrRXKZdApPaNnDkBbIiCZqBwcCWvVcbnrCcHIigMmgGAabRr&quot;\n    &quot;BLlZdDZzhHzOPmMCccamLTtYyTJjWMGgCcCCDdZkKlLtTvVNNnnzBvYyGgPpPAasdHhcCfFsSX&quot;\n    &quot;xqQYyOoxrIizZPxXtTdUuDUKkLuRrBbUluUISIisifhHqhHGgWwSDdsDVvwWTrRsStpEcCuxwR&quot;\n    &quot;wSsYJjndDCuUcCoMmOIeEisSUuiuUfuBbYdDyHhLvJjxXvVVlUoOZOGBhBbHbLsSlBYyLaAlYy&quot;\n    &quot;izjJRrsLxhHIiXcCxvdDjJVGgSLVCcvAalsxXPsSpBbXeiwxNnXsmMhVvHZpcjjJDPpXEcCexg&quot;\n    &quot;ERkZzKCNFfSAatNnTqQuOoCcUEeEeCcYPwWVvtdrRHhrRDkKVvNnQqoOIaAUuNeDCKGgkcQqAa&quot;\n    &quot;JjmMKuxXzLGgRrvVvVPHhvVwWMwQrnsFYfFaAbDlDvVtXbBpPFfXxxaATnNuUfFhzbSVFfDCgq&quot;\n    &quot;fFQpjJLlPynNoMmNNmMwWNQqsSDdnBbnYGSsjJgKOoPQDdsGgSqmMpBbkdDsShTDdtrROJvWwW&quot;\n    &quot;pSsuUPwZMvVmzGgLlqQduhUuHYWmrfFnNyqQiiIIYkKRaBXTkKNubUWnNycaACCNSjkflLAdnR&quot;\n    &quot;HhaANnqAxUuXMmaSTtsCcIiKkeEAjJaFBLlQPpgOlLsSrzYyEeeEzfFRRXyVoJjOvYtTPpBYzB&quot;\n    &quot;DYyhAtGBbMmtTcfFZGfKkWwFWwgzIhZzFBGgxXxUaAiqQRzNLPgGUupBbGglTtcxXxvPGsIaKk&quot;\n    &quot;mAaiBEBbnNhxBbZLlwLyYllspwWTEmMmMZmjJMKmXDdxvVHhDddkirRfxFfXrDdkkAalLvVUmn&quot;\n    &quot;NHhCcrMjGnEeNSsgYybfSHhpqQUunNMEiRrIeEeqaAeEpqQGMmgVtTvPzZXdDxpaAPVVZzcCRi&quot;\n    &quot;IIiryYQqfRcUUIiuohBMmRrfTZgtFvsScqSsgGQQOvBWmzZffFFtiIlEeoOUpPlvVLZjJHhyYx&quot;\n    &quot;ZtiIOotTHaAcPXxpCdcCDzZicCXVvGbhGgZOoHhWoOJjPfFBSoOsfIsSiEeFVWnNKTcCeExliI&quot;\n    &quot;aAqNTtnPnOvZpAaHyYsSUuCcAVvYBbyaWsSSBbQqshBbgGTNntHiIHJoOjicfFYymMCIhkKuHG&quot;\n    &quot;gQoOUzvVKbBKAacuUCAANjJvVnzZwMOkKhHnYiSsqsSuUUujHfFhsgGXxGWwOUapcNmMnTtYTt&quot;\n    &quot;XYwglAagwYWwNBZzblEeLGTtgOrljJLOoxsNnQEslfFSsgRrExaAWwaAMxXPbBHdaPpmMjJeBb&quot;\n    &quot;ZzExXEezHRrNqOKkExrpZzPNoOnSsfFwMUFfCgPpGtEbVIiIkKoOiaAiZzBHnEuiIUxXQdDCbB&quot;\n    &quot;cezsSZQqfodLlQoOkKdDDdiIyqQIaAkxtiXxaaAATnfFUuNVCctQqzZTnkKyesSOlLFfBbkVVe&quot;\n    &quot;EXqYyYpkiILEEyYecCAhrRHHhYuQqUyxXFfaNnxXaAHlLBhHbBEqQRrMmetTWwbWwCEtLloKkO&quot;\n    &quot;txcCXTpPTecSuUppeEnOoNAaEUueCWDdwckOaysSMuUlskAGgaKXazZIBbHivVIHhtlMqQlGgL&quot;\n    &quot;FqBbQVCcOhHMmOcLlnslLaASYyNCxtSsUuWCciCcSsmwWnhWkZzYcCWGgwQAaEePcnNaAtTpPN&quot;\n    &quot;QqRrnUuIOuULlTtJaBJjNRsPBcCIGwNnWCsSGgxoOlDuBbqkKKkHdDgGeNnlLROLoOlXFSIisY&quot;\n    &quot;ynNSsNOjzoSTzZbBQfVaAvFxXiMuUbBOBIiLyfFIqQiiWwAaEFfuUCVLDdlvOOEpPgxXZzcwWe&quot;\n    &quot;EnNhHCUcCUuAatnKkWwRriINUwlRrLWuwzRrZToOtWZggIiGmJjVvMSaAXiKeEkIxivVQqSLls&quot;\n    &quot;lLSsQtTqXxtjLNnkKxNnzqQvVOoNxIivlLpdeFfExXDGHdwwWJjWnXgrRGqQlLxTtIiLlhRrMm&quot;\n    &quot;VNNEeAQqaXBMcCfrWtFfNDdNSscIwDmMsYtDdTACOfFolUDdszHSseEOJevJxXjbGSsgTtSWwH&quot;\n    &quot;RGglLXFfTtcCaAZKKNnVvEeQsRuvPplLfFTtHhyJjHhEzuUiIZYhSGgYVTaATTuUttfFLluUbZ&quot;\n    &quot;zBCngGUxwxTRrHmfFeEfWwVvrvDEMmuUuLHCwWYyNncJjHhOoRXxvsShHVrQqiICbBPpIpZjOI&quot;\n    &quot;AaibFpPZtTKGMHhwAiIKsSsQzZliPuGgwjAWyYoOwFIAOoFgxbTHbBhtHhuUIiGTkcXNpPQqnL&quot;\n    &quot;SsGDagGABbdSsKkNMmnzMNRrzFjJhHfIeEeEGgHhFfZzexLlXNZJrRkQWkiILlFfPCcJQqgFiD&quot;\n    &quot;SWICaAObSMmsAatHhTaMjJkGbBvDdVgkeEhkLZfzxXnNaAlNnhMVvdFfbBHhgBwWeEbBbUucCW&quot;\n    &quot;wbBeqQEyPpYFMmFFfhHLVvzZAGzbgGBSQqQvPqJjKAanZzwPIxXUHrRtJjaGgEesSgGIPsztpe&quot;\n    &quot;sSMmgGwWezlLnnNSsogGOTBCqFkKaHhSgGqlLGgNrVxXpbBbbaALgQqOoVCSslLPprgaZzHhgw&quot;\n    &quot;UEeuDUKeEEekcuUAacwKdDHqQhVvsHmMtThIUWFfwEMdDGXxhZGcFuyAaYdDXVfFnnNmMnNXxp&quot;\n    &quot;PpPVvAgGfFaNSsWtAapPTAaNqQZznyDPcyYJtUZzhDJIiKkjIifyYFtveCXxuUcCiYyxUuXcBo&quot;\n    &quot;ellNnWPpPpFfnLlNIUWXjikKRrCYycfFjqQkKWaZzQqbHhUalLAbCcBGhKwWkWlLcmMClUuLEe&quot;\n    &quot;TtVVzBdKwsSWmjlLosSOKkBOogXbzRIYNnNNNHhnWwJHhfunVjJjnNDLlUeEilLSmJAZvVVvza&quot;\n    &quot;YzZLlyDdzIFfyVvVCchHgGQqevVEpPnNhrgGWhHwlLQqsDdSYxVvvXxTEbiIBePptlVvajJFfG&quot;\n    &quot;gskKmlLeDHcCfFhtuknEomHhMmZbdDBtTLsdGqQXWVvwrRxggxXxqQQqXGxXkKInNBazDvVbBt&quot;\n    &quot;aRrUmNnLiIgGrdjECiyGWLsSmeOuUoluvcCVcthHDMmIgGeRrMmXjYyQMJYyYDwwXxWhjCdFJj&quot;\n    &quot;rzZpPhHpVvSsfeHhWGgMZzmbBlLHhUeEuHiIRDdqpPQkKliIKkpPQjlLyCmpPcIiUuQqjKwKYy&quot;\n    &quot;kDduUiEgGZpPtpeEPNnTlokRrKmMOyYQBYMZzyAaboOLZKfyYFXSaAmMYHhxXgZzGySgqbBgGo&quot;\n    &quot;BJjbOkKYyaKfPpOoxXyUuVRrvYQqFmMeEYyWwmrRhivoCcwWOQaHhArRBEKkelLOodDRrgzZiI&quot;\n    &quot;uBbUNnLfVooOVXxvOvAaRrBbFBbkXqQrKBEOoebkgyYKnNkuUWwGRoOsSTtKmZzAaoGguBNnBb&quot;\n    &quot;mMVwvVPlgHFZIiSTtwWsxXXxUuWrRvLlUtTfhHUuSsIYReEUurCUPIgIzlLJjZiPwWeETthrUi&quot;\n    &quot;cWwJjFvLGPpDdcCZtTzhHcrcCRCfHhFlLMbtaAgiBDdlGJoOOoEeeVUbBKkMHjYywgQqGWveEp&quot;\n    &quot;PCGgHWNnATtitTPQkkKKaAmxXdDMgGqRrmMKkprhHXxRCWwBqQdjJMBbiIOoSsCcSgvGgXSstd&quot;\n    &quot;DTZzqfNnFQeETiuPpPpkyYnElDaPpyYAdsKpfOPpoUuJLludDCyYlxuUXeIhHXTZViIEecCviV&quot;\n    &quot;vIzZzfZzsUuSNnqLXjJZUuNmMbBiInzxhwWpmXYynSrRxXgyjJYOopPGsaAxMmGQGNOSgeEMOE&quot;\n    &quot;eEfoTtOlEeWNWwLlaRfMdDwIlLTxyYXBbWcyWAaXuUxszZSaoOAZjJBSkKsgbUuDDNKumYxXmN&quot;\n    &quot;nLiNnFfIhRvzQZzjBKkbJmOVBbDpPdtTWYKdeEjJuePmMpOoVvDdbJjLlzZFwzlWuUwLnhHpPO&quot;\n    &quot;omMcAxGLlOLdDsSlkKiZzwiZzTBEeqQbrRPplnSsNLUuBZxOBiIDdoOjJLlugyQgfjiSoBbOmM&quot;\n    &quot;YeJEejrREZnNCczMJxSsbeEvVaVahHynNuNEeqQWtsSTbIAaYyMXiJjIRryYOoWsOpPPIdRAus&quot;\n    &quot;EbpEcCrRrjJpPBYPpLUeEtfBbFrRZHoxKsSfFvFBbfVaAmMZzaAbByMtTGgQqZzTiItqMmxnqN&quot;\n    &quot;XxknjkcCFDdJjVEeAmMbBSsavhvVHUCOoOJZpHlLvVhHHhPpQlLeKQLlqkQOouUkvVEeeESsHQ&quot;\n    &quot;VvZwWEezUVQAQqNlEHlLhewBYSDCUuNUuLlAQqKkBmQAVZWUdDyXxmTtYyRGgTGwWBKkGgHhhK&quot;\n    &quot;kbBHGgCMkKmHMEemcxXoJxedDEXsSBqQRLlYyMGgmeERkXxzZUvDMnNJjmWwhlphsHAigNnSsR&quot;\n    &quot;rNUQLcCbBkuHhgGtTUNpVWtKkTwivVIGdrFpWwPnLlMmFgGvVDMmqQdpleEaLlAfFKkwWLxXxX&quot;\n    &quot;iIzsTYymCyernsBOAaobBRFfayYwwoOvSsSsVWNLYylnNHhFhvksHicpOcaegGHhevxyjjJaaA&quot;\n    &quot;fPmOcivaqQfhAagGHEiKrRFuuedDfWwHhKVgdDvVUJjlLTtxgJhdDVhHhHyDdYVHhxAVvVDdva&quot;\n    &quot;fFfFKUuTGRLqQRrMmrzQquUMmzZZkgGvNrRZWxHhXWmGoRraAxXOmMXqQKCfLVvzvVNnpPZlUu&quot;\n    &quot;hkXukKUZzXbNnnAcdIGioOaAjHhpXxdDRruquUOlLoVTtvTRGRNgGLkKhHJzcUrqQRNcCnDrTs&quot;\n    &quot;UzLloKmJjThnNPEeptTHUurVedcCMpPHhCcoOAaNMiILlyYOsSjJqQqQfbBMwtpPKjJkWwvVTC&quot;\n    &quot;cDiIjEwfkWwLiIiNnBSkrkIiEejUqQiKkicTeEdDPPpBbhHpBbGZzgJaAMmUxCcPPlKkLKkjJK&quot;\n    &quot;kzZUsSCXxhHcbkKmzYpPyCIiWwcZzSsUAkQYqQEfrWcVLlvyVutTUoJpPibSZzQqYdUukGgKKM&quot;\n    &quot;QoOqaAwRrlLiIGHhkKxjJXXKQNnuUxhyYopUZzZzKIiYyFXxWwfKxXwWqsSuVvUseEMmGqFfGJ&quot;\n    &quot;AaPgxyhHYhquUQWwAAaXfFxEecJyZKkKqQdwxXWPppYCcyPqzbiIunxXfRiJjIebiMmYyABFIi&quot;\n    &quot;zBbEeDdZMoOmfgxTdoBdwcXxgNnxXOhHVynwWVjOBbVIiMmYggOiHhIbntCosSOsSGSsgGgUuI&quot;\n    &quot;qoCaUuwaAPpWAchWaAgGwHOqsXKyPdHhkKcCDdCiIvxxXEgfmMFaDwWghHMmvrbtJjTINnlIAg&quot;\n    &quot;GuRrLlUiIMmairxLaQQuUqQZvVzKhtTkVuUuUvKbBUulKXAKuUkaMGgmonZzOoUuXxyYGELlZm&quot;\n    &quot;MlLWmPUuMmuUAaSiwGzgEwvcLlEeTtCYybZznSsNZiImMwXxWgxNnqQJDnUIbqsWDdqdJffEzZ&quot;\n    &quot;eQqEfCcFpPtKkTkiIUkqrRXywWwxmyYqQCjJBlJtuUoZjuQdlLdzkKEGgqQsmgGgKkZzxXkxlJ&quot;\n    &quot;jKkLXKdsSUuDEqDnUsSfEmtYyfQqmMhfFHCQpEvVeqQMDjhODtaBvVAJjadaQCcqVWwpPsNkKU&quot;\n    &quot;qQJoOvzZSswWPpOozUijzZyzRQqsAxXQpPhDdDKkfiIFsoUSoCgWwwltreEOoRcCgGweEuUrVf&quot;\n    &quot;soVvaoCcONaMmaAFMhepXVnQqiIlLNtlLCvSUuIiskKZUuLqQrgGzuUVvspSalLDPpfFKDdkdr&quot;\n    &quot;erXWwTMaAmvWtTdDhHwnUuNXJFfjyYIRrDNniIdZzoOXcQqczZxfFXERrheJjAPGgQqmMXLOol&quot;\n    &quot;UulZzdqQalfGtduUPAUuAWzwWwHULIiluAbBavqQuMmguuNnyYUysqfUGgCUvZRwMmpjvVvKki&quot;\n    &quot;AaNmkOVPFQqiUhtTVVvvBbjJGbDwWdwkWIxhyaFIifAGTnwQxXWDfjFVvqFgXxdhHDGrRJjHvk&quot;\n    &quot;nNKkLVvlCpPcBjJrjJRrbBRhHZCkQJjqKtoDdPnCSnNsCcEjzhnYyEeKkNdDIUyFLosSkKOlBs&quot;\n    &quot;SSKFKkKkVgQqRrMcClCVvhHcozlLXxXOoWwqQuOWwWmtTIiyYyaAPpYuOiepPEIoquUgGuRvVG&quot;\n    &quot;TFfvSsVxPIirVvVKFMmVCIyZGJlLjwHmMctTldDJDMmFfuMMIHdLemRhHrSsrfYNEjcjHwWWHS&quot;\n    &quot;GghZznNSsHDvVdWwBIiTuwWDaLlkKyYbBTERgANnaEelLzGghCaZAabBhTtLUGguDFRrGTtgfG&quot;\n    &quot;zYyZzxgGXZgFfKQnGOoRrqQxXiItMhSIzZNniObvVvVRroRrqaAQBUvVdCtTcjJkKFFpCcCcbB&quot;\n    &quot;lLPsSHhLnNzNTStPXIWwitCWlLNnweEcrkHhYPqQtTpXcKwFWqQxcCVulOmvDawWAzNcDvVdEW&quot;\n    &quot;wQPpqWwjnuUIdDiCupUBbRoOrpPPvVpFLRcnLJjlqQTVhHAHfAncCNhHIiaoMmpuUApPaPADrp&quot;\n    &quot;gwIBbMGgvzZVstTSmAtTivnmuEeZzUbBnDQfFSsqoOHhHHLvVlrOoRbBLSsUuUtThnNLUulMmH&quot;\n    &quot;kKuGMmPqSwWwqEKkegeEODqYkMmKbjvRrfFYyVfFeFqQfWoOpPjzjPihXiHhPpHhWqdLlDrRKN&quot;\n    &quot;nXxlvvVCuUcZaADdzUUaAuKkGiwxXYyCcWIuvQiXiEELEekbBzZKaEPZfdrKiIWrxXovVZZAZz&quot;\n    &quot;xQquULeMjPHRXdqplLPqQQdkgejJxeEyYXYyIJJladTDoOpapEeslTtkmMYatwQqeEbgGgGsSP&quot;\n    &quot;pbuBgFLOolSwEpRrENEWwteZCczPNnHRrjEeAafFSkKZzESOokUDAfFVvfwAaWIiUPpzgGuAan&quot;\n    &quot;tlHKiLDdnNXFXxfxbBoKdDkOSsHhSTMLURrTtucePRrmMPpoORrhHWwUTkzKRGYqhHQzcChOHk&quot;\n    &quot;cyoOEjiQqnEegdDNnGOoRjdDpMTwaArSsWWwnzXZzAMmmMaDdxFqbBiIgGlEPpXZzpPDLkKVvl&quot;\n    &quot;mPpobeaAfNkKDbnISDdYSsnNRrvOoToIZoVvGjxRrwVPpPpmPCAvjJZzAlCcMmYtXZWrVvWzMU&quot;\n    &quot;IiVVfZzsSFQjJhHqQNRrkKKUOouIijMCcXxtCcrbTtCQqXeIiEDEedstDdHSsfvVTtZyYbHhHd&quot;\n    &quot;DMTtovNWwPaXoGHyYFlLNjJJjnLlRrJssvVSniINScCEoeRrAWTtoOYKzVvdxRPZSDdsKqQacC&quot;\n    &quot;cuHhCGgcHHsqiZzIKkJvnNjgUuGFUVvufoiCIBIkKRvVmtlBbeExEqoFUumMJHxcZhHJcdjbBJ&quot;\n    &quot;DwWdDZqsSXLJjuLzMZwGglVqSIimMkOgmQOCRrcCcnLwELltWUuYRuDtLlTsSeakipPYsSvVyI&quot;\n    &quot;PpKGdVEenNvxhHXXgeECpiIqdDFxLGRraZzEfFeEeTzxQkwaAWsgGhHeCHhpvwYWDdPpuUgGWS&quot;\n    &quot;sbBwtTwuNnNZzuEJjJNdDVvyVvYneEcaNnAZOBbmMpzXxWkKwOdizMTACuOiIoUQqXoOwyyZzJ&quot;\n    &quot;jUvkZhHpPkVtTnqmAaMyxSffJMmZbBrUuRuUCJjpPPcRXiISnEAaDdednqLlLOMmJnNWIuqqQY&quot;\n    &quot;uUyZCclLzZfjJoXxORdpPaADQqrUnYxXjkKrAaRJNoOnJdDjyUuPAapXxNuBvzmfMpTfuUiNFN&quot;\n    &quot;nmxoFBbfOcCDtmMTnmaQRqbrxOgGgGHiIUCcXzqJWvcCBhHfzZpPGqQbqQFLNHhIinNwWbtTxq&quot;\n    &quot;QuUuUIdrpPRHHhRrRxlXtfFHhlzZxcgGxXGgxKkYqQdDyQxjJjuNnhIodwVfjJfFmYyBPpPoOw&quot;\n    &quot;VIeEiezpbkBbaALBbWwllCvfSsdZOoJjWuDdUrRvVwlLzyYvYpPjJsSUiIfukuUfFmtTnfKFNZ&quot;\n    &quot;gHnPpvEezcbSHXxhsBihZzByYeHhUeuUVvJTtmyrVkEkbgDdwWfPnNfFppvVluTVLlhDdiIbBD&quot;\n    &quot;bBqHCcCcKAWwXnCMkKoyjTKsSAtFfZoOziITtNmJQqTnNigkWuUTtwKYeDdECcVXqQdBbhHQsB&quot;\n    &quot;WXxmMaDdtTSnyYOAQuJzUCweRrmKFrjxrNNfFnndYeEKkrpPlfFfaAxmMXxPCthHwbcCBEKLev&quot;\n    &quot;GLNTDihkKIvQdnXcaAxXCVtaFleMDoOTtQqxXRpbBPRcQdyYZxFSsnNckwWQTQWwdDAafHnFNy&quot;\n    &quot;CVvdRrDPWwwZeujJVvwBbWHhkRBVpPVoeEOPpPkKgGrLnLltlLTcCeYyQdgGjqSfBGgVkKTWQE&quot;\n    &quot;nNuBbHLVvCcVzZJjNZzAkKVvcJjCcvifwIDdivtTAtNndDFwlOolLjJzAbvjNPxXuFYDdyDdrh&quot;\n    &quot;tojCfFcuUUuoOTIjBbxxXXSbBCciZuxkJkKxNDdDNnbBeEdnRHuUsSbBTthHcPWhHsAaSZzZxA&quot;\n    &quot;aiqzZfFjJeFxXrnWTtaAIiiScqQuQGgqQDrWwRlyPpYLtTEoBbOpPlLNrDsSdzoWwfEeQDdqsC&quot;\n    &quot;cSEkeEBjIhHFssapPtTcxXlMhHmRrMmgRrOohHYKFfvlLmEeBnzJVRxTGHkkKKeEqRrSZPzGgG&quot;\n    &quot;aAgZplIyqAamMVvWdddDDKrpdGCeEeVZWwyYzKrLLrWMLNRzAoOagiIAaGNPdLlKLENsRDGwVV&quot;\n    &quot;gxXGdAuLlOOnDdLlaUSSssItTmwJVRfcKkCIimMxNnoUhGgSpPjwuceEeaKkrRSscCuUUcZPpS&quot;\n    &quot;jjQBvFfSLlHtrRrpffZzLoSNACcnNTtagsrRSJPJTVqQvYyCqjJQRAaBblTVvpEetbBwWLHGZz&quot;\n    &quot;LPvVtThHgGCqLzuJjUOCBbDHhHCaXmDsSMJvVAbqQUHhuQqdDGClLwDEedWOoIYwQbQcuJkmxX&quot;\n    &quot;MKPUuchHyYhTxTtSsldRrkKDXqQEuMBTpPtJedStTjtTAwWvVLOQZElsSoSbTToJjtTkFYyAaZ&quot;\n    &quot;zOyVvVkdDKJKSCcIYtTzZhDPYTUuBboOcmvzzZmdhHGajteEQWwMmMmpPLJjudlLFfHnTxXzZS&quot;\n    &quot;bSERrehbKkbdDgGElRKDcxQqXhnBJjQkbvVvqQuFDdfCctHwPSspsSMLxnQboInUAMNnLxPXxb&quot;\n    &quot;BXTrgTqLluwZzqQWzbDdsSxXMguTjJstTioOdfFDIRAvhWwnGOzioOIJQqJGeEihTtVNnvfFtB&quot;\n    &quot;bwWLxfFhjJHLFyuHKmjaHozLlZNnaFlLWwrtQybBkKerBbXiIgxXAQYxrRxkOqpPbBCcgedDxW&quot;\n    &quot;vVhNpBbjJgGfpOoPjUqYjJxhHXtCdvBaAuTzZKpPJkKLFflIatJgGoOrmMRYgGPAJxRlLYrRUu&quot;\n    &quot;iILpwQqcCgXxLqQvlYEQBTttRroOCOGPpJaAgDWxAmPhnQqNHfFRjEeGBbCQTtqlUuqQhHAaVq&quot;\n    &quot;QnSsNvxXSsuJjURrMmxJjPWYywlLpFfuUwpLlHeJbBjVyYOokQBjzaABvVGIiSdDTtvVhCqSwr&quot;\n    &quot;RRRrZzZzonuUNolZymhZqbTtTbBjJVvYyXxoGgzZDdXOhHfFoPwWponlLAUNlJbBjLYXAUuvsS&quot;\n    &quot;OYypwsLFfNktkKwBbIioKtBtYyhiIkKHKkThLkjJFaAEzZjJlKMmkKXBJjmjJqGzfyWwnAkDaA&quot;\n    &quot;seEUuTtwWsRcCFiINnjJIrsSLlrakfgGPpnTtMfcnaQygGRIiRWwWcKkflkKLBbYyFQUuqJjgG&quot;\n    &quot;pPvLlBmFWwpPgGxRKQzuFBcwWRUfePbCcBAquUngGgBVcEiQUuPpDMmyxXYyqpwWiJOoNnwdNV&quot;\n    &quot;vSLOaEiIqQezeEZHcQoPClLLuUlcuuqQOoVvsUVvRIVvWdDwwgGaAbXxIKyMmYeDOrRDrOyGgY&quot;\n    &quot;aAuzLlNZzAMmpkasSQqNnAxCcXmycCgkZzKvVAYmwRUuKyqytAaDWCqoNiIKkSsnJoOTXIitrd&quot;\n    &quot;DRhboDxaAaUuhzfJjQqDDdxhkrbhAaHJjuUGUlVzcMmKIJjiQRrqkdRYQTuZeBMqPvzZOrRMjd&quot;\n    &quot;SCDEeVCcEEeULeEEwXxGgXhWeiMmIvVbBJjnsSEXpjJeEOocCXpMaAtTmPaQrOkKoRosXbBXxx&quot;\n    &quot;CjJcmMNWwnlgeLQHcCCeETtcRrPzWwsXHjKkqRGouUOoFSTBbbTtBBjvOormMRDdOoVwSZasqs&quot;\n    &quot;SJqQNVnMmepXFcCXMdDTHgfFrBJjEQNRrRrhHoOoQCDAaCcdygdRrsCUNwWnXwWxrRoBbiAaIk&quot;\n    &quot;aYyTyAaZZhHDVmLuUtPpTmVxXLyYlLohmJQqXkziDpLSYAaynNuDdTtVvEeMmDcCNfFJLljZHh&quot;\n    &quot;AaqQWwLlxLlWneErxgnNoNnsIzdtTjJUEOtFduUwWDyoSshLrPbVvoOEeHhvVyMmYSpzsSZPKi&quot;\n    &quot;IbBkNnZzLItMzZhUuSsQqHfnLIilYLsmMmYyHhazcmUuswtsKkBbvuUJzKOofFaApEjJgGUBbX&quot;\n    &quot;xeEuvSdDsxhHqQXVeeELubBjAFTtfaeEgGtEGzQQryWlLwQYoOcyvzZRXxratmdgGDdmMDMFfm&quot;\n    &quot;AFiXxrRwTtzoshjJHSuuiodDOIyYWAYZudzrqujtTmFlNXxABbzZCcdNnQqgriIGkLlPpzdtjl&quot;\n    &quot;LPWwkpJjBbawLlUYLzbRTrtTxiPoVGgWrRlndDNEMDRrEpSauLwYcCyWyYtjJTiKkIPpAOokSs&quot;\n    &quot;KHMmwtkKoMvWUulLMmeEnNevMGCeYsSJjPqNDdnKkGwWakJPdhbzIZzFIiMXLlhhNmkCVvZMBE&quot;\n    &quot;cCvaQXhHKBzpDJmcCMmMaAHhZLsShMmrkKRuHhRChNnHsxMJcwWDdFUuPpJWwHyYGqjzZnNcWP&quot;\n    &quot;lgtXxjNSjfNcCjJnPklMXGgkEsSeKSdvVmMDrPiItTpDqQAAagPHxXqCcALlZTtkEGnOaqzHxX&quot;\n    &quot;sEeSUMmRrzZgGMmQqdbrsIzcbBClaAHggpEsdDqQwWSHSRraADXHhhHsZpPndDdDllvHEhHehV&quot;\n    &quot;MzcCkKZcMJiIAFPpxAaeUlBbbBzVcatHhpgihRwDhHrjJcmTvlMNCQqwmXxMTPpEdCqQcQrXxP&quot;\n    &quot;QoOqpDlGgLkKIiXkvasSAVKhNxNnjzWwnNZVvLgGHhlzTULoQqJbedDZZyHhAPVvVnYxYSOeCP&quot;\n    &quot;JdDdDpEWwenrRQGxXMOoZziCcIsaAIfBHhkrRSsYyhHCMzeAaeRvVqRGNnuJjUgrQFlLOWTHhj&quot;\n    &quot;JuvVGSpDdYZIiXntTNcCAtTrRwikKiwWIzdDZqLZQqvVvIimRCQqnNqaZzgEzAhHcCkGIiaDdN&quot;\n    &quot;NnmMSsmMrkpPcCKdfWZYZRrsFfwSFpAuvWRYNbCMgGmKIXFfkEXJTXFPUNzkaZzAKeLEdDPpVU&quot;\n    &quot;KrKmMgpVuUnNpaeEgGzQYLloOpPpghFftaZFfVKapWPpwijYyJdZztXywWYxjSspPCAaJWSxcP&quot;\n    &quot;pCXlLUhHuJVcsSCBXUuWUlLhQLlUTtOZODdLdwLhxnDCcdVXwlLoaoCtNHhKsSDdkKRykqvQqW&quot;\n    &quot;UuUuyclfFLlFACzLtTlWKZpSHbaInbUurSsUuxCcXRJFJlRrLhigFmJYhHdvXlVliIvbHvaAde&quot;\n    &quot;XFfGhKWNpPnpPNttTttITtwWijeYysxXLGPvImmtnNDdTLimyLuSptqfFkIYKPMEWUApPaLRoY&quot;\n    &quot;THfFIMGgMyjPprJPpiyvVtFfTXxrRjhloOrkPpUdyqQsETLlqTrJjLQqvosSyYHhWYFCiaPfWw&quot;\n    &quot;gGZzFpAIwPdOPhgUuXKkxbOpPuQAaqFQbBzZqUgMmBUrRxsSwlLUuTttHhTHOGgFGgfnRaAeEn&quot;\n    &quot;qgGlsSPKCckYyVxXXcdDCxQqvpqQZftWhnSsWDtAlLaTgOoxnxVlurzZCcsSvhHVaApPmuzZuu&quot;\n    &quot;UrHwXHPFlOzoJSufFPHAaiZZUWoOvMpcYwWOCUmMuqzbBZWJYyBbjaAzZpreEuUoeyKkcCSeEc&quot;\n    &quot;mMFslLYykjJKWQyYBnpMOvlLFOrznEYPyrkwJuUjQhEhqSspPNnKfdksLaAVJfFWbUSDJJdNJo&quot;\n    &quot;OTNxdTtEvVBXhTtwbeXkKPpuUYVNNnDYxUuoFyYMGVvQqOSOFWtORAaYqQfRXxrHhoOYYyOhrM&quot;\n    &quot;KkSmMjJFdFfnBhynqmMiXYQqyxAouRnLxvVNnPSEOiZiIcBILKBbkLyYBdZzDDSkKHhHygvUlt&quot;\n    &quot;uUxTtCCcKXnOdIwWONnJyMOKPNlxZzpwdDwfSAHuUhCXxtTJsZrkbBjJxlRrUjJPlIjBbJxXMm&quot;\n    &quot;jJizZRrETtUaAfFJjAJLvVFfVAuUbNnSAOENGToFfuhHgDVYyYmMaKkeQbdzZGgPIrbsmeEpPM&quot;\n    &quot;MmLoOomxuWJNnFfcoYsSgGyxHhCjJttTxwowRmMzZrTJbBDlNVsiZOoAXJjKOOonIyYiwWRyYI&quot;\n    &quot;aupGOPTWfjqQBJbBjKiICFfdHGzFNnssSCdthKSoyIUSUurhebMDdTtINnAsSsmaAQaGQqgAiC&quot;\n    &quot;qdXZGsSUcHhItTkKKqpLszXgGxYlcCGEesvUHVyRaArPCAwwWKfgMnsiIXxQqmMUubtSOPVSZG&quot;\n    &quot;XxgwPpWMzhMmqQbZzuUbTtYmWwMydtzFvVxXflTJvttTTPpDNThHIhJjHTzpcfojHAvbCBqCFI&quot;\n    &quot;jJipPiGKAKkaSskgYoOuYeQhHCcSWTmnIZyhHainyGgZqQqQeVXfAzChHcZyYwDdZiIWwzOkIH&quot;\n    &quot;yYnkkYdmhGPxVQXxqJjMmJjlSvHhJSFtNnWKEejfyYFAjJaWJMdgGDHpUWOocBbhPRYyZDafMT&quot;\n    &quot;tAHuBWyNMlLfFepPsSbQqdDLADQPBrJjsxcVvlLOeEoxkWeEVJjvVMxXEVOhqQDdFamhHFXbPm&quot;\n    &quot;RrsSSVYZFEeONnoQZeZgSsOodzKTtTmMpwWApMIurMHheKOEoOefFokEHHhPpAeEVvOuPRoYLI&quot;\n    &quot;kKiQNgFnNKwMDdRNfFRrcKZhUiIUTgJNLxpnjJrKkjJiGkJbBzZMmjkKocCOgGNNLzZlXYLPoO&quot;\n    &quot;ANcGbWKhoRPprSZaAzLlzZuexmMVNnsLlSMmaBbFfAvXEvNhgbTkQPaAhnCcNnOoNcwnqyYkcA&quot;\n    &quot;IGjcbRrMmdvaOFfogvuqrsdxywKLCCcVvFfMwMdLCcPaHboaAXIOWpPJjIDdQyxZvViMZzPpkR&quot;\n    &quot;NnwbBRXLGgXzZHhqhUbJVvtTsSGIfFLdQuUqFfzTZJnNjzrRGgtHVRrFwJyFpPeWzZfcZMmEYz&quot;\n    &quot;tWlLvwWrlafPRouUOKVGpZznNPeJwbATyAadLRRWmFfMWTFgGqQERYyitBbgJjSRICQJAawWjw&quot;\n    &quot;WORYsgReQSsnNqxYxXLlSKksObBVaAdfFDOowoOxfHhXxFUsZgtzZTgIyPrRUuFpPAafpyMsSr&quot;\n    &quot;JphVbBwPIYQqmDvaDZpMmMnNmzZLJaCDQbzZpPWXWGgwXVRVMAasOFynRreBbPQqfZvgjiIJOo&quot;\n    &quot;aAhTtaAKAakyoNnOBbIiJjVvVuVElcSsCmdDYyhuaysKmbDqQmMVFfTtGgXxnNodHhiqkiMmYR&quot;\n    &quot;mMkbIiqLaUhiyYmXBbgGPwtTqYyQWpwWYyLlYbfkeiHIsSsSyLlVvVGmMXeQkHMGgGaAkvVWwo&quot;\n    &quot;rZpPzmnSCFbAExaAuNzetvVTDmEWJoqmMhHYcCrcymTNDJroZfArRzZecaRrcCVkKzaLwAqAaQ&quot;\n    &quot;NlVvykDqQqlLlQxikzTwPNBbXxUuxXnprRWtnfXxDhaFaQqCHhDCctBeEknLnBhRrMzZiqQInL&quot;\n    &quot;lHVmMoEeSsCzGLHOADuUkVvcCBbEhhQqHMvVTOvVRIEsjCcgGrEDvVdMmPpKJLuLBCJjcfTtsT&quot;\n    &quot;UZUVdnUAgpcCPGcCaTYSsgGXInUueFzCVVtcCcZJyKaAdYYvAajmOEWTFEeJjfdhHMyZvVzWMv&quot;\n    &quot;VmWTgbLlqQfcJhcJjFfCBbwWFDdvKBbKkkFFfDlLdfvVJdLkAtZzTbchHCcEWpibgWIYyjobBK&quot;\n    &quot;tpUuxXZzPOadpPpPzZbSaMwEgaAWDUPpusVIQqiBaAlCUFRSCcUtVXxrRBbLlvICEnTUHhhsAa&quot;\n    &quot;vVSHctzVvZDaVvYyiMfjSsJFtTasOoSKkbPpUrLuHCchFvKNnCNnFdDGBhvVZlzZLzHbpPgfcN&quot;\n    &quot;nkAaPpVfUlRubBBPMmZzpAfFmIUuVvYyjJAdxuUXTCyGgYutNeceEiTusrfdDucLbvSFfdwGeW&quot;\n    &quot;mAGSsgsBDAoTkOsSJVLlvZIiziJjyYwGBIPlLweCBaKlDRrjVDdMbBPpmfHuUjCFqQBGtzZwmM&quot;\n    &quot;wYmDnNtweoMJVyyDmNnMlLkYjXkKxzCGgTvvcZsStTfEbBNixSswWFfytuNDvuvVmVvMzFfBbu&quot;\n    &quot;GgtLlSJjFblcCUKenMmNjJTtEkgGljbpPBkDdeRJSeirotmasSAqgGQHeKdaTtohVvoOlgRrZM&quot;\n    &quot;mYycOvhNBbmHbNcClNKMmkKJrRjbnNTdjJcAfiIAHdFNFDhHdfZKvuUrRVIXDdqLQdKYLnSsaT&quot;\n    &quot;tWlATmMtZvACEaFzORjdntfFMYCRQqyQEeOmGgMjwePpMdtEeTEZnUXeaBfcsNMROKgmhKqMmE&quot;\n    &quot;xGgQaAoOJjqgvYihIEhOoHKbBfFFByftTFWwxMIqQLlHuAlnNQBKryIKQIDOAavdBMkSIxXiYA&quot;\n    &quot;UHMLhsMmSHUbfFBuevUvOoUVvuLloOYlLcCHlsRrLlSLGVzFpwWEvVNYcCfCcoSmvrvxFfWwgX&quot;\n    &quot;xGxwCcBqdVvcAbBjloOPzdAVdcCMmyYMyiQqpWvHPjRlLmYmMsSyfPpFYYiGnDdNGzSuXWvoyX&quot;\n    &quot;EraAGPpSyroqcQlLqirsGfFTRrTtIOorefEFfeMmtwwrrlDxXYtayAaYBWRrjZzEVZzvpPgvCc&quot;\n    &quot;kiIrpFALRVwWwTZyezOowWQqCFwEfYjWfSsSsvhJjZQAdDaqDligsSgGBbXxjBuHQxlxrWrKmI&quot;\n    &quot;chHMmCtTzXYqiuUpPPpwnNoZzixOBhApNnNpPnlDmWmBbBbclkWYXDSRQUuhHUVZzGAVDBCJgi&quot;\n    &quot;aCKQNWCHpqKtHhBGHBbnYmrRMyVUBbOzZoJiywWYIEejspPYyOHZvVzkwBgCnaplyxnngGKgIC&quot;\n    &quot;cRFWwfNYyQqPXlnjGtuuHlLaAzkPpCnrmWkfGnqlyOrRCcrHhpUYyoaQqpPhmRMmUimPIiaoOt&quot;\n    &quot;TPtgGkSsZMxXmWwDGzEzqpPfzyvkpPuUKsnDdLlNMdDwWpBxfhHMAeEfHovebBPQqpmkKDdxXn&quot;\n    &quot;NvwKXCXSTtRbpMmZEezqdaCclgGmMvVBEmnYtTwbUhaKkmFAdzrMmpHCXxwuiFfIPSRrFfsxXh&quot;\n    &quot;mjwJPpYykLlyYwTucCUfsjVsLBbvkKXpgHMDLliIyKGgKNhiKoWDdVvxXdDyYaFxvwWEiLlIQq&quot;\n    &quot;wWztTYNIAYzaAiNnNMMmYytwsZzoOqEyUyIfcQbzZcBVahJOFCsSPZtitndVjzZtLWwZTDrRBB&quot;\n    &quot;UuYyXxZzHZaAmODdSsozEeWJjwsTtsSvppPosTBrRSEeNmGFkWacpYmMCcvhAaumMVdDSgLSsy&quot;\n    &quot;XxQqQqZSlOoKkPewWEQkiCugzxDQcIagLlGAlLnNpPqMSaelLWgGwEimBEHRUusuiYONpPPpns&quot;\n    &quot;kHTDVvcSfZghDJjckbJjCcJFoOwqQtpofFgPUAirvSsVrRNMmokxazrgGRISvnLdjtWOWXxQqX&quot;\n    &quot;TczZQqXTTttWwOCjPpwUeEXMOlmMmMmMIiSBNnRiHhpDBqEAyQCcqvdSseEmCcMtTGgGUOtEeg&quot;\n    &quot;neoasBavljauewWLplPpLXxuLQqXKRzSfFUujctTXxasFWdDZzjJdDWPXLnCcpkomYjowWinND&quot;\n    &quot;lLoNxBkKPnNpbkcXTLuuUVGTtYiIhsdbllibCYyzIoTtespDdXlNrUOkKgGaEeIpPQKkNYHNsS&quot;\n    &quot;nbDdNDbBfsmRHoyofFOFqQyroTwEefosoKkgmNlLndDvVeEfOrqQRXydnvyxmMEBjJWcCzZHxb&quot;\n    &quot;uUWwenNDXntjnMYymDjOojdqQEesuogGUuOBwPpjvlSYyKDFiIkQHeHqSsHhWKRYpEeyeNZRof&quot;\n    &quot;DdEGgeVomPZzeENrRbVvBbqkKwcCSfkKCsdDYGgEORPwQcoyAaCPfFmVwOMmouJmMjzzIXxRrb&quot;\n    &quot;JjBfFhpUSssjnNOQqZoLfphMmxWhRUJrRjvVsLlSUMJjGgzZRULvXNXGdwxXNHwTFzkKEeLQNr&quot;\n    &quot;mMNohGgWQqXSsubGufUkKoBzZbBGHpoyYDpWjJZzcfSsywOVVvlfgjJGyzEzZeZYFHhRtQteSD&quot;\n    &quot;dFfYDuKRjJLHJWMmwbBYIjRyYJYmbBEemqQiIkKihtZzyOrluOowehHmpkyiKmMmMwWQTiIPsU&quot;\n    &quot;lYBbMIlMMpPOoiVpglSTtEJTTTndaADwkeEHgxdDEYyMmDVhBVLvbBLxQqVDyGgjMfGIHTtjfH&quot;\n    &quot;hAajUuOoBNzZZzdDbBiWwyYLlAgGBhsCcBbDQYxXyqdPzkwaAIiRrBZzbFfoOZcCcafBbLnNCY&quot;\n    &quot;wHhVQKYroOkOolLnEeTcOAOWxXxvNIiXRrHlWUuSsDlozouqsSHuwxbvjTtsdDZGgzwpHhPjcJ&quot;\n    &quot;TDIVBbvPAkvzATHGPhHyqZJjAPGgvPGkRjJjgGeEJkuvCceUWwulEZnPpupfxFcCftjxeKxikL&quot;\n    &quot;GSoOsglaALlcBnyFPpqfFQfrlXHhxLEewVjJwWNnUsSyYaPrFfRfsWcCSzyzwlLFDcRrNVtTvf&quot;\n    &quot;FnCRlLnAgXxKaZenOxXodDmxXkTtKMNGAQcrMVPpxXOozlQkKtTZzBbiIIMmKkWauUAzZPpaYy&quot;\n    &quot;TnNtxRKkqQrzPhHpyJjhHPszZgUTttwoqQfYyrEOoEWwZFfmceEKLlbFWwizZSsShHmgqqQPpN&quot;\n    &quot;PGgjpcEBbosyXyNoOFfvpaNnYvVwWzzVqQvEBwiIWjOhHlutOoWwqQZJXnHXxPpxQqdmMdDRhH&quot;\n    &quot;qDetWcnmLGgLhHlVFflLeEtMCRdWrHIGPTNnACvZxXhHZzLuEXfajIimCmLLuUNzSVvxdFfshT&quot;\n    &quot;teobBOHhPGyYGhnNuULZJYyjiSRBDuQvVqhZQsSAoNgeKzaQhDdpvVGJbBjeElLaYydhHmMRkK&quot;\n    &quot;sxmLKpNnFJzZsnJPpTGLpDdwFfoOCJQghEejKkfNnSsChHtTjmoOXSbBcrUVvHJjlzaAjdPZqQ&quot;\n    &quot;bjJkKkxqAVoOebmzcKMnfFHHGgxmfiZBHdDDpjKAgoOQpyEwWcgmVEuUwXxgGVCcmOQIikKqTS&quot;\n    &quot;sWqQoOhalUAsPedmksSKeLwvOpIOoXRtrBZRruUlyuJjWAPKplLJTDZeEKgRZzGDanmMLfmMMJ&quot;\n    &quot;UQKeEzZknNbBNnRZDUzyJjawlLUUOZWIDxXdfUjJwWuMzHhZmaEeMTObBoOopPEeAPpVYCoOyq&quot;\n    &quot;YHhRSsbBqXxqLlZgeTAauUKUOxFfXouBbRrkUgGuJBbUDdlzZeEPbDdZzvVBmMkZjFfVeQqaAL&quot;\n    &quot;sSrRlrRSTWZzSMCZAOokKMSlMmRrIiyNFsSmTilUuvVssZzSBpRlHOYPpkKfToeuDZPpiSaAOg&quot;\n    &quot;GGXRNwXMmqRpPUuUurQAazHhqQdHhDNnndUAaoORraSsAslPyYdkKMmIZKxjNnMHOZzlvheNnE&quot;\n    &quot;HMjJUulMvpsSPEedwWhcCHVvDdzDdzYtAKuyYUOxXnnCfFcNNucpPSRrDSsGYcqOnqebRzZGaA&quot;\n    &quot;htmmMFfxpPdhwWzZmFfMHKkDfxPEgGdDNvRroOwWEeUunjQDdSAZzzsiIWSmMsJboOtsOkKofO&quot;\n    &quot;fFgRsSrrQJBbhBbxOPpoSZpPphnIiNqlEGMmLpaAPIiSOJjqAlLLlxSsHhnQlLqNGgPJjxeNat&quot;\n    &quot;TApPWwEwyYHzZxWeluzZeRPprvcCdcsDJeyYEmoVmMpZPpzQmbEzUtqyrDVjJvCZZzvyYLfFug&quot;\n    &quot;BRKZzzZIiHXhHDddFUuZHAPpUnNjJuXdOBNnHTxtWEewjOfFQdDcwgGdTYnNQYZzAaUukrWQqM&quot;\n    &quot;yzYiIyZaGYMKPaUlufFULunZVvUoRbBdodpPEyUpPuaAYkiBWuUirnyyYYkKNqQuqQSUeEUUup&quot;\n    &quot;OsSqCVJjmMvQQqLlqhAolsnDWaAjOaACcoIPQFMmfTtvhHVYdGgqIefFCvfOoCFOofcqQyYFbG&quot;\n    &quot;NQapcCEFMmGgurCbWcCwfUZyYqrRkrXeEfMHhbVyYCQqwrrQqYqANqQCFmGgCcNFKARwWxXRfF&quot;\n    &quot;ijJfrSsSTtzZnNSHhdKhHaeENYTtFZgAaQMbxFsCcSfqQkRrXPpxLevViIfVvKlIiHcCbSvVsT&quot;\n    &quot;kOWwHCPpchWcCTKnlSWPorRcCVaxynuaNOxOzZDdaAAcCaHhtBQzHMYTtzLOOrgGbBWsQcHLls&quot;\n    &quot;KWwkgvVbxXZJPpbqKvNnEYPpkKyhPWQqXnNLzZjJcgJrpMafFVvXxgGXwdGGgjgYcCyochHTbq&quot;\n    &quot;eyxXLVlGaAWPlyrXjSsSsapyjTAiVvUujMmkBbIiFftUAawWiIJjwWbJCcjVDnNcTyQuJFPnHw&quot;\n    &quot;XYyEGQoKXXyqaGTtBzZbxRFfEsSYqiIfFjJTRsSfWwAlLdDGgOhAMmdDJMvVkhUYRrflXleEwS&quot;\n    &quot;sWTHIgjBbSsjYyZoVvgNwVvWmMQqCcHVpParStUGmBiIIiZUQtGRtxwWpXQqlBLlbmadDuNiOB&quot;\n    &quot;qNXlmbBpPWhAaqQTUVBKqoObNYyHMmCdkIirLFfUueSshSQqsHBBHsPpBstqQNhXxDUlMmrRqn&quot;\n    &quot;NTJAghHDnNqQMZEScCseVMCtyTtptTdscCSlGgUuLHIiyPhHqZzqQQpiskjYyuUvYofkKvaeEa&quot;\n    &quot;UuAAVKOroORHhtkKtBsOxXfFLWwezqvVoFBaoMmVTtvOAbRrflaJsDEjbmUexdCcOoDRPprLXt&quot;\n    &quot;HGgCpjGLlgUwWCqBqWyicgkKOoBaIijwOoWmdMxTEtAchdfFRrcJjoZeElEZzKkeQHhcCfFcmM&quot;\n    &quot;ZzjJpRrlAYyaghpPlBbTPQqpgGPyYtLPpqQrkKciIAuUatjpBXxbOojGnsgGOjJliFFYyffIFF&quot;\n    &quot;PRThsVbwWAFsSOofaqFEeXxfEeJJszCxqYymMQXSsJjVvuuUcUuQqCeEmMAgaAGEdDCSsBbUWJ&quot;\n    &quot;sHHHNnhhuMmaAOHhjJXFfFrvjyYQquUaAWMhHUuiybBYuANozZomMUUuaMmDvSXPpAlLEeaxsv&quot;\n    &quot;WgdrSneEfFMmYyelkDxXpnZrZmMSLlsznuiIUlQqmCcwgGRSslldDfFnNRkHhvEcgDPRRrkDTt&quot;\n    &quot;OrRoYywLzZlQYSsieELYyzsQhgtlLXrtTvjZNbMlLVFMmfZWwzgGkyGuURrLStTsCRyYbSsgGB&quot;\n    &quot;rAdaADScHBcCbhvVAauUbkKBCwWSfQMmqiJkKbTtKevVpPKkFoOOZnNOoRnelIiwWLdqUCsIlL&quot;\n    &quot;yYwoONIZziRfEzYySsZQIXzEemoOMwBbpHhEeCvVYyhJjrXtbBTUujKXUzIBpPbsJitvvVVCcJ&quot;\n    &quot;OTHQqfFRfZzXtiITxUMmpnJVBaeEUuZuUeJjELWfZzNztcCTZnTLlaVWFIVPpCanvlhhHUeUuE&quot;\n    &quot;ePpqwtvbbBFgGshHQJHhcCkKDIwWSdviIVVvDsinKkNqErHhRNlRBbpvvbrKUEzWbMmBvkKVpc&quot;\n    &quot;EeYnfNGghUUuuFEedDNnjYyJbBqtqKvVCaKkAfqcCQVvqQXzDqCwWrrVhHaArRvcCdmEQqLbBK&quot;\n    &quot;kHhHhfAZhHzTvxKkNDqGPpgViJjHIdtBzZbndDllLcCgUuVEJjSAaslkKaAeEkeUJNnjuEeWmM&quot;\n    &quot;TcpiINngGXFYyLfFRyDlLHfFhRXJRfkMEWiIUumMcukKkQqKZjUqaoNsAXxwPpbSqDUuzZVvxv&quot;\n    &quot;yGnNIQqtjMnTaktJYOmcNxazZkhvVYyQdmHhHrUuRhMgGPpDdHvMUumtULPrRFGTXxtTtBKLlz&quot;\n    &quot;ZeKvRYMTfFDnNUudoOtjIiuUNyYtTnvVEufFHhEbYYyPpyHIjCZzMtTmcuUJwWCBbqQZVNhhHG&quot;\n    &quot;znfkFNdMmdDDuDdUMKUFnNuLlyVCcdDEpPeDyYFVLlcLJjzZUuZzuUHhwWZzKBeEPuUZUuEvWp&quot;\n    &quot;bMFVvvWhHFflLDrROYyiQqHLlUgGJXqQqXCbTtrRBXuUEQqeADdLlaLLlTxLXpDDddWwPyhQqH&quot;\n    &quot;YrhDiiIODdoXlLBnlTtfFfBgzZUuFRrwWFfbZzVDdwjQZONnQqoxuhzZoXRBQrqAMYyNdUUuuX&quot;\n    &quot;bBMfnCShHscIFxXzZynNKkFwWfuUtTXxYtRrPmGgFkKMZVbFzQekKEUiwlLjolQNjJDNsxwWrC&quot;\n    &quot;pgFfGPtTpczZziIjFFsXYmMQQqNvKzKVuyYUueEYYWxuUcatmZIDaAoYyZPomMzCNQeRrqQEqn&quot;\n    &quot;jeUxXiInaAUVyYvyjJBkKbWVPDvkKVdVXxvcZzErRaASCcKqVvXnNZFiIFfftJkKjxXAUuggGl&quot;\n    &quot;XfQyYGgPcGdDxDgAEzZMmMmdUrywTcCFfSsegGiIWzZlNeEbBCcoqMGoRrKiIsQvsSLWzmTGgt&quot;\n    &quot;ZOoEelUlxtTsSRrQzsSCjmTtMzCXyYhTtjThHtsSfrRrROQDdeJjMmGgXmMLThlLHMaAribicI&quot;\n    &quot;rROhHMOoGgPcCCcpmJVjQAYyLxXlacCShsShUCSsAkzprXDZZzkywqQbBaEUuOeVkKvbIiBjBc&quot;\n    &quot;CbfhTtLlFfgYyJRYoCcCOoTtYycOyrkGiIAagKjfFOAaxApnVOmhaABKkzZzGgiIsaYyASFAah&quot;\n    &quot;TSDfFPpkKDddmMxpPcbBBtTmMRTmJNnkfFnqvvuCcwWmZwkKkKRwzxcCxXTyLzZaVcCalLpPcp&quot;\n    &quot;MSsvWXJgPpOziOwWtOoKnNkVfFyIyYisiNBdYqQyxXUunFnNEtTcCBuEeLlUPpOpPMEedoOxUu&quot;\n    &quot;FfeLQfZNwRWtKkmcCAHEehacCPJrNIVvJeYCKhoHZyKkKkjJgaArkZeEKrRtuKkpEfFmuxXCcU&quot;\n    &quot;MCjJlmUutscCYyOoSsQqIiOmMlLoFfYylIkhLKaAkTvzZVqQNEeWwsSUZLlSsHdDhuFasSpPdu&quot;\n    &quot;KNnsekKsDdJhpEKkThHeHhneBbPXxeTaAtWsWLldDTtwfGoOeEbUBBwWuUuUXxHhoTtOWTAyMm&quot;\n    &quot;ZHhzKLSPAPdgGtDzZAXxLjjiELlOoMmGKDDxrhHWwWwJvjOoJaAVjhpJmNnEcdDBbChHOoQqYy&quot;\n    &quot;uHhUlQqXazzOJYyjRZzzZwkRDFxXzpeArRBsYIiySblXxeeIxIqVvVaHhARrUgvVuIhHaALliV&quot;\n    &quot;YyLTIihRrHtkJjQwIxHITtpJpwWPZSuUsJjJZaDZzDddAzwiIEgGJRPprByWwAaZaAzQdBhHFf&quot;\n    &quot;fFMmboMljJLmGWwEFfeQWHhsQsSAapgllLvVXxdDhhdNMoOmMNVIaoOnNiWGPRdYyaSsUlLrDY&quot;\n    &quot;GgylLzZdRuhHOAKkaWwFfFhaAUuDdaPwWvVpvPptdfCcFDfFNCrlfKkgYyLpPlGUusSHhqQuPU&quot;\n    &quot;cOogGNJeCyYnZaSsFdDfTtAdgGIiVMoLlLpbBPUvVvMxXmMmkKXaNnrRKkAwdDfYcCLlfFEeyW&quot;\n    &quot;kLlmcCMCxGhHgyKdHhDRBbTrRxeEppPTstnZAalffEeFfDubOBosIisSavVAHNnmTbBgNqgcCG&quot;\n    &quot;kEeyYTtuUnYXxeEfFyNHhoOdlHzZzgGAcNnHGgZGretQqAdcClLUkKtbMXxmkKshvVwSshJCnN&quot;\n    &quot;JtTenyFRMNnElDhWwimhHQqvVjJmUFgGfSsdjLChWjJgzYijlLJEecvfkvRQlSsDdLqpXtgrGg&quot;\n    &quot;UQUyYMwcCoUxZOLmGGgvTtfFfpPksbfYqQuiHZJeAacNpRrOTuUczYhHybCcFfjpPPpJKVyYGg&quot;\n    &quot;hrXxRfuUQyYiIfOoJFdwqWmgGMNtgYHXiwKWkDUudKqyYQBMmgGvhHVYFfRrhHzqQZyIiggGHw&quot;\n    &quot;WuSpQqPsIfpvoicsSpPCIpPKMnIVIivVJIiPWrzVujJcuFgGNnQSYUGUQqVQqhWWwZwauUapDp&quot;\n    &quot;PTNngFSsLlLAfFcCRrZztTDLxiIdDpaEKkHeCEefFCxbBiRrxoOVuUttTxYyRERbBMVvmqQGgX&quot;\n    &quot;xRrAsLlbBPSjJZRVwWvlwDdWzAaVVvzZKkcHhnNTvxPEuUepPEHhHnNmfKSlLsYykALaAaAlnA&quot;\n    &quot;EeuUOslLSVvSFfDdFvRWSsqiIQdDSsTaALWGcOsuOSdHqaCcSrOoZYpPLlJGgwWWwIuKkYyZnN&quot;\n    &quot;WwVgGpPJjiIjungyYmMGhHSviIVTtvALlDbATdKkXxqnNQoHJdmPFpPfOoqcFTMbBeFumMCcNd&quot;\n    &quot;RrIieEpPQtTeiIzZGMSMlLmeuUZDDdesHhSEDqUJSszOXxTjLSsbLHKuUkhlcqQMXgGWwmMjJH&quot;\n    &quot;huUWhHYxMmQVvIicKMjiIJmkAaCKxXuKQqcwWCeQqFFjDQwSQBtFfBbTiuRrUueEXxNncCXxNK&quot;\n    &quot;kPTtpsRrwWScCYydjXGzBVWeGgGZgCcWIsQZzqDrGgRdTxXHhEetpYyYyMwNnEevVzebZzBgGX&quot;\n    &quot;xgEetTyYBblLNOVvVLlvxkSsoOLGgoKBbkOHfFIOoinNiIkezZkKERwWMmVvpPeErqPpqqQAlX&quot;\n    &quot;RLtTinNcCBRJjVIiGdIiAGecCXVcyYFfJjDpYkxSjJnNtTQQicYQqVvyDxXdTNBLloGGyvoOpP&quot;\n    &quot;vVoJvNlNnLGgIiwBbWYvoGkKpPCWDbODjJtiIJjXGtpPvVTrRbauUIBErFNThHPuFEeiIfUPpp&quot;\n    &quot;gRrGPptSsUIZzFfiDPpWwQqdaAKqQkAaVveElLBUuZFfQpPoODgaAgGGkHhrRtTzvVYXxXZzxu&quot;\n    &quot;UrRCcjCaHCuUcQtTUuqTtXGpAajgQgSQxXkJjArRakuPwWOHjJFfhHXjYyUuJqkxgWmGiIgkZz&quot;\n    &quot;dDDysBIjDdOvYOoJjZzYKkJjyCcCwRFeyqKyYauAazZZMyYBupjTtbBTtJpvVXuwWZwWzjGgxX&quot;\n    &quot;ZzGgPItTPpiptWwuUCxXIaegGEAyYzSHhbBsZHhIwWuJKRugHhGUDdgXxGGNngpPfFiIdDKcQq&quot;\n    &quot;GgCvVsPpboODsSMmdDlLdIlKFWeJOoddDWmFnNEIRrieouUHhgGfVvGgLlYyAaFgGYxXJYQqyj&quot;\n    &quot;ymLlPpJjnBYhHybDTtdvVtTvVcCIiqbBQmDEvRaAtdDMkOZuoOStRdiIuCZjlRrUvVuPprRnNn&quot;\n    &quot;rgrtVvCcQCXxcUPnNYyJIPpgiDCdDaYyNCcBGgxxSBbsKHFckYhHyEpPQqexdFfDGgEeKkgMww&quot;\n    &quot;znVKRlFfvVExRYyrdDoOGgtTiLbBlIXergvVtwWHhkIirHhRXvhHvMmHjGXYuUNnyuGvsSWwrR&quot;\n    &quot;kFnNEfFUUkKBbmMfkIeFAVIsSuUcCRrCbgGhHBuUqQoMrRpFRrAJfFYtTXVpPhHEEACniINoPC&quot;\n    &quot;IDdhSsSKVHzZfJjqQKknyYmSsMWANaAnhHrbSAarRNREvVYLlqQcPpiIMHVvhtMmRrTtSAaZlv&quot;\n    &quot;VLPfOoNfRtWwyZSszYTcCDVvbBYoOyKkgvPnaLlAKlqdDunGIahnNSDdHXxPLHIidSsVurRKmM&quot;\n    &quot;rrbjeEOChTtcbwWgtrMYuwzvuUHhaqMIibQqaaAncdsybWLwWnVaqvxXuiIqhMJjmKKkJjqtXx&quot;\n    &quot;TEqhPZzgqeEQGzjocCuUcrRKJjkuTuUtRrfHhKJqQLlrRNRXxrRrLlKqQFfnQoOZzPXxoOfTtF&quot;\n    &quot;gGpNjJXVvQeEmXDGgdaAeEeyYExYkIXxyYeEiXOkKhzLZztTNnleETqQuloOyZzbeERQqePBpP&quot;\n    &quot;lLelLSULlZzarDGejEUNnoXxWwOugiGgFfpBboSIikKwWwxmiBOlLiIVvXGgxouUwnUYWwtTmt&quot;\n    &quot;TMAqQvoBbFWwfogGIXhnNHxiOOABZzXjmyswVvWGgIJaAPpFbBGqYGUbnNoXzbxXtcCvVvVIPp&quot;\n    &quot;zZWJHhjIfFaELleAhHLxWYywXVvPplHhogxXOoCcXaCNZWfBMmEUIhHihHDkywQrRqvoyYMqZV&quot;\n    &quot;rHlMFfyMUknddBGVvbzrRwkTtKYCiIwLTtlKktirREeHhgGWmFrAxZzAalLXoOnwLSdDIisKkF&quot;\n    &quot;lLeomGsowzZWpFfPngqBbgXNxMPHaASshHvvVVRsSrhHlQFWeEwtSzVvCcZJgxXGGgVvjoOsxF&quot;\n    &quot;fHhicAaCFfELPkKpcqyRrYQUjAaFbBPkSzZLeZNbBnzNIihHwWoSsATWPpmMwtaDFfZzMmMmdO&quot;\n    &quot;KVvrnNRhHUItxYyoOVGsIVvBcCbiyYvVOomDYybcGoVvOghHPmMpIzZmuUMawhcVpPJhQqXtTx&quot;\n    &quot;ZzmdDnNCTtcuIcCibBvEEejgLbBGgbIGbbBBTKkFfBiIXvVKVvYykxmglVfCeEipNnPrRIzZcC&quot;\n    &quot;pPNnINniIuoOSsRWwlGgLHpGipucyiYyFQquCxXcVXxGgwIdDiKLVvlFfkftTFEezfhBbGxXLJ&quot;\n    &quot;jpWvblLGgUOhHPpoOZzMkEbBexWwKLjJlNnfrRWQXxqEDdefaAFwFlzZGjBbJRrmMNntPpTtTb&quot;\n    &quot;qDnNdxFfXdDVIHqQrvVRMkBbszZwWJGgVFfvjSAaaAJjBbAQGfFQqMmsUuEdDesxgGOobBZXxz&quot;\n    &quot;kzlxXBTtYIimjJyeEbJZzsSjqJjhHcCLzeGgIvVqQWkvVJoOCjJCcSsUuQqMuRrgHfFqQRrhGU&quot;\n    &quot;cYKkuZzzZQqJjUJDdlLkKqLrhYyluyYULYywHhtTbBElLYyaAnNFOotgGObBoTKkPRrOpPotTk&quot;\n    &quot;XxKRfLlFfDWwcJOqRrQoHdxXDWlLqQDXxddyjmQqqQYyYyqJMmxCcdoODVvbBlLFfIiuUEYyoO&quot;\n    &quot;pPwrRIiWJjidHhTCULcbBCxXEMlwgYqumMBbpPYyUQIInNiMZzmsSegGeEvVEceRrqQPpJDRlM&quot;\n    &quot;uATGTCyYcWwzZtgdjJZAbiSsCiIcdDDSlzsSMOeNKUTTkKEetzZLlUudFIifTttcCTEeyYEBbM&quot;\n    &quot;IiPpSpPALjJVXyRHpPvYioOZNnvhHVRrjMsItTudFfJjJvdDNUlLFjnUDdunyiMmcCrWwBdtTD&quot;\n    &quot;bZBxCcGbJomMhHOMkbmMBVAavBbDbZoORsSrwWqQvUgGubBqQztTZMmSsvYyFfwUuHghkKHuBA&quot;\n    &quot;jJwXxJIJvVxPpwPpKlZzLLlkuiCciNnIwNnLLEObCIcENnVTyYdoOnNIRriHuTjCDdpzuUZJjd&quot;\n    &quot;YDBbdLlwvQqDdmMxUgGfCgzHrRgmePrRpuKkigGSQqQqkWCjJrNPpZznRBbYyCSsudWGmMzZAG&quot;\n    &quot;RQqcvGmMLlldDBBUQquPvfFRnQsAnNfqQQMmcgpPGbtyWwMmYNkKiIQyYcLbBlCqvVZEEsSZzP&quot;\n    &quot;TZSJjVcCvpleEZzLisSAEhHeThRrrRWwjoOLlNnJuiKvVkpWNkQMmEeHhpVUuqQqsRKCckrGgo&quot;\n    &quot;OZbnNwWBpPgOJjoLlWwaJjIilffsbBMmSGDCcgGmpPKEeQvVqkHLZBbaRrAFzdDeElKDdHKMmK&quot;\n    &quot;JBbjPpnNmAVtTvBoUpPHMmVvhfFqQuqQEeoOsSciXtTxwsdIfGjpKwqKjaAzxXnEiZAtTvVanE&quot;\n    &quot;emZAaVvKXxkTtgWwlxCFAaYykKfKtlLWwfFBbgTtBXuUGfcCaiuFJMmVvjfUgHhGOofaJWFfat&quot;\n    &quot;oOTAUdDpILcCwCIicWBFfoBHhbObKEekqSkzZjJaCcpIiMmPpPWmguUkzfdDBxXtToJYyzPich&quot;\n    &quot;lyYAaJjUeHhdfFHhlLEeVRvVFmMJSsjMgGhtXtQqJjTWXPjJphHuvBbpPqQVSsNctvyTdDtsPp&quot;\n    &quot;HCgGcwWWwybBeYNnYOoSsyVUIirSqvVoOoOjVjJvJkkzDqSzZsDMmdQdSsejtTGgJEfFxrhsSs&quot;\n    &quot;BqQVEpPjJjJjwWohvVZvVAaSuHhLcaNNnnmMyMmkqQYDdyzOoPpnPpNZKSdWiCSstJjTkKcCnc&quot;\n    &quot;CneExXTpPOsSoUuHhJzZjpPwRFCcJjHhHhmEeYycCbxpPnnEjkKJevHRrNlLDhgyYPlyYLVXnn&quot;\n    &quot;NvVcCZpPkkKKJlLqQjzZXGglFfJTFeQqhfFHEHbBTtGgKkhRQqrfKwWrRsSWwkIcCDdfFBbAac&quot;\n    &quot;CgEeGsqQGzTrRujJqQGeoopPceIYHhuUlIywWYQqiQqbompPwWLlBbIeEqILlitsONnZZzJonf&quot;\n    &quot;kKxtTRroHhrEkKePdgFfGDpEdDhUukKQUdrRLFfXcgeEibpSrqQdDJjwTtWnbAjoKOocCkiCcC&quot;\n    &quot;pUuqIaAiyoDdOsGgEeSKwHHhNMIwTXoZzaAociQqIufFKkUCvfmLTwWVgeEGvjJfFhjJiBbAnh&quot;\n    &quot;MvVjJmHNxwWsmMSSLZDdzKkmQqYcCAsSoUuKlLPPshPpGRrBxXbgEoOcCRreoOelcCBSsbKPyQ&quot;\n    &quot;pPxtXxTvvbZzBKoWwEtTGMmEegkKHhFfYnNcCAsSJhHjaRrjJkKNLaBQKkkKqbAlvBTtbnNtyw&quot;\n    &quot;WYuUpPpPITQqoOXzZKiYqQYTtyqDOFEqlLWKkkKzZzRrZMRrXxmwmMdDLleNcChuMmDdUAabIK&quot;\n    &quot;keEvBFfTteqQSsRrRrToOcuDdmkKWNnRPpjJBbvVXesoOSTtUuoRrQnHhhZfFAgGDPphpuUmQq&quot;\n    &quot;dDXkKnNeGLvVeExXSAaieEIeiIqNnUujJSBbUwWuKkoObBXRvVoGgnklLKOoYyGgSVdDLlGBbB&quot;\n    &quot;bgZzvsnNLRJjBmMDdMmAarRDdbrlyWPpKCckbBDqQduUtTGFrRMmfaAoOLGWysSxyCPrLKkAab&quot;\n    &quot;BoOlsSrRRANQqnuogYyCcSkKdfFDJLIOoiCcKklDdQpPHhJjIvVyjJNtToeEOoBbmoOZzWLliQ&quot;\n    &quot;qaAIaxlLQqXakkZuqhUBoOFfXxcKkCiISsDdbwhAoOKkwWaPzrRBXSseEuUxbVoQqNpQLXtLlk&quot;\n    &quot;uUwRrvfJjXxSDdsFaAbFfpjJJjwOoEezHxXBgcCJjsSxIHhdqQDhTzXYyaAzXxuLOoCcwWnNTV&quot;\n    &quot;vMwDdbVoqNnCYVvyIiSFfsVOVdDvofTGztFbiIMmOowWHOaAuCUurIiSsuUFVvIivdDvRpPdIk&quot;\n    &quot;KiDrlLHaARrjJlLhnNeEBbfFQuUBbmSsPsFBJRrmRCvVRGsSgrpPcOowQqFfWMuKKRFIKDHhMf&quot;\n    &quot;FkzetPSGgLDdgGWUuzcCXHeDtTdbIMARrIiiSgpVSsXCnZrIuXZzbycjkKJCYCcfaAKkHDXxdi&quot;\n    &quot;BLlbNnCgXxTOoavVHVvuUdbZnfFNwWyiIRiIpbBgGPUusSrrhEeHRbXxBbiItUHhuIiTgGfFhH&quot;\n    &quot;qHKoOtTkhQxrrZjJZRoGqbKkfaAEeQrNDaaAMCXqQxcmFyYKJsncRLlCRQqsSrcoOrAasSYwuB&quot;\n    &quot;RrFfHDHhdhUntgGkKxbPzpPZpkKiIiItTAZzqQJAarRXxjMrRwBbyepPFfEYyZzwWrRTtUDdDV&quot;\n    &quot;joHfFyDdhHQqnqQGgAaHQqhOYGcUudCcvsCiIxXczZkKoDdOBZHwWEPDdpeYyPpwWdDmFRrfMj&quot;\n    &quot;JYAayqKkQdtTLdByfSNeEjlLJwWRzZrRqfFWmFfKkOopEelZUktTqQdEeEndDrRKsSkiTpyELl&quot;\n    &quot;hHeoOsncreaUuAGrJjRIidJChlLHPhHzSrRqlLsSXxzZQWQqIuajJAUkKwWlLEvDdVkWuUEewK&quot;\n    &quot;lSzZOoZIYyzZbwWDdMmgrRozOoovVOUuFIcNwWOoyhcCHWrWcCjJXUpPrReXxWxXgGwPTlLhHo&quot;\n    &quot;AoOaOUuuUtdiIQFFfNntLlaHhxXASsTupenNERMmXdDDSpdwgGWDSJjsNnrRrRVLlbBbccmwtU&quot;\n    &quot;udDcClMTtACWwjJsSpPpLWwsSloWwrRSsCcRrGnNgGuUhgDdGPpRzZNPpBoKkOCbQzFfsKkDdS&quot;\n    &quot;PpchHKxXzUUdDuuYyaAsSkxKkrRrNaAnXTtxGnNCcxXaaAOopdDOowWCcssSsnVvsfpPRvbeEI&quot;\n    &quot;bBCkaADdxWDdNEenwRrKkEeXAZFfDtpPWwTdzGgOobBfEezZYyzbhHtTNmEtTecCqQVPphRBnN&quot;\n    &quot;bryYMpPSsrREAaAaPtKkQqIRJjrsgpPGSMfFpfHhFMmVfFMmvVWIZtTzaAiwkKvBbPDnNdDQqW&quot;\n    &quot;WwwhHXZzoHhCsScFIiXxfzZMWwHUuhMOSJjsySsYfKlLHhOweEdDWWwgCLbBNnnLllbiUXxulv&quot;\n    &quot;VgCOMmgIiGqQUuxGbBAaGgoNmMfMmnPWwgnNIqsLlLlUJjuSQCcDXqQHzZgCcnNGHhhVvQSbLB&quot;\n    &quot;uOfYyBbQsSqFXxojAgGvrRqdDQcvlLVxXpKGgEUuekGgKCrpXxMmkSLlNHFfVvhnqVrbBtTaAZ&quot;\n    &quot;jkcCKJEemijJIMzKYJjJjEeVXTtxAavmlCcKwWnPJjpNCcvVbqGwWgQSWwaloOLAstfAxXWwfW&quot;\n    &quot;wBDdSsfFUuMqQpmQgFwWZzQCkKxGbBcCgWwnNAaXSsfSGmwWiIVFfFuUeiIEpPZzrpPTtNwaAu&quot;\n    &quot;UGyYJjgeZzEfQTtqWwFTtAatiAaSMmGgoOsNndrtTsSQqgKkmwWXuUlLxmMlLAaHhCctXxwWwr&quot;\n    &quot;RriIEeJjbfFOofFJMmqqLKklQQQqfOoCcWwoocDgSscYGEyRbEidTEJjebbBBjJWwMILlivVJH&quot;\n    &quot;XxyFflxXPUGrdYyDcRrCUKkuNnoORgIiuIipjJPpLkqRrQWPpBzZpPLlLlLZzVDdpLlmsSNnuU&quot;\n    &quot;iILTqQeMmCcsSmMDfFrIFfivnjJjJNtTjJiIjnNsSJVUGgQXZztDdZFfSsHhqrgGRQvOoxXSCc&quot;\n    &quot;sVuGZqQxXzgEeNnSsyXERrdDDdqQWweMmVDdLltTvkyYKiIGgbBSsKkcUutTHhOoCuaAUkKyvd&quot;\n    &quot;DVgvVGqkBbCcKiIvVxNnuUdeEDXglLFnPVvpzAaZzSspHhCcPHhPpXNnfFZzzZxjJaWwATFfbB&quot;\n    &quot;yHLljUuGjJzZuUguUfLlFBbOvVoPBbdDpjjlaALejJPpHTtQqCcRVvrlyeExXGHfMHhmgGFhvV&quot;\n    &quot;sHMmviPpKIqRrPiIIiEFuUaxXwWAbhCcpvpvVPooOWBrRbHyYRKwhHWbBAZTfkKNhHwWkXpmMP&quot;\n    &quot;KkxKQjsLUumoOMzZRlxbBXbBuvrfFRBEebQPpcwcbpeEPBQCPpgGrnNRntOHfFrCcRgGhtbiIB&quot;\n    &quot;OdxXNnDgoOVvUujJGKjgyrdGgMmgqmMnRrZpPjvCcVXxeEJgEeSsGihHYcCUfAFfxYyXcziIuU&quot;\n    &quot;oONZuJjzZvkOsgeEzZVviIBfFoObnNglxXwLlWFfIiLlJeEjFftTZzLLlIrkzZKRcaACiuUdpz&quot;\n    &quot;ZPVhHqwWQvqQDJPpfWgFfVBbNnoMVmXqNnRrAaQOonQqMLlmUukckJvszobXtTmMjJeEUiAVMm&quot;\n    &quot;vyziIUoOuzZYPuICrRchTdDtbBTtXxQvHhbBQqGRrgAaqjJlOocfFCCbCcBQnyndDFvVffHNbx&quot;\n    &quot;HhhHIiTtlLXMmBmqQlnSsIhHitTNBbHhpSsDnDVXIisShovlqQPEeLLdtTOoZoOzDoZzOtMIhH&quot;\n    &quot;chzZHLlDdCEuoNnOIOozZgWwvVvVWzdDvVRSsVwWwbByrRYVvrRvVfFONnzZEtTEeWXDNndcCu&quot;\n    &quot;LlrRoOpZzGgbBChHcPTtWzBbwWGFfgZUGguwIDdsSsSFfYLlsSrkKRzZBNUuVsSLGglSsnNvHJ&quot;\n    &quot;HpfFWeEjJxCMhHmMmRruUuonNrRjuUJOUXxSsgGPAaBbCcZzpsQqoOLlWVwWyLlIiYSxXidtrx&quot;\n    &quot;XRTDKkDdkKdwwWUuOfUXXxxJwWOojYWQqOoOocNVvnwWxpPrRueEwWsPpYySFfwWBblKaAkjJZ&quot;\n    &quot;OVvozDdYaARCccCreEyRrARraepiIPoOjJHhEeRryUuwWeoOfFwkKGGggPpQYGgQgBbLFffhKk&quot;\n    &quot;HkKeysSYGgQPpnNqXkKqQwWirzZCwacdDeECAOoWcTtgbBGeEIWwWmzmFHhsSFfsSFnNFYCcaA&quot;\n    &quot;yfpwWdiIDTBbhHWwdDVCiItTcHhMgoOjJtRAnNlLarTGGXHhfgGlLyxESswWFftSQqsQYJjlrR&quot;\n    &quot;LIiPCjJxiItTuUjxdDXMcCBUurRTtpTXEZzeaAYEeyWDdKMmJiDdIUuEeVvkKHhVvKVvAQKkqf&quot;\n    &quot;uUxXFRWyYwvUudDVslLvCcZzVvwsSWCOTDdkzYKkyZibKkmZkcCKzOoQqrRvVkQQqpTtFfZzkK&quot;\n    &quot;NnPpMmPnNTHWErReXxrRwpdToOoOtKpghuUsSHGLlwWPiITiItQxvdvKkVOoxnNXDqmuyYvvjq&quot;\n    &quot;QvVhHLAXzZfFGgWwpPHhOKkmMKkhpPEeTtXxKngGVvUUEewBJUuZmMzxXHFIifdDFbBsSiIRqq&quot;\n    &quot;QQruUEDKkdTyoOYSSsSsvVidsSrRcFfCPplLDVvZzNntJAAaajrnNRecCEISeTlLjZzXyYxDnE&quot;\n    &quot;YUhHNAanuwfBbjJFNZzoEaAhHezgcpMDdmnNPHGguUhwWLlcCcCFCLlddtWvVLLsSlJjGgEXdD&quot;\n    &quot;oOLwWjBbJjjCcJDdJWWwwlVvkKUurXOGEeIigoNiInVMmvxCcbWwBwnbMmbHhBBMaPpmyYvVrR&quot;\n    &quot;iOAZzaogVvkKrRGWwZzWqQpPpPweHhybWwKdDkBzZLlNneEMsSxXmYlhTbBtxXDlIiONnozSGg&quot;\n    &quot;fFPyYcjJCXxpiuKOokUCWvVwcCTtnbBNbHhBPpMMmJJYyTtrXxTtzZRUIibicusSUhIKkaAoOu&quot;\n    &quot;UjQLyjJYQCsSGXsxXSnuVvUKkyYxXWAEeazZwXxEejLpaAPlMmbBhHAlLPpaSsJMwGrRGggXxp&quot;\n    &quot;aAPWiPpUDdvVFfubBqNkKlxXeEeEDfFdirRIDdgGeEveEVpPCcrUpPlkKLuNnRjJmIiAnNtTaM&quot;\n    &quot;DdbBLIiVvOGSsLloOaAQLlIwWyOocCtLzZlvdVmMSAaaDTORxXaRrArxevuzZpvVXcCIeEiVhH&quot;\n    &quot;CaAcbBjSoKkDdOBbgEFQqfEaJjfYtwQqWTzZzZyFAcCyYjJarRqsSQywWilKkLpJjEQqmMdDaA&quot;\n    &quot;vaASpEebBhHXPpsSxgqQUuhKkFfvVhHSxXmMYyFEzEenNJjazZAIWwhHSsWwZxkKiIXEyYeEKk&quot;\n    &quot;GwIiWNncCAlLtyYTalzRrZbBVvcCuxXUHhwEwWeBnNbLlXxDTQqbBtrRgnNGdWwTVvdDlUuHxm&quot;\n    &quot;kkKyYEYhkKsXxSKCckdzZmMHhHqQVFlLJjXxzZfUXAauURNnrxXxyYoOuMmVvmMHhfSsdeEDNn&quot;\n    &quot;JrRMsSENnUueEMmNnWWwKNVvngGkkKwwWZzNQqivVQjJqtTYySGZzncpWwPCeuNnUFaAcCfQSs&quot;\n    &quot;LxXefFELllqmMUujJHhhHQnNlmPwWpMnuUNRrEeVvAaLnNoOhfoOeGdqQVJjpPcbByYDdzrRPp&quot;\n    &quot;RrHhfKhcCwWHFfQqjJkFPHZzYXZzjJeExpPTIVGgRrHRrOohUutWwTDPplNnLvVZejkvGgVyXx&quot;\n    &quot;NEenHrRhNZzXxnwWWwYkNFfnmITtinIiNqQaGgQZqGgQRrBvkKvVJKkjVfiIQezZpPQOKkKqQo&quot;\n    &quot;EAIiDdaGgYyoOeOtQKknhHNhHrjJfFBfFHWwCchCnOGgLljJadMmDtCcDdGgeEnNkCcKdAAmDd&quot;\n    &quot;iIMZzKkWQquOoSsxXOogGXAaQqxoOhHEenNnqlLcIcCAlLHhtTzBbyYDdZfFtTzGgZYyEeSFPx&quot;\n    &quot;XpaAgGbdWwSsyYYJpHgjJGhVvHhPEexyYMmkSsnRrLlNxXVVytTeEbBYTtiIAaQLlkKqjJOovv&quot;\n    &quot;eGgEfFIpPizZimFZzJoODDdJjWdGgDgGRnkDdByYbKDfuUQqTJwWFPIIiXWbzZByaAYwWxXUuI&quot;\n    &quot;iSsUsCAOoWwaWwcSyeEYLlTWwlLreBMKkrRLlakKAfNnoOjJUiIpPCcrRQqvZzgGVwWpRnNRUL&quot;\n    &quot;AmMBzZPpbVWwXwWJRBbrEesSHKkhjJqQKmDrRAagjJkweEWKQuUGvVmAaMHpPhJvVHcCekKdbB&quot;\n    &quot;KcCyFfAaAaYSftXxDkKrKeEcCWwMmkVsRrStEBmMovVMmdDOzxGMmKpgDdGHcChaAIrRFqbBbB&quot;\n    &quot;dDsSBbQqDrCcRIIiqQiiIxXdvVvavVmlLMgZzsSEegGGTJjMHRrhmYJjyFftTtsfFSCcsnlLiO&quot;\n    &quot;oIKkvwjJWgGmMOoRrVVvfYyrQqROoZzFRgGvTgxKBbNnkbxXBBbOoUXxubBTtgnNGXYyJjWSbB&quot;\n    &quot;iIsWEecPpFZSsSzZWHhSeEJjJCcjsDdzZcnnVAakeERUunNQUuqRrwNSeEHhwWQqQRrEuUfFId&quot;\n    &quot;DBkKbNUungGoOwoOWQqlLEQiIqXgtTEApfFMiIjPDdpRrsOfFlLoWwKvVlByYbVmfFMMmZcvbB&quot;\n    &quot;VIiTtLlLbBCcHXxoOhhpPShyLtTOolYOpOQiIWTtxjJJjTtyFfYAaAEeQqSszIiZaRvVUurvVv&quot;\n    &quot;MmVYyqMYVtgcCGTvyXwAaqqQQdhdeEDCfFcRIiYoODdAarWwMmhnNjJJjeEpPICciMVcCvmhHG&quot;\n    &quot;gvEevVDxvGDSkKsnMXDWlLwWbDCcdUPpmFdDfDdMbBRrTKTtUQquCczZlLTtiKkIEeKwobBOWa&quot;\n    &quot;drRpPlHhJZfRrFzBbAOlqQLKkXxYyLSsMmIzZiDFfpPoOEeBOiIhIiOonDfOoOoqQDdWqQdBJj&quot;\n    &quot;AaIayCVjJvyYOAalLoyYOnNAaFnNvVflLMowWLlNnKkjJKkKknNCiIekIZzwEeWjJiHRrhIeET&quot;\n    &quot;iwWIOhHozDdvVvWwXxokxXKOQEbBajyYrqQpXNVvmMnxElgGTtLeGgiIHNncUuvDdbBOVqaTte&quot;\n    &quot;EAwWUuQqQqGPpOogGgLlhmMhHHqQowfFHhWXxcBbYyfopPEEeuUuuUxNsSAaAzZUufFdDaKWwb&quot;\n    &quot;BWwkqrTtRIZziiIgGCmMhHpPcKkBJjxEeDhbBHfFdAhHMmalLsoOIiSXyYSvVzoOlcCLUuhHWw&quot;\n    &quot;CHxXWwhLlVOovWKkwHmdDWKmMIeEANOouDpmMaAIhldDlLLDCcNLvVcCcyhoOHYRrMmCIiGlbB&quot;\n    &quot;XxtElLIYwWwWuUfzBbZTtgGbMCcqQtPpWgGkKwrWAaxXvVIiDhthlLgaAGHzZnNBbwWTHlCczh&quot;\n    &quot;HFZzfCczZZMKkmqQXFOofxEeGQqgLdAgdAaCIiXKkcCZzxjYyTtJITiISwWscEeCWaAOotTzRr&quot;\n    &quot;PpZtTlWwLmMpUuLtTtJjTNkKszZAMmaBtHcOhHLloCglLGcChTlWOohHzZIiITtCxLlPpfFtTK&quot;\n    &quot;LiEeMmeEUlLdDuuUoTtnNOfFRlSswzZcGgCamMfMmFHhbIiCugGvVtTUuPXxpUBbjJwWzIiEeZ&quot;\n    &quot;dVCuUcvkKGgyXxIiXxhHzZEeeKkcCXEeEXxzXxYyjJseESIlLEeVvIiKohHxXBvVboOGgQHhqg&quot;\n    &quot;GoNnQqXWbBwCcHHDdhRrYlLyYYgGyIJLAaXxlcCaYyisSDeEaAbBdMmoOvAaJcbBDdMxvVjJHD&quot;\n    &quot;zZABbJFfIijatTdOcChqQjJPqOoQpOozZVgfzZXeExUAaUyYXbPpBxuBbMmWwGfFDgGZzbFfBu&quot;\n    &quot;UsXxCDkKdYmMlbBEeLJjbhLlUuJjOoqZdDiItTOaeBbLlEhHJvVjXxKxvVVmUuxXMuUTtpZzPS&quot;\n    &quot;UuWcCfFFuUfoOgTtGUuJjgGkAajJKTEetsAagKcCbBdOhHoKhtBbwWrRTHIiDddIltfoOFgWwt&quot;\n    &quot;AAKKIUZkKzHjJduUDGgNnyYjJWwYdDyRrxGgpQgGqPmMVvXrRGgQqhKwnNWRUurbGgBaZQqRpP&quot;\n    &quot;rzAeEkxXEvnNpcMmnNeECPdDRrlCcxVvXxDPMmvVNLKuUxXFfIiklnofFgGWwOPpdDGgyYpPsS&quot;\n    &quot;YyuUhHTtFfOiIomOohHcyYCMoOhHmYZzyOgGaAOoYyohHMnNUuSfFsPxXpnmMNnGgLlNMmuwWZ&quot;\n    &quot;zKkZzMVzZqQcCjJRJjrWYHaAhVvywXvVaAMmMmHhUuJIiqQwuUWvJTssSHkvVKCchTUNAaDsDd&quot;\n    &quot;bBSdnXxRresStNnPLljTtfbsSkKEejJLbBOoLCuUcaARrlDdXGNngxHtThkKhbBjZzugGUUTCs&quot;\n    &quot;SgGckKHrRHhpbBzZzPeEeNLloOZzneEvrQqWwRyYNDdJjnRrTaAuUOiIocDdjJCNnCSgGDPGgp&quot;\n    &quot;dkmLUulVngGNMgGrFfjAykKHhlLuUoOAaetTElSxeIHhiWwpPHzZwWjJaAhGzZSWgGIGpPgsSi&quot;\n    &quot;LlEewcjJCUVvuBbAasSqAaQpPkuUUlLuKkXxEelLiNnMSsCcTtJjDdwWDdmBbIwWiyYDdpGrFY&quot;\n    &quot;dYyNnDBhHdDOobdPsqQSKsSdDHhkgGZztTiDmMjvVJjJTtdIsSFfphHOowkGSsgOsSbBRxzZNn&quot;\n    &quot;JjUTtuqQIiwvVBbJjVvfFEeNkKnoTtfFqfjJLlFQOtgGTPTEGgaACcHhDYytTtUuZlLHhpmuUM&quot;\n    &quot;KkWwTlRrXxMaAmeEQqyYXxLWwEMwWwWmBfFDdbGiITQqriIBbMnbBYJjMmSsbByolLmhHMWwHw&quot;\n    &quot;WhxKkXKOokkOoXxxXKwIiTyjJUWKkwuBbIxyYuUxytkKBbhHTdaABmLlwWMpPMyYTtmVveEbsM&quot;\n    &quot;mSFfMMmcCzZjMhHmPpKuzZUVvkSQqsiIXxuUMmKuUSshyYrRHPpXxongGMmilksSKLYyovVOIX&quot;\n    &quot;iIMmNnVvCGxXgVvrPpRpPcxXYFfyXdpPQqIioHoOqQhgNvVsSnGyYZAabBmPpyYzMmZGgwWMdD&quot;\n    &quot;oOCnaeEGDfFziaAXYyxICcWMlLcEetTUHhUuSsuuUfiIVAavFNvVnrRLIiliIduUnNLDhEeHzZ&quot;\n    &quot;NnXxdTtMGjJWwgDcyYejJshfFMLlmPpWXxRryYxBrRbUuDRrhHdNUujAaJAdDaCxvVXxSsXsSM&quot;\n    &quot;ENnZOSsqYynvVNBbMyYEeDdhEeHmBbblLVvqeEYyOobBuUCcCcCjJcSjJsuaAUMjJyYRrdPMUu&quot;\n    &quot;mYJjyxMihHIHhkpPPpKeXoOxEIigKkGgGmaAsylwWMmIMmNnCIfFiCJjMcCmDYyUKRrkWwRrsS&quot;\n    &quot;hHIhHFWxNnPpuRrMMmmMUAaumXlLHhKSsvVSskxUkdDKqBbQpSstUuTvVokKOPkKrUuRgGJZvV&quot;\n    &quot;tTbsbBvVUuHhhHxUWwiIhHFfKkumMjAatMmlLKkiDfdDLkKAaevVZzZzpVvGgboOBPEliInKiI&quot;\n    &quot;STtXqnNQxBNnVvbWwBboOwERcnNzfFZzhFfHPrUUuuRpDDHhddRrXFNncCoEWwEeRzEeEOoCqQ&quot;\n    &quot;cTjJtUuKkFfeOZzRrIDdGZzkKgUpVvPGgvVHhuotTLlHAahAaOoxXlUuLYyBViouUOIvbPpWuU&quot;\n    &quot;uROorUiIuLdDQqTtLlVvXxBOocCkjJKzZGgJjbBDdUDPpdBbjJHhUqgMTQqiIvVtRtTrsRrzUu&quot;\n    &quot;hmMHvVHhglxXQgGjxXMmyLlYlLPpyYJqJfFjhgGsSxXrWwFfyYLlVvqdTtxXeEgGihHfFIIitT&quot;\n    &quot;jJpPwWBbYySsbBrRDjJgGNnfFvxXgGfwWSsFSsjyYJVaAtxXfeEeEkKaNnUfFuvOosGgSjYsSa&quot;\n    &quot;AnNBfFvrZPpwWnNTtSsgMmGgqQTtRrMmwPpSsWhRrvViEeIHhHHhqaAQGJjzkKppPBbPZpaAZz&quot;\n    &quot;MmUuWgsVvmMcCgGLlbbdDBdEeGgDbvVhAaHdDGgBBlWprRPEewEsSYyEepPeEeLSrRuUIWwXxi&quot;\n    &quot;zsQpPkKqfFSeEUdDZlHhLNnzuPWwcCnNmMJjrRkWLqQJjYyixXvVIVvPpOcQqjoOiEeIeEJCoZ&quot;\n    &quot;hyYpgxUVvugjJGXbBkKLqQlETBuUbteUroOVvRBbiIdDZWwznNBGgDdsSbuNvVsSIieKiIGgjJ&quot;\n    &quot;dPoOpWwDyfFpPYIikdDTtpPEaUuAIizZUpPuYsSCcYyIFvNOoutTUfFyYHhWxXqQoyYOwaAvVy&quot;\n    &quot;YKkngGJjmGHAaiICcSRApPJjeEaSsiIeIiEdDrsQHhWwKkYyuUscCFVvfSAwoOyYWaYyeEUnNC&quot;\n    &quot;BbsLIilSvZNnzUuVuUpqQZzLlPcCsScpEBbNdDnegBbTtGPyOoYyYPvawDdWtJjlkKQlLKkhHq&quot;\n    &quot;WwSsLlfjPpKkJFjJRrEeHvFfVEQKkqdDJjXLhHlTtJjxLlWtRrTIlLiZhJjiIHzwxXjJKcMyYm&quot;\n    &quot;CCcHhksSLlenNWRrwScZzCDdsrqQRgGzPsSpBALlFfacCEzZOomMiIejGgtTJoOlLBbsSbzZpP&quot;\n    &quot;BZzTtJWwjLSslbBMsqQSsqGgQGgSqlayYeEAQFNnfqhHJjPpAadDvEeVcCbBpPKgGoOkRQqrer&quot;\n    &quot;REGwWfZzFeEgwmMZpPIiUWwuAazpbBvVqQPtTWStEeTvVaAskXRrxHhKbNnqQBIpPiebIgGasS&quot;\n    &quot;ACciEwOoSsWiIZzeBMcCmpCcPEFEefrRCZzcVqAaQJjvJjKZznaAaANAakoOPpbJjBDUvVudDd&quot;\n    &quot;YsSyIiBbZWSAaAaHhValLAwWAavLlHxXheEeEVixXjJIEyYxXiIxkKwvVRrOorRWwWQlLqLlUu&quot;\n    &quot;sSJjbBhlLZgGzGgncPpCNjlXKkxLoORrJHnPVEekKvpNWqKvVTJjtEuiIUwWwWCcyYPWwpcCji&quot;\n    &quot;ITtYcCyECceJjpnNPJBkhHfBbzkKMDHhdmJHhjtTFfyJjHhdUujyYXxJKkQqDMwWuUmmukKUZz&quot;\n    &quot;jJuUHOoOoDdqQqQaAUuyYrHhRkKbBWwhazloiIhHRrOLPpDNnZZzLzgGZYNnqQylfFaAeEiICc&quot;\n    &quot;zdmoOLeElmMnWLlwvvrRVaAVPsSqQpuUzYyRrZBboOKkgGTNGgntMmssSbtLfmMFciICdDloOT&quot;\n    &quot;fYyPpSNFfnWwiuUIBwNnAaWkZUuIiQqzKXxvoOtTmMbGgcTYydDRHtThrQqlLwAaalLALAalvV&quot;\n    &quot;XYNnNPpuUKkNLlpPkKnhtTHtTXxlEnNeAHhaUuVAavLHhBbzTtFfZGBbaAJjvEeVxXZzgKHhkg&quot;\n    &quot;pPxXPfFeEpGcCCDdDdreJjErRHhxBbzZXxXCaAyYclLDvPpVtTdCkDdJjKmmMlIiLMmMKkYXmM&quot;\n    &quot;QVvXxUuREeJVvqQLlBVvZzbjOGgSSsoOsGgHheEdDoRtTrXxWoOwOjJoYyMmVvAaFBbfEeTtqK&quot;\n    &quot;zZkIEepPNuUnEeGbBlLcFrEeREwWqhHQmOoMXxeAQPjJpJjCcoBbYypNYynWwIiaVvAcjJeEAp&quot;\n    &quot;PRrNnICcxXiaANnakKEehHRrgGCPoOsEeStTdfFDpPAaNnNIiTtZznPoOpiISsXxjIMpPmtcCT&quot;\n    &quot;ieIHhSlLgBbGglLLlheEtspPxXSTTrRlUDdupyYYyhHUNnFfpiIxXTMmtfXxxXFPeEmxXVKkfF&quot;\n    &quot;vCcrWLVvlwRqRrQFfPVvFfFlLZzdDfpHhbBWwyxQqXZmMVgbBGvlUuLxXYyzAabBCkQqZqQiIm&quot;\n    &quot;RnNrRhcCHrMpPQIiHDdhqdqQMmigGrRIiTtlLZwWYyEPpekHOohVvKDdRfSspiIPZLlzFrNnmw&quot;\n    &quot;WtTMnNrReXxifFIsSwuUWEOYyKrRkfrfcCFtTCcwNSsnWJOojOUXsSxBbjXxjJJuFfYMmCcyGt&quot;\n    &quot;WwTbBLnNyYlOohHSsLlgSDdoOHhhHsMQqYytTHtTjJOoLlhKkowWUbBTtsWwSuNnLlxXrROcyY&quot;\n    &quot;ZfFzvVCZzHhqHhNeiIckKVvuUuJjiIJjUXxzZCEGHiIyYhgDsSHLlfFUuhrNnRaApAsSaPXxdk&quot;\n    &quot;dDGgKzZntWwTkKbpvVuUGgPQcCqUHhuWwNnuUEelLYVvhHyBvGgVrRBbreEWwRsiIHYJjAIiat&quot;\n    &quot;DdaATWwyOohEdmMDYyTtYyDdJKkKGgkXLFflwEeWUuGgfVqQvBbFYyeEtrRCTHhvVTtpPtdMmD&quot;\n    &quot;iINnrHhQqfFrcCRdQqkCmMtTYyeEcGWwtTlgSrDdVvRsGgaARrOAaTtEjJQHhqeoWffFFuUwRJ&quot;\n    &quot;tTcuUCjruUmCcLjfFVhHXxrsSRnNuUVvaTtBnRrNiIbBbAxBbpPGuUgBbXbByYqQkKqQaDdALl&quot;\n    &quot;IiprTtROoPwDdGbBpPIigWxCcCtTcImSsYyMJjuJjUmMpPtMmhHpPTGgjJpPaAcHhCiTfFEcCe&quot;\n    &quot;tVwWvKTtkKkiItKkIiyYQqOoTVxXgGJXsSxWwrREeJzZjpRoOrPnNjvoOqQruURNnhHmJjMKkX&quot;\n    &quot;FOMmofFfNnbBZzJjpwWBbxXPYytTzZuUYEeyraARNnpKVSsvkFfVvAQnNqBbitTfFgmMGIoOPp&quot;\n    &quot;hHaTtTtMidDIWwRDdrRrcCvVqQqyYmeEMWeErRwcCXxBbryYKkRxXRHhmeEMmsSMSsruUFAFfm&quot;\n    &quot;tTMabIilLFWRrwfkIiYyeEPpKfFGgFffFTtBaAQLEelPyVvYpXlLPpYyxqxXVgGwIiWkLlKfkK&quot;\n    &quot;zZFZzwWVwWLlvvgUDduaAdWwDWDdwDdDqQdsSlLvVvVqQCcuUkKsSzZGjJoOfMOojJmlLjqQJj&quot;\n    &quot;JQtTVvapPCcAJXxjXxerRhHESsmxJjnNWhHyYwXOoSsYyxXeSsxXZzZzLlhXxHEGjJgjiIJGha&quot;\n    &quot;AsbBvVeuUFzZfZzESgaZzAzzZvVZbAaBGtTHrGgRrRBhHnaANbcsxXSApPonNObmMBanNtTkKY&quot;\n    &quot;WwaArKuUmMoOyYKkkbBWwfFRrRTtGgTpPeEtsWNNnnRroOjrRJwNcDduUCnORBbrGguUoZzsSs&quot;\n    &quot;SUNnuAaPpIYysSiNnhHdDFfkKSsQCXxaAEUuecxrHkKMmhHaAhQqtxXaAOHGghZTtzoTFfOoiI&quot;\n    &quot;cChHnNUmMuYyRJjdMmDPsSXxTtppPqQJjlLZCcHhqQgGzXPTtpMbBmqqQQAuUTdrRDnNxXWwtv&quot;\n    &quot;VYyiIIigGOoVvYyHhagGZzKkqVvrlLdDROGgovVKpPkBbwWOotTOrRgGWwHhfFKkgTtGWwNnwi&quot;\n    &quot;UiIuIQDdKkSsSsYQOoVvHhaABbsSDGguUsSCzZcIxXidziYyrrRRIqrRGgQWwMjJmFfZJjnNhq&quot;\n    &quot;QmiIYyAaMhnNHiInNMyqQkKIGgiYQXxqoOTpPtmyAaYpPqcbBCQqXxpPQExXexXiIHLzZSswWl&quot;\n    &quot;LlJUugGjoOrRJjqYyrxXRkoObFfDdBWwKkkKnBgGUubsSNqQpkcCKgGPdDgfFGxuUmCcfFmMSB&quot;\n    &quot;LlDdPRrkzZKIigGfNiInFYyGtTbBgnsSzZhHoONgOoGbBTFfrRzZFfgQqGyYmsSMtnNCwpPWwW&quot;\n    &quot;rQqRcoOBbhnNHjJpTtTtdbBfFSsDEebfFLlBbmGTtgMHhaAhHS&quot;;\n\nint main() {\n\n  int64_t input_len = sizeof(input) - 1;\n  char *s = input;\n\n  int64_t i = 0;\n  while (i &lt; input_len) {\n    if (abs(s[i] - s[i + 1]) == 32) {\n      memmove(s + i, s + i + 2, input_len - i - 2);\n      input_len -= 2;\n      i = i &gt; 0 ? i - 1 : 0;\n    } else\n      i++;\n  }\n\n  printf(&quot;`%zu`\\n&quot;, input_len);\n}\nThe x64 implementation\nThe full code\nBITS 64\nCPU X64\n\n%define SYSCALL_EXIT 60\n%define SYSCALL_WRITE 1\n\nsection .data\n\n\nprefix: db 1\ninput: db &quot;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&quot;\n;input: db &quot;dabAcCaCBAcCcaDA&quot;\nstatic input:data\n\n%define input_len 50000\n;%define input_len 16\n\nsection .text\n\nexit:\nstatic exit:function\n  mov rax, SYSCALL_EXIT\n  mov rdi, 0\n  syscall\n\nwrite_int_to_stdout:\nstatic write_int:function\n  push rbp\n  mov rbp, rsp\n\n  sub rsp, 32\n\n  %define ARG0 rdi\n  %define N rax\n  %define BUF rsi\n  %define BUF_LEN r10\n  %define BUF_END r9\n\n  lea BUF, [rsp+32]\n  mov BUF_LEN, 0\n  lea BUF_END, [rsp]\n  mov N, ARG0\n\n  .loop:\n    mov rcx, 10 ; Divisor.\n    mov rdx, 0 ; Reset rem.\n    div rcx ; rax /= rcx\n\n    add rdx, \'0\' ; Convert to ascii.\n\n    ; *(end--) = rem\n    dec BUF_END\n    mov [BUF_END], dl\n    \n    inc BUF_LEN\n\n    cmp N, 0\n    jnz .loop\n\n  mov rax, SYSCALL_WRITE\n  mov rdi, 1\n  mov rsi, BUF_END\n  mov rdx, BUF_LEN\n  syscall\n\n\n  %undef ARG0\n  %undef N\n  %undef BUF\n  %undef BUF_LEN\n  %undef BUF_END\n\n  add rsp, 32\n  pop rbp\n  ret\n\nsolve:\nstatic solve:function\n  push rbp\n  mov rbp, rsp\n\n  %define INPUT_LEN r10\n  %define CURRENT r9\n  %define NEXT r11\n  %define REMAINING_COUNT rax\n  %define END r8\n\n  lea CURRENT, [input] \n  lea NEXT, [input + 1] \n  mov INPUT_LEN, input_len\n  mov REMAINING_COUNT, INPUT_LEN\n  lea END, [input]\n  add END, INPUT_LEN\n  \n\n.loop:\n  movzx dx, BYTE [CURRENT]\n  movzx cx, BYTE [NEXT]\n  sub dx, cx\n  imul dx, dx\n\n  mov rcx, 32*32\n\n  cmp rdx, rcx\n  jnz .else\n  .then:\n    mov BYTE [CURRENT], 0\n    mov BYTE [NEXT], 0\n\n    sub REMAINING_COUNT, 2\n\n    .reverse_search:\n    dec CURRENT\n    mov dl, [CURRENT]\n    cmp dl, 0\n    jz .reverse_search\n\n\n    jmp .endif\n  .else:\n    mov CURRENT, NEXT\n  .endif:\n\n  inc NEXT\n  cmp NEXT, END\n  jl .loop\n\n  %undef INPUT_LEN\n  %undef CURRENT\n  %undef NEXT\n  %undef REMAINING_COUNT\n  %undef END\n\n\n  pop rbp\n  ret\n\nglobal _start\n_start:\n  call solve\n\n  mov rdi, rax\n  call write_int_to_stdout\n\n  call exit\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2859141830-the-new-solution",
"#2432913330-the-x86-64-implementation",
"#2843714489-benchmarking",
"#1768815813-learnings",
"#2879187008-appendix-the-full-code",
"#2199062290-the-old-c-implementation",
"#2467435296-the-x64-implementation",
],
title_text_offsets:[
1825,4381,9026,9754,10821,10845,72840,],
},
{
name:"wayland_from_scratch.html",
text:"Learn Wayland by writing a GUI from scratch\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-10-12\nLearn Wayland by writing a GUI from scratch\nC\nWayland\nGUI\nX11\nTable of contents\nWhat do we need?\nWayland basics\nOpening a socket\nCreating a registry\nShared memory: the frame buffer\nChatting with the compositor\nReacting to events: binding interfaces\nUsing the interfaces we created\nReacting to events: ping/pong\nReacting to events: configure/ACK configure\nRendering a frame: the red rectangle\nRendering a frame: The Wayland logo\nThe end\nAddendum: the full code\nDiscussions:\nHacker News\n,\nLobsters\n.\nWayland\nis all the rage those days. Distributions left and right switch to it, many readers of my previous article on\nwriting a X11 GUI from scratch in x86_64 assembly\nasked for a follow-up article about Wayland, and I now run Wayland on my desktop. So here we go, let\'s write a (very simple) GUI program with Wayland, without any libraries, this time in C.\nHere is what we are working towards:\nWe display the Wayland logo in its own window (we can see the mountain wallpaper in the background since we use a fixed size buffer). It\'s not quite Visual Studio yet, I know, but it\'s a good foundation for more in future articles, perhaps.\nWhy not in assembly again you ask? Well, the Wayland protocol has some peculiarities that necessitate the use of some C standard library macros to make it work reliably on different platforms (Linux, FreeBSD, etc): namely, sending a file descriptor over a UNIX socket. Maybe it could be done in assembly, but it would be much more tedious. Also, the Wayland protocol is completely asynchronous by nature, whereas the X11 protocol was more of a request-(maybe) response chatter, and as such, we have to keep track of some state in our program, and C makes it easier.\nNow, if you want to follow along and translate the C snippets into assembly, go for it, it is doable, just tedious.\nIf you spot an error, please open a\nGithub issue\n!\nWhat do we need?\nNot much: We\'ll use C99 so any C compiler of the last 20 years will do. Having a Wayland desktop to test the application will also greatly help.\nNote that I have only run it on Linux; it should work (meaning: compile and run) on other platforms running Wayland such as FreeBSD, it\'s just that I have not tried.\nNote that the code in this article has not been written in the most robust way, it simply exits when things are not how they should be for example. So, not production ready, but still a good learning resource and a good foundation for more.\nWayland basics\nWayland is a protocol specification for GUI applications (and more), in short. We will write the client side, while the server side is a compositor which understands our protocol. If you have a Wayland desktop right now, a Wayland compositor is already running so there is nothing to do.\nMuch like X11, a client opens a UNIX socket, sends some commands in a specific format (which are different from the X11 ones), to open a window and the server can also send messages to notify the client to resize the window, that there is some keyboard input, etc. It\'s important to note that contrary to X11, in Wayland, the client only has access to its own window.\nIt is also interesting to note that Wayland is quite a limited protocol and any GUI will have to use extension protocols.\nMost client applications use\nlibwayland\nwhich is a library composed of C files that are autogenerated from a XML file describing the protocol.\nThe same goes for extension protocols: they simply are one XML file that is turned into C files, which are then compiled and linked to a GUI application.\nNow, we will not do any of this: we will instead write our own serialization and deserialization functions, which is really not a lot of work as you will see.\nThere are many advantages:\nNo need to link to external libraries: no build system complexities, no dynamic linking issues, and so on.\nWe do not have to use the callback system that\nlibwayland\nrequires.\nWe can use the I/O mechanism we wish to listen to incoming messages: blocking,\npoll\n,\nselect\n,\nepoll\n,\nio_uring\n,\nkqueue\non some systems, etc. Here, we will use blocking calls for simplicity but the world is your oyster.\nEasy troubleshooting: 100% of the code is our own.\nNo XML\nThe protocols we will use are stable so the numeric values on the wire should not change underneath us, but in the unlikely event they do, we simply have to fix them in our code and compile again.\nSo at this point you might be thinking: this is going to be so much work! Well, not really. Here are\nall\nof the Wayland protocol numeric values we will need, including the extension protocols:\nstatic const uint32_t wayland_display_object_id = 1;\nstatic const uint16_t wayland_wl_registry_event_global = 0;\nstatic const uint16_t wayland_shm_pool_event_format = 0;\nstatic const uint16_t wayland_wl_buffer_event_release = 0;\nstatic const uint16_t wayland_xdg_wm_base_event_ping = 0;\nstatic const uint16_t wayland_xdg_toplevel_event_configure = 0;\nstatic const uint16_t wayland_xdg_toplevel_event_close = 1;\nstatic const uint16_t wayland_xdg_surface_event_configure = 0;\nstatic const uint16_t wayland_wl_display_get_registry_opcode = 1;\nstatic const uint16_t wayland_wl_registry_bind_opcode = 0;\nstatic const uint16_t wayland_wl_compositor_create_surface_opcode = 0;\nstatic const uint16_t wayland_xdg_wm_base_pong_opcode = 3;\nstatic const uint16_t wayland_xdg_surface_ack_configure_opcode = 4;\nstatic const uint16_t wayland_wl_shm_create_pool_opcode = 0;\nstatic const uint16_t wayland_xdg_wm_base_get_xdg_surface_opcode = 2;\nstatic const uint16_t wayland_wl_shm_pool_create_buffer_opcode = 0;\nstatic const uint16_t wayland_wl_surface_attach_opcode = 1;\nstatic const uint16_t wayland_xdg_surface_get_toplevel_opcode = 1;\nstatic const uint16_t wayland_wl_surface_commit_opcode = 6;\nstatic const uint16_t wayland_wl_display_error_event = 0;\nstatic const uint32_t wayland_format_xrgb8888 = 1;\nstatic const uint32_t wayland_header_size = 8;\nstatic const uint32_t color_channels = 4;\nSo, not that much!\nOpening a socket\nThe first step is opening a UNIX domain socket. Note that this step is exactly the same as for X11, save for the path of the socket. Also, X11 is designed to be used over the network so it does not have to be a UNIX domain socket, on the same machine - but everybody does so on their desktop machine anyway.\nTo craft the socket path, we follow these simple steps:\nIf\n$WAYLAND_DISPLAY\nis set, attempt to connect to\n$XDG_RUNTIME_DIR/$WAYLAND_DISPLAY\nOtherwise, attempt to connect to\n$XDG_RUNTIME_DIR/wayland-0\nOtherwise, fail\nHere goes, along with two utility macros we\'ll use everywhere:\n#define cstring_len(s) (sizeof(s) - 1)\n\n#define roundup_4(n) (((n) + 3) &amp; -4)\n\nstatic int wayland_display_connect() {\n  char *xdg_runtime_dir = getenv(&quot;XDG_RUNTIME_DIR&quot;);\n  if (xdg_runtime_dir == NULL)\n    return EINVAL;\n\n  uint64_t xdg_runtime_dir_len = strlen(xdg_runtime_dir);\n\n  struct sockaddr_un addr = {.sun_family = AF_UNIX};\n  assert(xdg_runtime_dir_len &lt;= cstring_len(addr.sun_path));\n  uint64_t socket_path_len = 0;\n\n  memcpy(addr.sun_path, xdg_runtime_dir, xdg_runtime_dir_len);\n  socket_path_len += xdg_runtime_dir_len;\n\n  addr.sun_path[socket_path_len++] = \'/\';\n\n  char *wayland_display = getenv(&quot;WAYLAND_DISPLAY&quot;);\n  if (wayland_display == NULL) {\n    char wayland_display_default[] = &quot;wayland-0&quot;;\n    uint64_t wayland_display_default_len = cstring_len(wayland_display_default);\n\n    memcpy(addr.sun_path + socket_path_len, wayland_display_default,\n           wayland_display_default_len);\n    socket_path_len += wayland_display_default_len;\n  } else {\n    uint64_t wayland_display_len = strlen(wayland_display);\n    memcpy(addr.sun_path + socket_path_len, wayland_display,\n           wayland_display_len);\n    socket_path_len += wayland_display_len;\n  }\n\n  int fd = socket(AF_UNIX, SOCK_STREAM, 0);\n  if (fd == -1)\n    exit(errno);\n\n  if (connect(fd, (struct sockaddr *)&amp;addr, sizeof(addr)) == -1)\n    exit(errno);\n\n  return fd;\n}\nIn Wayland, there is no connection setup to do, such as sending some special messages, so there is nothing more to do.\nCreating a registry\nNow, to do anything useful, we want to create a registry: it is an object that allows us to query at runtime the capabilities of the compositor.\nIn Wayland, to create an object, we simply send the right message followed by an id of our own. Ids should be unique so we simply increment a number each time we want to create a new resource. After this is done, we will remember this number to be able to refer to it in later messages:\nThis is coincidentally our first message we send, so let\'s briefly go over the structure of a Wayland message. It is basically a RPC mechanism. All bytes are in the host endianness so there is nothing special to do about it:\n4 bytes: The id of the resource (\'object\') we want to call a method on\n2 bytes: The opcode of the method we want to call\n2 bytes: The size of the message\nDepending on the method, arguments in their wire format follow\nThe object id in this case is\n1\n, which is the singleton\nwl_display\nthat already exists.\nThe method is:\nget_registry(u32 new_id)\nwhose opcode we listed before.\nThe sole argument takes 4 bytes and is this incremental number we keep track of client-side.\nIt does not necessarily have to be incremental, but that\'s what\nlibwayland\ndoes and also it\'s the easiest.\nFor convenience and efficiency, we always craft the message on the stack and do not allocate dynamic memory.\nWe first introduce a few utility functions to read and write parts of messages:\nstatic void buf_write_u32(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                          uint32_t x) {\n  assert(*buf_size + sizeof(x) &lt;= buf_cap);\n  assert(((size_t)buf + *buf_size) % sizeof(x) == 0);\n\n  *(uint32_t *)(buf + *buf_size) = x;\n  *buf_size += sizeof(x);\n}\n\nstatic void buf_write_u16(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                          uint16_t x) {\n  assert(*buf_size + sizeof(x) &lt;= buf_cap);\n  assert(((size_t)buf + *buf_size) % sizeof(x) == 0);\n\n  *(uint16_t *)(buf + *buf_size) = x;\n  *buf_size += sizeof(x);\n}\n\nstatic void buf_write_string(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                             char *src, uint32_t src_len) {\n  assert(*buf_size + src_len &lt;= buf_cap);\n\n  buf_write_u32(buf, buf_size, buf_cap, src_len);\n  memcpy(buf + *buf_size, src, roundup_4(src_len));\n  *buf_size += roundup_4(src_len);\n}\n\nstatic uint32_t buf_read_u32(char **buf, uint64_t *buf_size) {\n  assert(*buf_size &gt;= sizeof(uint32_t));\n  assert((size_t)*buf % sizeof(uint32_t) == 0);\n\n  uint32_t res = *(uint32_t *)(*buf);\n  *buf += sizeof(res);\n  *buf_size -= sizeof(res);\n\n  return res;\n}\n\nstatic uint16_t buf_read_u16(char **buf, uint64_t *buf_size) {\n  assert(*buf_size &gt;= sizeof(uint16_t));\n  assert((size_t)*buf % sizeof(uint16_t) == 0);\n\n  uint16_t res = *(uint16_t *)(*buf);\n  *buf += sizeof(res);\n  *buf_size -= sizeof(res);\n\n  return res;\n}\n\nstatic void buf_read_n(char **buf, uint64_t *buf_size, char *dst, uint64_t n) {\n  assert(*buf_size &gt;= n);\n\n  memcpy(dst, *buf, n);\n\n  *buf += n;\n  *buf_size -= n;\n}\nAnd we finally can send our first message:\nstatic uint32_t wayland_wl_display_get_registry(int fd) {\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_display_object_id);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_wl_display_get_registry_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(wayland_current_id);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, MSG_DONTWAIT))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_display@%u.get_registry: wl_registry=%u\\n&quot;,\n         wayland_display_object_id, wayland_current_id);\n\n  return wayland_current_id;\n}\nAnd by calling it, we have created our very first Wayland resource!\nFrom this point on, the utility functions to send Wayland messages (\nwayland_*\n) will not be included in the code snippets for brevity (but you will find all of the code at the end!), just because they all are similar to the one above.\nShared memory: the frame buffer\nTo avoid drawing  a frame in our application, and having to send all of the bytes over the socket to the compositor, there is a smarter approach: the buffer should be shared between the two processes, so that no copying is required.\nWe need to synchronize the access between the two so that presenting the frame does not happen while we are still drawing it, and Wayland has us covered here.\nFirst, we need to create this buffer. We are going to make it easier for us by using a fixed size. Wayland is going to send us \'resize\' events, whenever the window size changes, which we will acknowledge and ignore. This is done here just to simplify a bit the article, obviously in a real application, you would resize the buffer.\nFirst, we introduce a struct that will hold all of the client-side state so that we remember which resources we have created so far. We also need a super simple state machine for later to track whether the surface (i.e. the \'frame\' data) should be drawn to, as mentioned:\ntypedef enum state_state_t state_state_t;\nenum state_state_t {\n  STATE_NONE,\n  STATE_SURFACE_ACKED_CONFIGURE,\n  STATE_SURFACE_ATTACHED,\n};\n\ntypedef struct state_t state_t;\nstruct state_t {\n  uint32_t wl_registry;\n  uint32_t wl_shm;\n  uint32_t wl_shm_pool;\n  uint32_t wl_buffer;\n  uint32_t xdg_wm_base;\n  uint32_t xdg_surface;\n  uint32_t wl_compositor;\n  uint32_t wl_surface;\n  uint32_t xdg_toplevel;\n  uint32_t stride;\n  uint32_t w;\n  uint32_t h;\n  uint32_t shm_pool_size;\n  int shm_fd;\n  uint8_t *shm_pool_data;\n\n  state_state_t state;\n};\nWe use it so in\nmain()\n:\nstate_t state = {\n      .wl_registry = wayland_wl_display_get_registry(fd),\n      .w = 117,\n      .h = 150,\n      .stride = 117 * color_channels,\n  };\n\n  // Single buffering.\n  state.shm_pool_size = state.h * state.stride;\nThe window is a rectangle, of width\nw\nand height\nh\n. We will use the color format\nxrgb8888\nwhich is 4 color channels, each taking one bytes, so 4 bytes per pixel. This is one of the two formats that is guaranteed to be supported by the compositor per the specification. The stride counts how many bytes a horizontal row takes:\nw * 4\n.\nAnd so, our buffer size for the frame is :\nw * h * 4\n. We use single buffering again for simplicity and also because we want to display a static image.\nWe could choose to use double or even triple buffering, thus respectively doubling or tripling the buffer size. The compositor is none the wiser - we would simply keep a counter client-side that increments each time we render a frame (and wraps around back to 0 when reaching the number of buffers), we would draw in the right location of this big buffer (i.e. at an offset), and attach the right part of the buffer to the surface.\nAll the Wayland calls would remain the same.\nAlright, time to really create this buffer, and not only keep track of its size:\nstatic void create_shared_memory_file(uint64_t size, state_t *state) {\n  char name[255] = &quot;/&quot;;\n  for (uint64_t i = 1; i &lt; cstring_len(name); i++) {\n    name[i] = ((double)rand()) / (double)RAND_MAX * 26 + \'a\';\n  }\n\n  int fd = shm_open(name, O_RDWR | O_EXCL | O_CREAT, 0600);\n  if (fd == -1)\n    exit(errno);\n\n  assert(shm_unlink(name) != -1);\n\n  if (ftruncate(fd, size) == -1)\n    exit(errno);\n\n  state-&gt;shm_pool_data =\n      mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n  assert(state-&gt;shm_pool_data != NULL);\n  state-&gt;shm_fd = fd;\n}\nWe use\nshm_open(3)\nto create a POSIX shared memory object, so that we later can send the corresponding file descriptor to the compositor so that the latter also has access to it. The flags mean:\nO_RDWR\n: Read-write.\nO_CREAT\n: If the file does not exist, create it.\nO_EXCL\n: Return an error if the shared memory object with this name already exists (we do not want that another running instance of the application gets by mistake the same memory buffer).\nWe alternatively could use\nmemfd_create(2)\nwhich spares us from crafting a unique path but this is Linux specific.\nWe craft a unique, random path to avoid clashes with other running applications.\nRight after, we remove the file on the filesystem with\nshm_unlink\nto not leave any traces when the program finishes. Note that the file descriptor remains valid since our process still has the file open (there is a reference counting mechanism in the kernel behind the scenes).\nWe then resize with\nftruncate\nand memory map this file with\nmmap(2)\n, effectively allocating memory, with the\nMAP_SHARED\nflag to allow the compositor to also read this memory.\nLater, we will send the file descriptor over the UNIX domain socket as ancillary data to the compositor.\nAlright, we now have some memory to draw our frame to, but the compositor does not know of it yet. Let\'s tackle that now.\nChatting with the compositor\nWe are going to exchange messages back and forth over the socket with the compositor. Let\'s use plain old blocking calls in\nmain\nlike it\'s the 70\'s. We read as much as we can from the socket:\nwhile (1) {\n    char read_buf[4096] = &quot;&quot;;\n    int64_t read_bytes = recv(fd, read_buf, sizeof(read_buf), 0);\n    if (read_bytes == -1)\n      exit(errno);\n\n    char *msg = read_buf;\n    uint64_t msg_len = (uint64_t)read_bytes;\n\n    while (msg_len &gt; 0)\n      wayland_handle_message(fd, &amp;state, &amp;msg, &amp;msg_len);\n    }\n  }\nThe read buffer very likely now contains a sequence of various messages, which we parse and handle with\nwayland_handle_message\neagerly until the end of the buffer.\nThis might break if a message is spanning two different read buffers - a ring buffer would be more appropriate to handle this case gracefully, but again, for this article this is fine.\nwayland_handle_message\nreads the header part of every message as described in the beginning, and reacts to known opcodes and objects:\nstatic void wayland_handle_message(int fd, state_t *state, char **msg,\n                                   uint64_t *msg_len) {\n  assert(*msg_len &gt;= 8);\n\n  uint32_t object_id = buf_read_u32(msg, msg_len);\n  assert(object_id &lt;= wayland_current_id);\n\n  uint16_t opcode = buf_read_u16(msg, msg_len);\n\n  uint16_t announced_size = buf_read_u16(msg, msg_len);\n  assert(roundup_4(announced_size) &lt;= announced_size);\n\n  uint32_t header_size =\n      sizeof(object_id) + sizeof(opcode) + sizeof(announced_size);\n  assert(announced_size &lt;= header_size + *msg_len);\n\n  if (object_id == state-&gt;wl_registry &amp;&amp;\n      opcode == wayland_wl_registry_event_global) {\n      // TODO\n  }\n  // Following: Lots of `if (opcode == ...) {... } else if (opcode = ...) { ... } [...]`\n}\nReacting to events: binding interfaces\nAt this point we have sent one message to the compositor:\nwl_display@1.get_registry()\nthanks to our C function\nwayland_wl_display_get_registry\n.\nThe compositor responds with a series of events, listing the available global objects, such as shared memory support, extension protocols, etc.\nEach event contains the interface name, which is a string. Now, in the Wayland protocol, the string length gets padded to a multiple of four, so we have read those padding bytes as well.\nIf we see a global object that we are interested in, we create one of this type, and record the new id in our\nstate\nstructure for later use. While we\'re at it, we also handle error events. If the compositor does not like our messages, it will complain with some useful error messages in there:\nif (object_id == state-&gt;wl_registry &amp;&amp;\n      opcode == wayland_wl_registry_event_global) {\n    uint32_t name = buf_read_u32(msg, msg_len);\n\n    uint32_t interface_len = buf_read_u32(msg, msg_len);\n    uint32_t padded_interface_len = roundup_4(interface_len);\n\n    char interface[512] = &quot;&quot;;\n    assert(padded_interface_len &lt;= cstring_len(interface));\n\n    buf_read_n(msg, msg_len, interface, padded_interface_len);\n    // The length includes the NULL terminator.\n    assert(interface[interface_len - 1] == 0);\n\n    uint32_t version = buf_read_u32(msg, msg_len);\n\n    printf(&quot;&lt;- wl_registry@%u.global: name=%u interface=%.*s version=%u\\n&quot;,\n           state-&gt;wl_registry, name, interface_len, interface, version);\n\n    assert(announced_size == sizeof(object_id) + sizeof(announced_size) +\n                                 sizeof(opcode) + sizeof(name) +\n                                 sizeof(interface_len) + padded_interface_len +\n                                 sizeof(version));\n\n    char wl_shm_interface[] = &quot;wl_shm&quot;;\n    if (strcmp(wl_shm_interface, interface) == 0) {\n      state-&gt;wl_shm = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    char xdg_wm_base_interface[] = &quot;xdg_wm_base&quot;;\n    if (strcmp(xdg_wm_base_interface, interface) == 0) {\n      state-&gt;xdg_wm_base = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    char wl_compositor_interface[] = &quot;wl_compositor&quot;;\n    if (strcmp(wl_compositor_interface, interface) == 0) {\n      state-&gt;wl_compositor = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    return;\n  } else if (object_id == wayland_display_object_id &amp;&amp; opcode == wayland_wl_display_error_event) {\n    uint32_t target_object_id = buf_read_u32(msg, msg_len);\n    uint32_t code = buf_read_u32(msg, msg_len);\n    char error[512] = &quot;&quot;;\n    uint32_t error_len = buf_read_u32(msg, msg_len);\n    buf_read_n(msg, msg_len, error, roundup_4(error_len));\n\n    fprintf(stderr, &quot;fatal error: target_object_id=%u code=%u error=%s\\n&quot;,\n            target_object_id, code, error);\n    exit(EINVAL);\n  }\nRemember: Since the Wayland protocol is a kind of RPC, we need to create the objects first before calling remote methods on them.\nIn terms of robustness, we do not have guarantees that every feature (i.e.: interface) we need in our application will be supported by the compositor. It could be a good idea to bail if the interfaces we require are not present.\nUsing the interfaces we created\nWe can now call methods on the new interfaces to create more entities we will need, namely:\nA\nwl_surface\nA\nxdg_surface\nA\nxdg_toplevel\nThe last two being entities from extension protocols, which is inconsequential in our implementation since we do not link against any libraries. This is just the same logic as the other messages and events from the core protocol.\nOnce we have done that, the surface is setup, and we commit it, to signal to the compositor to atomically apply the changes to the surface.\n    while (msg_len &gt; 0)\n      wayland_handle_message(fd, &amp;state, &amp;msg, &amp;msg_len);\n\n    if (state.wl_compositor != 0 &amp;&amp; state.wl_shm != 0 &amp;&amp;\n        state.xdg_wm_base != 0 &amp;&amp;\n        state.wl_surface == 0) { // Bind phase complete, need to create surface.\n      assert(state.state == STATE_NONE);\n\n      state.wl_surface = wayland_wl_compositor_create_surface(fd, &amp;state);\n      state.xdg_surface = wayland_xdg_wm_base_get_xdg_surface(fd, &amp;state);\n      state.xdg_toplevel = wayland_xdg_surface_get_toplevel(fd, &amp;state);\n      wayland_wl_surface_commit(fd, &amp;state);\n    }\n  }\nReacting to events: ping/pong\nFor some entities, the Wayland compositor will send us a ping message and expect a pong back to ensure our application is responsive and not deadlocked or frozen.\nWe just have to add one more\nif\nto the long list of\nif\ns to handle each event from the compositor:\nif (object_id == state-&gt;xdg_wm_base &amp;&amp;\n             opcode == wayland_xdg_wm_base_event_ping) {\n    uint32_t ping = buf_read_u32(msg, msg_len);\n    printf(&quot;&lt;- xdg_wm_base@%u.ping: ping=%u\\n&quot;, state-&gt;xdg_wm_base, ping);\n    wayland_xdg_wm_base_pong(fd, state, ping);\n\n    return;\n  }\nReacting to events: configure/ACK configure\nAkin to the previous ping/pong mechanism, we receive a\nconfigure\nevent for the\nxdg_surface\nand we reply with a\nack_configure\nmessage.\nThis is an important milestone since from that point on, we can start rendering our frame! We thus advance our little state machine:\nif (object_id == state-&gt;xdg_surface &amp;&amp;\n             opcode == wayland_xdg_surface_event_configure) {\n    uint32_t configure = buf_read_u32(msg, msg_len);\n    printf(&quot;&lt;- xdg_surface@%u.configure: configure=%u\\n&quot;, state-&gt;xdg_surface,\n           configure);\n    wayland_xdg_surface_ack_configure(fd, state, configure);\n    state-&gt;state = STATE_SURFACE_ACKED_CONFIGURE;\n\n    return;\n  } \nRendering a frame: the red rectangle\nOnce the configure/ack configure step has been completed, we can render a frame.\nTo do so, we need to create two final entities: a shared memory pool (\nwl_shm_pool\n) and a\nwl_buffer\nif they do not exist yet.\nFinally, we fiddle with the pixel data anyway we want, remembering the color format we picked (XRGB8888), attach the buffer to the surface, and commit the surface.\nThis acts as synchronization mechanism between the client and the compositor to avoid presenting a half-rendered frame. To sum up:\nThe\nack_configure\nevent signals us that we can start rendering the frame\nWe render the frame client-side by setting the pixel data to whatever we want\nWe send the\nattach\n+\ncommit\nmessages to notify the compositor that the frame is ready to be presented\nWe advance our state machine to avoid writing to the frame data while the compositor is presenting it\nSo let\'s show a red rectangle as a warm-up. The alpha component is completely ignored as far as I can tell in this color format:\nif (state.state == STATE_SURFACE_ACKED_CONFIGURE) {\n      // Render a frame.\n      assert(state.wl_surface != 0);\n      assert(state.xdg_surface != 0);\n      assert(state.xdg_toplevel != 0);\n\n      if (state.wl_shm_pool == 0)\n        state.wl_shm_pool = wayland_wl_shm_create_pool(fd, &amp;state);\n      if (state.wl_buffer == 0)\n        state.wl_buffer = wayland_wl_shm_pool_create_buffer(fd, &amp;state);\n\n      assert(state.shm_pool_data != 0);\n      assert(state.shm_pool_size != 0);\n\n      uint32_t *pixels = (uint32_t *)state.shm_pool_data;\n      for (uint32_t i = 0; i &lt; state.w * state.h; i++) {\n        uint8_t r = 0xff;\n        uint8_t g = 0;\n        uint8_t b = 0;\n        pixels[i] = (r &lt;&lt; 16) | (g &lt;&lt; 8) | b;\n      }\n      wayland_wl_surface_attach(fd, &amp;state);\n      wayland_wl_surface_commit(fd, &amp;state);\n\n      state.state = STATE_SURFACE_ATTACHED;\n    }\nResult:\nRendering a frame: The Wayland logo\nLet\'s render something more interesting. We download the\nWayland logo\n, but we do not want to have to deal with a complicated format like PNG (because we then have to uncompress the image data with\nzlib\nor similar).\nWe thus convert it offline to a simpler image format, PPM6, and then embed the raw pixel data in our code as an byte array, skipping over the first 15 bytes which are metadata:\n$ file wayland.png\nwayland.png: PNG image data, 117 x 150, 8-bit/color RGBA, non-interlaced\n$ convert wayland.png wayland.ppm\n$ file wayland.ppm\nwayland.ppm: Netpbm image data, size = 117 x 150, rawbits, pixmap\n$ xxd -s +15 -i wayland.ppm  &gt; wayland-logo.h\n$ sed -i \'s/wayland_ppm/wayland_logo/g\' wayland-logo.h\nThe resulting C array created by\nxxd\nwill be named after the input file i.e.\nwayland_ppm\n. We rename it with the last command to something more human-readable.\nThe image is now in the\nRGB\nformat (3 bytes per pixel), which we have to convert to the\nXRGB\nformat (4 bytes per pixel). Our frame rendering loop becomes:\n#include &quot;wayland-logo.h&quot;\n\n[...]\n\n      for (uint32_t i = 0; i &lt; state.w * state.h; i++) {\n        uint8_t r = wayland_logo[i * 3 + 0];\n        uint8_t g = wayland_logo[i * 3 + 1];\n        uint8_t b = wayland_logo[i * 3 + 2];\n        pixels[i] = (r &lt;&lt; 16) | (g &lt;&lt; 8) | b;\n      }\nAnd finally we see the result.\nTiled:\nFloating:\nNote: We handle the absolute minimum set of events coming from the compositor to make it work in a simple way. If your particular compositor sends more events, they will have to be read (and possibly ignored). Since the Wayland protocol uses a Tag-Length-Value (TLV) encoding, one can simply skip over\n&lt;length&gt;\nbytes if the opcode is unknown. But some events will demand a reply (e.g. ping/pong)!\nThe end\nIt was not that much work to go from zero to a working GUI application, albeit a simplistic one.\nCompared to X11, it was a bit more work, but not that much. The barrier of entry is higher but the concepts and architecture are more sound, it seems to me.\nThe setup is a bit tedious but once this is done, we are in practice going to spend all of our time in the frame rendering code, and perhaps add support for a few additional events (we do not yet support keyboard or mouse events, for example, or animations, which would require us to notify the compositor that a region was \'damaged\' meaning modified, and needs re-rendering).\nThus, I have the feeling that Wayland really goes out of the way once the initial scaffolding is done.\nAs for the next steps, I would like to draw some text, and react to user input events. Maybe even port something like\nmicroui\n, which only needs a few drawing routines, to our application.\nAddendum: the full code\nDo not forget to generate\nwayland-logo.h\nwith the aforementioned commands!\nCompile with:\ncc -std=c99 wayland.c -Ofast\n.\nThe full code\n#define _POSIX_C_SOURCE 200112L\n#include &lt;assert.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;stddef.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;sys/time.h&gt;\n#include &lt;sys/un.h&gt;\n#include &lt;unistd.h&gt;\n\n#include &quot;wayland-logo.h&quot;\n\n#define cstring_len(s) (sizeof(s) - 1)\n\n#define roundup_4(n) (((n) + 3) &amp; -4)\n\nstatic uint32_t wayland_current_id = 1;\n\nstatic const uint32_t wayland_display_object_id = 1;\nstatic const uint16_t wayland_wl_registry_event_global = 0;\nstatic const uint16_t wayland_shm_pool_event_format = 0;\nstatic const uint16_t wayland_wl_buffer_event_release = 0;\nstatic const uint16_t wayland_xdg_wm_base_event_ping = 0;\nstatic const uint16_t wayland_xdg_toplevel_event_configure = 0;\nstatic const uint16_t wayland_xdg_toplevel_event_close = 1;\nstatic const uint16_t wayland_xdg_surface_event_configure = 0;\nstatic const uint16_t wayland_wl_display_get_registry_opcode = 1;\nstatic const uint16_t wayland_wl_registry_bind_opcode = 0;\nstatic const uint16_t wayland_wl_compositor_create_surface_opcode = 0;\nstatic const uint16_t wayland_xdg_wm_base_pong_opcode = 3;\nstatic const uint16_t wayland_xdg_surface_ack_configure_opcode = 4;\nstatic const uint16_t wayland_wl_shm_create_pool_opcode = 0;\nstatic const uint16_t wayland_xdg_wm_base_get_xdg_surface_opcode = 2;\nstatic const uint16_t wayland_wl_shm_pool_create_buffer_opcode = 0;\nstatic const uint16_t wayland_wl_surface_attach_opcode = 1;\nstatic const uint16_t wayland_xdg_surface_get_toplevel_opcode = 1;\nstatic const uint16_t wayland_wl_surface_commit_opcode = 6;\nstatic const uint16_t wayland_wl_display_error_event = 0;\nstatic const uint32_t wayland_format_xrgb8888 = 1;\nstatic const uint32_t wayland_header_size = 8;\nstatic const uint32_t color_channels = 4;\n\ntypedef enum state_state_t state_state_t;\nenum state_state_t {\n  STATE_NONE,\n  STATE_SURFACE_ACKED_CONFIGURE,\n  STATE_SURFACE_ATTACHED,\n};\n\ntypedef struct state_t state_t;\nstruct state_t {\n  uint32_t wl_registry;\n  uint32_t wl_shm;\n  uint32_t wl_shm_pool;\n  uint32_t wl_buffer;\n  uint32_t xdg_wm_base;\n  uint32_t xdg_surface;\n  uint32_t wl_compositor;\n  uint32_t wl_surface;\n  uint32_t xdg_toplevel;\n  uint32_t stride;\n  uint32_t w;\n  uint32_t h;\n  uint32_t shm_pool_size;\n  int shm_fd;\n  uint8_t *shm_pool_data;\n\n  state_state_t state;\n};\n\nstatic int wayland_display_connect() {\n  char *xdg_runtime_dir = getenv(&quot;XDG_RUNTIME_DIR&quot;);\n  if (xdg_runtime_dir == NULL)\n    return EINVAL;\n\n  uint64_t xdg_runtime_dir_len = strlen(xdg_runtime_dir);\n\n  struct sockaddr_un addr = {.sun_family = AF_UNIX};\n  assert(xdg_runtime_dir_len &lt;= cstring_len(addr.sun_path));\n  uint64_t socket_path_len = 0;\n\n  memcpy(addr.sun_path, xdg_runtime_dir, xdg_runtime_dir_len);\n  socket_path_len += xdg_runtime_dir_len;\n\n  addr.sun_path[socket_path_len++] = \'/\';\n\n  char *wayland_display = getenv(&quot;WAYLAND_DISPLAY&quot;);\n  if (wayland_display == NULL) {\n    char wayland_display_default[] = &quot;wayland-0&quot;;\n    uint64_t wayland_display_default_len = cstring_len(wayland_display_default);\n\n    memcpy(addr.sun_path + socket_path_len, wayland_display_default,\n           wayland_display_default_len);\n    socket_path_len += wayland_display_default_len;\n  } else {\n    uint64_t wayland_display_len = strlen(wayland_display);\n    memcpy(addr.sun_path + socket_path_len, wayland_display,\n           wayland_display_len);\n    socket_path_len += wayland_display_len;\n  }\n\n  int fd = socket(AF_UNIX, SOCK_STREAM, 0);\n  if (fd == -1)\n    exit(errno);\n\n  if (connect(fd, (struct sockaddr *)&amp;addr, sizeof(addr)) == -1)\n    exit(errno);\n\n  return fd;\n}\n\nstatic void buf_write_u32(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                          uint32_t x) {\n  assert(*buf_size + sizeof(x) &lt;= buf_cap);\n  assert(((size_t)buf + *buf_size) % sizeof(x) == 0);\n\n  *(uint32_t *)(buf + *buf_size) = x;\n  *buf_size += sizeof(x);\n}\n\nstatic void buf_write_u16(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                          uint16_t x) {\n  assert(*buf_size + sizeof(x) &lt;= buf_cap);\n  assert(((size_t)buf + *buf_size) % sizeof(x) == 0);\n\n  *(uint16_t *)(buf + *buf_size) = x;\n  *buf_size += sizeof(x);\n}\n\nstatic void buf_write_string(char *buf, uint64_t *buf_size, uint64_t buf_cap,\n                             char *src, uint32_t src_len) {\n  assert(*buf_size + src_len &lt;= buf_cap);\n\n  buf_write_u32(buf, buf_size, buf_cap, src_len);\n  memcpy(buf + *buf_size, src, roundup_4(src_len));\n  *buf_size += roundup_4(src_len);\n}\n\nstatic uint32_t buf_read_u32(char **buf, uint64_t *buf_size) {\n  assert(*buf_size &gt;= sizeof(uint32_t));\n  assert((size_t)*buf % sizeof(uint32_t) == 0);\n\n  uint32_t res = *(uint32_t *)(*buf);\n  *buf += sizeof(res);\n  *buf_size -= sizeof(res);\n\n  return res;\n}\n\nstatic uint16_t buf_read_u16(char **buf, uint64_t *buf_size) {\n  assert(*buf_size &gt;= sizeof(uint16_t));\n  assert((size_t)*buf % sizeof(uint16_t) == 0);\n\n  uint16_t res = *(uint16_t *)(*buf);\n  *buf += sizeof(res);\n  *buf_size -= sizeof(res);\n\n  return res;\n}\n\nstatic void buf_read_n(char **buf, uint64_t *buf_size, char *dst, uint64_t n) {\n  assert(*buf_size &gt;= n);\n\n  memcpy(dst, *buf, n);\n\n  *buf += n;\n  *buf_size -= n;\n}\n\nstatic uint32_t wayland_wl_display_get_registry(int fd) {\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_display_object_id);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_wl_display_get_registry_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(wayland_current_id);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_display@%u.get_registry: wl_registry=%u\\n&quot;,\n         wayland_display_object_id, wayland_current_id);\n\n  return wayland_current_id;\n}\n\nstatic uint32_t wayland_wl_registry_bind(int fd, uint32_t registry,\n                                         uint32_t name, char *interface,\n                                         uint32_t interface_len,\n                                         uint32_t version) {\n  uint64_t msg_size = 0;\n  char msg[512] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), registry);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), wayland_wl_registry_bind_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(name) + sizeof(interface_len) +\n      roundup_4(interface_len) + sizeof(version) + sizeof(wayland_current_id);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), name);\n  buf_write_string(msg, &amp;msg_size, sizeof(msg), interface, interface_len);\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), version);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  assert(msg_size == roundup_4(msg_size));\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_registry@%u.bind: name=%u interface=%.*s version=%u\\n&quot;,\n         registry, name, interface_len, interface, version);\n\n  return wayland_current_id;\n}\n\nstatic uint32_t wayland_wl_compositor_create_surface(int fd, state_t *state) {\n  assert(state-&gt;wl_compositor &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_compositor);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_wl_compositor_create_surface_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(wayland_current_id);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_compositor@%u.create_surface: wl_surface=%u\\n&quot;,\n         state-&gt;wl_compositor, wayland_current_id);\n\n  return wayland_current_id;\n}\n\nstatic void create_shared_memory_file(uint64_t size, state_t *state) {\n  char name[255] = &quot;/&quot;;\n  for (uint64_t i = 1; i &lt; cstring_len(name); i++) {\n    name[i] = ((double)rand()) / (double)RAND_MAX * 26 + \'a\';\n  }\n\n  int fd = shm_open(name, O_RDWR | O_EXCL | O_CREAT, 0600);\n  if (fd == -1)\n    exit(errno);\n\n  assert(shm_unlink(name) != -1);\n\n  if (ftruncate(fd, size) == -1)\n    exit(errno);\n\n  state-&gt;shm_pool_data =\n      mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n  assert(state-&gt;shm_pool_data != NULL);\n  state-&gt;shm_fd = fd;\n}\n\nstatic void wayland_xdg_wm_base_pong(int fd, state_t *state, uint32_t ping) {\n  assert(state-&gt;xdg_wm_base &gt; 0);\n  assert(state-&gt;wl_surface &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;xdg_wm_base);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), wayland_xdg_wm_base_pong_opcode);\n\n  uint16_t msg_announced_size = wayland_header_size + sizeof(ping);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), ping);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; xdg_wm_base@%u.pong: ping=%u\\n&quot;, state-&gt;xdg_wm_base, ping);\n}\n\nstatic void wayland_xdg_surface_ack_configure(int fd, state_t *state,\n                                              uint32_t configure) {\n  assert(state-&gt;xdg_surface &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;xdg_surface);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_xdg_surface_ack_configure_opcode);\n\n  uint16_t msg_announced_size = wayland_header_size + sizeof(configure);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), configure);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; xdg_surface@%u.ack_configure: configure=%u\\n&quot;, state-&gt;xdg_surface,\n         configure);\n}\n\nstatic uint32_t wayland_wl_shm_create_pool(int fd, state_t *state) {\n  assert(state-&gt;shm_pool_size &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_shm);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), wayland_wl_shm_create_pool_opcode);\n\n  uint16_t msg_announced_size = wayland_header_size +\n                                sizeof(wayland_current_id) +\n                                sizeof(state-&gt;shm_pool_size);\n\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;shm_pool_size);\n\n  assert(roundup_4(msg_size) == msg_size);\n\n  // Send the file descriptor as ancillary data.\n  // UNIX/Macros monstrosities ahead.\n  char buf[CMSG_SPACE(sizeof(state-&gt;shm_fd))] = &quot;&quot;;\n\n  struct iovec io = {.iov_base = msg, .iov_len = msg_size};\n  struct msghdr socket_msg = {\n      .msg_iov = &amp;io,\n      .msg_iovlen = 1,\n      .msg_control = buf,\n      .msg_controllen = sizeof(buf),\n  };\n\n  struct cmsghdr *cmsg = CMSG_FIRSTHDR(&amp;socket_msg);\n  cmsg-&gt;cmsg_level = SOL_SOCKET;\n  cmsg-&gt;cmsg_type = SCM_RIGHTS;\n  cmsg-&gt;cmsg_len = CMSG_LEN(sizeof(state-&gt;shm_fd));\n\n  *((int *)CMSG_DATA(cmsg)) = state-&gt;shm_fd;\n  socket_msg.msg_controllen = CMSG_SPACE(sizeof(state-&gt;shm_fd));\n\n  if (sendmsg(fd, &amp;socket_msg, 0) == -1)\n    exit(errno);\n\n  printf(&quot;-&gt; wl_shm@%u.create_pool: wl_shm_pool=%u\\n&quot;, state-&gt;wl_shm,\n         wayland_current_id);\n\n  return wayland_current_id;\n}\n\nstatic uint32_t wayland_xdg_wm_base_get_xdg_surface(int fd, state_t *state) {\n  assert(state-&gt;xdg_wm_base &gt; 0);\n  assert(state-&gt;wl_surface &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;xdg_wm_base);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_xdg_wm_base_get_xdg_surface_opcode);\n\n  uint16_t msg_announced_size = wayland_header_size +\n                                sizeof(wayland_current_id) +\n                                sizeof(state-&gt;wl_surface);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_surface);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; xdg_wm_base@%u.get_xdg_surface: xdg_surface=%u wl_surface=%u\\n&quot;,\n         state-&gt;xdg_wm_base, wayland_current_id, state-&gt;wl_surface);\n\n  return wayland_current_id;\n}\n\nstatic uint32_t wayland_wl_shm_pool_create_buffer(int fd, state_t *state) {\n  assert(state-&gt;wl_shm_pool &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_shm_pool);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_wl_shm_pool_create_buffer_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(wayland_current_id) + sizeof(uint32_t) * 5;\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  uint32_t offset = 0;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), offset);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;w);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;h);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;stride);\n\n  uint32_t format = wayland_format_xrgb8888;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), format);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_shm_pool@%u.create_buffer: wl_buffer=%u\\n&quot;, state-&gt;wl_shm_pool,\n         wayland_current_id);\n\n  return wayland_current_id;\n}\n\nstatic void wayland_wl_surface_attach(int fd, state_t *state) {\n  assert(state-&gt;wl_surface &gt; 0);\n  assert(state-&gt;wl_buffer &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_surface);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), wayland_wl_surface_attach_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(state-&gt;wl_buffer) + sizeof(uint32_t) * 2;\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_buffer);\n\n  uint32_t x = 0, y = 0;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), x);\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), y);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_surface@%u.attach: wl_buffer=%u\\n&quot;, state-&gt;wl_surface,\n         state-&gt;wl_buffer);\n}\n\nstatic uint32_t wayland_xdg_surface_get_toplevel(int fd, state_t *state) {\n  assert(state-&gt;xdg_surface &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;xdg_surface);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg),\n                wayland_xdg_surface_get_toplevel_opcode);\n\n  uint16_t msg_announced_size =\n      wayland_header_size + sizeof(wayland_current_id);\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  wayland_current_id++;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), wayland_current_id);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; xdg_surface@%u.get_toplevel: xdg_toplevel=%u\\n&quot;,\n         state-&gt;xdg_surface, wayland_current_id);\n\n  return wayland_current_id;\n}\n\nstatic void wayland_wl_surface_commit(int fd, state_t *state) {\n  assert(state-&gt;wl_surface &gt; 0);\n\n  uint64_t msg_size = 0;\n  char msg[128] = &quot;&quot;;\n  buf_write_u32(msg, &amp;msg_size, sizeof(msg), state-&gt;wl_surface);\n\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), wayland_wl_surface_commit_opcode);\n\n  uint16_t msg_announced_size = wayland_header_size;\n  assert(roundup_4(msg_announced_size) == msg_announced_size);\n  buf_write_u16(msg, &amp;msg_size, sizeof(msg), msg_announced_size);\n\n  if ((int64_t)msg_size != send(fd, msg, msg_size, 0))\n    exit(errno);\n\n  printf(&quot;-&gt; wl_surface@%u.commit: \\n&quot;, state-&gt;wl_surface);\n}\n\nstatic void wayland_handle_message(int fd, state_t *state, char **msg,\n                                   uint64_t *msg_len) {\n  assert(*msg_len &gt;= 8);\n\n  uint32_t object_id = buf_read_u32(msg, msg_len);\n  assert(object_id &lt;= wayland_current_id);\n\n  uint16_t opcode = buf_read_u16(msg, msg_len);\n\n  uint16_t announced_size = buf_read_u16(msg, msg_len);\n  assert(roundup_4(announced_size) &lt;= announced_size);\n\n  uint32_t header_size =\n      sizeof(object_id) + sizeof(opcode) + sizeof(announced_size);\n  assert(announced_size &lt;= header_size + *msg_len);\n\n  if (object_id == state-&gt;wl_registry &amp;&amp;\n      opcode == wayland_wl_registry_event_global) {\n    uint32_t name = buf_read_u32(msg, msg_len);\n\n    uint32_t interface_len = buf_read_u32(msg, msg_len);\n    uint32_t padded_interface_len = roundup_4(interface_len);\n\n    char interface[512] = &quot;&quot;;\n    assert(padded_interface_len &lt;= cstring_len(interface));\n\n    buf_read_n(msg, msg_len, interface, padded_interface_len);\n    // The length includes the NULL terminator.\n    assert(interface[interface_len - 1] == 0);\n\n    uint32_t version = buf_read_u32(msg, msg_len);\n\n    printf(&quot;&lt;- wl_registry@%u.global: name=%u interface=%.*s version=%u\\n&quot;,\n           state-&gt;wl_registry, name, interface_len, interface, version);\n\n    assert(announced_size == sizeof(object_id) + sizeof(announced_size) +\n                                 sizeof(opcode) + sizeof(name) +\n                                 sizeof(interface_len) + padded_interface_len +\n                                 sizeof(version));\n\n    char wl_shm_interface[] = &quot;wl_shm&quot;;\n    if (strcmp(wl_shm_interface, interface) == 0) {\n      state-&gt;wl_shm = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    char xdg_wm_base_interface[] = &quot;xdg_wm_base&quot;;\n    if (strcmp(xdg_wm_base_interface, interface) == 0) {\n      state-&gt;xdg_wm_base = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    char wl_compositor_interface[] = &quot;wl_compositor&quot;;\n    if (strcmp(wl_compositor_interface, interface) == 0) {\n      state-&gt;wl_compositor = wayland_wl_registry_bind(\n          fd, state-&gt;wl_registry, name, interface, interface_len, version);\n    }\n\n    return;\n  } else if (object_id == wayland_display_object_id &amp;&amp;\n             opcode == wayland_wl_display_error_event) {\n    uint32_t target_object_id = buf_read_u32(msg, msg_len);\n    uint32_t code = buf_read_u32(msg, msg_len);\n    char error[512] = &quot;&quot;;\n    uint32_t error_len = buf_read_u32(msg, msg_len);\n    buf_read_n(msg, msg_len, error, roundup_4(error_len));\n\n    fprintf(stderr, &quot;fatal error: target_object_id=%u code=%u error=%s\\n&quot;,\n            target_object_id, code, error);\n    exit(EINVAL);\n  } else if (object_id == state-&gt;wl_shm &amp;&amp;\n             opcode == wayland_shm_pool_event_format) {\n\n    uint32_t format = buf_read_u32(msg, msg_len);\n    printf(&quot;&lt;- wl_shm: format=%#x\\n&quot;, format);\n    return;\n  } else if (object_id == state-&gt;wl_buffer &amp;&amp;\n             opcode == wayland_wl_buffer_event_release) {\n    // No-op, for now.\n\n    printf(&quot;&lt;- xdg_wl_buffer@%u.release\\n&quot;, state-&gt;wl_buffer);\n    return;\n  } else if (object_id == state-&gt;xdg_wm_base &amp;&amp;\n             opcode == wayland_xdg_wm_base_event_ping) {\n    uint32_t ping = buf_read_u32(msg, msg_len);\n    printf(&quot;&lt;- xdg_wm_base@%u.ping: ping=%u\\n&quot;, state-&gt;xdg_wm_base, ping);\n    wayland_xdg_wm_base_pong(fd, state, ping);\n\n    return;\n  } else if (object_id == state-&gt;xdg_toplevel &amp;&amp;\n             opcode == wayland_xdg_toplevel_event_configure) {\n    uint32_t w = buf_read_u32(msg, msg_len);\n    uint32_t h = buf_read_u32(msg, msg_len);\n    uint32_t len = buf_read_u32(msg, msg_len);\n    char buf[256] = &quot;&quot;;\n    assert(len &lt;= sizeof(buf));\n    buf_read_n(msg, msg_len, buf, len);\n\n    printf(&quot;&lt;- xdg_toplevel@%u.configure: w=%u h=%u states[%u]\\n&quot;,\n           state-&gt;xdg_toplevel, w, h, len);\n\n    return;\n  } else if (object_id == state-&gt;xdg_surface &amp;&amp;\n             opcode == wayland_xdg_surface_event_configure) {\n    uint32_t configure = buf_read_u32(msg, msg_len);\n    printf(&quot;&lt;- xdg_surface@%u.configure: configure=%u\\n&quot;, state-&gt;xdg_surface,\n           configure);\n    wayland_xdg_surface_ack_configure(fd, state, configure);\n    state-&gt;state = STATE_SURFACE_ACKED_CONFIGURE;\n\n    return;\n  } else if (object_id == state-&gt;xdg_toplevel &amp;&amp;\n             opcode == wayland_xdg_toplevel_event_close) {\n    printf(&quot;&lt;- xdg_toplevel@%u.close\\n&quot;, state-&gt;xdg_toplevel);\n    exit(0);\n  }\n\n  fprintf(stderr, &quot;object_id=%u opcode=%u msg_len=%lu\\n&quot;, object_id, opcode,\n          *msg_len);\n  assert(0 &amp;&amp; &quot;todo&quot;);\n}\n\nint main() {\n  struct timeval tv = {0};\n  assert(gettimeofday(&amp;tv, NULL) != -1);\n  srand(tv.tv_sec * 1000 * 1000 + tv.tv_usec);\n\n  int fd = wayland_display_connect();\n\n  state_t state = {\n      .wl_registry = wayland_wl_display_get_registry(fd),\n      .w = 117,\n      .h = 150,\n      .stride = 117 * color_channels,\n  };\n\n  // Single buffering.\n  state.shm_pool_size = state.h * state.stride;\n  create_shared_memory_file(state.shm_pool_size, &amp;state);\n\n  while (1) {\n    char read_buf[4096] = &quot;&quot;;\n    int64_t read_bytes = recv(fd, read_buf, sizeof(read_buf), 0);\n    if (read_bytes == -1)\n      exit(errno);\n\n    char *msg = read_buf;\n    uint64_t msg_len = (uint64_t)read_bytes;\n\n    while (msg_len &gt; 0)\n      wayland_handle_message(fd, &amp;state, &amp;msg, &amp;msg_len);\n\n    if (state.wl_compositor != 0 &amp;&amp; state.wl_shm != 0 &amp;&amp;\n        state.xdg_wm_base != 0 &amp;&amp;\n        state.wl_surface == 0) { // Bind phase complete, need to create surface.\n      assert(state.state == STATE_NONE);\n\n      state.wl_surface = wayland_wl_compositor_create_surface(fd, &amp;state);\n      state.xdg_surface = wayland_xdg_wm_base_get_xdg_surface(fd, &amp;state);\n      state.xdg_toplevel = wayland_xdg_surface_get_toplevel(fd, &amp;state);\n      wayland_wl_surface_commit(fd, &amp;state);\n    }\n\n    if (state.state == STATE_SURFACE_ACKED_CONFIGURE) {\n      // Render a frame.\n      assert(state.wl_surface != 0);\n      assert(state.xdg_surface != 0);\n      assert(state.xdg_toplevel != 0);\n\n      if (state.wl_shm_pool == 0)\n        state.wl_shm_pool = wayland_wl_shm_create_pool(fd, &amp;state);\n      if (state.wl_buffer == 0)\n        state.wl_buffer = wayland_wl_shm_pool_create_buffer(fd, &amp;state);\n\n      assert(state.shm_pool_data != 0);\n      assert(state.shm_pool_size != 0);\n\n      uint32_t *pixels = (uint32_t *)state.shm_pool_data;\n      for (uint32_t i = 0; i &lt; state.w * state.h; i++) {\n        uint8_t r = wayland_logo[i * 3 + 0];\n        uint8_t g = wayland_logo[i * 3 + 1];\n        uint8_t b = wayland_logo[i * 3 + 2];\n        pixels[i] = (r &lt;&lt; 16) | (g &lt;&lt; 8) | b;\n      }\n      wayland_wl_surface_attach(fd, &amp;state);\n      wayland_wl_surface_commit(fd, &amp;state);\n\n      state.state = STATE_SURFACE_ATTACHED;\n    }\n  }\n}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3018859686-what-do-we-need",
"#2474413437-wayland-basics",
"#4163415294-opening-a-socket",
"#2693341289-creating-a-registry",
"#3637969354-shared-memory-the-frame-buffer",
"#2024835768-chatting-with-the-compositor",
"#1038699131-reacting-to-events-binding-interfaces",
"#663050396-using-the-interfaces-we-created",
"#3236706263-reacting-to-events-ping-pong",
"#2838931666-reacting-to-events-configure-ack-configure",
"#3853643148-rendering-a-frame-the-red-rectangle",
"#2039654787-rendering-a-frame-the-wayland-logo",
"#1770781618-the-end",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
2013,2582,6102,8213,12452,17217,19043,22526,23692,24294,25019,26945,28760,29691,],
},
{
name:"roll_your_own_memory_profiling.html",
text:"Roll your own memory profiling: it&#39;s actually not hard\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-11-23\nRoll your own memory profiling: it\'s actually not hard\nC\nAllocator\nProfiling\nPprof\nLinux\nTable of contents\nPprof\nThe text format\nGenerating a\nVariations and limitations\nAlternatives\nConclusion\nAddendum: the full code\nDiscussions:\n/r/c_programming\nOr: An exploration of the\npprof\nmemory profiler and its textual format for fun an profit.\nSay that you are using a programming language where memory is manually managed, and you have decided to use a custom allocator for one reason or another, for example an arena allocator, and are wondering:\nHow do I track every allocation, recording how many bytes were allocated and what was the call stack at that time?\nHow much memory is my program using, and what is the peak use?\nHow much memory does my program free? Is it all of it (are there leaks)?\nWhich line of code in my function is allocating, and how much?\nI want a flamegraph showing allocations by function\nWhat to do? Mainstream allocators such as\ntcmalloc\nand\njemalloc\ncan provide us this information but we have lost this ability by using our own!\nWell, it turns out that this can all be achieved very simply without adding dependencies to your application, in ~100 lines of code (including lots of comments). I\'ll show one way and then explore other possibilities. And here are the results we are working towards:\nProfiling the memory usage of my\nmicro-kotlin\nproject.\nShowing which lines of code are allocating in a function.\nA flamegraph based on the previous data.\nThe only requirement to make it all work is to be able to run a bit of code on each allocation.\nAnother good reason to do this, is when the system\'s\nmalloc\ncomes with some form of memory profiling which is not suitable for your needs and you want something different/better/the same on every platform.\nIf you spot an error, please open a\nGithub issue\n!\nPprof\nHere is the plan:\nEach time there is an allocation in our program, we record information about it in an array.\nAt the end of the program (or upon receiving a signal, a special TCP packet, whatever), we dump the information in the (original)\npprof\nformat, which is basically just a text file with one line per allocation (more details on that in a bit).\nWe can then use the (original)\npprof\nwhich is just a\ngiant Perl script\nwhich will extract interesting information and most importantly symbolize (meaning: transform memory addresses into line/column/function/file information).\nI will showcase this approach with C code using an arena allocator. The full code can be found in my project\nmicro-kotlin\n. But this can be done in any language since the\npprof\ntext format is so simple! Also, using arenas, we do not bother to free anything so the memory profiling part is even simpler.\nThe original\npprof\nwritten in Perl is not to be confused with the rewritten\npprof\nin Go which offers a superset of the features of the original but based on a completely different and incompatible file format (protobuf)!\nThe text format\nHere is the text format we want to generate:\nheap profile:    &lt;in use objects sum&gt;:  &lt;in use bytes sum&gt; [   &lt;space objects sum&gt;:  &lt;space bytes sum&gt;] @ heapprofile\n&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]\n&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]\n&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]\n                                                                             \nMAPPED_LIBRARIES:\n[...]\nThe first line is a header identifying that this is a heap profile (contrary to a CPU profile which\npprof\ncan also analyze, which uses a different, binary, format) and gives for each of the four fields we will record, their sum.\nThen comes one line per entry. Each entry has these four fields that the header just gave us a sum of:\nin use objects\n: How many objects are \'live\' i.e. in use on the heap at the time of the allocation. Allocating increases its value, freeing decreases it.\nin use bytes\n: How many bytes are \'live\' i.e. in use on the heap at the time of the allocation. Allocating increases its value, freeing decreases it.\nspace objects\n: How many objects have been allocated since the start of the program. It is not affected by freeing memory, it only increases.\nspace bytes\n: How many bytes have been allocated since the start of the program. It is not affected by freeing memory, it only increases.\nSo when we allocate an object e.g.\nnew(Foo)\nin C++:\nin use objects\nand\nspace objects\nincrement by 1\nin use bytes\nand\nspace bytes\nincrement by\nsizeof(Foo)\nWhen we allocate an array of N elements of type\nFoo\n:\nin use objects\nand\nspace objects\nincrement by N\nin use bytes\nand\nspace bytes\nincrement by\nN * sizeof(Foo)\nWhen we free an object:\nin use objects\ndecrements by 1\nin use bytes\ndecrements by\nsizeof(Foo)\nWhen we free an array of N elements of type\nFoo\n:\nin use objects\ndecrements by N\nin use bytes\ndecrements by\nN * sizeof(Foo)\nThese 4 dimensions are really useful to spot memory leaks (\nin use objects\nand\nin use bytes\nincrease over time), peak memory usage (\nspace bytes\n), whether we are doing many small allocations versus a few big allocations, etc.\npprof\nalso supports sampling and we could supply a sampling rate here optionally but we want to track each and every allocation so we do not bother with that.\nEach entry (i.e. line) ends with the call stack which is a space-separated list of addresses. We\'ll see that it is easy to get that information without resorting to external libraries such as\nlibunwind\nby simply walking the stack, a topic I touched on in a previous\narticle\n.\nVery importantly, multiple allocation records with the same stack must be merged together into one, summing their values. In that sense, each line conceptually an entry in a hashmap where the key is the call stack (the part of the right of the\n@\ncharacter) and the value is a 4-tuple:\n(u64, u64, u64, u64)\n(the part on the left of the\n@\ncharacter).\nThe text file ends with a trailer which is crucial for symbolication (to transform memory addresses into source code locations), which on Linux is trivial to get: This is just a copy of the file\n/proc/self/maps\n. It lists of the loaded libraries and at which address they are.\nI have not implemented it myself but a quick internet search shows that the other major operating systems have a similar capability, named differently:\nWindows:\nVirtualQuery\nmacOS:\nmach_vm_region_info\nFreeBSD:\nprocstat_getvmmap\nHere is a small example:\n#include &lt;stdlib.h&gt;\n\nvoid b(int n) { malloc(n); }\n\nvoid a(int n) {\n  malloc(n);\n  b(n);\n}\n\nint main() {\n  for (int i = 0; i &lt; 2; i++)\n    a(2);\n\n  b(3);\n}\nLeveraging\ntcmalloc\n, this program will generate a heap profile:\n$ cc /tmp/test_alloc.c -ltcmalloc  -g3\n$ HEAPPROFILE=/tmp/heapprof ./a.out\nStarting tracking the heap\nDumping heap profile to /tmp/heapprof.0001.heap (Exiting, 11 bytes in use)\nThis is just an example to showcase the format, we will from this point on use our own code to generate this text format.\nheap profile:      5:       11 [     5:       11] @ heapprofile\n     2:        4 [     2:        4] @ 0x558e804cc165 0x558e804cc18e 0x558e804cc1b0 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085\n     2:        4 [     2:        4] @ 0x558e804cc184 0x558e804cc1b0 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085\n     1:        3 [     1:        3] @ 0x558e804cc165 0x558e804cc1c4 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085\n\nMAPPED_LIBRARIES:\n558e804cb000-558e804cc000 r--p 00000000 00:00 183128      /tmp/a.out\n558e804cc000-558e804cd000 r-xp 00001000 00:00 183128      /tmp/a.out\n558e804cd000-558e804ce000 r--p 00002000 00:00 183128      /tmp/a.out\n558e804ce000-558e804cf000 r--p 00002000 00:00 183128      /tmp/a.out\n558e804cf000-558e804d0000 rw-p 00003000 00:00 183128      /tmp/a.out\n558e814b7000-558e81db8000 rw-p 00000000 00:00 0           [heap]\n7f4529e7e000-7f452a112000 rw-p 00000000 00:00 0           \n7f452a112000-7f452a115000 r--p 00000000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1\n7f452a115000-7f452a136000 r-xp 00003000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1\n7f452a136000-7f452a142000 r--p 00024000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1\n7f452a142000-7f452a143000 r--p 00030000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1\n7f452a143000-7f452a144000 rw-p 00031000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1\n7f452a144000-7f452a152000 r--p 00000000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6\n7f452a152000-7f452a1d0000 r-xp 0000e000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6\n7f452a1d0000-7f452a22b000 r--p 0008c000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6\n7f452a22b000-7f452a22c000 r--p 000e6000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6\n7f452a22c000-7f452a22d000 rw-p 000e7000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6\n7f452a22d000-7f452a22f000 rw-p 00000000 00:00 0           \n7f452a22f000-7f452a2cb000 r--p 00000000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32\n7f452a2cb000-7f452a3fc000 r-xp 0009c000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32\n7f452a3fc000-7f452a489000 r--p 001cd000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32\n7f452a489000-7f452a494000 r--p 0025a000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32\n7f452a494000-7f452a497000 rw-p 00265000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32\n7f452a497000-7f452a49b000 rw-p 00000000 00:00 0           \n7f452a49b000-7f452a49e000 r--p 00000000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1\n7f452a49e000-7f452a4a8000 r-xp 00003000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1\n7f452a4a8000-7f452a4ab000 r--p 0000d000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1\n7f452a4ab000-7f452a4ac000 r--p 0000f000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1\n7f452a4ac000-7f452a4ad000 rw-p 00010000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1\n7f452a4ad000-7f452a4b7000 rw-p 00000000 00:00 0           \n7f452a4b7000-7f452a4d9000 r--p 00000000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6\n7f452a4d9000-7f452a651000 r-xp 00022000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6\n7f452a651000-7f452a6a9000 r--p 0019a000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6\n7f452a6a9000-7f452a6ad000 r--p 001f1000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6\n7f452a6ad000-7f452a6af000 rw-p 001f5000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6\n7f452a6af000-7f452a6bc000 rw-p 00000000 00:00 0           \n7f452a6bc000-7f452a6bf000 r--p 00000000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1\n7f452a6bf000-7f452a6da000 r-xp 00003000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1\n7f452a6da000-7f452a6de000 r--p 0001e000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1\n7f452a6de000-7f452a6df000 r--p 00021000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1\n7f452a6df000-7f452a6e0000 rw-p 00022000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1\n7f452a6e0000-7f452a6f3000 r--p 00000000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9\n7f452a6f3000-7f452a719000 r-xp 00013000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9\n7f452a719000-7f452a729000 r--p 00039000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9\n7f452a729000-7f452a72a000 r--p 00048000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9\n7f452a72a000-7f452a72b000 rw-p 00049000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9\n7f452a72b000-7f452a8e1000 rw-p 00000000 00:00 0           \n7f452a8e4000-7f452a8f8000 rw-p 00000000 00:00 0           \n7f452a8f8000-7f452a8f9000 r--p 00000000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2\n7f452a8f9000-7f452a921000 r-xp 00001000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2\n7f452a921000-7f452a92b000 r--p 00029000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2\n7f452a92b000-7f452a92d000 r--p 00033000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2\n7f452a92d000-7f452a92f000 rw-p 00035000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2\n7fff91a4d000-7fff91a6e000 rw-p 00000000 00:00 0           [stack]\n7fff91b3f000-7fff91b43000 r--p 00000000 00:00 0           [vvar]\n7fff91b43000-7fff91b45000 r-xp 00000000 00:00 0           [vdso]\nffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0           [vsyscall]\nWe see that at the end of the program, we have (looking at the first line):\n5 objects in use\n11 bytes in use\n5 objects allocated in total\n11 bytes allocated in total\nSince we never freed any memory, the\nin use\ncounters are the same as the\nspace\ncounters.\nWe have 3 unique call stacks that allocate, in the same order as they appear in the text file (although order does not matter for\npprof\n):\nb\n&lt;-\na\n&lt;-\nmain\na\n&lt;-\nmain\nb\n&lt;-\nmain\nSince our program is a Position Independant Executable (PIE), the loader picks a random address for where to load our program in virtual memory. Consequently, addresses collected from within our program have this offset added to them and this offset is different every run. Thankfully, the\nMAPPED_LIBRARIES\nsection lists address ranges (the first column of each line in that section) for each library that gets loaded.\nAs such,\npprof\nonly needs to find for each address the relevant range, subtract the start of the range from this address, and it has the real address in our executable. It then runs\naddr2line\nor similar to get the code location.\nFinally we can use\npprof\nto extract human-readable information from this text file:\n$ pprof --text ./a.out ./heapprof.0001.heap\nUsing local file ./a.out.\nUsing local file /tmp/heapprof.0001.heap.\nTotal: 0.0 MB\n     0.0  63.6%  63.6%      0.0  63.6% b\n     0.0  36.4% 100.0%      0.0  72.7% a\n     0.0   0.0% 100.0%      0.0 100.0% __libc_start_call_main\n     0.0   0.0% 100.0%      0.0 100.0% __libc_start_main_impl\n     0.0   0.0% 100.0%      0.0 100.0% _start\n     0.0   0.0% 100.0%      0.0 100.0% main\nGenerating a\nLet\'s start with a very simple arena (directly based on\nhttps://nullprogram.com/blog/2023/09/27/\n) and show how it is used:\n#define _GNU_SOURCE\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;unistd.h&gt;\n\n\ntypedef struct {\n  u8 *start;\n  u8 *end;\n} arena_t;\n\nstatic void * arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {\n  pg_assert(a-&gt;start &lt;= a-&gt;end);\n  pg_assert(align == 1 || align == 2 || align == 4 || align == 8);\n\n  size_t available = a-&gt;end - a-&gt;start;\n  size_t padding = -(size_t)a-&gt;start &amp; (align - 1);\n\n  size_t offset = padding + size * count;\n  if (available &lt; offset) {\n    fprintf(stderr,\n            &quot;Out of memory: available=%lu &quot;\n            &quot;allocation_size=%lu\\n&quot;,\n            available, offset);\n    abort();\n  }\n\n  uint8_t *res = a-&gt;start + padding;\n\n  a-&gt;start += offset;\n\n  return (void *)res;\n}\nNow, we are ready to add memory profiling to our simple allocator.\nFirst, we model a record with the 4 counters and the call stack:\ntypedef struct {\n  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;\n  uint64_t *call_stack;\n  uint64_t call_stack_len;\n} mem_record_t;\nThen, the profile, which contains the 4 counters as a sum and an array of records.\nAn arena now has an (optional) pointer to a memory profile:\ntypedef struct mem_profile_t mem_profile_t;\ntypedef struct {\n  uint8_t *start;\n  uint8_t *end;\n  mem_profile_t* profile;\n} arena_t;\n\nstruct mem_profile_t {\n  mem_record_t *records;\n  uint64_t records_len;\n  uint64_t records_cap;\n  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;\n  arena_t arena;\n};\nNote that the memory profile needs to allocate to store this metadata and as such needs an arena. Which makes these two structures cyclic!\nThe way we solve it is:\nWe create an small arena dedicated to the memory profiling and this arena does\nnot\nhave a memory profile attached (otherwise we would end up in a infinite recursion, and we are not interested in profiling the memory usage of the memory profiler anyway; its memory usage is capped by the size of its dedicated arena).\nWe create the memory profile using this arena.\nWe create the main arena for our program to use and attach the profile to it.\nstatic arena_t arena_new(uint64_t cap, mem_profile_t *profile) {\n  uint8_t *mem = mmap(NULL, cap, PROT_READ | PROT_WRITE,\n                      MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);\n\n  arena_t arena = {\n      .profile = profile,\n      .start = mem,\n      .end = mem + cap,\n  };\n  return arena;\n}\n\nint main(){\n  arena_t mem_profile_arena = arena_new(1 &lt;&lt; 16, NULL);\n  mem_profile_t mem_profile = {.arena = mem_profile_arena};\n\n  arena_t arena = arena_new(1 &lt;&lt; 22, &amp;mem_profile);\n}\nNow, in\narena_alloc\n, if there is a non-NULL memory profile, we record the allocation just before returning the freshly allocated pointer:\nstatic void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {\n  [...]\n\n  if (a-&gt;profile) {\n    mem_profile_record_alloc(a-&gt;profile, count, offset);\n  }\n\n  return (void *)res;\n}\nWe now have to implement\nmem_profile_record_alloc\nand exporting the profile to the text format, and we are done.\nWhen recording an allocation, we need to capture the call stack, so we walk the stack upwards until we reach a frame address that is 0 or does not have the alignement of a pointer (8); at which point we know not to dereference it and go further.\nThis will break if we disable frame pointers when compiling (\n-fomit-frame-pointer\n) which is in my opinion always a bad idea. There are other ways to get a call stack fortunately but they all are more involved and potentially slower. Note that this approach probably only works on x86_64, no idea how ARM does that. Here is a\ndeep dive\non getting a stack trace in different environments.\nstatic uint8_t record_call_stack(uint64_t *dst, uint64_t cap) {\n  uintptr_t *rbp = __builtin_frame_address(0);\n\n  uint64_t len = 0;\n\n  while (rbp != 0 &amp;&amp; ((uint64_t)rbp &amp; 7) == 0 &amp;&amp; *rbp != 0) {\n    const uintptr_t rip = *(rbp + 1);\n    rbp = (uintptr_t *)*rbp;\n\n    // `rip` points to the return instruction in the caller, once this call is\n    // done. But: We want the location of the call i.e. the `call xxx`\n    // instruction, so we subtract one byte to point inside it, which is not\n    // quite \'at\' it, but good enough.\n    dst[len++] = rip - 1;\n\n    if (len &gt;= cap)\n      return len;\n  }\n  return len;\n}\nNow we can record the allocation proper, upserting the new record into our existing list of records, trying to find an existing record with the same call stack.\nThat part is important to avoid having a huge profile and that\'s why\npprof\nmade this design decision.\nThe code is slightly lengthy because we need to roll our own arrays here in this minimal example, but in a real application you\'d have your own array structure and helper functions, most likely:\nstatic void mem_profile_record_alloc(mem_profile_t *profile,\n                                     uint64_t objects_count,\n                                     uint64_t bytes_count) {\n  // Record the call stack by stack walking.\n  uint64_t call_stack[64] = {0};\n  uint64_t call_stack_len =\n      record_call_stack(call_stack, sizeof(call_stack) / sizeof(call_stack[0]));\n\n  // Update the sums.\n  profile-&gt;alloc_objects += objects_count;\n  profile-&gt;alloc_space += bytes_count;\n  profile-&gt;in_use_objects += objects_count;\n  profile-&gt;in_use_space += bytes_count;\n\n  // Upsert the record.\n  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {\n    mem_record_t *r = &amp;profile-&gt;records[i];\n\n    if (r-&gt;call_stack_len == call_stack_len &amp;&amp;\n        memcmp(r-&gt;call_stack, call_stack, call_stack_len * sizeof(uint64_t)) ==\n            0) {\n      // Found an existing record, update it.\n      r-&gt;alloc_objects += objects_count;\n      r-&gt;alloc_space += bytes_count;\n      r-&gt;in_use_objects += objects_count;\n      r-&gt;in_use_space += bytes_count;\n      return;\n    }\n  }\n\n  // Not found, insert a new record\n  mem_record_t record = {\n      .alloc_objects = objects_count,\n      .alloc_space = bytes_count,\n      .in_use_objects = objects_count,\n      .in_use_space = bytes_count,\n  };\n  record.call_stack = arena_alloc(&amp;profile-&gt;arena, sizeof(uint64_t),\n                                  _Alignof(uint64_t), call_stack_len);\n  memcpy(record.call_stack, call_stack, call_stack_len * sizeof(uint64_t));\n  record.call_stack_len = call_stack_len;\n\n  if (profile-&gt;records_len &gt;= profile-&gt;records_cap) {\n    uint64_t new_cap = profile-&gt;records_cap * 2;\n    // Grow the array.\n    mem_record_t *new_records = arena_alloc(\n        &amp;profile-&gt;arena, sizeof(mem_record_t), _Alignof(mem_record_t), new_cap);\n    memcpy(new_records, profile-&gt;records,\n           profile-&gt;records_len * sizeof(mem_record_t));\n    profile-&gt;records_cap = new_cap;\n    profile-&gt;records = new_records;\n  }\n  profile-&gt;records[profile-&gt;records_len++] = record;\n}\nFinally, we can dump this profile in the\npprof\ntextual representation:\nstatic void mem_profile_write(mem_profile_t *profile, FILE *out) {\n  fprintf(out, &quot;heap profile: %lu: %lu [     %lu:    %lu] @ heapprofile\\n&quot;,\n          profile-&gt;in_use_objects, profile-&gt;in_use_space,\n          profile-&gt;alloc_objects, profile-&gt;alloc_space);\n\n  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {\n    mem_record_t r = profile-&gt;records[i];\n\n    fprintf(out, &quot;%lu: %lu [%lu: %lu] @ &quot;, r.in_use_objects, r.in_use_space,\n            r.alloc_objects, r.alloc_space);\n\n    for (uint64_t j = 0; j &lt; r.call_stack_len; j++) {\n      fprintf(out, &quot;%#lx &quot;, r.call_stack[j]);\n    }\n    fputc(\'\\n\', out);\n  }\n\n  fputs(&quot;\\nMAPPED_LIBRARIES:\\n&quot;, out);\n\n  static uint8_t mem[4096] = {0};\n  int fd = open(&quot;/proc/self/maps&quot;, O_RDONLY);\n  assert(fd != -1);\n  ssize_t read_bytes = read(fd, mem, sizeof(mem));\n  assert(read_bytes != -1);\n  close(fd);\n\n  fwrite(mem, 1, read_bytes, out);\n\n  fflush(out);\n}\nAnd we\'re done! Let\'s try it with our initial example (bumping the size of the allocations a bit because\npprof\nignores tiny allocations for readability - although this is configurable):\nvoid b(int n, arena_t *arena) {\n  arena_alloc(arena, sizeof(int), _Alignof(int), n);\n}\n\nvoid a(int n, arena_t *arena) {\n  arena_alloc(arena, sizeof(int), _Alignof(int), n);\n  b(n, arena);\n}\n\nint main() {\n  [...]\n\n  arena_t arena = arena_new(1 &lt;&lt; 28, &amp;mem_profile);\n\n  for (int i = 0; i &lt; 2; i++)\n    a(2 * 1024 * 1024, &amp;arena);\n\n  b(3 * 1024 * 1024, &amp;arena);\n\n  mem_profile_write(&amp;mem_profile, stderr);\n}\n$ cc -g3 example.c\n$ ./a.out 2&gt; heap.profile\n$ pprof --web ./a.out heap.profile\nAnd we see in our browser:\nAnd we can even generate a flamegraph for it leveraging the great\nOG flamegraph project\n:\n$ pprof --collapsed ./a.out heap.profile | flamegraph.pl &gt; out.svg\nVariations and limitations\nFor this article we always do memory profiling and abort once the arena is full; but it does not have to be this way. Memory profiling could be enabled in a CLI program with a command line flag; if it is disabled we do not create a memory profile nor an arena for it. Or, it could be enabled/disabled dynamically, after a given amount of time, etc. It could also stop when its dedicated arena is full instead of aborting the whole program.\nSampling could be easily added to\nmem_profile_record_alloc\nto only record some records, say 1%\nThe current maximum call stack depth is 64, for brevity in the context of this article. We can store a bigger one by having a dynamically sized array or storing each address in a more compact format, e.g. varint instead of a fixed 8 bytes\nStack traces won\'t work across library calls that are compiled without frame pointers. To which I\'d say: It\'s likely easier to compile all of the code you depend on with the build flags you require than try to come up with alternative ways to walk the stack. Your mileage may vary.\nWe use linear scanning to find an existing record with the same call stack. When having lots of records, it would be advantageous to use a binary search on a sorted array or perhaps a hashtable.\nAlternatives\npprof\n(the Perl one) is not the only way to get this information.\nIt turns out that your browser comes with a built-in profiler and a nice one to use at that! And it has support for native allocations, stack traces and so forth. Another possibility is the new\npprof\n(the Go one). They all have more features than the original\npprof\nthat are really handy, most notably:\nA built-in interactive flamegraph feature\nTracking the time at which an allocation happened, which can then be used to produce a flamechart representing allocations over time (for example to observe a memory leak increasing the memory usage over time, and discover where it comes from)\nTo make use of these, our application needs to generate the information we gathered in the format the profiler expects, just like we did with\npprof\n.\nChrome expects a\nJSON file\n, which I did not experiment with yet.\nFirefox expects a\ndifferent JSON file\n. A good starting point is\nhttps://github.com/mstange/samply\n. I experimented with it but dropped this avenue because of several frustrating aspects:\nIt is very JS-centric so much of the profile has to be filled with\nnull\nvalues or explicitly saying that the each sample is not for JS.\nAll fields must be provided even if empty, including arrays. Failing to do so throws an obscure exception in the profiler, that has to be tracked in the browser debugger, which shows the minified JS profiler code, which is not fun (yes, the profiler is written mostly/entirely in JS). The consequence is that most of the profile file is made of lengthy arrays only containing\nnull\nvalues. Thus, most of the code to generate it is boilerplate noise.\nMemory traces are supported but it seems that a CPU trace is required for each memory trace which makes the profile even bigger, and harder to generate. Only providing memory samples shows nothing in the graphs.\nThe new\npprof\n(the Go version) expects a relatively simple gzipped\nprotobuf file\n, but that means adding code generation and a library dependency. I use this tool when writing Go quite often and it is helpful. It also supports adding labels to samples, for example we could label the allocations coming from different arenas differently to be able to distinguish them in the same profile.\nConclusion\nI like that one of the most common memory profilers uses a very simple text format that anyone can generate, and that\'s it\'s stand-alone. It\'s very UNIXy!\nNonetheless, I will in the future explore the other aforementioned profilers (probably the Chrome one because it seems the most straightforward) and I do not think it should be much additional work. It\'s nice to leverage the existing browser to avoid having to install a profiler.\nAfter all, it\'s been\ndone before\n!\nAddendum: the full code\nThe full code\n#define _GNU_SOURCE\n#include &lt;assert.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;unistd.h&gt;\n\ntypedef struct {\n  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;\n  uint64_t *call_stack;\n  uint64_t call_stack_len;\n} mem_record_t;\n\ntypedef struct mem_profile mem_profile_t;\ntypedef struct {\n  uint8_t *start;\n  uint8_t *end;\n  mem_profile_t *profile;\n} arena_t;\n\nstruct mem_profile {\n  mem_record_t *records;\n  uint64_t records_len;\n  uint64_t records_cap;\n  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;\n  arena_t arena;\n};\n\nstatic void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count);\n\nstatic uint8_t record_call_stack(uint64_t *dst, uint64_t cap) {\n  uintptr_t *rbp = __builtin_frame_address(0);\n\n  uint64_t len = 0;\n\n  while (rbp != 0 &amp;&amp; ((uint64_t)rbp &amp; 7) == 0 &amp;&amp; *rbp != 0) {\n    const uintptr_t rip = *(rbp + 1);\n    rbp = (uintptr_t *)*rbp;\n\n    // `rip` points to the return instruction in the caller, once this call is\n    // done. But: We want the location of the call i.e. the `call xxx`\n    // instruction, so we subtract one byte to point inside it, which is not\n    // quite \'at\' it, but good enough.\n    dst[len++] = rip - 1;\n\n    if (len &gt;= cap)\n      return len;\n  }\n  return len;\n}\nstatic void mem_profile_record_alloc(mem_profile_t *profile,\n                                     uint64_t objects_count,\n                                     uint64_t bytes_count) {\n  // Record the call stack by stack walking.\n  uint64_t call_stack[64] = {0};\n  uint64_t call_stack_len =\n      record_call_stack(call_stack, sizeof(call_stack) / sizeof(call_stack[0]));\n\n  // Update the sums.\n  profile-&gt;alloc_objects += objects_count;\n  profile-&gt;alloc_space += bytes_count;\n  profile-&gt;in_use_objects += objects_count;\n  profile-&gt;in_use_space += bytes_count;\n\n  // Upsert the record.\n  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {\n    mem_record_t *r = &amp;profile-&gt;records[i];\n\n    if (r-&gt;call_stack_len == call_stack_len &amp;&amp;\n        memcmp(r-&gt;call_stack, call_stack, call_stack_len * sizeof(uint64_t)) ==\n            0) {\n      // Found an existing record, update it.\n      r-&gt;alloc_objects += objects_count;\n      r-&gt;alloc_space += bytes_count;\n      r-&gt;in_use_objects += objects_count;\n      r-&gt;in_use_space += bytes_count;\n      return;\n    }\n  }\n\n  // Not found, insert a new record.\n  mem_record_t record = {\n      .alloc_objects = objects_count,\n      .alloc_space = bytes_count,\n      .in_use_objects = objects_count,\n      .in_use_space = bytes_count,\n  };\n  record.call_stack = arena_alloc(&amp;profile-&gt;arena, sizeof(uint64_t),\n                                  _Alignof(uint64_t), call_stack_len);\n  memcpy(record.call_stack, call_stack, call_stack_len * sizeof(uint64_t));\n  record.call_stack_len = call_stack_len;\n\n  if (profile-&gt;records_len &gt;= profile-&gt;records_cap) {\n    uint64_t new_cap = profile-&gt;records_cap * 2;\n    // Grow the array.\n    mem_record_t *new_records = arena_alloc(\n        &amp;profile-&gt;arena, sizeof(mem_record_t), _Alignof(mem_record_t), new_cap);\n    memcpy(new_records, profile-&gt;records,\n           profile-&gt;records_len * sizeof(mem_record_t));\n    profile-&gt;records_cap = new_cap;\n    profile-&gt;records = new_records;\n  }\n  profile-&gt;records[profile-&gt;records_len++] = record;\n}\n\nstatic void mem_profile_write(mem_profile_t *profile, FILE *out) {\n  fprintf(out, &quot;heap profile: %lu: %lu [     %lu:    %lu] @ heapprofile\\n&quot;,\n          profile-&gt;in_use_objects, profile-&gt;in_use_space,\n          profile-&gt;alloc_objects, profile-&gt;alloc_space);\n\n  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {\n    mem_record_t r = profile-&gt;records[i];\n\n    fprintf(out, &quot;%lu: %lu [%lu: %lu] @ &quot;, r.in_use_objects, r.in_use_space,\n            r.alloc_objects, r.alloc_space);\n\n    for (uint64_t j = 0; j &lt; r.call_stack_len; j++) {\n      fprintf(out, &quot;%#lx &quot;, r.call_stack[j]);\n    }\n    fputc(\'\\n\', out);\n  }\n\n  fputs(&quot;\\nMAPPED_LIBRARIES:\\n&quot;, out);\n\n  static uint8_t mem[4096] = {0};\n  int fd = open(&quot;/proc/self/maps&quot;, O_RDONLY);\n  assert(fd != -1);\n  ssize_t read_bytes = read(fd, mem, sizeof(mem));\n  assert(read_bytes != -1);\n  close(fd);\n\n  fwrite(mem, 1, read_bytes, out);\n\n  fflush(out);\n}\n\nstatic void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {\n  size_t available = a-&gt;end - a-&gt;start;\n  size_t padding = -(size_t)a-&gt;start &amp; (align - 1);\n\n  size_t offset = padding + size * count;\n  if (available &lt; offset) {\n    fprintf(stderr,\n            &quot;Out of memory: available=%lu &quot;\n            &quot;allocation_size=%lu\\n&quot;,\n            available, offset);\n    abort();\n  }\n\n  uint8_t *res = a-&gt;start + padding;\n\n  a-&gt;start += offset;\n\n  if (a-&gt;profile) {\n    mem_profile_record_alloc(a-&gt;profile, count, offset);\n  }\n\n  return (void *)res;\n}\n\nstatic arena_t arena_new(uint64_t cap, mem_profile_t *profile) {\n  uint8_t *mem = mmap(NULL, cap, PROT_READ | PROT_WRITE,\n                      MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);\n\n  arena_t arena = {\n      .profile = profile,\n      .start = mem,\n      .end = mem + cap,\n  };\n  return arena;\n}\n\nvoid b(int n, arena_t *arena) {\n  arena_alloc(arena, sizeof(int), _Alignof(int), n);\n}\n\nvoid a(int n, arena_t *arena) {\n  arena_alloc(arena, sizeof(int), _Alignof(int), n);\n  b(n, arena);\n}\n\nint main() {\n  arena_t mem_profile_arena = arena_new(1 &lt;&lt; 16, NULL);\n  mem_profile_t mem_profile = {\n      .arena = mem_profile_arena,\n      .records = arena_alloc(&amp;mem_profile_arena, sizeof(mem_record_t),\n                             _Alignof(mem_record_t), 16),\n      .records_cap = 16,\n  };\n\n  arena_t arena = arena_new(1 &lt;&lt; 28, &amp;mem_profile);\n\n  for (int i = 0; i &lt; 2; i++)\n    a(2 * 1024 * 1024, &amp;arena);\n\n  b(3 * 1024 * 1024, &amp;arena);\n\n  mem_profile_write(&amp;mem_profile, stderr);\n}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#1714161565-pprof",
"#3080183899-the-text-format",
"#1521287171-generating-a",
"#2279041372-variations-and-limitations",
"#3437344394-alternatives",
"#3796851539-conclusion",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
1987,3097,14478,23571,24849,27107,27589,],
},
{
name:"gnuplot_lang.html",
text:"Solving a problem with Gnuplot, the programming language (not the plotting software!)\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-12-01\nSolving a problem with Gnuplot, the programming language (not the plotting software!)\nAdvent of Code\nGnuplot\nTable of contents\nThe problem\nClosing thoughts\nAddendum: The full code\nIs it any good? Can you solve real problems with it?\nMost people know\nGnuplot\nas a way to plot data. Two lines of code and we can visualize data:\nset output &quot;plot.png&quot;\nplot &quot;out.dat&quot; with lines\nwhere\nout.data\nis a text file with a number on each line.\nThe software engineering advice that I heard a long time ago and left a mark on me is:\nFind a way to visualize your problem.\nSo Gnuplot is definitely worth of a spot in a Software Engineer\'s toolbox.\nHowever, few know that Gnuplot is actually also Turing complete programming language. It is similar in syntax to Perl or Awk. So I scratched an itch and solved a\nproblem\nwith it.\nThe problem\nIn short, we get a text file where each line contains random ASCII characters. For each line, we must find the first and last digit characters, combine them into an number and at the end output the sum of all these numbers.\nThe way we read the data into a variable is through a shell command:\ndata = system(&quot;cat in.txt&quot;)\nGnuplot has the\nplot\ncommand to turn input data into a plot, but nothing built-in to read input data into a variable, it seems. No matter,\nsystem\nwhich spawns a command in a subshell does the trick.\nSince we need to check whether a character is a string, let\'s define our own little function for it. Yes, Gnuplot has user defined functions! The unfortunate limitation is that the body has to be an expression:\nis_digit(c) = c eq &quot;0&quot; || c eq &quot;1&quot; || c eq &quot;2&quot; || c eq &quot;3&quot; || c eq &quot;4&quot; || c eq &quot;5&quot; || c eq &quot;6&quot; || c eq &quot;7&quot; || c eq &quot;8&quot; || c eq &quot;9&quot;\nCharacters are not a thing; instead we deal with a string of length 1. Comparing strings for equality is done with the operator\neq\n.\nThen, we iterate over each line in the data. Gnuplot has a for-each construct we can use for that.\nWe then iterate over each character in the line with a for-range loop, isolating the \'character\' (remember, it\'s just a string of length 1) with a slicing syntax that many modern languages have:\nsum = 0\n\ndo for [line in data] {\n  len = strlen(line)\n\n  do for [i = 1:len] {\n    c = line[i:i]\n  }\n}\nOne thing to note here is that strings are 1-indexed and the slicing syntax is:\nfoo[start_inclusive:end_inclusive]\n.\nWe then set\nfirst\nto the first digit character we find:\ndo for [line in data] {\n  len = strlen(line)\n\n  first= &quot;&quot;\n\n  do for [i = 1:len] {\n    c = line[i:i]\n    if (is_digit(c)) {\n      if (first eq &quot;&quot;) {\n        first = c\n        break\n      }  \n    }\n  }\n}\nWe do the same for the last character, iterating in reverse order:\nlast = &quot;&quot;\n\n  do for [i = len:1:-1] {\n    c = line[i:i]\n    if (is_digit(c)) {\n      if (last eq &quot;&quot;) {\n        last = c\n        break\n      }  \n    }\n  }\nFinally, we concatenate the two digits (which are still two strings of length 1 at that point) with the\n.\noperator, convert it to a number with the\n+ 0\nidiom, and increase our sum:\nnum = first . last + 0\n  sum = sum + num\nWe just have to print the sum at the end:\nprint(sum)\nClosing thoughts\nPretty straightforward, isn\'t it? Well, no. The language is weirdly restrictive, for example\nsum += num\ndoes not parse.\nfor\nand\nwhile\nloops cannot for some reason be used interchangeably due to the weird\ndo\nprefix for for-loops. Very few builtin functions are available.\nThere does not seem to be basic data structures such as arrays and maps. Every variable is global. And so on.\nIt\'s weird because the language also has very modern constructs that some mainstream languages still do not have, like the slicing syntax.\nAwk, Lua or Perl are honestly better in every way, to pick relatively simple, dynamic languages that people usually reach to for Unixy text transformations. And these will have better tooling, such as a debugger. Heck, even shell scripting is probably easier and more straightforward, and that\'s a low bar.\nEverything points to the fact that Gnuplot expects it\'s input data in some prearranged tabular form, and just wants to plot it, not transform it. That means that another (real) programming language is expected to do prior work and Gnuplot is at the end of the data pipeline as a \'dumb\' visualization tool. I can also see how the limited language can still be useful for Physicists or Mathematicians to write simple numerical, pure functions e.g.\nf(x) = x*2 + 1\n.\nI\'ll investigate Julia and perhaps R in the future, which are in the same niche of science/data visualization but are full programming languages with plentiful tooling.\nAddendum: The full code\nRun with\ngnuplot my_file.dem\n.\ndata = system(&quot;cat in.txt&quot;)\n\nis_digit(c) = c eq &quot;0&quot; || c eq &quot;1&quot; || c eq &quot;2&quot; || c eq &quot;3&quot; || c eq &quot;4&quot; || c eq &quot;5&quot; || c eq &quot;6&quot; || c eq &quot;7&quot; || c eq &quot;8&quot; || c eq &quot;9&quot;\n\nsum = 0\n\ndo for [line in data] {\n  len = strlen(line)\n\n  first= &quot;&quot;\n\n  do for [i = 1:len] {\n    c = line[i:i]\n    if (is_digit(c)) {\n      if (first eq &quot;&quot;) {\n        first = c\n        break\n      }  \n    }\n  }\n\n\n  last = &quot;&quot;\n\n  do for [i = len:1:-1] {\n    c = line[i:i]\n    if (is_digit(c)) {\n      if (last eq &quot;&quot;) {\n        last = c\n        break\n      }  \n    }\n  }\n  num = first . last + 0\n  sum = sum + num\n}\n\nprint(sum)\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2580162644-the-problem",
"#3440295979-closing-thoughts",
"#2853131083-addendum-the-full-code",
],
title_text_offsets:[
1019,3442,4918,],
},
{
name:"feed.html",
text:"This blog now has an Atom feed, and yours should probably too\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-12-15\nThis blog now has an Atom feed, and yours should probably too\nFeed\nAtom\nUUID\nFind it\nhere\nor in the header on the top right-hand corner.\nImagine a world where you can see the content of each website you like inside the app of your choosing, read the articles offline and save them on disk for later, be notified whenever the website has something new, and all of which is implemented with an open standard. Well that was most of the web some years ago and this blog now does all of that.\nAnd it\'s not hard! The only thing we need is to serve a\nfeed.xml\nfile that lists articles with some metadata such as \'updated at\' and a UUID to be able to uniquely identify an article. This XML file is an\nAtom feed\nwhich has a nice\nRFC\n.\nI implemented that in under an hour, skimming at the RFC and examples. It\'s a bit hacky but it works. The script to do so is\nhere\n. And you can do too! Again, it\'s not hard. Here goes:\nWe pick a UUID for our feed. I just generated one and stuck it as a constant in the script.\nThe \'updated at\' field for the feed is just\ntime.Now()\n. It\'s not exactly accurate, it should probably be the most recent\nmtime\nacross articles but it\'s good enough.\nFor each article (\n*.html\n) file in the directory, we add an entry (\n&lt;entry&gt;\n) in the XML document with:\nThe link to the article, that\'s just the filename in my case.\nThe \'updated at\' field, which is\njust the\nmtime\nof the file locally\nqueried from git\nThe \'published at\' field, which is\njust the\nctime\nof the file locally\nqueried from git\nA UUID. Here I went with UUIDv5 which is simply the sha1 of the file name in the UUID format. It\'s nifty because it means that the script is stateless and idempotent. If the article is later updated, the UUID remains the same (but the\nupdated at\nwill still hint at the update).\nAnd...that\'s it really. Enjoy reading these articles in your favorite app!\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"body_of_work.html",
text:"Body of work\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2023-12-19\nBody of work\nCobol\nC\nC#\nC++\nOpenGL\nOculus Rift\nTypescript\nGo\nRust\nKubernetes\nDocker\nTable of contents\nCr\u{e9}dit Mutuel (Bank), Strasbourg, France; 2013\nCNRS Intern Software Engineer experimenting with the Oculus Rift (VR) CNRS, Strasbourg, France; 2014\nFull-stack Software Engineer EdgeLab, Lausanne, Switzerland; 2015-2017\nBack-end Software Engineer &amp; DevOps PPRO, Munich, Germany; 2017-2023\nSenior Software Engineer Giesecke+Devrient, Munich, Germany; 2023-present\nI am here recounting chronologically what I have achieved in my career until now. I have a sub par memory so it\'s great for me to look back on that, and may it also hopefully serve as an interesting insight for fellow practitioners and recruiters into the kind of work I enjoy and am experienced with.\nCr\u{e9}dit Mutuel (Bank), Strasbourg, France; 2013\nThis was my first professional experience (a 8 weeks internship) and happened at one of the big banks in the country. Like most banks that have been founded in the 20th century, they have millions and millions of lines of code in COBOL, and realized this is not tenable and need to migrate to a modern tech stack to be able to keep it simply running.\nI migrated a business application used internally. The original application was a terminal (as in: made for a\nhardware\nterminal), with a basic UI, talking to a DB2 database, and running on IBM\'s z/OS on a (real) mainframe in the confines of the bank. The final application was a C# web application, still talking to the same database, but this time running on a Windows server.\nIn retrospect, that was such a unique experience to work on a 30+ year old codebase running on a tech stack, OS and hardware that most developers will never encounter.\nThe team insisted (although not unanimously) that I write\nnew\nCOBOL code for this brand new applications for the layer that talks to the database. I think they were worried that C# could not do this job properly, for some reason? So I got to do that, in a COBOL IDE made by IBM which only COBOL developers know of. To-do list item ticked, I guess.\nAll in all, that was a very interesting social experience and a great insight on how business and developers think and (try to) evolve, and how one can attempt to change the tech stack of an existing running application, which is a challenge any company will face at a moment or another. And how we engineers have a professional duty to keep learning and adapting to this changing world.\nCNRS Intern Software Engineer experimenting with the Oculus Rift (VR) CNRS, Strasbourg, France; 2014\nMy second internship (10 weeks), and perhaps the project I loved the most. This took place at an astronomy lab, I had the incredible privilege to have my office in the old library that was probably a few centuries old, filled with old books; the building was this 19th century observatory with a big park with bee houses... This will never be topped.\nThe work was also such a blast: I got to experiment with the first version of the Oculus Rift, and tinker with it. My adviser and I decided to work on two different projects: A (from scratch) 3D visualization of planets inside the Oculus Rift for kids to \'fly\' through the solar system and hopefully spark in them an interest in space exploration and astronomy. The second project was to add to an existing and large 3D simulation of planets a VR mode.\nIt was an exciting time, VR was all the rage and everything had to be figured out: the motion sickness, the controller (it turns out that most people are not so good at using a keyboard and mouse while being completely blind and a video game console controller is much more intuitive), how to plug the Oculus Rift SDK to an existing codebase, the performance, etc.\nEven though I wished I had a tad more time, I delivered both. Since we foresaw we would not have time for everything, the solar system visualization got cut down to blue sparkling cubes in 3D space, but still, the Oculus Rift worked beautifully with it. Even though the field was in its infancy, the feeling of realism was already jarring - our brain is tricked easily! The second project also worked, although we had visual artifacts in some cases when traveling far distances, which I suspected was due to floating point precision issues in the existing codebase. There are articles online discussing this fact with physical simulations where huge distances are present and I discussed it with codebase authors during our weekly check-ins and demo sessions.\nPerformance was initially also a challenge since VR consists of rendering the same scene twice, once for each eye, with a slight change in where the camera is in 3D space (since the camera is your eye, in a way). And 3D rendering will always be a domain where performance is paramount. It\'s interesting to note that new 3D APIs such as Vulkan do offer features for VR in the form of extensions to speed it up in hardware, having the GPU do the heavy lifting. But back in 2014, there was nothing like that. Also, 3D APIs have really evolved in the last decade, becoming more low level and giving the developer more control, power, but also responsibilities.\nMy major performance stepping stone was moving from rendering everything in the scene to using an octree to only render entities in the \'zone\' where the camera is, or is looking at.\nI used OpenGL and C++ for the first project, and C for the second one since the existing codebase was in C.\n3D, VR, extending an existing codebase, starting a new project from scratch with \'carte blanche\': I learned a ton! And my adviser, fellow coworkers exploring this space (notably trying to do the same with a different VR headset, the Sony Morpheus), and I even got to publish a paper based on our work, that got submitted:\nImmersive-3D visualization of astronomical data\n,\nlink 1\n,\nlink 2\n.\nFinally, I on-boarded my successor on the codebase and the build system and helped them troubleshoot some cross-platform issues.\nFull-stack Software Engineer EdgeLab, Lausanne, Switzerland; 2015-2017\nMy first full-time job, initially being a 6 months internship concluding my Master\'s degree of Computer Science, and then extending into a full time position. The company was a financial startup building simulations of the stock market: how does the price of a bond or an option evolve if there is an earthquake or a housing crash? The idea was to observe how these events affected the stock market historically and simulate these happening on your portfolio to get a sense of how robust or risky your positions are.\nThe startup was filled with super smart Math and Physics doctors and it was such a chance to work alongside them.\nIt was lots of new stuff for me: new country, new way of working, being in a small startup (something like 10 people when I joined, if at all), and having to ship something very quickly for a demo coming up in a few days!\nMy main achievements were at first to optimize and simplify the front-end experience which had complex and at times slow pages (I remember the infamous Tree Table: a classic HTML table, except that each cell shows tree shaped data, like a file system!). Then, realizing it would not scale easily, I convinced the team to migrate to Typescript (that\'s quite early at this point: end of 2015!). That was so effective that while the migration was on-going, you could tell which page of the application was written in JavaScript or Typescript based on whether it had random bugs or not. Most of the gains of Typescript was not so much the readability of static typing or the warnings, although these helped, but rather reducing the dynamism of the code by forcing the developer to stick to one type for a given variable. That of course dramatically improved correctness and reduced bugs, but incidentally also helped the performance!\nI then moved to the back-end, extending the financial models and simulations in C++. That was a lot of matrix code and financial math to learn!\nI also contributed to modernizing the codebase to C++11 and improving the build system to make it easier to on-board new people.\nEventually, the company got acquired for 8 digits by a Swiss bank.\nBack-end Software Engineer &amp; DevOps PPRO, Munich, Germany; 2017-2023\nI knew I did not want to stay in Switzerland, and found a job as a Software Engineer in Munich, Germany, at a FinTech company. This time not the stock market kind but the online payments kind. Think Paypal or the now defunct Wirecard (but we were honest and law abiding, and they were not).\nI joined to kick start the effort of transforming web applications from server-side rendered HTML with a tiny bit of JavaScript to fully dynamic single page applications (SPA) in Typescript. At the time, SPAs were all the rage, and it is true that C++ back-ends with a slow and complex deployment process are not a great fit to a fast growing company. Still, looking back, I am not sure if static HTML does not cover 90% of the use cases. However, it was so much fun to get feedback or a request from the users, implement it in a few hours, deploy it, and tell them to try it! They got used to that rapid cycle very quickly.\nI then moved to the back-end, working for a time in a full-stack manner, and then spear-heading the company-wide effort to move to the cloud and Kubernetes, thus I morphed into a DevOps person, migrating without any downtimes numerous applications. Without the customers even noticing!\nI also trained and helped other teams to adopt Kubernetes and the cloud, conducted very many interviews that resulted in hiring a number of very fine folks that I still hold dear to my heart to this day.\nI then again spear-headed a new transformation: Adopting the JVM, seen as more fitting to \'micro\'-services than C++, more specifically Kotlin.\nOne Kotlin application I worked on was an internal (soft) real-time ledger application for accounting and compliance purposes using the Cassandra database and then Postgres.\nAfter deploying several production Kotlin services, I moved to the payment platform team where I led a brand new transformation (again!): Moving from batch services running at night (and usually being troubleshooted during the day), to a real time event based architecture using Kafka (and then later Kinesis).\nMy work focused on writing from scratch the main producer of these events in Go: a bridge from a traditional RDBMS, to Kafka; as well as educating consumers on this new way of writing software. Challenges were plentiful: Events had to be first manually added to the existing C++ payment software, tracking down each location that mutated data and storing the right event in the database, without breaking the crucial payment flows. Then, our bridge would poll multiple such databases in multiple datacenters, (the databases being of course different RDBMS, versions, and OSes!), exporting (i.e. producing) in a live fashion these events to Kafka, 24/7/365.\nAs more and more services consuming these events blossomed in the company in various teams (be it reporting, billing, compliance, different internal UIs, etc), correctness, reliability and performance were paramount and I made sure that we nailed these factors, among other ways, by improving observability (with metrics, logs, alerts, and opentelemetry), and by constant profiling. The surest way to care about the quality of your software is to be on-call for it, and I was.\nAnother achievement of mine is helping a coworker finish a compliance project analyzing in real time each payment events being produced by my application and, based on rules conceived with business experts, deciding if a payment is fraudulent or not, potentially blocking it from progressing further and notifying a human to inspect it.\nFinally, I helped move the observability stack the company used to Datadog (by comparing several alternatives) and experimented with the serverless architecture by writing and deploying a production lambda in Go which ran flawlessly for months and never had an issue, costing less than 10$ to the company monthly, when the company was contemplating this path.\nI also had a short stint as a team manager, but after 2 months I decided this was not for me and stepped down. I am a Software Engineer and practitioner at heart.\nI look fondly on all these achievements, achieving business targets with a variety of tech stacks and cloud services, majorly contributing to fundamentally transform the company from a slow moving, datacenter based software stack, where developers sometimes wait for weeks for one deployment to happen, and a new project is a herculean effort of synchronizing every team; to a fast-moving, cloud based, self-service and event-oriented architecture, where each team is autonomous, gets a real-time stream of events containing all the information they need, and has nigh complete control and visibility on the whole lifecycle of their application.\nSenior Software Engineer Giesecke+Devrient, Munich, Germany; 2023-present\nAfter 6+ years in my job, I decided I was ready for the next challenge and joined my current company to help productionize an innovative Central Bank Digital Currency project (similar to a cryptocurrency, but backed by a sovereign state, using the state\'s currency, and with all the high standards one expects from regulated financial institutions). The most interesting feature, technically and product wise, is offline payments (card to card) with a focus on privacy.\nMy first focus has been making the product more reliable and fast, relentlessly optimizing the performance and memory usage to ensure that an entire nation can use this suite of applications 24/7, surviving network disruptions, datacenter disasters, etc; while adding crucial business features such as non-repudiation of payments.\nMy second focus has been security: going through regular threat analysis exercises with the team, adding scanning of dependencies and docker images to every project in order to find vulnerabilities or insecure code patterns, fuzzing, SBOM, establishing secure processes e.g. for vulnerability responses, reviewing cryptography code, etc.\nIndeed, I inherited a C++ codebase where the original author moved on, which was a central part of the company\'s offering. After investing some time to get it up to modern standards, I convinced stakeholders and developers to incrementally rewrite it in a memory-safe language (Rust). I led this effort by mentoring fellow developers, establishing a roadmap, doing the implementation work, and presenting regular demos of the progress to stakeholders. This software runs on various OSes and architectures including mobile platforms, and is now 100% Rust.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#811201111-cr-dit-mutuel-bank-strasbourg-france-2013",
"#3600106444-cnrs-intern-software-engineer-experimenting-with-the-oculus-rift-vr-cnrs-strasbourg-france-2014",
"#4038660206-full-stack-software-engineer-edgelab-lausanne-switzerland-2015-2017",
"#2656933116-back-end-software-engineer-amp-devops-ppro-munich-germany-2017-2023",
"#3015159783-senior-software-engineer-gieseckeplusdevrient-munich-germany-2023-present",
],
title_text_offsets:[
886,2567,6063,8257,13004,],
},
{
name:"image_size_reduction.html",
text:"Quick and easy PNG image size reduction\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-02-23\nQuick and easy PNG image size reduction\nOptimization\nPNG\nI seredenpitously noticed that my blog had somewhat big PNG images. But these are just very simple screenshots. There surely must be a way to reduce their size, without affecting their size or legibility?\nWell yes, let\'s quantize them!\nWhat? Quant-what?\nQuoting Wikipedia:\nQuantization, involved in image processing, is a lossy compression technique achieved by compressing a range of values to a single quantum (discrete) value. When the number of discrete symbols in a given stream is reduced, the stream becomes more compressible. For example, reducing the number of colors required to represent a digital image makes it possible to reduce its file size\nIn other words, by picking the right color palette for an image, we can reduce its size without the human eye noticing. For example, an image which has multiple red variants, all very close, are a prime candidate to be converted to the same red color (perhaps the average value) so long as the human eye does not see the difference. Since PNG images use compression, it will compress better.\nAt least, that\'s my layman understanding.\nFortunately there is an open-source\ncommand line tool\nthat is very easy to use and works great. So go give them a star and come back!\nI simply ran the tool on all images to convert them in place in parallel:\n$ ls *.png | parallel \'pngquant {} -o {}.tmp &amp;&amp; mv {}.tmp {}\'\nIt finished instantly, and here is the result:\n$ git show 2e126f55a77e75e182ea18b36fb535a0e37793e4 --compact-summary\ncommit 2e126f55a77e75e182ea18b36fb535a0e37793e4 (HEAD -&gt; master, origin/master, origin/HEAD)\n\n    use pgnquant to shrink images\n\n feed.png                        | Bin 167641 -&gt; 63272 bytes\n gnuplot.png                     | Bin 4594 -&gt; 3316 bytes\n mem_prof1.png                   | Bin 157587 -&gt; 59201 bytes\n mem_prof2.png                   | Bin 209046 -&gt; 81028 bytes\n mem_prof3.png                   | Bin 75019 -&gt; 27259 bytes\n mem_prof4.png                   | Bin 50964 -&gt; 21345 bytes\n wayland-screenshot-floating.png | Bin 54620 -&gt; 19272 bytes\n wayland-screenshot-red.png      | Bin 101047 -&gt; 45230 bytes\n wayland-screenshot-tiled.png    | Bin 188549 -&gt; 107573 bytes\n wayland-screenshot-tiled1.png   | Bin 505994 -&gt; 170804 bytes\n x11_x64_black_window.png        | Bin 32977 -&gt; 16898 bytes\n x11_x64_final.png               | Bin 47985 -&gt; 16650 bytes\n 12 files changed, 0 insertions(+), 0 deletions(-)\nEye-balling it, every image was on average halved. Not bad, for no visible difference!\nInitially, I wanted to use the new hotness: AVIF. Here\'s an example using the\navifenc\ntool on the original image:\n$ avifenc feed.png feed.avif\n$ stat -c \'%n %s\' feed.{png,avif}\nfeed.png 167641\nfeed.avif 36034\nThat\'s almost a x5 reduction in size! However this format is not yet well supported by all browsers. It\'s recommended to still serve a PNG as fallback, which is a bit too complex for this blog. Still, this format is very promising so I thought I should mention it.\nSo as of now, all PNG images on this blog are much lighter! Not too bad for 10m of work.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"you_inherited_a_legacy_cpp_codebase_now_what.html",
text:"You&#39;ve just inherited a legacy C++ codebase, now what?\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-02-29\nYou\'ve just inherited a legacy C++ codebase, now what?\nC++\nC\nLegacy\nCI\nGit\nRewrite\nTable of contents\nGet buy-in\nWrite down the platforms you support\nGet the build working on your machine\nGet the tests passing on your machine\nWrite down in the README how to build and test the application\nFind low hanging fruits to speed up the build and tests\nRemove all unnecessary code\nLinters\nCode formatting\nSanitizers\nAdd a CI pipeline\nIncremental code improvements\nRewrite in a memory safe language?\nConclusion\nAddendum: Dependency management\nAddendum: suggestions from readers\nDiscussions:\nHacker News\n,\nLobster.rs\n,\n/r/programming\n. I\'ve got great suggestions from the comments, see the addendum at the end!\nYou were minding your own business, and out of nowhere something fell on your lap. Maybe you started a new job, or perhaps changed teams, or someone experienced just left.\nAnd now you are responsible for a C++ codebase. It\'s big, complex, idiosyncratic; you stare too long at it and it breaks in various interesting ways. In a word, legacy.\nBut somehow bugs still need to be fixed, the odd feature to be added. In short, you can\'t just ignore it or better yet nuke it out of existence. It matters. At least to someone who\'s paying your salary. So, it matters to you.\nWhat do you do now?\nWell, fear not, because I have experience this many times in numerous places (the snarky folks in the back will mutter: what C++ codebase isn\'t exactly like I described above), and there is a way out, that\'s not overly painful and will make you able to actually fix the bugs, add features, and, one can dream, even rewrite it some day.\nSo join me on a recollection of what worked for me and what one should absolutely avoid.\nAnd to be fair to C++, I do not hate it (per se), it just happens to be one of these languages that people abuse and invariably leads to a horrifying mess and poor C++ is just the victim here and the C++ committee will fix it in C++45, worry not, by adding\nstd::cmake\nto the standard library and you\'ll see how it\'s absolutely a game changer, and - Ahem, ok let\'s go back to the topic at hand.\nSo here\'s an overview of the steps to take:\nGet it to work locally, by only doing the minimal changes required in the code and build system, ideally none. No big refactorings yet, even if itches really bad!\nGet out the chainsaw and rip out everything that\'s not absolutely required to provide the features your company/open source project is advertising and selling\nMake the project enter the 21st century by adding CI, linters, fuzzing, auto-formatting, etc\nFinally we get to make small, incremental changes to the code, Rinse and repeat until you\'re not awaken every night by nightmares of Russian hackers p@wning your application after a few seconds of poking at it\nIf you can, contemplate rewrite some parts in a memory safe language\nThe overarching goal is exerting the least amount of effort to get the project in an acceptable state in terms of security, developer experience, correctness, and performance. It\'s crucial to always keep that in mind. It\'s not about \'clean code\', using the new hotness language features, etc.\nOk, let\'s dive in!\nBy the way, everything here applies to a pure C codebase or a mixed C and C++ codebase, so if that\'s you, keep reading!\nGet buy-in\nYou thought I was going to compare the different sanitizers, compile flags, or build systems? No sir, before we do any work, we talk to people. Crazy, right?\nSoftware engineering needs to be a sustainable practice, not something you burn out of after a few months or years. We cannot do this after hours, on a death march, or even, alone! We need to convince people to support this effort, have them understand what we are doing, and why. And that encompasses everyone: your boss, your coworkers, even non-technical folks. And who knows, maybe you\'ll go on vacation and return to see that people are continuing this effort when you\'re out of office.\nAll of this only means: explain in layman terms the problem with a few simple facts, the proposed solution, and a timebox. Simple right? For example (to quote South Park:\nAll characters and events in this show\u{2014}even those based on real people\u{2014}are entirely fictional\n):\nHey boss, the last hire took 3 weeks to get the code building on his machine and make his first contribution. Wouldn\'t it be nice if, with minimal effort, we could make that a few minutes?\nHey boss, I put quickly together a simple fuzzing setup (\'inputting random data in the app like a monkey and seeing what happens\'), and it manages to crash the app 253 times within a few seconds. I wonder what would happen if people try to do that in production with our app?\nHey boss, the last few urgent bug fixes took several people and 2 weeks to be deployed in production because the app can only be built by this one build server with this ancient operating system that has not been supported for 8 years (FreeBSD 9, for the curious) and it kept failing. Oh by the way whenever this server dies we have no way to deploy anymore, like at all. Wouldn\'t it be nice to be able to build our app on any cheap cloud instance?\nHey boss, we had a cryptic bug in production affecting users, it took weeks to figure out and fix, and it turns out if was due to undefined behavior (\'a problem in the code that\'s very hard to notice\') corrupting data, and when I run this industry standard linter (\'a program that finds issues in the code\') on our code, it detects the issue instantly. We should run that tool every time we make a change!\nHey boss, the yearly audit is coming up and the last one took 7 months to pass because the auditor was not happy with what they saw. I have ideas to make that smoother.\nHey boss, there is a security vulnerability in the news right now about being able to decrypt encrypted data and stealing secrets, I think we might be affected, but I don\'t know for sure because the cryptography library we use has been vendored (\'copy-pasted\') by hand with some changes on top that were never reviewed by anyone. We should clean that up and setup something so that we get alerted automatically if there is a vulnerability that affects us.\nAnd here\'s what to avoid, again totally, super duper fictional, never-really-happened-to-me examples:\nWe are not using the latest C++ standard, we should halt all work for 2 weeks to upgrade, also I have no idea if something will break because we have no tests\nI am going to change a lot of things in the project on a separate branch and work on it for months. It\'s definitely getting merged at some point! (\nnarrator\'s voice:\nit wasn\'t)\nWe are going to rewrite the project from scratch, it should take a few weeks tops\nWe are going to improve the codebase, but no idea when it will be done or even what we are going to do exactly\nOk, let\'s say that now you have buy-in from everyone that matters, let\'s go over the process:\nEvery change is small and incremental. The app works before and works after. Tests pass, linters are happy, nothing was bypassed to apply the change (exceptions do happen but that\'s what they are, exceptional)\nIf an urgent bug fix has to be made, it can be done as usual, nothing is blocked\nEvery change is a measurable improvement and can be explained and demoed to non experts\nIf the whole effort has to be suspended or stopped altogether (because of priorities shifting, budget reasons, etc), it\'s still a net gain overall compared to before starting it (and that gain is in some form\nmeasurable\n)\nIn my experience, with this approach, you keep everyone happy and can do the improvements that you really need to do.\nAlright, let\'s get down to business now!\nWrite down the platforms you support\nThis is so important and not many projects do it. Write in the README (you do have a README, right?). It\'s just a list of\n&lt;architecture&gt;-&lt;operating-system&gt;\npair, e.g.\nx86_64-linux\nor\naarch64-darwin\n, that your codebase officially supports. This is crucial for getting the build working on every one of them but also and we\'ll see later, removing cruft for platforms you do\nnot\nsupport.\nIf you want to get fancy, you can even write down which version of the architecture such as ARMV6 vs ARMv7, etc.\nThat helps answer important questions such as:\nCan we rely on having hardware support for floats, or SIMD, or SHA256?\nDo we even care about supporting 32 bits?\nAre we ever running on a big-endian platform? (The answer is very likely: no, never did, never will - if you do, please email me with the details because that sounds interesting).\nCan a\nchar\nbe 7 bits?\nAnd an important point: This list should absolutely include the developers workstations. Which leads me to my next point:\nGet the build working on your machine\nYou\'d be amazed at how many C++ codebase in the wild that are a core part of a successful product earning millions and they basically do not compile. Well, if all the stars are aligned they do. But that\'s not what I\'m talking about. I\'m talking about reliably, consistently building on all platforms you support. No fuss, no \'I finally got it building after 3 weeks of hair-pulling\' (this brings back some memories). It just works(tm).\nA small aparte here. I used to be really into Karate. We are talking 3, 4 training sessions a week, etc. And I distinctly remember one of my teachers telling me (picture a wise Asian sifu - hmm actually my teacher was a bald white guy... picture Steve Ballmer then):\nYou do not yet master this move. Sometimes you do and sometimes you don\'t, so you don\'t. When eating with a spoon, do you miss your mouth one out of five times?\nAnd I carried that with me as a Software Engineer. \'The new feature works\' means it works every time. Not four out of five times. And so the build is the same.\nExperience has shown me that the best way to produce software in a fast and efficient way is to be able to build on your machine, and ideally even run it on your machine.\nNow if your project is humongous that may be a problem, your system might not even have enough RAM to complete the build. A fallback is to rent a big server somewhere and run your builds here. It\'s not ideal but better than nothing.\nAnother hurdle is the code requiring some platform specific API, for example\nio_uring\non Linux. What can help here is to implement a shim, or build inside a virtual machine on your workstation. Again, not ideal but better than nothing.\nI have done all of the above in the past and that works but building directly on your machine is still the best option.\nGet the tests passing on your machine\nFirst, if there are no tests, I am sorry. This is going to be really difficult to do any change at all. So go write some tests before doing any change to the code, make them pass, and come back. The easiest way is to capture inputs and outputs of the program running in the real world and write end-to-end tests based on that, the more varied the better. It will ensure there are no regressions when making changes, not that the behavior was correct in the first place, but again, better than nothing.\nSo, now you have a test suite. If some tests fail, disable them for now. Make them pass, even if the whole test suite takes hours to run. We\'ll worry about that later.\nWrite down in the README how to build and test the application\nIdeally it\'s one command to build and one for testing. At first it\'s fine if it\'s more involved, in that case the respective commands can be put in a\nbuild.sh\nand\ntest.sh\nthat encapsulate the madness.\nThe goal is to have a non C++ expert be able to build the code and run the tests without having to ask you anything.\nHere some folks would recommend documenting the project layout, the architecture, etc. Since the next step is going to rip out most of it, I\'d say don\'t waste your time now, do that at the end.\nFind low hanging fruits to speed up the build and tests\nEmphasis on \'low hanging\'. No change of the build system, no heroic efforts (I keep repeating that in this article but this is so important).\nAgain, in a typical C++ project, you\'d be amazed at how much work the build system is doing without having to do it at all. Try these ideas below and measure if that helps or not:\nBuilding and running tests\nof your dependencies\n. In a project which was using\nunittest++\nas a test framework, built as a CMake subproject, I discovered that the default behavior was to build the tests of the test framework, and run them, every time! That\'s crazy. Usually there is a CMake variable or such to opt-out of this.\nBuilding and running example programs\nof your dependencies\n. Same thing as above, the culprit that time was\nmbedtls\n. Again, setting a CMake variable to opt-out of that solved it.\nBuilding and running the tests of your project by default when it\'s being included as a subproject of another parent project. Yeah the default behavior we just laughed at in our dependencies? It turns out we\'re doing the same to other projects! I am no CMake expert but it seems that there is no standard way to exclude tests in a build. So I recommend adding a build variable called\nMYPROJECT_TEST\nunset by default and only build and run tests when it is set. Typically only developers working on the project directly will set it. Same with examples, generating documentation, etc.\nBuilding all of a third-party dependency when you only need a small part of it:\nmbedtls\ncomes to mind as a good citizen here since it exposes many compile-time flags to toggle lots of parts you might not need. Beware of the defaults, and only build what you need!\nWrong dependencies listed for a target leading to rebuilding the world when it does not have to: most build systems have a way to output the dependency graph from their point of view and that can really help diagnose these issues. Nothing feels worse than waiting for minutes or hours for a rebuild, when deep inside, you know it should have only rebuilt a few files.\nExperiment with a faster linker:\nmold\nis one that can be dropped in and really help at no cost. However that really depends on how many libraries are being linked, whether that\'s a bottleneck overall, etc.\nExperiment with a different compiler, if you can: I have seen projects where clang is twice as fast as gcc, and others where there is no difference.\nOnce that\'s done, here are a few things to additionally try, although the gains are typically much smaller or sometimes negative:\nLTO: off/on/thin\nSplit debug information\nMake vs Ninja\nThe type of file system in use, and tweaking its settings\nOnce the iteration cycle feels ok, the code gets to go under the microscope. If the build takes ages, it\'s not realistic to want to modify the code.\nRemove all unnecessary code\nDad, I see dead lines of code.\n(Get the reference? Well, ok then.)\nI have seen 30%, sometimes more, of a codebase, being completely dead code. That\'s lines of code you pay for every time you compile, you want to make a refactoring, etc. So let\'s rip them out.\nHere are some ways to go about it:\nThe compiler has a bunch of\n-Wunused-xxx\nwarnings, e.g.\n-Wunused-function\n. They catch some stuff, but not everything. Every single instance of these warnings should be addressed. Usually it\'s as easy as deleting the code, rebuilding and re-running the tests, done. In rare cases it\'s a symptom of a bug where the wrong function was called. So I\'d be somewhat reluctant to fully automate this step. But if you\'re confident in your test suite, go for it.\nLinters can find unused functions or class fields, e.g.\ncppcheck\n. In my experience there are quite a lot of false positives especially regarding virtual functions in the case of inheritance, but the upside is that these tools absolutely find unused things that the compilers did not notice. So, a good excuse for adding a linter to your arsenal, if not to the CI (more on that later).\nI have seen more exotic techniques were the linker is instructed to put each function in its own section and print every time a section is removed because it\'s detected to be unused at link time, but that results in so much noise e.g. about standard library functions being unused, that I have not found that really practical. Others inspect the generated assembly and compare which functions are present there with the source code, but that does not work for virtual functions. So, maybe worth a shot, depending on your case?\nRemember the list of supported platforms? Yeah, time to put it to use to kill all the code for unsupported platforms. Code trying to support ancient versions of Solaris on a project that exclusively ran on FreeBSD?  Out of the window it goes. Code trying to provide its own random number generator because maybe the platform we run on does not have one (of course it turned out that was never the case)? To the bin. Hundred of lines of code in case POSIX 2001 is not supported, when we only run on modern Linux and macOS? Nuke it. Checking if the host CPU is big-endian and swapping bytes if it is? Ciao (when was the last time you shipped code for a big-endian CPU? And if yes, how are you finding IBM?). That code introduced years ago for a hypothetical feature that never came? Hasta la vista.\nAnd the bonus for doing all of this, is not only that you sped up the build time by a factor of 5 with zero downside, is that, if your boss is a tiny bit technical, they\'ll love seeing PRs deleting thousands of lines of code. And your coworkers as well.\nLinters\nDon\'t go overboard with linter rules, add a few basic ones, incorporate them in the development life cycle, incrementally tweak the rules and fix the issues that pop up, and move on. Don\'t try to enable all the rules, it\'s just a rabbit hole of diminishing returns. I have used\nclang-tidy\nand\ncppcheck\nin the past, they can be helpful, but also incredibly slow and noisy, so be warned. Having no linter is not an option though. The first time you run the linter, it\'ll catch so many real issues that you\'ll wonder why the compiler is not detecting anything even with all the warnings on.\nCode formatting\nWait for the appropriate moment where no branches are active (otherwise people will have horrendous merge conflicts), pick a code style at random, do a one time formatting of the entire codebase (no exceptions), typically with\nclang-format\n, commit the configuration, done. Don\'t waste any bit of saliva arguing about the actual code formatting. It only exists to make diffs smaller and avoid arguments, so do not argue about it!\nSanitizers\nSame as linters, it can be a rabbit hole, unfortunately it\'s absolutely required to spot real, production affecting, hard to detect, bugs and to be able to fix them.\n-fsanitize=address,undefined\nis a good baseline. They usually do not have false positives so if something gets detected, go fix it. Run the tests with it so that issues get detected there as well. I even heard of people running the production code with some sanitizers enabled, so if your performance budget can allow it, it could be a good idea.\nIf the compiler you (have to) use to ship the production code does not support sanitizers, you can at least use clang or such when developing and running tests. That\'s when the work you did on the build system comes in handy, it should be relatively easy to use different compilers.\nOne thing is for sure: even in the best codebase in the world, with the best coding practices and developers, the second you enable the sanitizers, you absolutely will uncover horrifying bugs and memory leaks that went undetected for years. So do it. Be warned that fixing these can require a lot of work and refactorings.\nEach sanitizer also has options so it could be useful to inspect them if your project is a special snowflake.\nOne last thing: ideally, all third-party dependencies should also be compiled with the sanitizers enabled when running tests, to spot\nissues\nin them as well.\nAdd a CI pipeline\nAs Bryan Cantrill once said (quoting from memory), \'I am convinced most firmware just comes out of the home directory of a developer\'s laptop\'. Setting up a CI is quick, free, and automates all the good things we have set up so far (linters, code formatting, tests, etc). And that way we can produce in a pristine environment the production binaries, on every change. If you\'re not doing this already as a developer, I don\'t think you really have entered the 21st century yet.\nCherry on the cake: most CI systems allow for running the steps on a matrix of different platforms! So you can demonstrably check that the list of supported platforms is not just theory, it is real.\nTypically the pipeline just looks like\nmake all test lint fmt\nso it\'s not rocket science. Just make sure that issues that get reported by the tools (linters, sanitizers, etc) actually fail the pipeline, otherwise no one will notice and fix them.\nIncremental code improvements\nWell that\'s known territory so I won\'t say much here. Just that lots of code can often be dramatically simplified.\nI remember iteratively simplifying a complicated class that manually allocated and (sometimes) deallocated memory, was meant to handle generic things, and so on. All the class did, as it turned out, was allocate a pointer, later check whether the pointer was null or not, and...that\'s it. Yeah that\'s a boolean in my book. True/false, nothing more to it.\nI feel that\'s the step that\'s the hardest to timebox because each round of simplification opens new avenues to simplify further. Use your best judgment here and stay on the conservative side. Focus on tangible goals such as security, correctness and performance, and stray away from subjective criteria such as \'clean code\'.\nIn my experience, upgrading the C++ standard in use in the project can at times help with code simplifications, for example to replace code that manually increments iterators by a\nfor (auto x : items)\nloop, but remember it\'s just a means to an end, not an end in itself. If all you need is\nstd::clamp\n, just write it yourself.\nRewrite in a memory safe language?\nI am doing this right now at work, and that deserves an article of its own. Lots of gotchas there as well. Only do this with a compelling reason.\nConclusion\nWell, there you have it. A tangible, step-by-step plan to get out of the finicky situation that\'s a complex legacy C++ codebase. I have just finished going through that at work on a project, and it\'s become much more bearable to work on it now. I have seen coworkers, who previously would not have come within a 10 mile radius of the codebase, now make meaningful contributions. So it feels great.\nThere are important topics that I wanted to mention but in the end did not, such as the absolute necessity of being able to run the code in a debugger locally, fuzzing, dependency scanning for vulnerabilities, etc. Maybe for the next article!\nIf you go through this on a project, and you found this article helpful, shoot me an email! It\'s nice to know that it helped someone.\nAddendum: Dependency management\nThis section is very subjective, it\'s just my strong, biased opinion.\nThere\'s a hotly debated topic that I have so far carefully avoided and that\'s dependency management. So in short, in C++ there\'s none. Most people resort to using the system package manager, it\'s easy to notice because their README looks like this:\nOn Ubuntu 20.04: `sudo apt install [100 lines of packages]`\n\nOn macOS: `brew install [100 lines of packages named slightly differently]`\n\nAny other: well you\'re out of luck buddy. I guess you\'ll have to pick a mainstream OS and reinstall \u{af}\\_(\u{30c4})_/\u{af}\nEtc. I have done it myself. And I think this is a terrible idea. Here\'s why:\nThe installation instructions, as we\'ve seen above, are OS and distribution dependent. Worse, they\'re dependent on the version of the distribution. I remember a project that took months to move from Ubuntu 20.04 to Ubuntu 22.04, because they ship different versions of the packages (if they ship the same packages at all), and so upgrading the distribution also means upgrading the 100 dependencies of your project at the same time. Obviously that\'s a very bad idea. You want to upgrade one dependency at a time, ideally.\nThere\'s always a third-party dependency that has no package and you have to build it from source anyway.\nThe packages are never built with the flags you want. Fedora and Ubuntu have debated for years whether to build packaged with the frame pointer enabled (they finally do since very recently). Remember the section about sanitizers? How are you going to get dependencies with sanitizer enabled? It\'s not going to happen. But there are way more examples: LTO,\n-march\n, debug information, etc. Or they were built with a different C++ compiler version from the one you are using and they broke the C++ ABI between the two.\nYou want to easily see the source of the dependency when auditing, developing, debugging, etc,\nfor the version you are currently using\n.\nYou want to be able to patch a dependency easily if you encounter a bug, and rebuild easily without having to change the build system extensively\nYou never get the exact same version of a package across systems, e.g. when developer Alice is on macOS, Bob on Ubuntu and the production system on FreeBSD. So you have weird discrepancies you cannot reproduce and that\'s annoying.\nCorollary of the point above: You don\'t know exactly which version(s) you are using across systems and it\'s hard to produce a Bill of Material (BOM) in an automated fashion, which is required (or going to be required very soon? Anyway it\'s a good idea to have it) in some fields.\nThe packages sometimes do not have the version of the library you need (static or dynamic)\nSo you\'re thinking, I know, I will use those fancy new package managers for C++, Conan, vcpkg and the like! Well, not so fast:\nThey require external dependencies so your CI becomes more complex and slower (e.g. figuring out which exact version of Python they require, which surely will be different from the version of Python your project requires)\nThey do not have all versions of a package. Example:\nConan and mbedtls\n, it jumps from version\n2.16.12\nto\n2.23.0\n. What happened to the versions in between? Are they flawed and should not be used? Who knows! Security vulnerabilities are not listed anyways for the versions available! Of course I had a project in the past where I had to use version\n2.17\n...\nThey might not support some operating systems or architectures you care about (FreeBSD, ARM, etc)\nI mean, if you have a situation where they work for you, that\'s great, it\'s definitely an improvement over using system packages in my mind. It\'s just that I never encountered (so far) a project where I could make use of them - there was always some blocker.\nSo what do I recommend? Well, the good old git submodules and compiling from source approach. It\'s cumbersome, yes, but also:\nIt\'s dead simple\nIt\'s better than manually vendoring because git has the history and the diff functionalities\nYou know exactly, down to the commit, which version of the dependency is in use\nUpgrading the version of a single dependency is trivial, just run\ngit checkout\nIt works on every platform\nYou get to choose exactly the compilation flags, compiler, etc to build all the dependencies. And you can even tailor it per dependency!\nDevelopers know it already even if they have no C++ experience\nFetching the dependencies is secure and the remote source is in git. No one is changing that sneakily.\nIt works recursively (i.e.: transitively, for the dependencies of your dependencies)\nCompiling each dependency in each submodule can be as simple as\nadd_subdirectory\nwith CMake, or\ngit submodule foreach make\nby hand.\nIf submodules are really not an option, an alternative is to still compile from source but do it by hand, with one script, that fetches each dependency and builds it. Example in the wild: Neovim.\nOf course, if your dependency graph visualized in Graphviz looks like a Rorschach test and has to build thousands of dependencies, it is not easily doable, but it might be still possible, using a build system like Buck2, which does hybrid local-remote builds, and reuses build artifacts between builds from different users.\nIf you look at the landscape of package managers for compiled languages (Go, Rust, etc), all of them that I know of compile from source. It\'s the same approach, minus git, plus the automation.\nAddendum: suggestions from readers\nI\'ve gathered here some great ideas and feedback from readers (sometimes it\'s the almagamation of multiple comments from different people, and I am paraphrasing from memory so sorry if it\'s not completely accurate):\nYou should put more emphasis on tests (expanding the test suite, the code coverage, etc) - but also: a test suite in C++ is only worth anything when running it under sanitizers, otherwise you get lured into a false sense of safety.\n100% agree. Modifying complex foreign code without tests is just not possible in my opinion. And yes, sanitizers will catch so many issues in the tests that you should even consider running your tests suite multiple time in CI with different sanitizers enabled.\nvcpkg is a good dependency manager for C++ that solves all of your woes.\nI\'ve never got the chance to use it so I\'ll add it to my toolbox to experiment with. If it matches the requirements I listed, as well as enabling cross-compilation, then yes it\'s absolutely a win over git submodules.\nNix can serve as a good dependency manager for C++.\nI must admit that I was beaten into submission by Nix\'s complexity and slowness. Maybe in a few years when it has matured?\nYou should not invest so much time in refactoring a legacy codebase if all you are going to do is one bug fix a year.\nSomewhat agree, but it really is a judgement call. In my experience it\'s never one and only one bug fix, whatever management says. And all the good things such as removing dead code, sanitizers etc will be valuable even for the odd bug fix and also lead to noticing more bugs and fixing them. As one replier put it:\nIf you are going to own a codebase, then own it for real.\nIt\'s very risky to remove code, in general you never know for sure if it\'s being used or not, and if someone relies on this exact behavior in the wild.\nThat\'s true, that\'s why I advocate for removing code that is never called using static analysis tools, so that you know\nfor sure\n. But yes, when in doubt, don\'t. My pet peeve here are virtual methods that are very resistant to static analysis (since the whole point is to pick which exact method to call at runtime), these usually cannot be as easily removed. Also, talk to your sales people, your product managers, heck even your users if you can. Most of the time, if you ask them whether a given feature or platform is in use or not, you\'ll get a swift yes or no reply, and you\'ll know how to proceed. We engineers sometimes forget that a 15 minute talk with people can simplify  so much technical work.\nStick all your code in a LLM and start asking it questions\n: As a anti LLM person, I must admit that this idea never crossed my mind. However I think it might be worth a shot, if you can do that in a legally safe way, ideally fully locally, and take everything with a grain a salt. I\'m genuinely curious to see what answers it comes up with!\nThere are tools that analyze the code and produce diagrams, class relationships etc to get an overview of the code\n: I never used these tools but that\'s a good idea and I will definitely try one in the future\nStep 0 should be to add the code in a source control system if that\'s not the case already\n: For sure. I was lucky enough to never encounter that, but heck yeah, even the worst source control system is better than no source control system at all. And I say this after having had to use Visual Source Safe, the one where modifying a file means acquiring an exclusive lock on it, that you then have to release manually.\nSetting up a CI should be step 1\n: Fair point, I can totally see this perspective. I am quicker locally, but fair.\nDon\'t be a code beauty queen, just do the fixes you need\n: Amen.\nIf you can drop a platform that\'s barely used to reduce the combinatorial complexity, and that enables you to do major simplifications, go for it\n: Absolutely. Talk to your sales people and stakeholders and try to convince them. In my case it was ancient FreeBSD versions long out of support, I think we used the security angle to convince everyone to drop them.\nReproducible builds\n: This topic came up and was quite the debate. Honestly I don\'t think achieving a fully reproducible build in a typical C++ codebase is realistic. The compiler and standard library version alone are a problem since they usually are not considered in the build inputs. Achieving a reliable build though is definitely realistic. Docker came up on that topic. Now I have used Docker in anger since 2013 and I don\'t think it brings as much value as people generally think it does. But again - if all you can do is get the code building inside Docker, it\'s better than nothing at all.\nGit can be instructed to ignore one commit e.g. the one formatting the whole codebase so that git blame still works and the history still makes sense\n: Fantastic advice that I did not know before, so thanks! I\'ll definitely try that.\nUse the VCS statistics from the history to identify which parts of the codebase have the most churn and which ones get usually changed together\n: I never tried that, it\'s an interesting idea, but I also see lots of caveats. Probably worth a try?\nThis article applies not only to C++ but also to legacy codebases in other languages\n: Thank you! I have the most experience in C++, so that was my point of view, but I\'m glad to hear that. Just skip the C++-specific bits like sanitizers.\nThe book \'Working effectively with Legacy Code\' has good advice\n: I don\'t think I have ever read it from start to finish, so thanks for the recommendation. I seem to recall I skimmed it and found it very object-oriented specific with lots of OOP design patterns, and that was not helpful to me at the time, but my memory is fuzzy.\nGenerally, touch as little as possible, focus on what adds value (actual value, like, sales dollars).\n: I agree generally (see the point: don\'t be beauty queen), however in a typical big C++ codebase, the moment you start to examine it under the lens of security, you will find lots and lots a security vulnerabilities that need fixing. And that does not translate in a financial gain - it\'s reducing risk. And I find that extremely valuable. Although, some fields are more sensitive than others.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3970719462-get-buy-in",
"#935823156-write-down-the-platforms-you-support",
"#3432615743-get-the-build-working-on-your-machine",
"#2709220288-get-the-tests-passing-on-your-machine",
"#3557174246-write-down-in-the-readme-how-to-build-and-test-the-application",
"#3820736028-find-low-hanging-fruits-to-speed-up-the-build-and-tests",
"#2342264914-remove-all-unnecessary-code",
"#3779016797-linters",
"#1360834800-code-formatting",
"#3829291122-sanitizers",
"#2879635062-add-a-ci-pipeline",
"#3974654374-incremental-code-improvements",
"#1595479803-rewrite-in-a-memory-safe-language",
"#3796851539-conclusion",
"#2445862428-addendum-dependency-management",
"#1737337095-addendum-suggestions-from-readers",
],
title_text_offsets:[
3437,7800,8832,10654,11362,11937,14784,17525,18121,18567,19965,20905,22057,22238,23024,28452,],
},
{
name:"a_small_trick_to_improve_technical_discussions_by_sharing_code.html",
text:"A small trick to improve technical discussions by sharing code\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-03-07\nA small trick to improve technical discussions by sharing code\nLua\nNeovim\nGit\nTable of contents\nAddendum: the full code\nThis is a big title for a small trick that I\'ve been using daily for years now, in every place I\'ve worked at.\nWhenever there is a technical discussion, a bug hunt, or any disagreement about the codebase, I think it really helps to look at existing code to anchor the debate in reality and make it concrete.\nCopy pasting code, taking screenshots, or screen sharing may work at times but I have found a low-tech solution that\'s superior: Sharing a link to a region of code in the codebase. It\'s shorter, easier, and can be used in chats, documentation and PRs.\nIt works for any code, be it existing code on the main branch, or experimental code on a branch:\nEvery web UI of every Version Control System (VCS) worth its salt has that feature, let\'s take Github for example:\nhttps://github.com/gaultier/micro-kotlin/blob/master/class_file.h#L773-L775\nThe hurdle is that every hosting provider has its own URL \'shape\' and it\'s not always documented, so there is a tiny bit of reverse-engineering involved. Compare the previous URL with this one:\nhttps://gitlab.com/philigaultier/jvm-bytecode/-/blob/master/class_file.h?ref_type=heads#L125-127\n. It\'s slightly different.\nSo to make it easy to share a link to code with coworkers, I\'ve written a tiny script to craft the URL for me, inside my editor. I select a few lines, hit a keystroke, and the URL is now in the clipboard for me to paste anywhere.\nSince I use Neovim and Lua, this is what I\'ll cover, but I\'m sure any editor can do that. Now that I think of it, there should be an existing extension for this? Back when I started using this trick I remember searching for one and finding nothing.\nThis article could also serve as a gentle introduction to using Lua in Neovim. The code is also directly mappable to Vimscript, Vim9 script or anything really.\nSo first thing first we need to create a user command to invoke this functionality and later map it to a keystroke:\nvim.api.nvim_create_user_command(\'GitWebUiUrlCopy\', function(arg)\nend,\n{force=true, range=true, nargs=0, desc=\'Copy to clipboard a URL to a git webui for the current line\'})\nforce=true\noverrides any previous definition which is handy when iterating over the implementation\nrange=true\nallows for selecting multiple lines and calling this command on the line range, but it also works when not selecting anything (in normal mode)\nnargs=0\nmeans that no argument is passed to the command\nWe pass a callback to\nnvim_create_user_command\nwhich will be called when we invoke the command. For now it does nothing but we are going to implement it in a second.\narg\nis an object containing for our purposes the start and end line numbers:\nlocal line_start = arg.line1\n  local line_end = arg.line2\nAnd we also need to get the absolute path to the current file:\nlocal file_path_abs = vim.fn.expand(\'%:p\')\nFrom this point on explanations are git specific, but I\'m sure other VCSes have similar features.\nNote that since the current directory might be one or several directories deep relative to the root of the git repository, we need to fix this path, because the git web UI expects a path from the root of the git repository.\nThe easiest way to do so is using\ngit ls-files --full-name\nto convert the absolute path to the path from the root of the repostory.\nThere are many ways in Neovim to call out to a command in a subprocess, here\'s one of them, to get the output of the command:\nlocal file_path_abs = vim.fn.expand(\'%:p\')\n  local file_path_rel_cmd = io.popen(\'git ls-files --full-name &quot;\' .. file_path_abs .. \'&quot;\')\n  local file_path_relative_to_git_root = file_path_rel_cmd:read(\'*a\')\n  file_path_rel_cmd.close()\nWe also need to get the git URL of the remote (assuming there is only one, but it\'s easy to expand the logic to handle multiple):\nlocal cmd_handle = io.popen(\'git remote get-url origin\')\n  local git_origin = cmd_handle:read(\'*a\')\n  cmd_handle.close()\n  git_origin = string.gsub(git_origin, &quot;%s+$&quot;, &quot;&quot;)\nAnd the last bit of information we need is to get the current commit.\nIn the past, I just used the current branch name, however since this is a moving target, it meant that when opening the link, the code might be completely different than what it was when giving out the link. Using a fixed commit is thus better (assuming no one force pushes and messes with the history):\nlocal cmd_handle = io.popen(\'git rev-parse HEAD\')\n  local git_commit = cmd_handle:read(\'*a\')\n  cmd_handle.close()\n  git_commit = string.gsub(git_commit, &quot;%s+$&quot;, &quot;&quot;)\nNow, we can craft the URL by first extracting the interesting parts of the git remote URL and then tacking on at the end all the URL parameters precising the location.\nI assume the git remote URL is a\nssh\nURL here, again it\'s easy to tweak to also handle\nhttps\nURL. Also note that this is the part that\'s hosting provider specific.\nSince I am mainly using Azure DevOps (ADO) and Github at the moment this is what I\'ll show. In ADO, the git remote URL looks like this:\ngit@ssh.&lt;hostname&gt;:v3/&lt;organization&gt;/&lt;directory&gt;/&lt;project&gt;\nAnd the final URL looks like:\nhttps://&lt;hostname&gt;/&lt;organization&gt;/&lt;directory&gt;/_git/&lt;project&gt;?&lt;params&gt;\nIn Github, the git remote URL looks like this:\ngit@github.com:&lt;username&gt;/&lt;project&gt;.git\nAnd the final URL looks like this:\nhttps://github.com/&lt;username&gt;/&lt;project&gt;/blob/&lt;commit_id&gt;/&lt;file_path&gt;?&lt;params&gt;\nWe inspect the git remote url to know in which case we are:\nlocal url = \'\'\n  if string.match(git_origin, \'github\') then\n    -- Handle Github\n  elseif string.match(git_origin, \'azure.com\') then\n    -- End is exclusive in that case hence the `+ 1`.\n    line_end = line_end + 1\n\n    -- Handle ADO\n  else\n    print(\'hosting provider not supported\')\n  end\nWe use a Lua pattern to extract the components from the git remote URL using\nstring.gmatch\n. It weirdly returns an iterator yielding only one result containing our matches, we use a\nfor\nloop to do so (perhaps there is an easier way in Lua?):\nHere\'s for Github:\nfor host, user, project in string.gmatch(git_origin, \'git@([^:]+):([^/]+)/([^/]+)%.git\') do\n      url = \'https://\' .. host .. \'/\' .. user .. \'/\' .. project .. \'/blob/\' .. git_commit .. \'/\' .. file_path_relative_to_git_root .. \'#l\' .. line_start .. \'-l\' .. line_end\n      break\n    end\nAnd here\'s for ADO:\nfor host, org, dir, project in string.gmatch(git_origin, \'git@ssh%.([^:]+):v3/([^/]+)/([^/]+)/([^\\n]+)\') do\n    url = \'https://\' .. host .. \'/\' .. org .. \'/\' .. dir .. \'/_git/\' .. project .. \'?lineStartColumn=1&amp;lineStyle=plain&amp;_a=contents&amp;version=GC\' .. git_commit .. \'&amp;path=\' .. file_path_relative_to_git_root .. \'&amp;line=\' .. line_start .. \'&amp;lineEnd=\' .. line_end\n    break\n  end\nFinally we stick the result in the system clipboard, and we can even open the url in the default browser (I have only tested that logic on Linux but it\nshould\nwork on other OSes):\n-- Copy to clipboard.\n  vim.fn.setreg(\'+\', url)\n\n  -- Open URL in the default browser.\n  local os_name = vim.loop.os_uname().sysname\n  if os_name == \'Linux\' or os_name == \'FreeBSD\' or os_name == \'OpenBSD\' or os_name == \'NetBSD\' then\n    os.execute(\'xdg-open &quot;\' .. url .. \'&quot;\')\n  elseif os_name == \'Darwin\' then\n    os.execute(\'open &quot;\' .. url .. \'&quot;\')\n  elseif os_name == \'Windows\' then\n    os.execute(\'start &quot;\' .. url .. \'&quot;\')\n  else\n    print(\'Unknown os: \' .. os_name)\n  end\nWe can now map the command to our favorite keystroke, for me space + x, for both normal mode (\nn\n) and visual mode (\nv\n):\nvim.keymap.set({\'v\', \'n\'}, \'&lt;leader&gt;x\', \':GitWebUiUrlCopy&lt;CR&gt;\')\nAnd that\'s it, just 60 lines of Lua, and easy to extend to support even more hosting providers.\nAddendum: the full code\nThe full code\nvim.keymap.set({\'v\', \'n\'}, \'&lt;leader&gt;x\', \':GitWebUiUrlCopy&lt;CR&gt;\')\nvim.api.nvim_create_user_command(\'GitWebUiUrlCopy\', function(arg)\n  local file_path_abs = vim.fn.expand(\'%:p\')\n  local file_path_rel_cmd = io.popen(\'git ls-files --full-name &quot;\' .. file_path_abs .. \'&quot;\')\n  local file_path_relative_to_git_root = file_path_rel_cmd:read(\'*a\')\n  file_path_rel_cmd.close()\n\n  local line_start = arg.line1\n  local line_end = arg.line2\n\n  local cmd_handle = io.popen(\'git remote get-url origin\')\n  local git_origin = cmd_handle:read(\'*a\')\n  cmd_handle.close()\n  git_origin = string.gsub(git_origin, &quot;%s+$&quot;, &quot;&quot;)\n\n  local cmd_handle = io.popen(\'git rev-parse HEAD\')\n  local git_commit = cmd_handle:read(\'*a\')\n  cmd_handle.close()\n  git_commit = string.gsub(git_commit, &quot;%s+$&quot;, &quot;&quot;)\n\n  local url = \'\'\n  if string.match(git_origin, \'github\') then\n    for host, user, project in string.gmatch(git_origin, \'git@([^:]+):([^/]+)/([^/]+)%.git\') do\n      url = \'https://\' .. host .. \'/\' .. user .. \'/\' .. project .. \'/blob/\' .. git_commit .. \'/\' .. file_path_relative_to_git_root .. \'#L\' .. line_start .. \'-L\' .. line_end\n      break\n    end\n  elseif string.match(git_origin, \'azure.com\') then\n    -- End is exclusive in that case hence the `+ 1`.\n    line_end = line_end + 1\n\n    for host, org, dir, project in string.gmatch(git_origin, \'git@ssh%.([^:]+):v3/([^/]+)/([^/]+)/([^\\n]+)\') do\n      url = \'https://\' .. host .. \'/\' .. org .. \'/\' .. dir .. \'/_git/\' .. project .. \'?lineStartColumn=1&amp;lineStyle=plain&amp;_a=contents&amp;version=GC\' .. git_commit .. \'&amp;path=\' .. file_path_relative_to_git_root .. \'&amp;line=\' .. line_start .. \'&amp;lineEnd=\' .. line_end\n      break\n    end\n  else\n    print(\'Hosting provider not supported\')\n  end\n\n  -- Copy to clipboard.\n  vim.fn.setreg(\'+\', url)\n\n  -- Open URL in the default browser.\n  local os_name = vim.loop.os_uname().sysname\n  if os_name == \'Linux\' or os_name == \'FreeBSD\' or os_name == \'OpenBSD\' or os_name == \'NetBSD\' then\n    os.execute(\'xdg-open &quot;\' .. url .. \'&quot;\')\n  elseif os_name == \'Darwin\' then\n    os.execute(\'open &quot;\' .. url .. \'&quot;\')\n  elseif os_name == \'Windows\' then\n    os.execute(\'start &quot;\' .. url .. \'&quot;\')\n  else\n    print(\'Unknown os: \' .. os_name)\n  end\nend,\n{force=true, range=true, nargs=0, desc=\'Copy to clipboard a URL to a git webui for the current line\'})\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
8021,],
},
{
name:"how_to_rewrite_a_cpp_codebase_successfully.html",
text:"How to rewrite a C++ codebase successfully\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-05-03\nHow to rewrite a C++ codebase successfully\nC\nC++\nRust\nRewrite\nSafety\nTable of contents\nThe project\nImprove the existing codebase\nGet buy-in\nKeeping buy-in\nPreparations to introduce the new language\nIncremental rewrite\nFuzzing\nPure Rust vs interop (FFI)\nC FFI in Rust is cumbersome and error-prone\nAn example of a real bug at the FFI boundary\nAnother example of a real bug at the FFI boundary\nCross-compilation\nConclusion\nDiscussions:\n/r/programming\n,\n/r/rust\n,\nLobsters\nNot your typical \'Rewrite it in Rust\' article.\nI recently wrote about\ninheriting a legacy C++ codebase\n. At some point, although I cannot pinpoint exactly when, a few things became clear to me:\nNo one in the team but me is able - or feels confident enough - to make a change in this codebase\nThis is a crucial project for the company and will live for years if not decades\nThe code is pretty bad on all the criteria we care about: correctness, maintainability, security, you name it. I don\'t blame the original developers, they were understaffed and it was written as a prototype (the famous case of the prototype which becomes the production code).\nNo hiring of C++ developers is planned or at least in the current budget (also because that\'s the only C++ project we have and we have many other projects to maintain and extend)\nSo it was apparent to me that sticking with C++ was a dead end. It\'s simply a conflict of values and priorities: C++ values many things that are not that important in this project, such as performance above all; and it does not give any guarantees about things that are crucial to us, such as memory and temporal safety (special mention to integer under/overflows. Have fun reviewing every single instance of arithmetic operations to check if it can under/overflow).\nWe bought a race car but what we needed was a family-friendly 5 seater, that\'s our mistake.\nThe only solution would be to train everyone in the team on C++ and dedicate a significant amount of time rewriting the most problematic parts of the codebase to perhaps reach a good enough state, and even then, we\'d have little confidence our code is robust against nation-state attacks.\nIt\'s a judgment call in the end, but that seemed to be more effort than \'simply\' introducing a new language and doing a rewrite.\nI don\'t actually like the term \'rewrite\'. Folks on the internet will eagerly repeat that rewrites are a bad idea, will undoubtedly fail, and are a sign of hubris and naivety. I have experienced such rewrites, from scratch, and yes that does not end well.\nHowever, I claim, because I\'ve done it, and many others before me, that an\nincremental\nrewrite can be successful, and is absolutely worth it. It\'s all about how it is being done, so here\'s how I proceeded and I hope it can be applied in other cases, and people find it useful.\nI think it\'s a good case study because whilst not a big codebase, it is a complex codebase, and it\'s used in production on 10+ different operating systems and architectures, including by external customers. This is not a toy.\nSo join me on this journey, here\'s the guide to rewrite a C++ codebase successfully. And also what not do!\nThe project\nThis project is a library that exposes a C API but the implementation is C++, and it vendors C libraries (e.g. mbedtls) which we build from source. The final artifacts are a\nlibfoo.a\nstatic library and a\nlibfoo.h\nC header. It is used to talk to applets on a\nsmart card\nlike your credit card, ID, passport or driving license (yes, smart cards are nowadays everywhere - you probably carry several on you right now), since they use a\nbizarre\ninteresting communication protocol. The library also implements a home-grown protocol on top of the well-specified smart card protocol, encryption, and business logic.\nIt is meant to be part of an user-facing application running on smartphones and Point of Sales terminals, as well as in servers running in a datacenter or in the cloud.\nThis library is used in:\nAndroid applications, through JNI\nGo back-end services running in Kubernetes, through CGO\niOS applications, through Swift FFI\nC and C++ applications running on very small 32 bits ARM boards similar to the first Raspberry Pi\nAdditionally, developers are using macOS (x64 and arm64) and Linux so the library needs to build and run on these platforms.\nSince external customers also integrate their applications with our library and we do not control these environments, and because some developer machines and servers use glibc and others musl,  we also need to work with either the glibc and the musl C libraries, as well as clang and gcc, and expose a C89-ish API, to maximize compatibility.\nAlright, now that the stage is set, let\'s go through the steps of rewriting this project.\nImprove the existing codebase\nThat\'s basically all the steps in\nInheriting a legacy C++ codebase\n. We need to start the rewrite with a codebase that builds and runs on every platform we support, with tests passing, and a clear README explaining how to setup the project locally. This is a small investment (a few days to a few weeks depending on the scale of the codebase) that will pay massive dividends in the future.\nBut I think the most important point is to trim all the unused code which is typically the majority of the codebase! No one wants to spend time and effort on rewriting completely unused code.\nAdditionally, if you fail to convince your team and the stakeholders to do the rewrite, you at least have improved the codebase you are now stuck with. So it\'s time well spent either way.\nGet buy-in\nSame as in my previous article: Buy-in from teammates and stakeholders is probably the most important thing to get, and maintain.\nIt\'s a big investment in time and thus money we are talking about, it can only work with everyone on board.\nHere I think the way to go is showing the naked truth and staying very factual, in terms managers and non-technical people can understand. This is roughly what I presented:\nThe bus factor for this project is 1 (me)\nTool X shows that there are memory leaks at the rate of Y MiB/hour which means the application using our library will be OOM killed after around Z minutes/hours.\nQuick and dirty fuzzing manages to make the library crash 133 times in 10 seconds\nLinter X detects hundreds of real issues we need to fix\nAll of these points make it really likely a hacker can exploit our library to gain Remote Code Execution (RCE) or steal secrets\nEssentially, it\'s a matter of genuinely presenting the alternative of rewriting being cheaper in terms of time and effort compared to improving the project with pure C++. If your teammates and boss are reality-based, it should be a straightforward decision.\nWe use at my day job basically a RFC process to introduce a major change. That\'s great because it forces the person pushing for a change to document the current issues, the possible solutions, and allowing for a rational discussion to take place in the team. And documenting the whole process in a shared document (that allows comments) is very valuable because when people ask about it months later, you can just share the link to it.\nAfter the problematic situation has been presented, I think at least 3 different solutions should be presented and compared (including sticking with pure C++), and seriously consider each option. I find it important here to be as little emotionally invested as possible even if one option is your favorite, and to be ready to work for possibly months on your least favorite option, if it happens to be chosen by the collective.\nIdeally, if time permits, a small prototype for the preferred solution should be done, to confirm or infirm early that it can work, and to eliminate doubts. It\'s a much more compelling argument to say: &quot;Of course it will work, here is prototype I made, let\'s look at it together!&quot; compared to &quot;I hope it will work, but who knows, oh well I guess we\'ll see 3 months in...&quot;.\nAfter much debate, we settled on Rust as the new programming language being introduced into the codebase. It\'s important to note that I am not a Rust die hard fan. I appreciate the language but it\'s not perfect (see the FFI section later), it has issues, it\'s just that it solves all the issues we have in this project, especially considering the big focus on security (since we deal with payments),  the relative similarity with the company tech stack (Go), and the willingness of the team to learn it and review code in it.\nAfter all, the goal is also to gain additional developers, and stop being the only person who can even touch this code.\nI also seriously considered Go, but after doing a prototype, I was doubtful the many limitations of CGO would allow us to achieve the rewrite. Other teammates also had concerns on how the performance and battery usage would look like on low-end Android and Linux devices, especially 32 bits, having essentially two garbage collectors running concurrently, the JVM one and the Go one.\nKeeping buy-in\nKeeping buy-in after initially getting it is not a given, since software always takes longer than expected and unexpected hurdles happen all the time. Here, showing the progress through regular demos (weekly or biweekly is a good frequency) is great for stakeholders especially non-technical ones. And it can potentially motivate fellow developers to also learn the new language and help you out.\nAdditionally, showing how long-standing issues in the old code get automatically solved by the new code, e.g. memory leaks, or fuzzing crashes in one function, are a great sign for stakeholders of the quality improving and the value of the on-going effort.\nBe prepared to repeat many many times the decision process that led to the rewrite to your boss, your boss\'s boss, the odd product manager who\'s not technical, the salesperson supporting the external customers, etc. It\'s important to nail the elevator\'s pitch.\nThat applies also to teammates, who might be unsure the new programming language \'carries its weight\'. It helps to regularly ask them how they feel about the language, the on-going-effort, the roadmap, etc. Also, pairing with them, so that ideally, everyone in the team feels confident working on this project alone.\nPreparations to introduce the new language\nBefore adding the first line of code in the new language, I created a Git tag\nlast-before-rust\n. The commit right after introduced some code in Rust.\nThis proved invaluable, because when rewriting the legacy code, I found tens of bugs lying around, and I think that\'s very typical. Also, this rewriting effort requires time, during which other team members or external customers may report bugs they just found.\nEvery time such a bug appeared, I switched to this Git tag, and tried to reproduce the bug. Almost every time, the bug was already present before the rewrite. That\'s a very important information (for me, it was a relief!) for solving the bug, and also for stakeholders. That\'s the difference in their eye between: We are improving the product by fixing long existing bugs; or: we are introducing new bugs with our risky changes and we should maybe stop the effort completely because it\'s harming the product.\nFurthermore, I think the first commit introducing the new code should add dummy code and focus on making the build system and CI work seamlessly on every supported platform. This is not appealing work but it\'s necessary. Also, having instructions in the README explaining a bit what each tool does (\ncargo\n,\nrustup\n,\nclippy\n, etc) is very valuable and will ease beginners into contributing in the new language.\nIncremental rewrite\nAlong with stakeholder buy-in, the most important point in the article is that only an\nincremental\nrewrite can succeed, in my opinion. Rewriting from scratch is bound to fail, I think. At least I have never seen it succeed, and have seen it fail many times.\nWhat does it mean, very pragmatically? Well it\'s just a few rules of thumb:\nA small component is picked to be rewritten, the smallest, the better. Ideally it is as small as one function, or one class.\nThe new implementation is written in the same Git (or whatever CVS you use) repository as the existing code, alongside it. It\'s a \'bug for bug\' implementation which means it does the exact same thing as the old implementation, even if the old seems sometimes non-sensical. In some cases, what the old code tries to do is so broken and insecure, that we have to do something different in the new code, but that should be rare.\nTests for the new implementation are written and pass (so that we know the new implementation is likely correct)\nEach site calling the function/class is switched to using the new implementation. After each replacement, the test suite is run and passes (so that we know that nothing broke at the scale of the project; a kind of regression testing). The change is committed. That way is something breaks, we know exactly which change is the culprit.\nA small PR is opened, reviewed and merged. Since our changes are anyways incremental, it\'s up to us to decide that the current diff is of the right size for a PR. We can make the PR as big or small as we want. We can even make a PR with only the new implementation that\'s not yet used at all.\nOnce the old function/class is not used anymore by any code, it can be \'garbage-collected\' i.e. safely removed. This can even be its own PR depending on the size.\nRinse and repeat until all of the old code has been replaced\nThere are of course thornier cases, but that\'s the gist of it. What\'s crucial is that each commit on the main branch builds and runs fine. At not point the codebase is ever broken, does not build, or is in an unknown state.\nIt\'s actually not much different from the way I do a refactor in a codebase with just one programming language.\nWhat\'s very important to avoid are big PRs that are thousands lines long and nobody wants to review them, or long running branches that effectively create a multiverse inside the codebase. It\'s the same as regular software development, really.\nHere are a few additional tips I recommend doing:\nStarting from the leaves of the call graph is much easier than from the root. For example, if\nfoo\ncalls\nbar\nwhich calls\nbaz\n, first rewriting\nbaz\nthen\nbar\nthen\nfoo\nis straightforward, but the reverse is usually not true.\nThus, mapping out at the start from a high-level what are the existing components and which component calls out to which other component is invaluable in that regard, but also for establishing a rough roadmap for the rewrite, and reporting on the progress (&quot;3 components have been rewritten, 2 left to do!&quot;).\nPort the code comments from the old code to the new code if they make sense and add value. In my experience, a few are knowledge gems and should be kept, and most are completely useless noise.\nIf you can use automated tools (search and replace, or tools operating at the AST level) to change every call site to use the new implementation, it\'ll make your reviewers very happy, and save you hours and hours of debugging because of a copy-paste mistake\nSince Rust and C++ can basically only communicate through a C API (I am aware of experimental projects to make them talk directly but we did not use those - we ultimately want 100% Rust code exposing a C API, just like the old C++ did), it means that each Rust function must be accompanied by a corresponding C function signature, so that C++ can call it as a C function. I recommend automating this process with\ncbindgen\n. I have encountered some limitations with it but it\'s very useful, especially to keep the implementation (in Rust) and the API (in C) in sync, or if your teammates are not comfortable with C.\nAutomate when you can, for example I added the\ncbindgen\ncode generation step to CMake so that rebuilding the C++ project would automatically run\ncbindgen\nas well as\ncargo build\nfor the right target in the right mode (debug or release) for the right platforms (\n--target=...\n). DevUX matters!\nWhen rewriting a function/class, port the tests for this function/class to the new implementation to avoid reducing the code coverage each time\nMake the old and the new test suites fast so that the iteration time is short\nWhen a divergence is detected (a difference in output or side effects between the old and the new implementation), observe with tests or within the debugger the output of the old implementation (that\'s where the initial Git tag comes handy, and working with small commits) in detail so that you can correct the new implementation. Some people even develop big test suites verifying that the output of the old and the new implementation are exactly the same.\nSince it\'s a bug-for-bug rewrite,\nwhat\nthe new implementation does may seem weird or unnecessarily convoluted but shall be kept (at least as a first pass). However,\nhow\nit does it in the new code should be up to the best software engineering standards, that means tests, fuzzing, documentation, etc.\nThread lightly, what can tank the project is being too bold when rewriting code and by doing so, introducing bugs or subtly changing the behavior which will cause breakage down the line. It\'s better to be conservative here.\nPick a prefix for all structs and functions in the C API exposed by the Rust code, even if it\'s just\nRUST_xxx\n, so that they are immediately identifiable and greppable. Just like\nlibcurl\nhas the prefix\ncurl_xxx\n.\nFinally, there is one hidden advantage of doing an incremental rewrite. A from-scratch rewrite is all or nothing, if it does not fully complete and replace the old implementation, it\'s useless and wasteful. However, an incremental rewrite is immediately useful, may be paused and continued a number of times, and even if the funding gets cut short and it never fully completes, it\'s still a clear improvement over the starting point.\nFuzzing\nI am a fan a fuzzing, it\'s great. Almost every time I fuzz some code, I find an corner case I did not think about, especially when doing parsing.\nI added fuzzing to the project so that every new Rust function is fuzzed. I initially used\nAFL\nbut then turned to\ncargo-fuzz\n, and I\'ll explain why.\nFuzzing is only useful if code coverage is\nhigh\n. The worst that can happen is to dedicate serious time to setup fuzzing, to only discover at the end that the same few branches are always taken during fuzzing.\nCoverage can only be improved if developers can easily see exactly which branches are being executed during fuzzing. And I could not find an easy way with AFL to get a hold on that data.\nUsing\ncargo-fuzz\nand various LLVM tools, I wrote a small shell script to visualize exactly which branches are taken during fuzzing as well as the code coverage in percents for each file and for the project as a whole (right now it\'s at around 90%).\nTo get to a high coverage, the quality of the corpus data is paramount, since fuzzing works by doing small mutations of this corpus and observing which branches are taken as a result.\nI realized that the existing tests in C++ had lots of useful data in them, e.g.:\nconst std::vector&lt;char&gt; input = {0x32, 0x01, 0x49, ...}; // &lt;= This is the interesting data.\nassert(foo(input) == ...);\nSo I had the idea of extracting all the\ninput = ...\ndata from the tests to build a good fuzzing corpus. My first go at it was a hand-written quick and dirty C++ lexer in Rust. It worked but it was clunky. Right after I finished it, I thought: why don\'t I use\ntree-sitter\nto properly parse C++ in Rust?\nAnd so I did, and it turned out great, just 300 lines of Rust walking through each\nTestXXX.cpp\nfile in the repository and using tree-sitter to extract each pattern. I used the query language of tree-sitter to do so:\nlet query = tree_sitter::Query::new(\n    tree_sitter_cpp::language(),\n    &quot;(initializer_list (number_literal)+) @capture&quot;,\n)\nThe tree-sitter website thankfully has a playground where I could experiment and tweak the query and see the results live.\nAs time went on and more and more C++ tests were migrated to Rust tests, it was very easy to extend this small Rust program that builds the corpus data, to also scan the Rust tests!\nA typical Rust test would look like this:\nconst INPUT: [u8; 4] = [0x01, 0x02, 0x03, 0x04]; // &lt;= This is the interesting data.\nassert_eq!(foo(&amp;INPUT), ...);\nAnd the query to extract the interesting data would be:\nlet query = tree_sitter::Query::new(\n    tree_sitter_rust::language(),\n    // TODO: Maybe make this query more specific with:\n    // `(let_declaration value: (array_expression (integer_literal)+)) @capture`.\n    // But in a few cases, the byte array is defined with `const`, not `let`.\n    &quot;(array_expression (integer_literal)+) @capture&quot;,\n)\nHowever I discovered that not all data was successfully extracted. What about this code:\nconst BAR : u8 = 0x42;\nconst INPUT: [u8; 4] = [BAR, 0x02, 0x03, 0x04]; // &lt;= This is the interesting data.\nassert_eq!(foo(&amp;INPUT), ...);\nWe have a constant\nBAR\nwhich trips up tree-sitter, because it only sees a literal (i.e. 3 letters: \'B\', \'A\' and \'R\') and does not know its value.\nThe way I solved this issue was to do two passes: once to collect all constants along with their values in a map, and then a second pass to find all arrays in tests:\nlet query = tree_sitter::Query::new(\n    tree_sitter_rust::language(),\n    &quot;(const_item value: (integer_literal)) @capture &quot;,\n)\nSo that we can then resolve the literals to their numeric value.\nThat\'s how I implemented a compiler for the Kotlin programming language in the past and it worked great. Maybe there are more advanced approaches but this one is dead-simple and fast so it\'s good enough for us.\nI am pretty happy with how this turned out, scanning all C++ and Rust files to find interesting test data in them to build the corpus. I think this was key to move from the initial 20% code coverage with fuzzing (using a few hard-coded corpus files) to 90%. It\'s fast too.\nAlso, it means the corpus gets better each time we had a test (be it in C++ or Rust), for free.\nDoes it mean that the corpus will grow to an extreme size? Well, worry not, because LLVM comes with a fuzzing corpus minimizer:\n# Minimize the fuzzing corpus (in place).\n$ cargo +nightly fuzz cmin [...]\nFor each file in the corpus, it feeds it as input to our code, observes which branches are taken, and if a new set of branches is taken, this file remains (or perhaps gets minimized even more, not sure how smart this tool is). Otherwise it is deemed a duplicate and is trimmed.\nSo:\nWe generate the corpus with our program\nMinimize it\nRun the fuzzing for however long we wish. It runs in CI for every commit and developers can also run it locally.\nWhen fuzzing is complete, we print the code coverage statistics\nFinally, we still have the option to add manually crafted files to this corpus if we wish. For example after hitting a bug in the wild, and fixing it, we can add a reproducer file to the corpus as a kind of regression test.\nPure Rust vs interop (FFI)\nWriting Rust has been a joy, even for more junior developers in the team. Pure Rust code was pretty much 100% correct on the first try.\nHowever we had to use\nunsafe {}\nblocks in the FFI layer. We segregated all the FFI code to one file, and converted the C FFI structs to Rust idiomatic structs as soon as possible, so that the bulk of the Rust code can be idiomatic and safe.\nBut that means this FFI code is the most likely part of the Rust code to have bugs. To get some confidence in its correctness, we write Rust tests using the C FFI functions (as if we were a C consumer of the library) running under\nMiri\nwhich acts as valgrind essentially, simulating a CPU and checking that our code is memory safe. Tests run perhaps 5 to 10 times as slow as without Miri but this has proven invaluable since it detected many bugs ranging from alignment issues to memory leaks and use-after-free issues.\nWe run tests under Miri in CI to make sure each commit is reasonably safe.\nSo beware: introducing Rust to a C or C++ codebase may actually introduce new memory safety issues, usually all located in the FFI code.\nThankfully that\'s a better situation to be in than to have to inspect all of the codebase when a memory issue is detected.\nC FFI in Rust is cumbersome and error-prone\nThe root cause for all these issues is that the C API that C++ and Rust use to call each other is very limited in its expressiveness w.r.t ownership, as well as many Rust types not being marked\n#[repr(C)]\n, even types you would expect to, such as\nOption\n,\nVec\nor\n&amp;[u8]\n. That means that you have to define your own equivalent types:\n#[repr(C)]\n// An option type that can be used from C\npub struct OptionC&lt;T&gt; {\n    pub has_value: bool,\n    pub value: T,\n}\n\n\n#[repr(C)]\n// Akin to `&amp;[u8]`, for C.\npub struct ByteSliceView {\n    pub ptr: *const u8,\n    pub len: usize,\n}\n\n/// Owning Array i.e. `Vec&lt;T&gt;` in Rust or `std::vector&lt;T&gt;` in C++.\n#[repr(C)]\npub struct OwningArrayC&lt;T&gt; {\n    pub data: *mut T,\n    pub len: usize,\n    pub cap: usize,\n}\n\n/// # Safety\n/// Only call from C.\n#[no_mangle]\npub extern &quot;C&quot; fn make_owning_array_u8(len: usize) -&gt; OwningArrayC&lt;u8&gt; {\n    vec![0; len].into()\n}\nApparently, Rust developers do not want to commit to a particular ABI for these types, to avoid missing out on some future optimizations. So it means that every Rust struct now needs the equivalent &quot;FFI friendly&quot; struct along with conversion functions (usually implemented as\n.into()\nfor convenience):\nstruct Foo&lt;\'a&gt; {\n    x: Option&lt;usize&gt;,\n    y: &amp;\'a [u8],\n    z: Vec&lt;u8&gt;,\n}\n\n\n#[repr(C)]\nstruct FooC {\n    x: OptionC&lt;usize&gt;,\n    y: ByteSliceView,\n    z: OwningArrayC&lt;u8&gt;,\n}\nWhich is cumbersome but still fine, especially since Rust has powerful macros (which I investigated using but did not eventually). However, since Rust also does not have great idiomatic support for custom allocators, we stuck with the standard memory allocator, which meant that each struct with heap-allocated fields has to have a deallocation function:\n#[no_mangle]\npub extern &quot;C&quot; fn foo_free(foo: &amp;FooC) {\n    ...\n}\nAnd the C or C++ calling code would have to do:\nFooC foo{};\nif (foo_parse(&amp;foo, bytes) == SUCCESS) {\n    // do something with foo...\n    ...\n\n    foo_free(foo);\n}\nTo simplify this, I introduced a\ndefer\nconstruct\nto C++ (thanks Gingerbill!):\nFooC foo{};\ndefer({foo_free(foo);});\n\nif (foo_parse(&amp;foo, bytes) == SUCCESS) {\n    // do something with foo...\n    ...\n}\nWhich feels right at home for Go developers, and is an improvement over the style in use in the old C++ code where it was fully manual calls to new/delete.\nStill, it\'s more work than what you\'d have to do in pure idiomatic Rust or C++ code (or even C code with arenas for that matter).\nIn Zig or Odin, I would probably have used arenas to avoid that, or a general allocator with\ndefer\n.\nAn example of a real bug at the FFI boundary\nMore perniciously, it\'s easy to introduce memory unsafety at the FFI boundary. Here is a real bug I introduced, can you spot it? I elided all the error handling to make it easier to spot:\n#[repr(C)]\nstruct BarC {\n    x: ByteSliceView,\n}\n\n#[no_mangle]\nunsafe extern &quot;C&quot; fn bar_parse(input: *const u8, input_len: usize, bar_c: &amp;mut BarC) {\n    let input: &amp;[u8] = unsafe { std::slice::from_raw_parts(input, input_len) };\n\n    let bar: Bar = Bar {\n        x: [input[0], input[1]],\n    };\n\n    *bar_c = BarC {\n        x: ByteSliceView {\n            ptr: bar.x.as_ptr(),\n            len: bar.x.len(),\n        },\n    };\n}\nclippy\ndid not notice anything.\naddress-sanitizer\ndid not notice anything. However, both\nmiri\nand\nvalgrind\ndid, and fuzzing crashed (which was not easy to troubleshoot but at least pinpointed to a problem).\nSo...found it? Still nothing? Well, let\'s be good developers and add a test for it:\n#[test]\nfn bar() {\n    // This mimicks how C/C++ code would call our function.\n    let mut bar_c = MaybeUninit::&lt;BarC&gt;::uninit();\n    let input = [0, 1, 2];\n    unsafe {\n        bar_parse(\n            input.as_ptr(),\n            input.len(),\n            bar_c.as_mut_ptr().as_mut().unwrap(),\n        );\n    }\n\n    let bar_c = unsafe { bar_c.assume_init_ref() };\n    let x: &amp;[u8] = (&amp;bar_c.x).into();\n    assert_eq!(x, [0, 1].as_slice());\n}\nIf you\'re lucky,\ncargo test\nwould fail at the last assertion saying that the value is not what we expected, but in my case it passed every time, and so the bug stayed undetected for a while. That\'s because we unknowingly introduced undefined behavior, and as such, how or if it manifests is impossible to tell.\nLet\'s run the test with Miri:\nrunning 1 test\ntest api::tests::bar ... error: Undefined Behavior: out-of-bounds pointer use: alloc195648 has been freed, so this pointer is dangling\n    --&gt; src/tlv.rs:321:18\n     |\n321  |         unsafe { &amp;*core::ptr::slice_from_raw_parts(item.ptr, item.len) }\n     |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ out-of-bounds pointer use: alloc195648 has been freed, so this pointer is dangling\n     |\n     = help: this indicates a bug in the program: it performed an invalid operation, and caused Undefined Behavior\n     = help: see https://doc.rust-lang.org/nightly/reference/behavior-considered-undefined.html for further information\nhelp: alloc195648 was allocated here:\n    --&gt; src/api.rs:1396:9\n     |\n1396 |     let bar: Bar = Bar {\n     |         ^^^\nhelp: alloc195648 was deallocated here:\n    --&gt; src/api.rs:1406:1\n     |\n1406 | }\nMiri is great, I tell you.\nThe issue here is that we essentially return a pointer to local variable (\nx\n) from inside the function, so the pointer is dangling.\nAlternatively we can call our function from C/C++ and run that under valgrind:\nint main() {\n  BarC bar{};\n  const uint8_t input[] = {0, 1, 2, 3};\n  bar_parse(input, sizeof(input), &amp;bar);\n  assert(bar.x.ptr[0] == 0);\n  assert(bar.x.ptr[1] == 1);\n}\nAnd I get:\n==805913== Conditional jump or move depends on uninitialised value(s)\n==805913==    at 0x127C34: main (src/example.cpp:13)\n==805913== \n==805913== Conditional jump or move depends on uninitialised value(s)\n==805913==    at 0x127C69: main (src/example.cpp:14)\nWhich is not very informative, but better than nothing.\nMiri\n\'s output is much more actionable.\nSo in conclusion, Rust\'s FFI capabilities work but are tedious are error-prone in my opinion, and so require extra care and testing with Miri/fuzzing, with high code coverage of the FFI functions. It\'s not enough to only test the pure (non FFI) Rust code.\nAnother example of a real bug at the FFI boundary\nWhen I started this rewrite, I was under the impression that the Rust standard library uses the C memory allocator (basically,\nmalloc\n) under the covers when it needs to allocate some memory.\nHowever, I quickly discovered that it is not (anymore?) the case, Rust uses its own allocator - at least on Linux where there is no C library shipping with the kernel.\nMiri again is the MVP here since it detected the issue of mixing the C and Rust allocations which prompted this section.\nAs Bryan Cantrill once said: &quot;glibc on Linux, it\'s just, like, your opinion dude&quot;. Meaning, glibc is just one option, among many, since Linux is just the kernel and does not ship with a libC. So the Rust standard library cannot expect a given C library on every Linux system, like it would be on macOS or the BSDs or Illumos. All of that to say: Rust implements its own memory allocator.\nThe consequence of this, is that allocating memory on the C/C++ side, and freeing it on the Rust side, is undefined behavior: it amounts to freeing a pointer that was never allocated by this allocator. And vice-versa, allocating a pointer from Rust and freeing it from C.\nThat has dire consequences since most memory allocators do not detect this in release mode. You might free completely unrelated memory leading to use-after-free later, or corrupt the memory allocator structures. It\'s bad.\nHere\'s a simplified example of code that triggered this issue:\n#[repr(C)]\npub struct FooC {\n    foo: u8,\n    bar: *mut usize,\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn parse_foo(in_bytes: *const u8, in_bytes_len: usize, foo: &amp;mut FooC) {\n    let in_bytes: &amp;[u8] = unsafe { &amp;*core::ptr::slice_from_raw_parts(in_bytes, in_bytes_len) };\n\n    // Parse `foo` from `in_bytes` but `bar` is sometimes not present in the payload.\n    // In that case it is set manually by the calling code.\n    *foo = FooC {\n        foo: in_bytes[0],\n        bar: if in_bytes_len == 1 {\n            core::ptr::null_mut()\n        } else {\n            let x = Box::new(in_bytes[1] as usize);\n            Box::into_raw(x)\n        },\n    }\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn free_foo(foo: &amp;mut FooC) {\n    if !foo.bar.is_null() {\n        unsafe {\n            let _ = Box::from_raw(foo.bar);\n        }\n    }\n}\nAnd the calling code:\nFooC foo{};\n\nconst uint8_t data[] = { 1 };\nparse_foo(data, sizeof(data), &amp;foo);\nif (foo.bar == nullptr) {\n  foo.bar = new size_t{99999};\n}\n\nfree_foo(&amp;foo);\nThis is undefined behavior if the array is of size 1, since in that case the Rust allocator will free a pointer allocated by the C allocator, and address sanitizer catches it:\nSUMMARY: AddressSanitizer: alloc-dealloc-mismatch /home/runner/work/llvm-project/llvm-project/final/llvm-project/compiler-rt/lib/asan/asan_malloc_linux.cpp:52:3 in free\nHowever, it is only detected with sanitizers on and if a test (or fuzzing) triggers this case. Or by Miri if a Rust test covers this function.\nSo I recommend sticking to one \'side\', be it C/C++ or Rust, of the FFI boundary, to allocate and free all the memory used in FFI structures. Rust has an edge here since the long-term goal is to have 100% of Rust so it will have to allocate all the memory anyway in the end.\nDepending on the existing code style, it might be hard to ensure that the C/C++ allocator is not used at all for structures used in FFI, due to abstractions and hidden memory allocations.\nOne possible solution (which I did not implement but considered) is making FFI structures a simple opaque pointer (or \'handle\') so that the caller has to use FFI functions to allocate and free this structure. That also means implementing getter/setters for certain fields since the structures are now opaque. It maximizes the ABI compatibility, since the caller cannot rely on a given struct size, alignment, or fields.\nHowever that entails more work and more functions in the API.\nlibcurl\nis an example of such an approach,\nlibuv\nis an example of a library which did not do this initially, but plans to move to this approach in future versions, which would be a breaking change for clients.\nSo to summarize, Miri is so essential that I don\'t know whether it\'s viable to write Rust code with lots of FFI (and thus lots of unsafe blocks) without it. If Miri did not exist, I would seriously consider using only arenas or reconsider the use of Rust.\nCross-compilation\nRust has great cross-compilation support; C++ not so much. Nonetheless I managed to coerced CMake into cross-compiling to every platform we support from my Linux laptop. After using Docker for more than 10 years I am firmly against using Docker for that, it\'s just clunky and slow and not a good fit. Also we already have to cross-compile to the mobile platforms anyway so why not make that work for all platforms?\nThat way, I can even cross-compile tests and example programs in C or C++ using the library and run them inside\nqemu\nto make sure all platforms work as expected.\nI took inspiration from the CMake code in the Android project, which has to cross-compile for many architectures. Did you know that Android supports x86 (which is 32 bits), x86_64, arm (which is 32 bits), aarch64 (sometimes called arm64), and more?\nIn short, you instruct CMake to cross-compile by supplying on the command-line the variables\nCMAKE_SYSTEM_PROCESSOR\nand\nCMAKE_SYSTEM_NAME\n, which are the equivalent of\nGOARCH\nand\nGOOS\nif you are familiar with Go. E.g.:\n$ cmake -B .build -S src -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_SYSTEM_NAME=Linux -DCMAKE_SYSTEM_PROCESSOR=arm\nOn the Rust side, you tell\ncargo\nto cross-compile by supplying the\n--target\ncommand-line argument, e.g.:\n--target=x86_64-unknown-linux-musl\n. This works by virtue of installing the pre-compiled toolchain for this platform with\nrustup\nfirst:\n$ rustup target add x86_64-unknown-linux-musl\nSo now we have to convert in CMake\nCMAKE_SYSTEM_ARCHITECTURE\nand\nCMAKE_SYSTEM_NAME\ninto a target triple that clang and cargo can understand. Of course you have to do all the hard work yourself. This is complicated by lots of factors like Apple using the architecture name\narm64\ninstead of\naarch64\n, iOS peculiarities, soft vs hard float, arm having multiple variants (v6, v7, v8, etc), and so on. Your mileage may vary. We opt-in into using musl with a CMake command line option, on Linux.\nHere it is in all its glory:\n# We need to craft the target triple to make it work when cross-compiling.\n# NOTE: If an architecture supports both soft-float and hard-float, we pick hard-float (`hf`).\n# since we do not target any real hardware with soft-float.\n# Linux has two main libcs, glibc (the default) and musl (opt-in with `FMW_LIBC_MUSL=1`), useful for Alpine.\nif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;x86_64&quot; AND NOT DEFINED FMW_LIBC_MUSL)\n    set(TARGET_TRIPLE &quot;x86_64-unknown-linux-gnu&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;x86_64&quot; AND &quot;${FMW_LIBC_MUSL}&quot; EQUAL 1)\n    set(TARGET_TRIPLE &quot;x86_64-unknown-linux-musl&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;arm&quot; AND NOT DEFINED FMW_LIBC_MUSL)\n    set(TARGET_TRIPLE &quot;arm-unknown-linux-gnueabihf&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;arm&quot; AND &quot;${FMW_LIBC_MUSL}&quot; EQUAL 1)\n    set(TARGET_TRIPLE &quot;arm-unknown-linux-musleabihf&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;aarch64&quot; AND NOT DEFINED FMW_LIBC_MUSL)\n    set(TARGET_TRIPLE &quot;aarch64-unknown-linux-gnu&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;aarch64&quot; AND &quot;${FMW_LIBC_MUSL}&quot; EQUAL 1)\n    set(TARGET_TRIPLE &quot;aarch64-unknown-linux-musl&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Linux&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;armv7&quot;)\n    set(TARGET_TRIPLE &quot;armv7-unknown-linux-gnueabihf&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Darwin&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;aarch64&quot;)\n    set(TARGET_TRIPLE &quot;aarch64-apple-darwin&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Darwin&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;arm64&quot;)\n    set(TARGET_TRIPLE &quot;aarch64-apple-darwin&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Darwin&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;x86_64&quot;)\n    set(TARGET_TRIPLE &quot;x86_64-apple-darwin&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;iOS&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;x86_64&quot;)\n    set(TARGET_TRIPLE &quot;x86_64-apple-ios&quot;)\n    execute_process(COMMAND xcrun --sdk iphonesimulator --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT)\n    string(REPLACE &quot;\\n&quot; &quot;&quot; CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT})\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;iOS&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;aarch64&quot;)\n    set(TARGET_TRIPLE &quot;aarch64-apple-ios&quot;)\n    execute_process(COMMAND xcrun --sdk iphoneos --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT)\n    string(REPLACE &quot;\\n&quot; &quot;&quot; CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT})\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;iOS&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;arm64&quot;)\n    set(TARGET_TRIPLE &quot;aarch64-apple-ios&quot;)\n    execute_process(COMMAND xcrun --sdk iphoneos --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT)\n    string(REPLACE &quot;\\n&quot; &quot;&quot; CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT})\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;arm&quot;)\n    set(TARGET_TRIPLE &quot;arm-linux-androideabi&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;armv7&quot;)\n    set(TARGET_TRIPLE &quot;armv7-linux-androideabi&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;armv7-a&quot;)\n    set(TARGET_TRIPLE &quot;armv7-linux-androideabi&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;aarch64&quot;)\n    set(TARGET_TRIPLE &quot;aarch64-linux-android&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;i686&quot;)\n    set(TARGET_TRIPLE &quot;i686-linux-android&quot;)\nelseif (CMAKE_SYSTEM_NAME STREQUAL &quot;Android&quot; AND CMAKE_SYSTEM_PROCESSOR STREQUAL &quot;x86_64&quot;)\n    set(TARGET_TRIPLE &quot;x86_64-linux-android&quot;)\nelse()\n    message(FATAL_ERROR &quot;Invalid OS/Architecture, not supported: CMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME} CMAKE_SYSTEM_PROCESSOR=${CMAKE_SYSTEM_PROCESSOR}&quot;)\nendif()\n\nmessage(STATUS &quot;Target triple: ${TARGET_TRIPLE}&quot;)\n\n# If we are cross compiling manually (e.g to Linux arm), `CMAKE_C_COMPILER_TARGET` and `CMAKE_CXX_COMPILER_TARGET` are unset and we need to set them manually.\n# But if we are cross compiling through a separate build system e.g. to Android or iOS, they will set these variables and we should not override them.\nif ( NOT DEFINED CMAKE_C_COMPILER_TARGET )\n   set(CMAKE_C_COMPILER_TARGET ${TARGET_TRIPLE})\nendif()\nif ( NOT DEFINED CMAKE_CXX_COMPILER_TARGET )\n   set(CMAKE_CXX_COMPILER_TARGET ${TARGET_TRIPLE})\nendif()\nThere was a lot of trial and error as you can guess.\nAlso, gcc is not directly supported for cross-compilation in this approach because gcc does not support a\n--target\noption like clang does, since it\'s not a cross-compiler. You have to download the variant you need e.g.\ngcc-9-i686-linux-gnu\nto compile for x86, and set\nCMAKE_C_COMPILER\nand\nCMAKE_CXX_COMPILER\nto\ngcc-9-i686-linux-gnu\n. However, in that case you are not setting\nCMAKE_SYSTEM_NAME\nand\nCMAKE_SYSTEM_PROCESSOR\nsince it\'s in theory not cross-compiling, so\ncargo\nwill not have its\n--target\noption filled, so it won\'t work for the Rust code. I advise sticking with clang in this setup. Still, when not cross-compiling, gcc works fine.\nFinally, I wrote a Lua script to cross-compile for every platform we support to make sure I did not break anything. I resorted to using the Zig toolchain (not the language) to be able to statically link with musl or cross-compile from Linux to iOS which I could not achieve with pure clang. However this is only my local setup, we do not use the Zig toolchain when building the production artifacts (e.g. the iOS build is done in a macOS virtual machine, not from a Linux machine).\nThis is very useful also if you have several compile-time feature flags and want to build in different configurations for all platforms, e.g. enable/disable logs at compile time:\nlocal android_sdk = arg[1]\nif android_sdk == nil or android_sdk == &quot;&quot; then\n  print(&quot;Missing Android SDK as argv[1] e.g. \'~/Android/Sdk/ndk/21.4.7075529\'.&quot;)\n  os.exit(1)\nend\n\nlocal build_root = arg[2]\nif build_root == nil then\n  build_root = &quot;/tmp/&quot;\nend\n\nlocal rustup_targets = {\n  &quot;aarch64-apple-darwin&quot;,\n  &quot;aarch64-linux-android&quot;,\n  &quot;aarch64-unknown-linux-gnu&quot;,\n  &quot;aarch64-unknown-linux-musl&quot;,\n  &quot;arm-linux-androideabi&quot;,\n  &quot;arm-unknown-linux-gnueabihf&quot;,\n  &quot;arm-unknown-linux-musleabihf&quot;,\n  &quot;armv7-linux-androideabi&quot;,\n  &quot;armv7-unknown-linux-gnueabi&quot;,\n  &quot;armv7-unknown-linux-gnueabihf&quot;,\n  &quot;armv7-unknown-linux-musleabi&quot;,\n  &quot;armv7-unknown-linux-musleabihf&quot;,\n  &quot;i686-linux-android&quot;,\n  &quot;x86_64-apple-darwin&quot;,\n  &quot;x86_64-linux-android&quot;,\n  &quot;x86_64-unknown-linux-gnu&quot;,\n  &quot;x86_64-unknown-linux-musl&quot;,\n}\n\nfor i = 1,#rustup_targets do\n  local target = rustup_targets[i]\n  os.execute(&quot;rustup target install &quot; .. target)\nend\n\n\nlocal targets = {\n  {os=&quot;Linux&quot;, arch=&quot;x86_64&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;aarch64&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;arm&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;armv7&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;arm&quot;, cc=&quot;zig&quot;, cxx=&quot;zig&quot;, cmakeArgs=&quot;-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=arm-linux-musleabihf -DCMAKE_CXX_COMPILER_TARGET=arm-linux-musleabihf&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;aarch64&quot;, cc=&quot;zig&quot;, cxx=&quot;zig&quot;, cmakeArgs=&quot;-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=aarch64-linux-musl -DCMAKE_CXX_COMPILER_TARGET=aarch64-linux-musl&quot;},\n  {os=&quot;Linux&quot;, arch=&quot;x86_64&quot;, cc=&quot;zig&quot;, cxx=&quot;zig&quot;, cmakeArgs=&quot;-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=x86_64-linux-musl -DCMAKE_CXX_COMPILER_TARGET=x86_64-linux-musl&quot;},\n  {os=&quot;Darwin&quot;, arch=&quot;x86_64&quot;, cc=&quot;zig&quot;, cxx=&quot;zig&quot;, cmakeArgs=&quot;-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=x86_64-macos-none -DCMAKE_CXX_COMPILER_TARGET=x86_64-macos-none&quot;},\n  {os=&quot;Darwin&quot;, arch=&quot;arm64&quot;, cc=&quot;zig&quot;, cxx=&quot;zig&quot;, cmakeArgs=&quot;-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=aarch64-macos-none -DCMAKE_CXX_COMPILER_TARGET=aarch64-macos-none&quot;},\n  {os=&quot;Android&quot;, arch=&quot;armv7-a&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;-DCMAKE_ANDROID_NDK=\'&quot; .. android_sdk .. &quot;\'&quot;},\n  {os=&quot;Android&quot;, arch=&quot;aarch64&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;-DCMAKE_ANDROID_NDK=\'&quot; .. android_sdk .. &quot;\'&quot;},\n  {os=&quot;Android&quot;, arch=&quot;i686&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;-DCMAKE_ANDROID_NDK=\'&quot; .. android_sdk .. &quot;\'&quot;},\n  {os=&quot;Android&quot;, arch=&quot;x86_64&quot;, cc=&quot;clang&quot;, cxx=&quot;clang++&quot;, cmakeArgs=&quot;-DCMAKE_ANDROID_NDK=\'&quot; .. android_sdk .. &quot;\'&quot;},\n}\n\nfor i = 1,#targets do\n  local target = targets[i]\n  local build_dir = &quot;.build-&quot; .. target.os .. &quot;-&quot; .. target.arch .. &quot;-&quot; .. target.cc .. &quot;-&quot; .. target.cxx .. &quot;-&quot; .. target.cmakeArgs\n  build_dir = string.gsub(build_dir, &quot;%s+&quot;, &quot;_&quot;)\n  build_dir = string.gsub(build_dir, &quot;^./+&quot;, &quot;_&quot;)\n  build_dir = build_root .. &quot;/&quot; .. build_dir\n  print(build_dir)\n\n  local cmd_handle = io.popen(&quot;command -v llvm-ar&quot;)\n  local llvm_ar = cmd_handle:read(\'*a\')\n  cmd_handle:close()\n  llvm_ar = string.gsub(llvm_ar, &quot;%s+$&quot;, &quot;&quot;)\n\n  local cmd_handle = io.popen(&quot;command -v llvm-ranlib&quot;)\n  local llvm_ranlib = cmd_handle:read(\'*a\')\n  cmd_handle:close()\n  llvm_ranlib = string.gsub(llvm_ranlib, &quot;%s+$&quot;, &quot;&quot;)\n\n  local build_cmd = &quot;cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -B \'&quot; .. build_dir .. &quot;\' -DCMAKE_AR=&quot; .. llvm_ar .. &quot; -DCMAKE_RANLIB=&quot; .. llvm_ranlib .. &quot; -DCMAKE_SYSTEM_NAME=&quot; .. target.os .. &quot; -DCMAKE_SYSTEM_PROCESSOR=&quot; .. target.arch .. &quot; -DCMAKE_C_COMPILER=&quot; .. target.cc .. &quot; -DCMAKE_CXX_COMPILER=&quot; .. target.cxx .. &quot; &quot; ..  target.cmakeArgs .. &quot; -S src/. -G Ninja&quot;\n  print(build_cmd)\n  os.execute(build_cmd)\n\n  -- Work-around for getting rid of mbedtls linker flags specific to Apple\'s LLVM fork that are actually not needed.\n  if target.os == &quot;Darwin&quot; then\n    os.execute(&quot;sed -i \'&quot; .. build_dir .. &quot;/CMakeFiles/rules.ninja\' -e \'s/ -no_warning_for_no_symbols -c//g\'&quot;)\n  end\n\n  os.execute(&quot;ninja -C \'&quot; .. build_dir .. &quot;\'&quot;)\nend\nI look forward to only having Rust code and deleting all of this convoluted stuff.\nThat\'s something that people do not mention often when saying that modern C++ is good enough and secure enough. Well, first I disagree with this statement, but more broadly, the C++ toolchain to cross-compile sucks. You only have clang that can cross-compile in theory but in practice you have to resort to the Zig toolchain to automate cross-compiling the standard library etc.\nAlso, developers not deeply familiar with either C or C++ do not want to touch all this CMake/Autotools with a ten-foot pole. And I understand them. Stockholm syndrome notwithstanding, these are pretty slow, convoluted, niche programming languages and no one wants to actively learn and use them unless they have to.\nOnce you are used to simply typing\ngo build\nor\ncargo build\n, you really start to ask yourself if those weird things are worth anyone\'s time.\nConclusion\nThe rewrite is not yet fully done, but we have already more Rust code than C++ code, and it\'s moving along nicely, at our own pace (it\'s not by far the only project we have on our lap). Once all C++ code is removed, we will do a final pass to remove the CMake stuff and build directly via\ncargo\n. We\'ll see if that works when integrating with other build systems e.g. Bazel for Android or Xcode for iOS.\nDevelopers who learned Rust are overall very happy with it and did not have too many fights with the borrow checker, with one notable exception of trying to migrate a C struct that used an intrusive linked list (ah, the dreaded linked list v. borrow checker!). My suggestion was to simply use a\nVec\nin Rust since the linked list was not really justified here, and the problem was solved.\nAdding unit tests was trivial in Rust compared to C++ and as a result people would write a lot more of them. Built-in support for tests is expected in 2024 by developers. I don\'t think one single C++ test was written during this rewrite, now that I think of it.\nEveryone was really satisfied with the tooling, even though having to first do\nrustup target add ...\nbefore cross-compiling tripped up a few people, since in Go that\'s done automatically behind the scenes (I think one difference is that Go compiles everything from source and so does not need to download pre-compiled blobs?).\nEveryone also had an easy time with their text editor/IDE, Rust is ubiquitous enough now that every editor will have support for it.\nAll the tooling we needed to scan dependencies for vulnerabilities, linting, etc was present and polished. Shootout to\nosv-scanner\nfrom Google, which allowed us to scan both the Rust and C++ dependencies in the same project (and it evens supports Go).\nAs expected, developers migrating C++ code to Rust code had a breeze with the Rust code and almost every time asked for assistance when dealing with the C++ code. C++ is just too complex a language for most developers, especially compared to its alternatives.\nCMake/Make/Ninja proved surprisingly difficult for developers not accustomed to them, but I mentioned that already. I think half of my time during this rewrite was actually spent coercing all the various build systems (Bazel/Xcode/CMake/cargo/Go) on the various platforms into working well together. If there is no one in the team who\'s really familiar with build systems, I think this is going to be a real challenge.\nSo, I hope this article alleviated your concerns about rewriting your C++ codebase. It can absolutely be done, just pick the right programming language for you and your context, do it incrementally, don\'t overpromise, establish a rough roadmap with milestones, regularly show progress to stakeholders (even if it\'s just you, it helps staying motivated!), and make sure the team is on-board and enjoying the process.\nYou know, like any other software project, really!\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#878217442-the-project",
"#802215620-improve-the-existing-codebase",
"#3970719462-get-buy-in",
"#1704982617-keeping-buy-in",
"#2968870471-preparations-to-introduce-the-new-language",
"#3959077628-incremental-rewrite",
"#1275343589-fuzzing",
"#2929078078-pure-rust-vs-interop-ffi",
"#988259740-c-ffi-in-rust-is-cumbersome-and-error-prone",
"#3680487399-an-example-of-a-real-bug-at-the-ffi-boundary",
"#4044715241-another-example-of-a-real-bug-at-the-ffi-boundary",
"#1168506370-cross-compilation",
"#3796851539-conclusion",
],
title_text_offsets:[
3286,4880,5680,9117,10364,11739,17988,23127,24386,27078,30757,35170,49953,],
},
{
name:"write_a_video_game_from_scratch_like_1987.html",
text:"Let&#39;s write a video game from scratch like it&#39;s 1987\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-06-20\nLet\'s write a video game from scratch like it\'s 1987\nC\nX11\nVideo game\nOdin\nOptimization\nTable of contents\nWhat we\'re making\nAuthentication\nOpening a window\nLoading assets\nThe game entities\nReacting to keyboard and mouse events\nGame logic: uncover a cell\nConclusion\nAddendum: the full code\nDiscussions:\nHacker News\n,\n/r/programming\nIn a\nprevious article\nI\'ve done the \'Hello, world!\' of GUIs in assembly: A black window with a white text, using X11 without any libraries, just talking directly over a socket.\nIn a\nlater article\nI\'ve done the same with Wayland in C, displaying a static image.\nI showed that this is not complex and results in a very lean and small application.\nRecently, I stumbled upon this\nHacker News post\n:\nMicrosoft\'s official Minesweeper app has ads, pay-to-win, and is hundreds of MBs\nAnd I thought it would be fun to make with the same principles a full-fledged GUI application: the cult video game Minesweeper.\nWill it be hundred of megabytes when we finish? How much work is it really? Can a hobbyist make this in a few hours?\n        Your browser doesn\'t support this video. Here is a\nlink to the video\ninstead.\nScreencast\nPress enter to reset and press any mouse button to uncover the cell under the mouse cursor.\nHere is a\nYoutube link\nin case the video does not play (I tried lots of things so that it plays on iOS to no avail).\nThe result is a ~300 KiB statically linked executable, that requires no libraries, and uses a constant ~1 MiB of resident heap memory (allocated at the start, to hold the assets). That\'s roughly a thousand times smaller in size than Microsoft\'s. And it only is a few hundred lines of code.\nThe advantage of this approach is that the application is tiny and stand-alone: statically linked with the few bits of libC it uses (and that\'s it), it can be trivially compiled on every Unix, and copied around, and it will work on every machine (with the same OS/architecture that is). Even on ancient Linuxes from 20 years ago.\nI remember playing this game as a kid (must have been on Windows 98). It was a lot of fun! I don\'t exactly remember the rules though so it\'s a best approximation.\nIf you spot an error, please open a\nGithub issue\n! And the source code repository for the game is\nhere\n.\nWhat we\'re making\nThe 11th version of the X protocol was born in 1987 and has not changed since. Since it predates GPUs by a decade or so, its model does not really fit the hardware of today. Still, it\'s everywhere. Any Unix has a X server, even macOS with XQuartz, and now Windows supports running GUI Linux applications inside WSL! X11 has never been so ubiquitous. The protocol is relatively simple and the entry bar is low: we only need to create a socket and we\'re off the races. And for 2D applications, there\'s no need to be a Vulkan wizard or even interact with the GPU. Hell, it will work even without any GPU!\nEveryone writing GUIs these days use a giant pile of libraries, starting with the\noverly complicated\nvenerable\nlibX11\nand\nlibxcb\nlibraries, to Qt and SDL.\nHere are the steps we need to take:\nOpen a window\nUpload image data (the one sprite with all the assets)\nDraw parts of the sprite to the window\nReact to keyboard/mouse events\nAnd that\'s it. Spoiler alert: every step is 1-3 X11 messages that we need to craft and send. The only messages that we receive are the keyboard and mouse events. It\'s really not much at all!\nWe will implement this in the\nOdin programming language\nwhich I really enjoy. But if you want to follow along with C or anything really, go for it. All we need is to be able to open a Unix socket, send and receive data on it, and load an image into memory. We will use PNG for that, since Odin has in its standard library support for PNGs, but we could also very easily use a simple format like PPM (like I did in the linked Wayland article) that is trivial to parse. Since Odin has support for both in its standard library, it does not really matter, and I stuck with PNG since it\'s more space-efficient.\nFinally, if you\'re into writing X11 applications even with libraries, lots of things in X11 are undocumented or underdocumented, and this article can be a good learning resource. As a bonus, you can also follow along with pure Wayland, using my previous Wayland article.\nOr perhaps you simply enjoy, like me, peeking behind the curtain to understand the magician\'s tricks. It almost always ends up with: &quot;That\'s it? That\'s all there is to it?&quot;.\nAuthentication\nIn previous articles, we connected to the X server without any authentication.\nLet\'s be a bit more refined: we now also support the X authentication protocol.\nThat\'s because when running under Wayland with XWayland in some desktop environments like Gnome, we have to use authentication.\nThis requires our application to read a 16 bytes long token that\'s present in a file in the user\'s home directory, and include it in the handshake we send to the X server.\nThis mechanism is called\nMIT-MAGIC-COOKIE-1\n.\nThe catch is that this file contains multiple tokens for various authentication mechanisms, and network hosts. Remember, X11 is designed to work over the network. However we only care here about the entry for localhost.\nSo we need to parse a little bit. It\'s basically what\nlibXau\ndoes. From its docs:\nThe .Xauthority file is a binary file consisting of a sequence of entries\nin the following format:\n\t2 bytes\t\tFamily value (second byte is as in protocol HOST)\n\t2 bytes\t\taddress length (always MSB first)\n\tA bytes\t\thost address (as in protocol HOST)\n\t2 bytes\t\tdisplay &quot;number&quot; length (always MSB first)\n\tS bytes\t\tdisplay &quot;number&quot; string\n\t2 bytes\t\tname length (always MSB first)\n\tN bytes\t\tauthorization name string\n\t2 bytes\t\tdata length (always MSB first)\n\tD bytes\t\tauthorization data string\nFirst let\'s define some types and constants:\nAUTH_ENTRY_FAMILY_LOCAL: u16 : 1\nAUTH_ENTRY_MAGIC_COOKIE: string : &quot;MIT-MAGIC-COOKIE-1&quot;\n\nAuthToken :: [16]u8\n\nAuthEntry :: struct {\n\tfamily:    u16,\n\tauth_name: []u8,\n\tauth_data: []u8,\n}\nWe only define fields we are interested in.\nLet\'s now parse each entry accordingly:\nread_x11_auth_entry :: proc(buffer: ^bytes.Buffer) -&gt; (AuthEntry, bool) {\n\tentry := AuthEntry{}\n\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;entry.family))\n\t\tif err == .EOF {return {}, false}\n\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(entry.family))\n\t}\n\n\taddress_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;address_len))\n\t\tassert(err == .None)\n\n\t\taddress_len = bits.byte_swap(address_len)\n\t\tassert(n_read == size_of(address_len))\n\t}\n\n\taddress := make([]u8, address_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, address)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)address_len)\n\t}\n\n\tdisplay_number_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;display_number_len))\n\t\tassert(err == .None)\n\n\t\tdisplay_number_len = bits.byte_swap(display_number_len)\n\t\tassert(n_read == size_of(display_number_len))\n\t}\n\n\tdisplay_number := make([]u8, display_number_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, display_number)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)display_number_len)\n\t}\n\n\tauth_name_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;auth_name_len))\n\t\tassert(err == .None)\n\n\t\tauth_name_len = bits.byte_swap(auth_name_len)\n\t\tassert(n_read == size_of(auth_name_len))\n\t}\n\n\tentry.auth_name = make([]u8, auth_name_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, entry.auth_name)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)auth_name_len)\n\t}\n\n\tauth_data_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;auth_data_len))\n\t\tassert(err == .None)\n\n\t\tauth_data_len = bits.byte_swap(auth_data_len)\n\t\tassert(n_read == size_of(auth_data_len))\n\t}\n\n\tentry.auth_data = make([]u8, auth_data_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, entry.auth_data)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)auth_data_len)\n\t}\n\n\treturn entry, true\n}\nNow we can sift through the different entries in the file to find the one we are after:\nload_x11_auth_token :: proc(allocator := context.allocator) -&gt; (token: AuthToken, ok: bool) {\n\tcontext.allocator = allocator\n\tdefer free_all(allocator)\n\n\tfilename_env := os.get_env(&quot;XAUTHORITY&quot;)\n\n\tfilename :=\n\t\tlen(filename_env) != 0 \\\n\t\t? filename_env \\\n\t\t: filepath.join([]string{os.get_env(&quot;HOME&quot;), &quot;.Xauthority&quot;})\n\n\tdata := os.read_entire_file_from_filename(filename) or_return\n\n\tbuffer := bytes.Buffer{}\n\tbytes.buffer_init(&amp;buffer, data[:])\n\n\n\tfor {\n\t\tauth_entry := read_x11_auth_entry(&amp;buffer) or_break\n\n\t\tif auth_entry.family == AUTH_ENTRY_FAMILY_LOCAL &amp;&amp;\n\t\t   slice.equal(auth_entry.auth_name, transmute([]u8)AUTH_ENTRY_MAGIC_COOKIE) &amp;&amp;\n\t\t   len(auth_entry.auth_data) == size_of(AuthToken) {\n\n\t\t\tmem.copy_non_overlapping(\n\t\t\t\traw_data(&amp;token),\n\t\t\t\traw_data(auth_entry.auth_data),\n\t\t\t\tsize_of(AuthToken),\n\t\t\t)\n\t\t\treturn token, true\n\t\t}\n\t}\n\n    // Did not find a fitting token.\n\treturn {}, false\n}\nOdin has a nice shorthand to return early on errors:\nor_return\n, which is the equivalent of\n?\nin Rust or\ntry\nin Zig. Same thing with\nor_break\n.\nAnd we use it in this manner in\nmain\n:\nmain :: proc() {\n\tauth_token, _ := load_x11_auth_token(context.temp_allocator)\n}\nIf we did not find a fitting token, no matter, we will simply carry on with an empty one.\nOne interesting thing: in Odin, similarly to Zig, allocators are passed to functions wishing to allocate memory. Contrary to Zig though, Odin has a mechanism to make that less tedious (and more implicit as a result) by essentially passing the allocator as the last function argument which is optional.\nOdin is nice enough to also provide us two allocators that we can use right away: A general purpose allocator, and a temporary allocator that uses an arena.\nSince authentication entries can be large, we have to allocate - the stack is only so big. It would be unfortunate to stack overflow because a hostname is a tiny bit too long in this file.\nSome readers have pointed out that it is likely it would all fit on the stack here, but this was also a perfect opportunity to describe Odin\'s approach to memory management.\nHowever, we do not want to retain the parsed entries from the file in memory after finding the 16 bytes token, so we\ndefer free_all(allocator)\n. This is much better than going through each entry and freeing individually each field. We simply free the whole arena in one swoop (but the backing memory remains around to be reused later).\nFurthermore, using this arena places an upper bound (a few MiBs) on the allocations we can do. So if one entry in the file is huge, or malformed, we verifyingly cannot allocate many GiBs of memory. This is good news, because otherwise, the OS will start swapping like crazy and start killing random programs. In my experience it usually kills the window/desktop manager which kills all open windows. Very efficient from the OS perspective, and awful from the user perspective. So it\'s always good to place an upper bound on all resources including heap memory usage of your program.\nAll in all I find Odin\'s approach very elegant. I usually want the ability to use a different allocator in a given function, but also if I don\'t care, it will do the right thing and use the standard allocator.\nOpening a window\nThis part is almost exactly the same as the first linked article so I\'ll speed run this.\nFirst we open a UNIX domain socket:\nconnect_x11_socket :: proc() -&gt; os.Socket {\n\tSockaddrUn :: struct #packed {\n\t\tsa_family: os.ADDRESS_FAMILY,\n\t\tsa_data:   [108]u8,\n\t}\n\n\tsocket, err := os.socket(os.AF_UNIX, os.SOCK_STREAM, 0)\n\tassert(err == os.ERROR_NONE)\n\n\tpossible_socket_paths := [2]string{&quot;/tmp/.X11-unix/X0&quot;, &quot;/tmp/.X11-unix/X1&quot;}\n\tfor &amp;socket_path in possible_socket_paths {\n\t\taddr := SockaddrUn {\n\t\t\tsa_family = cast(u16)os.AF_UNIX,\n\t\t}\n\t\tmem.copy_non_overlapping(&amp;addr.sa_data, raw_data(socket_path), len(socket_path))\n\n\t\terr = os.connect(socket, cast(^os.SOCKADDR)&amp;addr, size_of(addr))\n\t\tif (err == os.ERROR_NONE) {return socket}\n\t}\n\n\tos.exit(1)\n}\nWe try a few possible paths for the socket, that can vary a bit from distribution to distribution.\nWe now can send the handshake, and receive general information from the server. Let\'s define some structs for that per the X11 protocol:\nScreen :: struct #packed {\n\tid:             u32,\n\tcolormap:       u32,\n\twhite:          u32,\n\tblack:          u32,\n\tinput_mask:     u32,\n\twidth:          u16,\n\theight:         u16,\n\twidth_mm:       u16,\n\theight_mm:      u16,\n\tmaps_min:       u16,\n\tmaps_max:       u16,\n\troot_visual_id: u32,\n\tbacking_store:  u8,\n\tsave_unders:    u8,\n\troot_depth:     u8,\n\tdepths_count:   u8,\n}\n\nConnectionInformation :: struct {\n\troot_screen:      Screen,\n\tresource_id_base: u32,\n\tresource_id_mask: u32,\n}\nThe structs are\n#packed\nto match the network protocol format, otherwise the compiler may insert padding between fields.\nOne thing to know about X11: Everything we send has to be padded to a multiple of 4 bytes. We define a helper to do that by using the formula\n((i32)x + 3) &amp; -4\nalong with a unit test for good measure:\nround_up_4 :: #force_inline proc(x: u32) -&gt; u32 {\n\tmask: i32 = -4\n\treturn transmute(u32)((transmute(i32)x + 3) &amp; mask)\n}\n\n@(test)\ntest_round_up_4 :: proc(_: ^testing.T) {\n\tassert(round_up_4(0) == 0)\n\tassert(round_up_4(1) == 4)\n\tassert(round_up_4(2) == 4)\n\tassert(round_up_4(3) == 4)\n\tassert(round_up_4(4) == 4)\n\tassert(round_up_4(5) == 8)\n\tassert(round_up_4(6) == 8)\n\tassert(round_up_4(7) == 8)\n\tassert(round_up_4(8) == 8)\n}\nWe can now send the handshake with the authentication token inside. We leverage the\nwritev\nsystem call to send multiple separate buffers of different lengths in one call.\nWe skip over most of the information the server sends us, since we only are after a few fields:\nx11_handshake :: proc(socket: os.Socket, auth_token: ^AuthToken) -&gt; ConnectionInformation {\n\tRequest :: struct #packed {\n\t\tendianness:             u8,\n\t\tpad1:                   u8,\n\t\tmajor_version:          u16,\n\t\tminor_version:          u16,\n\t\tauthorization_len:      u16,\n\t\tauthorization_data_len: u16,\n\t\tpad2:                   u16,\n\t}\n\n\trequest := Request {\n\t\tendianness             = \'l\',\n\t\tmajor_version          = 11,\n\t\tauthorization_len      = len(AUTH_ENTRY_MAGIC_COOKIE),\n\t\tauthorization_data_len = size_of(AuthToken),\n\t}\n\n\n\t{\n\t\tpadding := [2]u8{0, 0}\n\t\tn_sent, err := linux.writev(\n\t\t\tcast(linux.Fd)socket,\n\t\t\t[]linux.IO_Vec {\n\t\t\t\t{base = &amp;request, len = size_of(Request)},\n\t\t\t\t{base = raw_data(AUTH_ENTRY_MAGIC_COOKIE), len = len(AUTH_ENTRY_MAGIC_COOKIE)},\n\t\t\t\t{base = raw_data(padding[:]), len = len(padding)},\n\t\t\t\t{base = raw_data(auth_token[:]), len = len(auth_token)},\n\t\t\t},\n\t\t)\n\t\tassert(err == .NONE)\n\t\tassert(\n\t\t\tn_sent ==\n\t\t\tsize_of(Request) + len(AUTH_ENTRY_MAGIC_COOKIE) + len(padding) + len(auth_token),\n\t\t)\n\t}\n\n\tStaticResponse :: struct #packed {\n\t\tsuccess:       u8,\n\t\tpad1:          u8,\n\t\tmajor_version: u16,\n\t\tminor_version: u16,\n\t\tlength:        u16,\n\t}\n\n\tstatic_response := StaticResponse{}\n\t{\n\t\tn_recv, err := os.recv(socket, mem.ptr_to_bytes(&amp;static_response), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == size_of(StaticResponse))\n\t\tassert(static_response.success == 1)\n\t}\n\n\n\trecv_buf: [1 &lt;&lt; 15]u8 = {}\n\t{\n\t\tassert(len(recv_buf) &gt;= cast(u32)static_response.length * 4)\n\n\t\tn_recv, err := os.recv(socket, recv_buf[:], 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == cast(u32)static_response.length * 4)\n\t}\n\n\n\tDynamicResponse :: struct #packed {\n\t\trelease_number:              u32,\n\t\tresource_id_base:            u32,\n\t\tresource_id_mask:            u32,\n\t\tmotion_buffer_size:          u32,\n\t\tvendor_length:               u16,\n\t\tmaximum_request_length:      u16,\n\t\tscreens_in_root_count:       u8,\n\t\tformats_count:               u8,\n\t\timage_byte_order:            u8,\n\t\tbitmap_format_bit_order:     u8,\n\t\tbitmap_format_scanline_unit: u8,\n\t\tbitmap_format_scanline_pad:  u8,\n\t\tmin_keycode:                 u8,\n\t\tmax_keycode:                 u8,\n\t\tpad2:                        u32,\n\t}\n\n\tread_buffer := bytes.Buffer{}\n\tbytes.buffer_init(&amp;read_buffer, recv_buf[:])\n\n\tdynamic_response := DynamicResponse{}\n\t{\n\t\tn_read, err := bytes.buffer_read(&amp;read_buffer, mem.ptr_to_bytes(&amp;dynamic_response))\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(DynamicResponse))\n\t}\n\n\n\t// Skip over the vendor information.\n\tbytes.buffer_next(&amp;read_buffer, cast(int)round_up_4(cast(u32)dynamic_response.vendor_length))\n\t// Skip over the format information (each 8 bytes long).\n\tbytes.buffer_next(&amp;read_buffer, 8 * cast(int)dynamic_response.formats_count)\n\n\tscreen := Screen{}\n\t{\n\t\tn_read, err := bytes.buffer_read(&amp;read_buffer, mem.ptr_to_bytes(&amp;screen))\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(screen))\n\t}\n\n\treturn(\n\t\tConnectionInformation {\n\t\t\tresource_id_base = dynamic_response.resource_id_base,\n\t\t\tresource_id_mask = dynamic_response.resource_id_mask,\n\t\t\troot_screen = screen,\n\t\t} \\\n\t)\n}\nOur\nmain\nnow becomes:\nmain :: proc() {\n\tauth_token, _ := load_x11_auth_token(context.temp_allocator)\n\tsocket := connect_x11_socket()\n\tconnection_information := x11_handshake(socket, &amp;auth_token)\n}\nThe next step is to create a graphical context. When creating a new entity, we generate an id for it, and send that in the create request. Afterwards, we can refer to the entity by this id:\nnext_x11_id :: proc(current_id: u32, info: ConnectionInformation) -&gt; u32 {\n\treturn 1 + ((info.resource_id_mask &amp; (current_id)) | info.resource_id_base)\n}\nTime to create a graphical context:\nx11_create_graphical_context :: proc(socket: os.Socket, gc_id: u32, root_id: u32) {\n\topcode: u8 : 55\n\tFLAG_GC_BG: u32 : 8\n\tBITMASK: u32 : FLAG_GC_BG\n\tVALUE1: u32 : 0x00_00_ff_00\n\n\tRequest :: struct #packed {\n\t\topcode:   u8,\n\t\tpad1:     u8,\n\t\tlength:   u16,\n\t\tid:       u32,\n\t\tdrawable: u32,\n\t\tbitmask:  u32,\n\t\tvalue1:   u32,\n\t}\n\trequest := Request {\n\t\topcode   = opcode,\n\t\tlength   = 5,\n\t\tid       = gc_id,\n\t\tdrawable = root_id,\n\t\tbitmask  = BITMASK,\n\t\tvalue1   = VALUE1,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\nFinally we create a window. We subscribe to a few events as well:\nExposure\n: when our window becomes visible\nKEY_PRESS\n: when a keyboard key is pressed\nKEY_RELEASE\n: when a keyboard key is released\nBUTTON_PRESS\n: when a mouse button is pressed\nBUTTON_RELEASE\n: when a mouse button is released\nWe also pick an arbitrary background color, yellow. It does not matter because we will always cover every part of the window with our assets.\nx11_create_window :: proc(\n\tsocket: os.Socket,\n\twindow_id: u32,\n\tparent_id: u32,\n\tx: u16,\n\ty: u16,\n\twidth: u16,\n\theight: u16,\n\troot_visual_id: u32,\n) {\n\tFLAG_WIN_BG_PIXEL: u32 : 2\n\tFLAG_WIN_EVENT: u32 : 0x800\n\tFLAG_COUNT: u16 : 2\n\tEVENT_FLAG_EXPOSURE: u32 = 0x80_00\n\tEVENT_FLAG_KEY_PRESS: u32 = 0x1\n\tEVENT_FLAG_KEY_RELEASE: u32 = 0x2\n\tEVENT_FLAG_BUTTON_PRESS: u32 = 0x4\n\tEVENT_FLAG_BUTTON_RELEASE: u32 = 0x8\n\tflags: u32 : FLAG_WIN_BG_PIXEL | FLAG_WIN_EVENT\n\tdepth: u8 : 24\n\tborder_width: u16 : 0\n\tCLASS_INPUT_OUTPUT: u16 : 1\n\topcode: u8 : 1\n\tBACKGROUND_PIXEL_COLOR: u32 : 0x00_ff_ff_00\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tdepth:          u8,\n\t\trequest_length: u16,\n\t\twindow_id:      u32,\n\t\tparent_id:      u32,\n\t\tx:              u16,\n\t\ty:              u16,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t\tborder_width:   u16,\n\t\tclass:          u16,\n\t\troot_visual_id: u32,\n\t\tbitmask:        u32,\n\t\tvalue1:         u32,\n\t\tvalue2:         u32,\n\t}\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tdepth          = depth,\n\t\trequest_length = 8 + FLAG_COUNT,\n\t\twindow_id      = window_id,\n\t\tparent_id      = parent_id,\n\t\tx              = x,\n\t\ty              = y,\n\t\twidth          = width,\n\t\theight         = height,\n\t\tborder_width   = border_width,\n\t\tclass          = CLASS_INPUT_OUTPUT,\n\t\troot_visual_id = root_visual_id,\n\t\tbitmask        = flags,\n\t\tvalue1         = BACKGROUND_PIXEL_COLOR,\n\t\tvalue2         = EVENT_FLAG_EXPOSURE | EVENT_FLAG_BUTTON_RELEASE | EVENT_FLAG_BUTTON_PRESS | EVENT_FLAG_KEY_PRESS | EVENT_FLAG_KEY_RELEASE,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\nWe decide that our game will have 16 rows and 16 columns, and each asset is 16x16 pixels.\nmain\nis now:\nENTITIES_ROW_COUNT :: 16\nENTITIES_COLUMN_COUNT :: 16\nENTITIES_WIDTH :: 16\nENTITIES_HEIGHT :: 16\n\nmain :: proc() {\n\tauth_token, _ := load_x11_auth_token(context.temp_allocator)\n\tsocket := connect_x11_socket()\n\tconnection_information := x11_handshake(socket, &amp;auth_token)\n\n\tgc_id := next_x11_id(0, connection_information)\n\tx11_create_graphical_context(socket, gc_id, connection_information.root_screen.id)\n\n\twindow_id := next_x11_id(gc_id, connection_information)\n\tx11_create_window(\n\t\tsocket,\n\t\twindow_id,\n\t\tconnection_information.root_screen.id,\n\t\t200,\n\t\t200,\n\t\tENTITIES_COLUMN_COUNT * ENTITIES_WIDTH,\n\t\tENTITIES_ROW_COUNT * ENTITIES_HEIGHT,\n\t\tconnection_information.root_screen.root_visual_id,\n\t)\n}\nNote that the window dimensions are a hint, they might now be respected, for example in a tiling window manager. We do not handle this case here since the assets are fixed size.\nIf you have followed along, you will now see... nothing. That\'s because we need to tell X11 to show our window with the\nmap_window\ncall:\nx11_map_window :: proc(socket: os.Socket, window_id: u32) {\n\topcode: u8 : 8\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tpad1:           u8,\n\t\trequest_length: u16,\n\t\twindow_id:      u32,\n\t}\n\trequest := Request {\n\t\topcode         = opcode,\n\t\trequest_length = 2,\n\t\twindow_id      = window_id,\n\t}\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n\n}\nWe now see:\nTime to start programming the game itself!\nLoading assets\nWhat\'s a game without nice looking pictures\nstolen from somewhere on the internet\n?\nHere is our sprite, the one image containing all our assets:\nOdin has a nice feature to embed the image file in our executable which makes redistribution a breeze and startup a bit faster, so we\'ll do that:\npng_data := #load(&quot;sprite.png&quot;)\n\tsprite, err := png.load_from_bytes(png_data, {})\n\tassert(err == nil)\nNow here is the catch: The X11 image format is different from the one in the sprite so we have to swap the bytes around:\nsprite_data := make([]u8, sprite.height * sprite.width * 4)\n\n\t// Convert the image format from the sprite (RGB) into the X11 image format (BGRX).\n\tfor i := 0; i &lt; sprite.height * sprite.width - 3; i += 1 {\n\t\tsprite_data[i * 4 + 0] = sprite.pixels.buf[i * 3 + 2] // R -&gt; B\n\t\tsprite_data[i * 4 + 1] = sprite.pixels.buf[i * 3 + 1] // G -&gt; G\n\t\tsprite_data[i * 4 + 2] = sprite.pixels.buf[i * 3 + 0] // B -&gt; R\n\t\tsprite_data[i * 4 + 3] = 0 // pad\n\t}\nThe\nA\ncomponent is actually unused since we do not have transparency.\nNow that our image is in (client) memory, how to make it available to the server? Which, again, in the X11 model, might be running on a totally different machine across the world!\nX11 has 3 useful calls for images:\nCreatePixmap\nand\nPutImage\n. A\nPixmap\nis an off-screen image buffer.\nPutImage\nuploads image data either to a pixmap or to the window directly (a \'drawable\' in X11 parlance).\nCopyArea\ncopies one rectangle in one drawable to another drawable.\nIn my humble opinion, these are complete misnomers.\nCreatePixmap\nshould have been called\nCreateOffscreenImageBuffer\nand\nPutImage\nshould have been\nUploadImageData\n.\nCopyArea\n: you\'re fine buddy, carry on.\nWe cannot simply use\nPutImage\nhere since that would show the whole sprite on the screen (there are no fields to specify that only part of the image should be displayed). We could show only parts of it, with separate\nPutImage\ncalls for each entity, but that would mean uploading the image data to the server each time.\nWhat we want is to upload the image data once, off-screen, with one\nPutImage\ncall, and then copy parts of it onto the window. Here is the dance we need to do:\nCreatePixmap\nPutImage\nto upload the image data to the pixmap - at that point nothing is shown on the window, everything is still off-screen\nFor each entity in our game, issue a cheap\nCopyArea\ncall which copies parts of the pixmap onto the window - now it\'s visible!\nThe X server can actually upload the image data to the GPU on a\nPutImage\ncall (this is implementation dependent). After that,\nCopyArea\ncalls can be translated by the X server to GPU commands to copy the image data from one GPU buffer to another: that\'s really performant! The image data is only uploaded once to the GPU and then resides there for the remainder of the program.\nUnfortunately, the X standard does not enforce that (it says: &quot;may or may not [...]&quot;), but that\'s a useful model to have in mind.\nAnother useful model is to think of what happens when the X server is running across the network: We only want to send the image data once because that\'s time-consuming, and afterwards issue cheap\nCopyArea\ncommands that are only a few bytes each.\nOk, let\'s implement that then:\nx11_create_pixmap :: proc(\n\tsocket: os.Socket,\n\twindow_id: u32,\n\tpixmap_id: u32,\n\twidth: u16,\n\theight: u16,\n\tdepth: u8,\n) {\n\topcode: u8 : 53\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tdepth:          u8,\n\t\trequest_length: u16,\n\t\tpixmap_id:      u32,\n\t\tdrawable_id:    u32,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t}\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tdepth          = depth,\n\t\trequest_length = 4,\n\t\tpixmap_id      = pixmap_id,\n\t\tdrawable_id    = window_id,\n\t\twidth          = width,\n\t\theight         = height,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\n\nx11_put_image :: proc(\n\tsocket: os.Socket,\n\tdrawable_id: u32,\n\tgc_id: u32,\n\twidth: u16,\n\theight: u16,\n\tdst_x: u16,\n\tdst_y: u16,\n\tdepth: u8,\n\tdata: []u8,\n) {\n\topcode: u8 : 72\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tformat:         u8,\n\t\trequest_length: u16,\n\t\tdrawable_id:    u32,\n\t\tgc_id:          u32,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t\tdst_x:          u16,\n\t\tdst_y:          u16,\n\t\tleft_pad:       u8,\n\t\tdepth:          u8,\n\t\tpad1:           u16,\n\t}\n\n\tdata_length_padded := round_up_4(cast(u32)len(data))\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tformat         = 2, // ZPixmap\n\t\trequest_length = cast(u16)(6 + data_length_padded / 4),\n\t\tdrawable_id    = drawable_id,\n\t\tgc_id          = gc_id,\n\t\twidth          = width,\n\t\theight         = height,\n\t\tdst_x          = dst_x,\n\t\tdst_y          = dst_y,\n\t\tdepth          = depth,\n\t}\n\t{\n\t\tpadding_len := data_length_padded - cast(u32)len(data)\n\n\t\tn_sent, err := linux.writev(\n\t\t\tcast(linux.Fd)socket,\n\t\t\t[]linux.IO_Vec {\n\t\t\t\t{base = &amp;request, len = size_of(Request)},\n\t\t\t\t{base = raw_data(data), len = len(data)},\n\t\t\t\t{base = raw_data(data), len = cast(uint)padding_len},\n\t\t\t},\n\t\t)\n\t\tassert(err == .NONE)\n\t\tassert(n_sent == size_of(Request) + len(data) + cast(int)padding_len)\n\t}\n}\n\nx11_copy_area :: proc(\n\tsocket: os.Socket,\n\tsrc_id: u32,\n\tdst_id: u32,\n\tgc_id: u32,\n\tsrc_x: u16,\n\tsrc_y: u16,\n\tdst_x: u16,\n\tdst_y: u16,\n\twidth: u16,\n\theight: u16,\n) {\n\topcode: u8 : 62\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tpad1:           u8,\n\t\trequest_length: u16,\n\t\tsrc_id:         u32,\n\t\tdst_id:         u32,\n\t\tgc_id:          u32,\n\t\tsrc_x:          u16,\n\t\tsrc_y:          u16,\n\t\tdst_x:          u16,\n\t\tdst_y:          u16,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t}\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\trequest_length = 7,\n\t\tsrc_id         = src_id,\n\t\tdst_id         = dst_id,\n\t\tgc_id          = gc_id,\n\t\tsrc_x          = src_x,\n\t\tsrc_y          = src_y,\n\t\tdst_x          = dst_x,\n\t\tdst_y          = dst_y,\n\t\twidth          = width,\n\t\theight         = height,\n\t}\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\nLet\'s try in\nmain\n:\nimg_depth: u8 = 24\n\tpixmap_id := next_x11_id(window_id, connection_information)\n\tx11_create_pixmap(\n\t\tsocket,\n\t\twindow_id,\n\t\tpixmap_id,\n\t\tcast(u16)sprite.width,\n\t\tcast(u16)sprite.height,\n\t\timg_depth,\n\t)\n\n\tx11_put_image(\n\t\tsocket,\n\t\tpixmap_id,\n\t\tgc_id,\n\t\tsprite_width,\n\t\tsprite_height,\n\t\t0,\n\t\t0,\n\t\timg_depth,\n\t\tsprite_data,\n\t)\n\n    // Let\'s render two different assets: an exploded mine and an idle mine.\n\tx11_copy_area(\n\t\tsocket,\n\t\tpixmap_id,\n\t\twindow_id,\n\t\tgc_id,\n\t\t32, // X coordinate on the sprite sheet.\n\t\t40, // Y coordinate on the sprite sheet.\n\t\t0, // X coordinate on the window.\n\t\t0, // Y coordinate on the window.\n\t\t16, // Width.\n\t\t16, // Height.\n\t)\n\tx11_copy_area(\n\t\tsocket,\n\t\tpixmap_id,\n\t\twindow_id,\n\t\tgc_id,\n\t\t64,\n\t\t40,\n\t\t16,\n\t\t0,\n\t\t16,\n\t\t16,\n\t)\nResult:\nWe are now ready to focus on the game entities.\nThe game entities\nWe have a few different entities we want to show, each is a 16x16 section of the sprite sheet. Let\'s define their coordinates to be readable:\nPosition :: struct {\n\tx: u16,\n\ty: u16,\n}\n\nEntity_kind :: enum {\n\tCovered,\n\tUncovered_0,\n\tUncovered_1,\n\tUncovered_2,\n\tUncovered_3,\n\tUncovered_4,\n\tUncovered_5,\n\tUncovered_6,\n\tUncovered_7,\n\tUncovered_8,\n\tMine_exploded,\n\tMine_idle,\n}\n\nASSET_COORDINATES: [Entity_kind]Position = {\n\t.Uncovered_0 = {x = 0 * 16, y = 22},\n\t.Uncovered_1 = {x = 1 * 16, y = 22},\n\t.Uncovered_2 = {x = 2 * 16, y = 22},\n\t.Uncovered_3 = {x = 3 * 16, y = 22},\n\t.Uncovered_4 = {x = 4 * 16, y = 22},\n\t.Uncovered_5 = {x = 5 * 16, y = 22},\n\t.Uncovered_6 = {x = 6 * 16, y = 22},\n\t.Uncovered_7 = {x = 7 * 16, y = 22},\n\t.Uncovered_8 = {x = 8 * 16, y = 22},\n\t.Covered = {x = 0, y = 38},\n\t.Mine_exploded = {x = 32, y = 40},\n\t.Mine_idle = {x = 64, y = 40},\n}\nAnd we\'ll group everything we need in one struct called\nScene\n:\nScene :: struct {\n\twindow_id:              u32,\n\tgc_id:                  u32,\n\tsprite_pixmap_id:       u32,\n\tdisplayed_entities:     [ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]Entity_kind,\n\tmines:                  [ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool,\n}\nThe first interesting field is\ndisplayed_entities\nwhich keeps track of which assets are shown. For example, a mine is either covered, uncovered and exploded if the player clicked on it, or uncovered and idle if the player won).\nThe second one is\nmines\nwhich simply keeps track of where mines are. It could be a bitfield to optimize space but I did not bother.\nIn\nmain\nwe create a new scene and plant mines randomly.\nscene := Scene {\n\t\twindow_id              = window_id,\n\t\tgc_id                  = gc_id,\n\t\tsprite_pixmap_id       = pixmap_id,\n\t}\n\treset(&amp;scene)\nWe put this logic in the\nreset\nhelper so that the player can easily restart the game with one keystroke:\nreset :: proc(scene: ^Scene) {\n\tfor &amp;entity in scene.displayed_entities {\n\t\tentity = .Covered\n\t}\n\n\tfor &amp;mine in scene.mines {\n\t\tmine = rand.choice([]bool{true, false, false, false})\n\t}\n}\nHere I used a 1/4 chance that a cell has a mine.\nWe are now ready to render our (static for now) scene:\nrender :: proc(socket: os.Socket, scene: ^Scene) {\n\tfor entity, i in scene.displayed_entities {\n\t\trect := ASSET_COORDINATES[entity]\n\t\trow, column := idx_to_row_column(i)\n\n\t\tx11_copy_area(\n\t\t\tsocket,\n\t\t\tscene.sprite_pixmap_id,\n\t\t\tscene.window_id,\n\t\t\tscene.gc_id,\n\t\t\trect.x,\n\t\t\trect.y,\n\t\t\tcast(u16)column * ENTITIES_WIDTH,\n\t\t\tcast(u16)row * ENTITIES_HEIGHT,\n\t\t\tENTITIES_WIDTH,\n\t\t\tENTITIES_HEIGHT,\n\t\t)\n\t}\n}\nAnd here is what we get:\nThe next step is to respond to events.\nReacting to keyboard and mouse events\nThis is very straightforward. Since the only messages we expect are for keyboard and mouse events, with a fixed size of 32 bytes, we simply read 32 bytes exactly in a blocking fashion. The first byte indicates which kind of event it is:\nwait_for_x11_events :: proc(socket: os.Socket, scene: ^Scene) {\n\tGenericEvent :: struct #packed {\n\t\tcode: u8,\n\t\tpad:  [31]u8,\n\t}\n\tassert(size_of(GenericEvent) == 32)\n\n\tKeyReleaseEvent :: struct #packed {\n\t\tcode:            u8,\n\t\tdetail:          u8,\n\t\tsequence_number: u16,\n\t\ttime:            u32,\n\t\troot_id:         u32,\n\t\tevent:           u32,\n\t\tchild_id:        u32,\n\t\troot_x:          u16,\n\t\troot_y:          u16,\n\t\tevent_x:         u16,\n\t\tevent_y:         u16,\n\t\tstate:           u16,\n\t\tsame_screen:     bool,\n\t\tpad1:            u8,\n\t}\n\tassert(size_of(KeyReleaseEvent) == 32)\n\n\tButtonReleaseEvent :: struct #packed {\n\t\tcode:        u8,\n\t\tdetail:      u8,\n\t\tseq_number:  u16,\n\t\ttimestamp:   u32,\n\t\troot:        u32,\n\t\tevent:       u32,\n\t\tchild:       u32,\n\t\troot_x:      u16,\n\t\troot_y:      u16,\n\t\tevent_x:     u16,\n\t\tevent_y:     u16,\n\t\tstate:       u16,\n\t\tsame_screen: bool,\n\t\tpad1:        u8,\n\t}\n\tassert(size_of(ButtonReleaseEvent) == 32)\n\n\tEVENT_EXPOSURE: u8 : 0xc\n\tEVENT_KEY_RELEASE: u8 : 0x3\n\tEVENT_BUTTON_RELEASE: u8 : 0x5\n\n\tKEYCODE_ENTER: u8 : 36\n\n\tfor {\n\t\tgeneric_event := GenericEvent{}\n\t\tn_recv, err := os.recv(socket, mem.ptr_to_bytes(&amp;generic_event), 0)\n\t\tif err == os.EPIPE || n_recv == 0 {\n\t\t\tos.exit(0) // The end.\n\t\t}\n\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == size_of(GenericEvent))\n\n\t\tswitch generic_event.code {\n\t\tcase EVENT_EXPOSURE:\n\t\t\trender(socket, scene)\n\n\t\tcase EVENT_KEY_RELEASE:\n\t\t\tevent := transmute(KeyReleaseEvent)generic_event\n\t\t\tif event.detail == KEYCODE_ENTER {\n\t\t\t\treset(scene)\n\t\t\t\trender(socket, scene)\n\t\t\t}\n\n\t\tcase EVENT_BUTTON_RELEASE:\n\t\t\tevent := transmute(ButtonReleaseEvent)generic_event\n\t\t\ton_cell_clicked(event.event_x, event.event_y, scene)\n\t\t\trender(socket, scene)\n\t\t}\n\t}\n}\nIf the event is\nExposed\n, we simply render (that\'s our first render when the window becomes visible - or if the window was minimized and then made visible again).\nIf the event is the\nEnter\nkey, we reset the state of the game and render. X11 differentiates between physical and logical keys on the keyboard but that does not matter here (or I would argue in most games: we are interested in the physical location of the key, not what the user mapped it to).\nIf the event is (pressing and) releasing a mouse button, we run the game logic to uncover a cell and render.\nThat\'s it!\nGame logic: uncover a cell\nThe last thing to do is implementing the game rules.\nFrom my faint memory, when uncovering a cell, we have two cases:\nIf it\'s a mine, we lost\nIf it\'s not a mine, we uncover this cell and neighboring cells, in a flood fill fashion. We only uncover non-mines of course. An uncovered cell shows how many neighboring mines are around with a number (0 is simply empty, no number is shown).\nThe one thing that tripped me is that we inspect all 8 neighboring cells to count mines, but when doing the flood fill, we only visit the 4 neighboring cells: up, right, down, left - not the diagonal neighbors. Otherwise the flood fill ends up uncovering all cells in the game at once.\nFirst, we need to translate the mouse position in the window to a cell index/row/column in our grid:\nrow_column_to_idx :: #force_inline proc(row: int, column: int) -&gt; int {\n\treturn cast(int)row * ENTITIES_COLUMN_COUNT + cast(int)column\n}\n\nlocate_entity_by_coordinate :: proc(win_x: u16, win_y: u16) -&gt; (idx: int, row: int, column: int) {\n\tcolumn = cast(int)win_x / ENTITIES_WIDTH\n\trow = cast(int)win_y / ENTITIES_HEIGHT\n\n\tidx = row_column_to_idx(row, column)\n\n\treturn idx, row, column\n}\nThen the game logic:\non_cell_clicked :: proc(x: u16, y: u16, scene: ^Scene) {\n\tidx, row, column := locate_entity_by_coordinate(x, y)\n\n\tmined := scene.mines[idx]\n\n\tif mined {\n\t\tscene.displayed_entities[idx] = .Mine_exploded\n\t\t// Lose.\n\t\tuncover_all_cells(&amp;scene.displayed_entities, &amp;scene.mines, .Mine_exploded)\n\t} else {\n\t\tvisited := [ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]bool{}\n\t\tuncover_cells_flood_fill(row, column, &amp;scene.displayed_entities, &amp;scene.mines, &amp;visited)\n\n\t\t// Win.\n\t\tif count_remaining_goals(scene.displayed_entities, scene.mines) == 0 {\n\t\t\tuncover_all_cells(&amp;scene.displayed_entities, &amp;scene.mines, .Mine_idle)\n\t\t}\n\t}\n}\nThe objective is to uncover all cells without mines. We could keep a counter around and decrement it each time, but I wanted to make it idiot-proof, so I simply scan the grid to count how many uncovered cells without a mine underneath remain (in\ncount_remaining_goals\n). No risk that way to have a desync between the game state and what is shown on the screen, because we did not decrement the counter in one edge case.\nuncover_all_cells\nunconditionally reveals the whole grid when the player won or lost. We just need to show the mines exploded when they lost, and idle when they won.\nuncover_cells_flood_fill\nis the interesting one. We use recursion, and to avoid visiting the same cells multiple times and potentially getting into infinite recursion, we track which cells were visited:\nuncover_cells_flood_fill :: proc(\n\trow: int,\n\tcolumn: int,\n\tdisplayed_entities: ^[ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]Entity_kind,\n\tmines: ^[ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool,\n\tvisited: ^[ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]bool,\n) {\n\ti := row_column_to_idx(row, column)\n\tif visited[i] {return}\n\n\tvisited[i] = true\n\n\t// Do not uncover covered mines.\n\tif mines[i] {return}\n\n\tif displayed_entities[i] != .Covered {return}\n\n\t// Uncover cell.\n\n\tmines_around_count := count_mines_around_cell(row, column, mines[:])\n\tassert(mines_around_count &lt;= 8)\n\n\tdisplayed_entities[i] =\n\tcast(Entity_kind)(cast(int)Entity_kind.Uncovered_0 + mines_around_count)\n\n\t// Uncover neighbors.\n\n\t// Up.\n\tif !(row == 0) {\n\t\tuncover_cells_flood_fill(row - 1, column, displayed_entities, mines, visited)\n\t}\n\n\t// Right\n\tif !(column == (ENTITIES_COLUMN_COUNT - 1)) {\n\t\tuncover_cells_flood_fill(row, column + 1, displayed_entities, mines, visited)\n\t}\n\n\t// Bottom.\n\tif !(row == (ENTITIES_ROW_COUNT - 1)) {\n\t\tuncover_cells_flood_fill(row + 1, column, displayed_entities, mines, visited)\n\t}\n\n\t// Left.\n\tif !(column == 0) {\n\t\tuncover_cells_flood_fill(row, column - 1, displayed_entities, mines, visited)\n\t}\n}\nThere are a few helpers here and there that are simple, but otherwise... that\'s it, that\'s the end. We\'re done! All under 1000 lines of code without any tricks or clever things.\nConclusion\nX11 is old and crufty, but also gets out of the way. Once a few utility functions to open the window, receive events, etc have been implemented, it can be forgotten and we can focus all our attention on the game. That\'s very valuable. How many libraries, frameworks and development environments can say the same?\nI also enjoy that it works with any programming language, any tech stack. Don\'t need no bindings, no FFI, just send some bytes over the socket. You can even do that in Bash (don\'t tempt me!).\nI did not implement a few accessory things from the original game, like planting a flag on a cell you suspect has a mine. Feel free to do this at home, it\'s not much work.\nFinally, give Odin a try, it\'s great! It\'s this weird mix of a sane C with a Go-ish syntax and a good standard library.\nI hope that you had as much fun as I did!\nAddendum: the full code\nThe full code\npackage main\n\nimport &quot;core:bytes&quot;\nimport &quot;core:image/png&quot;\nimport &quot;core:math/bits&quot;\nimport &quot;core:math/rand&quot;\nimport &quot;core:mem&quot;\nimport &quot;core:os&quot;\nimport &quot;core:path/filepath&quot;\nimport &quot;core:slice&quot;\nimport &quot;core:sys/linux&quot;\nimport &quot;core:testing&quot;\n\nTILE_WIDTH :: 16\nTILE_HEIGHT :: 16\n\nPosition :: struct {\n\tx: u16,\n\ty: u16,\n}\n\nEntity_kind :: enum {\n\tCovered,\n\tUncovered_0,\n\tUncovered_1,\n\tUncovered_2,\n\tUncovered_3,\n\tUncovered_4,\n\tUncovered_5,\n\tUncovered_6,\n\tUncovered_7,\n\tUncovered_8,\n\tMine_exploded,\n\tMine_idle,\n}\n\nASSET_COORDINATES: [Entity_kind]Position = {\n\t.Uncovered_0 = {x = 0 * 16, y = 22},\n\t.Uncovered_1 = {x = 1 * 16, y = 22},\n\t.Uncovered_2 = {x = 2 * 16, y = 22},\n\t.Uncovered_3 = {x = 3 * 16, y = 22},\n\t.Uncovered_4 = {x = 4 * 16, y = 22},\n\t.Uncovered_5 = {x = 5 * 16, y = 22},\n\t.Uncovered_6 = {x = 6 * 16, y = 22},\n\t.Uncovered_7 = {x = 7 * 16, y = 22},\n\t.Uncovered_8 = {x = 8 * 16, y = 22},\n\t.Covered = {x = 0, y = 38},\n\t.Mine_exploded = {x = 32, y = 40},\n\t.Mine_idle = {x = 64, y = 40},\n}\n\nAuthToken :: [16]u8\n\nAuthEntry :: struct {\n\tfamily:    u16,\n\tauth_name: []u8,\n\tauth_data: []u8,\n}\n\nScreen :: struct #packed {\n\tid:             u32,\n\tcolormap:       u32,\n\twhite:          u32,\n\tblack:          u32,\n\tinput_mask:     u32,\n\twidth:          u16,\n\theight:         u16,\n\twidth_mm:       u16,\n\theight_mm:      u16,\n\tmaps_min:       u16,\n\tmaps_max:       u16,\n\troot_visual_id: u32,\n\tbacking_store:  u8,\n\tsave_unders:    u8,\n\troot_depth:     u8,\n\tdepths_count:   u8,\n}\n\nConnectionInformation :: struct {\n\troot_screen:      Screen,\n\tresource_id_base: u32,\n\tresource_id_mask: u32,\n}\n\n\nAUTH_ENTRY_FAMILY_LOCAL: u16 : 1\nAUTH_ENTRY_MAGIC_COOKIE: string : &quot;MIT-MAGIC-COOKIE-1&quot;\n\nround_up_4 :: #force_inline proc(x: u32) -&gt; u32 {\n\tmask: i32 = -4\n\treturn transmute(u32)((transmute(i32)x + 3) &amp; mask)\n}\n\nread_x11_auth_entry :: proc(buffer: ^bytes.Buffer) -&gt; (AuthEntry, bool) {\n\tentry := AuthEntry{}\n\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;entry.family))\n\t\tif err == .EOF {return {}, false}\n\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(entry.family))\n\t}\n\n\taddress_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;address_len))\n\t\tassert(err == .None)\n\n\t\taddress_len = bits.byte_swap(address_len)\n\t\tassert(n_read == size_of(address_len))\n\t}\n\n\taddress := make([]u8, address_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, address)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)address_len)\n\t}\n\n\tdisplay_number_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;display_number_len))\n\t\tassert(err == .None)\n\n\t\tdisplay_number_len = bits.byte_swap(display_number_len)\n\t\tassert(n_read == size_of(display_number_len))\n\t}\n\n\tdisplay_number := make([]u8, display_number_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, display_number)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)display_number_len)\n\t}\n\n\tauth_name_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;auth_name_len))\n\t\tassert(err == .None)\n\n\t\tauth_name_len = bits.byte_swap(auth_name_len)\n\t\tassert(n_read == size_of(auth_name_len))\n\t}\n\n\tentry.auth_name = make([]u8, auth_name_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, entry.auth_name)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)auth_name_len)\n\t}\n\n\tauth_data_len: u16 = 0\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, mem.ptr_to_bytes(&amp;auth_data_len))\n\t\tassert(err == .None)\n\n\t\tauth_data_len = bits.byte_swap(auth_data_len)\n\t\tassert(n_read == size_of(auth_data_len))\n\t}\n\n\tentry.auth_data = make([]u8, auth_data_len)\n\t{\n\t\tn_read, err := bytes.buffer_read(buffer, entry.auth_data)\n\t\tassert(err == .None)\n\t\tassert(n_read == cast(int)auth_data_len)\n\t}\n\n\n\treturn entry, true\n}\n\nload_x11_auth_token :: proc(allocator := context.allocator) -&gt; (token: AuthToken, ok: bool) {\n\tcontext.allocator = allocator\n\tdefer free_all(allocator)\n\n\tfilename_env := os.get_env(&quot;XAUTHORITY&quot;)\n\n\tfilename :=\n\t\tlen(filename_env) != 0 \\\n\t\t? filename_env \\\n\t\t: filepath.join([]string{os.get_env(&quot;HOME&quot;), &quot;.Xauthority&quot;})\n\n\tdata := os.read_entire_file_from_filename(filename) or_return\n\n\tbuffer := bytes.Buffer{}\n\tbytes.buffer_init(&amp;buffer, data[:])\n\n\n\tfor {\n\t\tauth_entry := read_x11_auth_entry(&amp;buffer) or_break\n\n\t\tif auth_entry.family == AUTH_ENTRY_FAMILY_LOCAL &amp;&amp;\n\t\t   slice.equal(auth_entry.auth_name, transmute([]u8)AUTH_ENTRY_MAGIC_COOKIE) &amp;&amp;\n\t\t   len(auth_entry.auth_data) == size_of(AuthToken) {\n\n\t\t\tmem.copy_non_overlapping(\n\t\t\t\traw_data(&amp;token),\n\t\t\t\traw_data(auth_entry.auth_data),\n\t\t\t\tsize_of(AuthToken),\n\t\t\t)\n\t\t\treturn token, true\n\t\t}\n\t}\n\n\t// Did not find a fitting token.\n\treturn {}, false\n}\n\nconnect_x11_socket :: proc() -&gt; os.Socket {\n\tSockaddrUn :: struct #packed {\n\t\tsa_family: os.ADDRESS_FAMILY,\n\t\tsa_data:   [108]u8,\n\t}\n\n\tsocket, err := os.socket(os.AF_UNIX, os.SOCK_STREAM, 0)\n\tassert(err == os.ERROR_NONE)\n\n\tpossible_socket_paths := [2]string{&quot;/tmp/.X11-unix/X0&quot;, &quot;/tmp/.X11-unix/X1&quot;}\n\tfor &amp;socket_path in possible_socket_paths {\n\t\taddr := SockaddrUn {\n\t\t\tsa_family = cast(u16)os.AF_UNIX,\n\t\t}\n\t\tmem.copy_non_overlapping(&amp;addr.sa_data, raw_data(socket_path), len(socket_path))\n\n\t\terr = os.connect(socket, cast(^os.SOCKADDR)&amp;addr, size_of(addr))\n\t\tif (err == os.ERROR_NONE) {return socket}\n\t}\n\n\tos.exit(1)\n}\n\n\nx11_handshake :: proc(socket: os.Socket, auth_token: ^AuthToken) -&gt; ConnectionInformation {\n\n\tRequest :: struct #packed {\n\t\tendianness:             u8,\n\t\tpad1:                   u8,\n\t\tmajor_version:          u16,\n\t\tminor_version:          u16,\n\t\tauthorization_len:      u16,\n\t\tauthorization_data_len: u16,\n\t\tpad2:                   u16,\n\t}\n\n\trequest := Request {\n\t\tendianness             = \'l\',\n\t\tmajor_version          = 11,\n\t\tauthorization_len      = len(AUTH_ENTRY_MAGIC_COOKIE),\n\t\tauthorization_data_len = size_of(AuthToken),\n\t}\n\n\n\t{\n\t\tpadding := [2]u8{0, 0}\n\t\tn_sent, err := linux.writev(\n\t\t\tcast(linux.Fd)socket,\n\t\t\t[]linux.IO_Vec {\n\t\t\t\t{base = &amp;request, len = size_of(Request)},\n\t\t\t\t{base = raw_data(AUTH_ENTRY_MAGIC_COOKIE), len = len(AUTH_ENTRY_MAGIC_COOKIE)},\n\t\t\t\t{base = raw_data(padding[:]), len = len(padding)},\n\t\t\t\t{base = raw_data(auth_token[:]), len = len(auth_token)},\n\t\t\t},\n\t\t)\n\t\tassert(err == .NONE)\n\t\tassert(\n\t\t\tn_sent ==\n\t\t\tsize_of(Request) + len(AUTH_ENTRY_MAGIC_COOKIE) + len(padding) + len(auth_token),\n\t\t)\n\t}\n\n\tStaticResponse :: struct #packed {\n\t\tsuccess:       u8,\n\t\tpad1:          u8,\n\t\tmajor_version: u16,\n\t\tminor_version: u16,\n\t\tlength:        u16,\n\t}\n\n\tstatic_response := StaticResponse{}\n\t{\n\t\tn_recv, err := os.recv(socket, mem.ptr_to_bytes(&amp;static_response), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == size_of(StaticResponse))\n\t\tassert(static_response.success == 1)\n\t}\n\n\n\trecv_buf: [1 &lt;&lt; 15]u8 = {}\n\t{\n\t\tassert(len(recv_buf) &gt;= cast(u32)static_response.length * 4)\n\n\t\tn_recv, err := os.recv(socket, recv_buf[:], 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == cast(u32)static_response.length * 4)\n\t}\n\n\n\tDynamicResponse :: struct #packed {\n\t\trelease_number:              u32,\n\t\tresource_id_base:            u32,\n\t\tresource_id_mask:            u32,\n\t\tmotion_buffer_size:          u32,\n\t\tvendor_length:               u16,\n\t\tmaximum_request_length:      u16,\n\t\tscreens_in_root_count:       u8,\n\t\tformats_count:               u8,\n\t\timage_byte_order:            u8,\n\t\tbitmap_format_bit_order:     u8,\n\t\tbitmap_format_scanline_unit: u8,\n\t\tbitmap_format_scanline_pad:  u8,\n\t\tmin_keycode:                 u8,\n\t\tmax_keycode:                 u8,\n\t\tpad2:                        u32,\n\t}\n\n\tread_buffer := bytes.Buffer{}\n\tbytes.buffer_init(&amp;read_buffer, recv_buf[:])\n\n\tdynamic_response := DynamicResponse{}\n\t{\n\t\tn_read, err := bytes.buffer_read(&amp;read_buffer, mem.ptr_to_bytes(&amp;dynamic_response))\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(DynamicResponse))\n\t}\n\n\n\t// Skip over the vendor information.\n\tbytes.buffer_next(&amp;read_buffer, cast(int)round_up_4(cast(u32)dynamic_response.vendor_length))\n\t// Skip over the format information (each 8 bytes long).\n\tbytes.buffer_next(&amp;read_buffer, 8 * cast(int)dynamic_response.formats_count)\n\n\tscreen := Screen{}\n\t{\n\t\tn_read, err := bytes.buffer_read(&amp;read_buffer, mem.ptr_to_bytes(&amp;screen))\n\t\tassert(err == .None)\n\t\tassert(n_read == size_of(screen))\n\t}\n\n\treturn (ConnectionInformation {\n\t\t\t\tresource_id_base = dynamic_response.resource_id_base,\n\t\t\t\tresource_id_mask = dynamic_response.resource_id_mask,\n\t\t\t\troot_screen = screen,\n\t\t\t})\n}\n\nnext_x11_id :: proc(current_id: u32, info: ConnectionInformation) -&gt; u32 {\n\treturn 1 + ((info.resource_id_mask &amp; (current_id)) | info.resource_id_base)\n}\n\nx11_create_graphical_context :: proc(socket: os.Socket, gc_id: u32, root_id: u32) {\n\topcode: u8 : 55\n\tFLAG_GC_BG: u32 : 8\n\tBITMASK: u32 : FLAG_GC_BG\n\tVALUE1: u32 : 0x00_00_ff_00\n\n\tRequest :: struct #packed {\n\t\topcode:   u8,\n\t\tpad1:     u8,\n\t\tlength:   u16,\n\t\tid:       u32,\n\t\tdrawable: u32,\n\t\tbitmask:  u32,\n\t\tvalue1:   u32,\n\t}\n\trequest := Request {\n\t\topcode   = opcode,\n\t\tlength   = 5,\n\t\tid       = gc_id,\n\t\tdrawable = root_id,\n\t\tbitmask  = BITMASK,\n\t\tvalue1   = VALUE1,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\n\nx11_create_window :: proc(\n\tsocket: os.Socket,\n\twindow_id: u32,\n\tparent_id: u32,\n\tx: u16,\n\ty: u16,\n\twidth: u16,\n\theight: u16,\n\troot_visual_id: u32,\n) {\n\tFLAG_WIN_BG_PIXEL: u32 : 2\n\tFLAG_WIN_EVENT: u32 : 0x800\n\tFLAG_COUNT: u16 : 2\n\tEVENT_FLAG_EXPOSURE: u32 = 0x80_00\n\tEVENT_FLAG_KEY_PRESS: u32 = 0x1\n\tEVENT_FLAG_KEY_RELEASE: u32 = 0x2\n\tEVENT_FLAG_BUTTON_PRESS: u32 = 0x4\n\tEVENT_FLAG_BUTTON_RELEASE: u32 = 0x8\n\tflags: u32 : FLAG_WIN_BG_PIXEL | FLAG_WIN_EVENT\n\tdepth: u8 : 24\n\tborder_width: u16 : 0\n\tCLASS_INPUT_OUTPUT: u16 : 1\n\topcode: u8 : 1\n\tBACKGROUND_PIXEL_COLOR: u32 : 0x00_ff_ff_00\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tdepth:          u8,\n\t\trequest_length: u16,\n\t\twindow_id:      u32,\n\t\tparent_id:      u32,\n\t\tx:              u16,\n\t\ty:              u16,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t\tborder_width:   u16,\n\t\tclass:          u16,\n\t\troot_visual_id: u32,\n\t\tbitmask:        u32,\n\t\tvalue1:         u32,\n\t\tvalue2:         u32,\n\t}\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tdepth          = depth,\n\t\trequest_length = 8 + FLAG_COUNT,\n\t\twindow_id      = window_id,\n\t\tparent_id      = parent_id,\n\t\tx              = x,\n\t\ty              = y,\n\t\twidth          = width,\n\t\theight         = height,\n\t\tborder_width   = border_width,\n\t\tclass          = CLASS_INPUT_OUTPUT,\n\t\troot_visual_id = root_visual_id,\n\t\tbitmask        = flags,\n\t\tvalue1         = BACKGROUND_PIXEL_COLOR,\n\t\tvalue2         = EVENT_FLAG_EXPOSURE | EVENT_FLAG_BUTTON_RELEASE | EVENT_FLAG_BUTTON_PRESS \n            | EVENT_FLAG_KEY_PRESS | EVENT_FLAG_KEY_RELEASE,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\n\nx11_map_window :: proc(socket: os.Socket, window_id: u32) {\n\topcode: u8 : 8\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tpad1:           u8,\n\t\trequest_length: u16,\n\t\twindow_id:      u32,\n\t}\n\trequest := Request {\n\t\topcode         = opcode,\n\t\trequest_length = 2,\n\t\twindow_id      = window_id,\n\t}\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n\n}\n\nx11_put_image :: proc(\n\tsocket: os.Socket,\n\tdrawable_id: u32,\n\tgc_id: u32,\n\twidth: u16,\n\theight: u16,\n\tdst_x: u16,\n\tdst_y: u16,\n\tdepth: u8,\n\tdata: []u8,\n) {\n\topcode: u8 : 72\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tformat:         u8,\n\t\trequest_length: u16,\n\t\tdrawable_id:    u32,\n\t\tgc_id:          u32,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t\tdst_x:          u16,\n\t\tdst_y:          u16,\n\t\tleft_pad:       u8,\n\t\tdepth:          u8,\n\t\tpad1:           u16,\n\t}\n\n\tdata_length_padded := round_up_4(cast(u32)len(data))\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tformat         = 2, // ZPixmap\n\t\trequest_length = cast(u16)(6 + data_length_padded / 4),\n\t\tdrawable_id    = drawable_id,\n\t\tgc_id          = gc_id,\n\t\twidth          = width,\n\t\theight         = height,\n\t\tdst_x          = dst_x,\n\t\tdst_y          = dst_y,\n\t\tdepth          = depth,\n\t}\n\t{\n\t\tpadding_len := data_length_padded - cast(u32)len(data)\n\n\t\tn_sent, err := linux.writev(\n\t\t\tcast(linux.Fd)socket,\n\t\t\t[]linux.IO_Vec {\n\t\t\t\t{base = &amp;request, len = size_of(Request)},\n\t\t\t\t{base = raw_data(data), len = len(data)},\n\t\t\t\t{base = raw_data(data), len = cast(uint)padding_len},\n\t\t\t},\n\t\t)\n\t\tassert(err == .NONE)\n\t\tassert(n_sent == size_of(Request) + len(data) + cast(int)padding_len)\n\t}\n}\n\nrender :: proc(socket: os.Socket, scene: ^Scene) {\n\tfor entity, i in scene.displayed_entities {\n\t\trect := ASSET_COORDINATES[entity]\n\t\trow, column := idx_to_row_column(i)\n\n\t\tx11_copy_area(\n\t\t\tsocket,\n\t\t\tscene.sprite_pixmap_id,\n\t\t\tscene.window_id,\n\t\t\tscene.gc_id,\n\t\t\trect.x,\n\t\t\trect.y,\n\t\t\tcast(u16)column * ENTITIES_WIDTH,\n\t\t\tcast(u16)row * ENTITIES_HEIGHT,\n\t\t\tENTITIES_WIDTH,\n\t\t\tENTITIES_HEIGHT,\n\t\t)\n\t}\n}\n\nENTITIES_ROW_COUNT :: 16\nENTITIES_COLUMN_COUNT :: 16\nENTITIES_WIDTH :: 16\nENTITIES_HEIGHT :: 16\n\nScene :: struct {\n\twindow_id:          u32,\n\tgc_id:              u32,\n\tsprite_pixmap_id:   u32,\n\tdisplayed_entities: [ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]Entity_kind,\n\t// TODO: Bitfield?\n\tmines:              [ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool,\n}\n\nwait_for_x11_events :: proc(socket: os.Socket, scene: ^Scene) {\n\tGenericEvent :: struct #packed {\n\t\tcode: u8,\n\t\tpad:  [31]u8,\n\t}\n\tassert(size_of(GenericEvent) == 32)\n\n\tKeyReleaseEvent :: struct #packed {\n\t\tcode:            u8,\n\t\tdetail:          u8,\n\t\tsequence_number: u16,\n\t\ttime:            u32,\n\t\troot_id:         u32,\n\t\tevent:           u32,\n\t\tchild_id:        u32,\n\t\troot_x:          u16,\n\t\troot_y:          u16,\n\t\tevent_x:         u16,\n\t\tevent_y:         u16,\n\t\tstate:           u16,\n\t\tsame_screen:     bool,\n\t\tpad1:            u8,\n\t}\n\tassert(size_of(KeyReleaseEvent) == 32)\n\n\tButtonReleaseEvent :: struct #packed {\n\t\tcode:        u8,\n\t\tdetail:      u8,\n\t\tseq_number:  u16,\n\t\ttimestamp:   u32,\n\t\troot:        u32,\n\t\tevent:       u32,\n\t\tchild:       u32,\n\t\troot_x:      u16,\n\t\troot_y:      u16,\n\t\tevent_x:     u16,\n\t\tevent_y:     u16,\n\t\tstate:       u16,\n\t\tsame_screen: bool,\n\t\tpad1:        u8,\n\t}\n\tassert(size_of(ButtonReleaseEvent) == 32)\n\n\tEVENT_EXPOSURE: u8 : 0xc\n\tEVENT_KEY_RELEASE: u8 : 0x3\n\tEVENT_BUTTON_RELEASE: u8 : 0x5\n\n\tKEYCODE_ENTER: u8 : 36\n\n\tfor {\n\t\tgeneric_event := GenericEvent{}\n\t\tn_recv, err := os.recv(socket, mem.ptr_to_bytes(&amp;generic_event), 0)\n\t\tif err == os.EPIPE || n_recv == 0 {\n\t\t\tos.exit(0) // The end.\n\t\t}\n\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_recv == size_of(GenericEvent))\n\n\t\tswitch generic_event.code {\n\t\tcase EVENT_EXPOSURE:\n\t\t\trender(socket, scene)\n\n\t\tcase EVENT_KEY_RELEASE:\n\t\t\tevent := transmute(KeyReleaseEvent)generic_event\n\t\t\tif event.detail == KEYCODE_ENTER {\n\t\t\t\treset(scene)\n\t\t\t\trender(socket, scene)\n\t\t\t}\n\n\t\tcase EVENT_BUTTON_RELEASE:\n\t\t\tevent := transmute(ButtonReleaseEvent)generic_event\n\t\t\ton_cell_clicked(event.event_x, event.event_y, scene)\n\t\t\trender(socket, scene)\n\t\t}\n\t}\n}\n\nreset :: proc(scene: ^Scene) {\n\tfor &amp;entity in scene.displayed_entities {\n\t\tentity = .Covered\n\t}\n\n\tfor &amp;mine in scene.mines {\n\t\tmine = rand.choice([]bool{true, false, false, false})\n\t}\n}\n\nx11_copy_area :: proc(\n\tsocket: os.Socket,\n\tsrc_id: u32,\n\tdst_id: u32,\n\tgc_id: u32,\n\tsrc_x: u16,\n\tsrc_y: u16,\n\tdst_x: u16,\n\tdst_y: u16,\n\twidth: u16,\n\theight: u16,\n) {\n\topcode: u8 : 62\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tpad1:           u8,\n\t\trequest_length: u16,\n\t\tsrc_id:         u32,\n\t\tdst_id:         u32,\n\t\tgc_id:          u32,\n\t\tsrc_x:          u16,\n\t\tsrc_y:          u16,\n\t\tdst_x:          u16,\n\t\tdst_y:          u16,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t}\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\trequest_length = 7,\n\t\tsrc_id         = src_id,\n\t\tdst_id         = dst_id,\n\t\tgc_id          = gc_id,\n\t\tsrc_x          = src_x,\n\t\tsrc_y          = src_y,\n\t\tdst_x          = dst_x,\n\t\tdst_y          = dst_y,\n\t\twidth          = width,\n\t\theight         = height,\n\t}\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\n\non_cell_clicked :: proc(x: u16, y: u16, scene: ^Scene) {\n\tidx, row, column := locate_entity_by_coordinate(x, y)\n\n\tmined := scene.mines[idx]\n\n\tif mined {\n\t\tscene.displayed_entities[idx] = .Mine_exploded\n\t\t// Lose.\n\t\tuncover_all_cells(&amp;scene.displayed_entities, &amp;scene.mines, .Mine_exploded)\n\t} else {\n\t\tvisited := [ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]bool{}\n\t\tuncover_cells_flood_fill(row, column, &amp;scene.displayed_entities, &amp;scene.mines, &amp;visited)\n\n\t\t// Win.\n\t\tif count_remaining_goals(scene.displayed_entities, scene.mines) == 0 {\n\t\t\tuncover_all_cells(&amp;scene.displayed_entities, &amp;scene.mines, .Mine_idle)\n\t\t}\n\t}\n}\n\ncount_remaining_goals :: proc(\n\tdisplayed_entities: [ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]Entity_kind,\n\tmines: [ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]bool,\n) -&gt; int {\n\n\tcovered := 0\n\n\tfor entity in displayed_entities {\n\t\tcovered += cast(int)(entity == .Covered)\n\t}\n\n\tmines_count := 0\n\n\tfor mine in mines {\n\t\tmines_count += cast(int)mine\n\t}\n\n\treturn covered - mines_count\n}\n\nuncover_all_cells :: proc(\n\tdisplayed_entities: ^[ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]Entity_kind,\n\tmines: ^[ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool,\n\tshown_mine: Entity_kind,\n) {\n\tfor &amp;entity, i in displayed_entities {\n\t\tif mines[i] {\n\t\t\tentity = shown_mine\n\t\t} else {\n\t\t\trow, column := idx_to_row_column(i)\n\t\t\tmines_around_count := count_mines_around_cell(row, column, mines[:])\n\t\t\tassert(mines_around_count &lt;= 8)\n\n\t\t\tentity = cast(Entity_kind)(cast(int)Entity_kind.Uncovered_0 + mines_around_count)\n\t\t}\n\t}\n}\n\nuncover_cells_flood_fill :: proc(\n\trow: int,\n\tcolumn: int,\n\tdisplayed_entities: ^[ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]Entity_kind,\n\tmines: ^[ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool,\n\tvisited: ^[ENTITIES_COLUMN_COUNT * ENTITIES_ROW_COUNT]bool,\n) {\n\ti := row_column_to_idx(row, column)\n\tif visited[i] {return}\n\n\tvisited[i] = true\n\n\t// Do not uncover covered mines.\n\tif mines[i] {return}\n\n\tif displayed_entities[i] != .Covered {return}\n\n\t// Uncover cell.\n\n\tmines_around_count := count_mines_around_cell(row, column, mines[:])\n\tassert(mines_around_count &lt;= 8)\n\n\tdisplayed_entities[i] =\n\tcast(Entity_kind)(cast(int)Entity_kind.Uncovered_0 + mines_around_count)\n\n\t// Uncover neighbors.\n\n\t// Up.\n\tif !(row == 0) {\n\t\tuncover_cells_flood_fill(row - 1, column, displayed_entities, mines, visited)\n\t}\n\n\t// Right\n\tif !(column == (ENTITIES_COLUMN_COUNT - 1)) {\n\t\tuncover_cells_flood_fill(row, column + 1, displayed_entities, mines, visited)\n\t}\n\n\t// Bottom.\n\tif !(row == (ENTITIES_ROW_COUNT - 1)) {\n\t\tuncover_cells_flood_fill(row + 1, column, displayed_entities, mines, visited)\n\t}\n\n\t// Left.\n\tif !(column == 0) {\n\t\tuncover_cells_flood_fill(row, column - 1, displayed_entities, mines, visited)\n\t}\n}\n\nidx_to_row_column :: #force_inline proc(i: int) -&gt; (int, int) {\n\tcolumn := i % ENTITIES_COLUMN_COUNT\n\trow := i / ENTITIES_ROW_COUNT\n\n\treturn row, column\n}\n\nrow_column_to_idx :: #force_inline proc(row: int, column: int) -&gt; int {\n\treturn cast(int)row * ENTITIES_COLUMN_COUNT + cast(int)column\n}\n\ncount_mines_around_cell :: proc(row: int, column: int, displayed_entities: []bool) -&gt; int {\n\t// TODO: Pad the border to elide all bound checks?\n\n\tup_left :=\n\t\trow == 0 || column == 0 \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row - 1, column - 1)]\n\tup := row == 0 ? false : displayed_entities[row_column_to_idx(row - 1, column)]\n\tup_right :=\n\t\trow == 0 || column == (ENTITIES_COLUMN_COUNT - 1) \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row - 1, column + 1)]\n\tright :=\n\t\tcolumn == (ENTITIES_COLUMN_COUNT - 1) \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row, column + 1)]\n\tbottom_right :=\n\t\trow == (ENTITIES_ROW_COUNT - 1) || column == (ENTITIES_COLUMN_COUNT - 1) \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row + 1, column + 1)]\n\tbottom :=\n\t\trow == (ENTITIES_ROW_COUNT - 1) \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row + 1, column)]\n\tbottom_left :=\n\t\tcolumn == 0 || row == (ENTITIES_COLUMN_COUNT - 1) \\\n\t\t? false \\\n\t\t: displayed_entities[row_column_to_idx(row + 1, column - 1)]\n\tleft := column == 0 ? false : displayed_entities[row_column_to_idx(row, column - 1)]\n\n\n\treturn(\n\t\tcast(int)up_left +\n\t\tcast(int)up +\n\t\tcast(int)up_right +\n\t\tcast(int)right +\n\t\tcast(int)bottom_right +\n\t\tcast(int)bottom +\n\t\tcast(int)bottom_left +\n\t\tcast(int)left \\\n\t)\n}\n\nlocate_entity_by_coordinate :: proc(win_x: u16, win_y: u16) -&gt; (idx: int, row: int, column: int) {\n\tcolumn = cast(int)win_x / ENTITIES_WIDTH\n\trow = cast(int)win_y / ENTITIES_HEIGHT\n\n\tidx = row_column_to_idx(row, column)\n\n\treturn idx, row, column\n}\n\nx11_create_pixmap :: proc(\n\tsocket: os.Socket,\n\twindow_id: u32,\n\tpixmap_id: u32,\n\twidth: u16,\n\theight: u16,\n\tdepth: u8,\n) {\n\topcode: u8 : 53\n\n\tRequest :: struct #packed {\n\t\topcode:         u8,\n\t\tdepth:          u8,\n\t\trequest_length: u16,\n\t\tpixmap_id:      u32,\n\t\tdrawable_id:    u32,\n\t\twidth:          u16,\n\t\theight:         u16,\n\t}\n\n\trequest := Request {\n\t\topcode         = opcode,\n\t\tdepth          = depth,\n\t\trequest_length = 4,\n\t\tpixmap_id      = pixmap_id,\n\t\tdrawable_id    = window_id,\n\t\twidth          = width,\n\t\theight         = height,\n\t}\n\n\t{\n\t\tn_sent, err := os.send(socket, mem.ptr_to_bytes(&amp;request), 0)\n\t\tassert(err == os.ERROR_NONE)\n\t\tassert(n_sent == size_of(Request))\n\t}\n}\n\nmain :: proc() {\n\tpng_data := #load(&quot;sprite.png&quot;)\n\tsprite, err := png.load_from_bytes(png_data, {})\n\tassert(err == nil)\n\tsprite_data := make([]u8, sprite.height * sprite.width * 4)\n\n\t// Convert the image format from the sprite (RGB) into the X11 image format (BGRX).\n\tfor i := 0; i &lt; sprite.height * sprite.width - 3; i += 1 {\n\t\tsprite_data[i * 4 + 0] = sprite.pixels.buf[i * 3 + 2] // R -&gt; B\n\t\tsprite_data[i * 4 + 1] = sprite.pixels.buf[i * 3 + 1] // G -&gt; G\n\t\tsprite_data[i * 4 + 2] = sprite.pixels.buf[i * 3 + 0] // B -&gt; R\n\t\tsprite_data[i * 4 + 3] = 0 // pad\n\t}\n\n\tauth_token, _ := load_x11_auth_token(context.temp_allocator)\n\n\tsocket := connect_x11_socket()\n\tconnection_information := x11_handshake(socket, &amp;auth_token)\n\n\tgc_id := next_x11_id(0, connection_information)\n\tx11_create_graphical_context(socket, gc_id, connection_information.root_screen.id)\n\n\twindow_id := next_x11_id(gc_id, connection_information)\n\tx11_create_window(\n\t\tsocket,\n\t\twindow_id,\n\t\tconnection_information.root_screen.id,\n\t\t200,\n\t\t200,\n\t\tENTITIES_COLUMN_COUNT * ENTITIES_WIDTH,\n\t\tENTITIES_ROW_COUNT * ENTITIES_HEIGHT,\n\t\tconnection_information.root_screen.root_visual_id,\n\t)\n\n\timg_depth: u8 = 24\n\tpixmap_id := next_x11_id(window_id, connection_information)\n\tx11_create_pixmap(\n\t\tsocket,\n\t\twindow_id,\n\t\tpixmap_id,\n\t\tcast(u16)sprite.width,\n\t\tcast(u16)sprite.height,\n\t\timg_depth,\n\t)\n\tscene := Scene {\n\t\twindow_id        = window_id,\n\t\tgc_id            = gc_id,\n\t\tsprite_pixmap_id = pixmap_id,\n\t}\n\treset(&amp;scene)\n\n\tx11_put_image(\n\t\tsocket,\n\t\tscene.sprite_pixmap_id,\n\t\tscene.gc_id,\n\t\tcast(u16)sprite.width,\n\t\tcast(u16)sprite.height,\n\t\t0,\n\t\t0,\n\t\timg_depth,\n\t\tsprite_data,\n\t)\n\n\tx11_map_window(socket, window_id)\n\n\twait_for_x11_events(socket, &amp;scene)\n}\n\n\n@(test)\ntest_round_up_4 :: proc(_: ^testing.T) {\n\tassert(round_up_4(0) == 0)\n\tassert(round_up_4(1) == 4)\n\tassert(round_up_4(2) == 4)\n\tassert(round_up_4(3) == 4)\n\tassert(round_up_4(4) == 4)\n\tassert(round_up_4(5) == 8)\n\tassert(round_up_4(6) == 8)\n\tassert(round_up_4(7) == 8)\n\tassert(round_up_4(8) == 8)\n}\n\n@(test)\ntest_count_mines_around_cell :: proc(_: ^testing.T) {\n\t{\n\t\tmines := [ENTITIES_ROW_COUNT * ENTITIES_COLUMN_COUNT]bool{}\n\t\tmines[row_column_to_idx(0, 0)] = true\n\t\tmines[row_column_to_idx(0, 1)] = true\n\t\tmines[row_column_to_idx(0, 2)] = true\n\t\tmines[row_column_to_idx(1, 2)] = true\n\t\tmines[row_column_to_idx(2, 2)] = true\n\t\tmines[row_column_to_idx(2, 1)] = true\n\t\tmines[row_column_to_idx(2, 0)] = true\n\t\tmines[row_column_to_idx(1, 0)] = true\n\n\t\tassert(count_mines_around_cell(1, 1, mines[:]) == 8)\n\t}\n}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3232213245-what-we-re-making",
"#2281387754-authentication",
"#526064357-opening-a-window",
"#2589078693-loading-assets",
"#2972734494-the-game-entities",
"#4044658410-reacting-to-keyboard-and-mouse-events",
"#962123213-game-logic-uncover-a-cell",
"#3796851539-conclusion",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
2409,4611,11562,22238,29242,31887,34475,38507,39357,],
},
{
name:"odin_and_musl.html",
text:"Odin and musl: Cross-compiling Odin programs for the Raspberry Pi Zero\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-09-10\nOdin and musl: Cross-compiling Odin programs for the Raspberry Pi Zero\nOdin\nMusl\nARM\nCross-compilation\nTable of contents\nInciting incident\nConfrontation\nResolution\nAppendix: Maybe you don\'t even need a libc\nOdin programming language\nis becoming my favorite tool as a Software Engineer. It\'s a fantastic programming language, mostly because it is dead simple.\nI have purchased some time ago a Raspberry Pi Zero 2, and I found myself wanting to write command-line Odin programs for it. Here it is in all its beauty:\nHere\'s the story of how I did it. If you do not work with Odin but do work a lot with cross-compilation, like I do at work, all of these techniques will be, I believe, very valuable anyway.\nNote: ARM64 is sometimes also called AARCH64 interchangeably.\nNote 2: The Rapsberry Pi Zero 1 is based on ARM (32 bits). The Raspberry Pi Zero 2 is based on ARM64 (64 bits). If you have a Raspberry Pi Zero 1, this article still applies, just adjust the target when cross-compiling.\nInciting incident\nThe thing is, I work on an Intel Linux laptop and the Zero is a Linux ARM 64 bits piece of hardware. It\'s also a relatively cheap component with only 512 MiB of RAM and a slow CPU (compared to a modern developer workstation), and based on a very slow SD card, so it\'s not fast to install the required tools and to build source code on it. Cross-compilation is much easier and faster.\nOdin can cross-compile to it with\n-target=linux_arm64\n, so that\'s great, let\'s try it:\n$ odin build src -target=linux_arm64\n[...]\n/usr/bin/ld: /home/pg/my-code/odin-music-chords-placements/src.o: error adding symbols: file in wrong format\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nOh no...The key part is:\nfile in wrong format\n.\nThat\'s because behind the scenes, the Odin compiler builds our code into an ARM64 object file, which is great. But then it tries to link this object file with libc, which on this computer is a x86_64 library, and that won\'t work.\nWe can confirm this theory by asking Odin to print the linking command:\n$ odin build src -target=linux_arm64 -print-linker-flags\nclang -Wno-unused-command-line-argument [...]  -lm -lc   -L/       -no-pie\nAnd we see it links libc with\n-lc\n, meaning it links our program with the local libc it finds on my machine which is a different architecture than our target.\nConfrontation\nWhat we want is to link our object file with the correct libc, meaning one that has been built for ARM64. Moreover, we\'d like to build our program statically with libc so that we can simply copy the one executable to the Raspberry Pi Zero and it is fully self-contained. We completely side-step issues of different glibc versions not being compatible with each other.\nEnter musl, a C library for Linux that supports many platforms including ARM64, and static compilation. That\'s exactly what we need!\nA big difference between Odin and Zig is that Zig is a full cross-compilation toolchain: it comes with the source code of\nmusl\n, and has put in a ton of work to cross-compile it to the target the user desires.\nSo to make our use-case work with Odin, without Odin the toolchain supporting what Zig supports, what we need to do is cross-compile our code to an ARM64 object file but without linking it yet. Then we link it manually to musl libc that has been built for ARM64. We could download this musl artifact from the internet but it\'s both more educational, empowering, and secure, to build it ourselves. So let\'s do this, it\'s not too much work.\nTo build musl, we can either use clang since it is a cross-compiler by default, or a GCC toolchain that has been made to target ARM64. Most Linux distributions provide such a compiler as a package typically called\ngcc-aarch64-xxx\ne.g.\nsudo apt-get install gcc-aarch64-linux-gnu\nor\nsudo dnf install gcc-aarch64-linux-gnu\n.\nSo let\'s now build a static musl for ARM64, following the official instructions. We just need to this once:\n$ git clone --recurse --depth 1 https://git.musl-libc.org/git/musl\n$ cd musl\n\n# With Clang:\n$ CFLAGS=\'--target=aarch64-unknown-linux-musl\' RANLIB=llvm-ranlib AR=llvm-ar CC=clang ./configure --target=aarch64 --disable-shared\n# Or with GCC:\n$ RANLIB=/usr/bin/aarch64-linux-gnu-gcc-ranlib AR=/usr/bin/aarch64-linux-gnu-gcc-ar CC=/usr/bin/aarch64-linux-gnu-gcc ./configure --target=aarch64 --disable-shared\n\n# Either way (Clang/GCC), the build command itself is the same.\n$ make\nWe now have the two artifacts we want:\ncrt1.o\nand\nlibc.a\n. We can confirm that they have been correctly built for our target:\n$ file lib/crt1.o\nlib/crt1.o: ELF 64-bit LSB relocatable, ARM aarch64, version 1 (SYSV), not stripped\n$ readelf -h lib/libc.a | grep \'^\\s*Machine:\'\n  Machine:                           AArch64\n  Machine:                           AArch64\n  Machine:                           AArch64\n  [...]\nResolution\nNow we can finally put all the pieces together. We can use any linker, I am using LLD (the LLVM linker) here, but the GNU LD linker would also work as long as it knows to target ARM64 e.g. using the one coming with the right GCC toolchain would work.\n$ odin build src  -target=linux_arm64 -build-mode=object\n$ file src.o\nsrc.o: ELF 64-bit LSB relocatable, ARM aarch64, version 1 (SYSV), not stripped\n$ ld.lld main.o ~/not-my-code/musl/lib/libc.a ~/not-my-code/musl/lib/crt1.o\n$ file a.out\na.out: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, not stripped\nAlternatively, we can decide to stick with the Odin compiler through and through, and we pass it the (lengthy) required build options:\n$ odin build src -target=linux_arm64 -extra-linker-flags:\'-L ~/not-my-code/musl/lib/ -nostdlib -fuse-ld=lld --target=linux-aarch64 ~/not-my-code/musl/lib/crt1.o -static\'\nWe can even verify it works by running it inside a ARM64 Linux system using\nqemu\n:\n$ qemu-aarch64-static a.out\n# It runs!\nCherry on the cake, the resulting program is small:\n$ llvm-strip a.out\n$ du -h a.out \n288K\ta.out\nSo it\'s a breeze to\nscp\nor\nrsync\nour small executable over to the Raspberry Pi Zero while hacking on it.\nPerhaps Odin will have built-in support for musl in the future like Zig does. In the meantime, this article shows it\'s absolutely possible to do that ourselves!\nBy the way, this technique can be used to cross-compile any C library that\'s a dependency of our project, assuming the library did not do anything silly that would prevent cross-compilation.\nAppendix: Maybe you don\'t even need a libc\nOdin comes with batteries included with a rich standard library. So why do we even need libc? Let\'s inspect which functions we really use from libc, i.e. are undefined symbols in the object file built from our source code:\n$ nm -u src.o\n                 U calloc\n                 U free\n                 U malloc\n                 U memcpy\n                 U memmove\n                 U memset\n                 U realloc\nOk, so basically: heap allocation and some functions to copy/set memory.\nHeap allocation functions are not actually required if our program does not do heap allocations (Odin provides the option\n-default-to-nil-allocator\nfor this case), or if we implement these ourselves, for example with a naive\nmmap\nimplementation, or by setting in our program the default allocator to be an arena. Odin has first class support for custom allocators!\nThe functions to manipulate memory are required even if we do not call them directly because typically, the compiler will replace some code patterns, e.g.\nstruct\nor array initialization, with these functions behind the scene.\nThese\nmemxxx\nfunctions could potentially be implemented by us, likely incurring a performance cost compared to the hand-optimized libc versions. But Odin can provide them for us! We can just use the\n-no-crt\noption.\nNote that not all targets will be equally supported for this use-case. ARM64 is not yet supported, so I will demonstrate targeting AMD64 (i.e. Intel/AMD 64 bits).\nI also had to install\nnasm\nto make it work because Odin ships with some assembly files which are then built for the target with\nnasm\n, but Odin does not ship with\nnasm\nitself.\nLet\'s try with a \'hello world\' example:\npackage main\n\nimport &quot;core:fmt&quot;\n\nmain :: proc() {\n\tfmt.println(&quot;Hello&quot;)\n}\nWe can build it as outlined like this:\n$ odin build hello.odin -file -target=linux_amd64 -default-to-nil-allocator -no-crt\n$ file hello\nhello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, BuildID[sha1]=ef8dfc9dc297295808f80ec66e92763358a598d1, not stripped\nAnd we can see the\nmalloc\nsymbol is not present since we do opted out of it, and that Odin provided with these assembly files the correct implementation for\nmemset\n:\n$ nm hello | grep malloc\n# Nothing\n$ nm hello | grep memset\n00000000004042c0 T memset\nI\'ll soon write about what programs I made for the Raspberry Pi Zero, so check back soon!\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#848107681-inciting-incident",
"#1339502364-confrontation",
"#3613299072-resolution",
"#301746397-appendix-maybe-you-don-t-even-need-a-libc",
],
title_text_offsets:[
1159,2521,5007,6585,],
},
{
name:"rust_c++_interop_trick.html",
text:"A small trick for simple Rust/C++ interop\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-09-19\nA small trick for simple Rust/C++ interop\nRust\nC++\nTable of contents\nThe trick\nExample\nAccessing std::string from Rust\nImproving the std::string situation\nConclusion\nAddendum: the full code\nDiscussions:\n/r/rust\n,\nHN\n.\nI am\nrewriting\na gnarly\nC++ codebase\nin Rust at work.\nDue to the heavy use of callbacks (sigh), Rust sometimes calls C++ and C++ sometimes calls Rust. This done by having both sides expose a C API for the functions they want the other side to be able to call.\nThis is for functions; but what about C++ methods? Here is a trick to rewrite one C++ method at a time, without headaches. And by the way, this works whatever the language you are rewriting the project in, it does not have to be Rust!\nThe trick\nMake the C++ class a\nstandard layout class\n. This is defined by the C++ standard. In layman terms, this makes the C++ class be similar to a plain C struct. With a few allowances, for example the C++ class can still use inheritance and a few other things. Most notably, virtual methods are forbidden. I don\'t care about this limitation because I never use virtual methods myself and this is my least favorite feature in any programming language.\nCreate a Rust struct with the\nexact\nsame layout as the C++ class.\nCreate a Rust function with a C calling convention, whose first argument is this Rust class. You can now access every C++ member of the class!\nNote: Depending on the C++ codebase you find yourself in, the first point could be either trivial or not feasible at all. It depends on the amount of virtual methods used, etc.\nIn my case, there were a handful of virtual methods, which could all be advantageously made non virtual, so I first did this.\nThis is all very abstract? Let\'s proceed with an example!\nExample\nHere is our fancy C++ class,\nUser\n. It stores a name, a uuid, and a comment count. A user can write comments, which is just a string, that we print.\n// Path: user.cpp\n\n#include &lt;cstdint&gt;\n#include &lt;cstdio&gt;\n#include &lt;cstring&gt;\n#include &lt;string&gt;\n\nclass User {\n  std::string name;\n  uint64_t comments_count;\n  uint8_t uuid[16];\n\npublic:\n  User(std::string name_) : name{name_}, comments_count{0} {\n    arc4random_buf(uuid, sizeof(uuid));\n  }\n\n  void write_comment(const char *comment, size_t comment_len) {\n    printf(&quot;%s (&quot;, name.c_str());\n    for (size_t i = 0; i &lt; sizeof(uuid); i += 1) {\n      printf(&quot;%x&quot;, uuid[i]);\n    }\n    printf(&quot;) says: %.*s\\n&quot;, (int)comment_len, comment);\n    comments_count += 1;\n  }\n\n  uint64_t get_comment_count() { return comments_count; }\n};\n\nint main() {\n  User alice{&quot;alice&quot;};\n  const char msg[] = &quot;hello, world!&quot;;\n  alice.write_comment(msg, sizeof(msg) - 1);\n\n  printf(&quot;Comment count: %lu\\n&quot;, alice.get_comment_count());\n\n  // This prints:\n  // alice (fe61252cf5b88432a7e8c8674d58d615) says: hello, world!\n  // Comment count: 1\n}\nSo let\'s first ensure it is a standard layout class. We add this compile-time assertion in the constructor (could be placed anywhere, but the constructor is as good a place as any):\n// Path: user.cpp\n\n    static_assert(std::is_standard_layout_v&lt;User&gt;);\nAnd... it builds!\nNow onto the second step: let\'s define the equivalent class on the Rust side.\nWe create a new Rust library project:\n$ cargo new --lib user-rs-lib\nAnd place our Rust struct in\nsrc/lib.rs\n.\nWe just need to be careful about alignment (padding between fields) and the order the fields, so we mark the struct\nrepr(C)\nto make the Rust compiler use the same layout as C does:\n// Path: ./user-rs/src/lib.rs\n\n#[repr(C)]\npub struct UserC {\n    pub name: [u8; 32],\n    pub comments_count: u64,\n    pub uuid: [u8; 16],\n}\nNote that the fields can be named differently from the C++ fields if you so choose.\nAlso note that\nstd::string\nis represented here by an opaque array of 32 bytes. That\'s because on my machine, with the standard library I have,\nsizeof(std::string)\nis 32. That is\nnot\nguaranteed by the standard, so this makes it very much not portable. We\'ll go over some options to work-around this at the end. I wanted to include a standard library type to show that it does not prevent the class from being a \'standard layout class\', but that is also creates challenges.\nFor now, let\'s forget about this hurdle.\nWe can also write a stub for the Rust function equivalent to the C++ method:\n// Path: ./user-rs-lib/src/lib.rs\n\n#[no_mangle]\npub extern &quot;C&quot; fn RUST_write_comment(user: &amp;mut UserC, comment: *const u8, comment_len: usize) {\n    todo!()\n}\nNow, let\'s use the tool\ncbindgen\nto generate the C header corresponding to this Rust code:\n$ cargo install cbindgen\n$ cbindgen -v src/lib.rs --lang=c++ -o ../user-rs-lib.h\nAnd we get this C header:\n// Path: user-rs-lib.h\n\n#include &lt;cstdarg&gt;\n#include &lt;cstdint&gt;\n#include &lt;cstdlib&gt;\n#include &lt;ostream&gt;\n#include &lt;new&gt;\n\nstruct UserC {\n  uint8_t name[32];\n  uint64_t comments_count;\n  uint8_t uuid[16];\n};\n\nextern &quot;C&quot; {\n\nvoid RUST_write_comment(UserC *user, const uint8_t *comment, uintptr_t comment_len);\n\n} // extern &quot;C&quot;\nNow, let\'s go back to C++, include this C header, and add lots of compile-time assertions to ensure that the layouts are indeed the same. Again, I place these asserts in the constructor:\n#include &quot;user-rs-lib.h&quot;\n\nclass User {\n // [..]\n\n  User(std::string name_) : name{name_}, comments_count{0} {\n    arc4random_buf(uuid, sizeof(uuid));\n\n    static_assert(std::is_standard_layout_v&lt;User&gt;);\n    static_assert(sizeof(std::string) == 32);\n    static_assert(sizeof(User) == sizeof(UserC));\n    static_assert(offsetof(User, name) == offsetof(UserC, name));\n    static_assert(offsetof(User, comments_count) ==\n                  offsetof(UserC, comments_count));\n    static_assert(offsetof(User, uuid) == offsetof(UserC, uuid));\n  }\n\n  // [..]\n}\nWith that, we are certain that the layout in memory of the C++ class and the Rust struct are the same. We could probably generate all of these asserts, with a macro or with a code generator, but for this article, it\'s fine to do manually.\nSo let\'s rewrite the C++ method in Rust. We will for now leave out the\nname\nfield since it is a bit problematic. Later we will see how we can still use it from Rust:\n// Path: ./user-rs-lib/src/lib.rs\n\n#[no_mangle]\npub extern &quot;C&quot; fn RUST_write_comment(user: &amp;mut UserC, comment: *const u8, comment_len: usize) {\n    let comment = unsafe { std::slice::from_raw_parts(comment, comment_len) };\n    let comment_str = unsafe { std::str::from_utf8_unchecked(comment) };\n    println!(&quot;({:x?}) says: {}&quot;, user.uuid.as_slice(), comment_str);\n\n    user.comments_count += 1;\n}\nWe want to build a static library so we instruct\ncargo\nto do so by sticking these lines in\nCargo.toml\n:\n[lib]\ncrate-type = [&quot;staticlib&quot;]\nWe now build:\n$ cargo build\n# This is our artifact:\n$ ls target/debug/libuser_rs_lib.a\nWe can use our Rust function from C++ in\nmain\n, with some cumbersome casts:\n// Path: user.cpp\n\nint main() {\n  User alice{&quot;alice&quot;};\n  const char msg[] = &quot;hello, world!&quot;;\n  alice.write_comment(msg, sizeof(msg) - 1);\n\n  printf(&quot;Comment count: %lu\\n&quot;, alice.get_comment_count());\n\n  RUST_write_comment(reinterpret_cast&lt;UserC *&gt;(&amp;alice),\n                     reinterpret_cast&lt;const uint8_t *&gt;(msg), sizeof(msg) - 1);\n  printf(&quot;Comment count: %lu\\n&quot;, alice.get_comment_count());\n}\nAnd link (manually) our brand new Rust library to our C++ program:\n$ clang++ user.cpp ./user-rs-lib/target/debug/libuser_rs_lib.a\n$ ./a.out\nalice (336ff4cec0a2ccbfc0c4e4cb9ba7c152) says: hello, world!\nComment count: 1\n([33, 6f, f4, ce, c0, a2, cc, bf, c0, c4, e4, cb, 9b, a7, c1, 52]) says: hello, world!\nComment count: 2\nThe output is slightly different for the uuid, because we use in the Rust implementation the default\nDebug\ntrait to print the slice, but the content is the same.\nA couple of thoughts:\nThe calls\nalice.write_comment(..)\nand\nRUST_write_comment(alice, ..)\nare strictly equivalent and in fact, a C++ compiler will transform the former into the latter in a pure C++ codebase, if you look at the assembly generated. So our Rust function is just mimicking what the C++ compiler would do anyway. However, we are free to have the\nUser\nargument be in any position in the function. An other way to say it: We rely on the API, not the ABI, compatibility.\nThe Rust implementation can freely read and modify private members of the C++ class, for example the\ncomment_count\nfield is only accessible in C++ through the getter, but Rust can just access it as if it was public. That\'s because\npublic/private\nare just rules enforced by the C++ compiler. However your CPU does not know nor care. The bytes are the bytes. If you can access the bytes at runtime, it does not matter that they were marked \'private\' in the source code.\nWe have to use tedious casts which is normal. We are indeed reinterpreting memory from one type (\nUser\n) to another (\nUserC\n). This is allowed by the standard because the C++ class is a \'standard layout class\'. If it was not the case, this would be undefined behavior and likely work on some platforms but break on others.\nAccessing std::string from Rust\nstd::string\nshould be an opaque type from the perspective of Rust, because it is not the same across platforms or even compiler versions, so we cannot exactly describe its layout.\nBut we only want to access the underlying bytes of the string. We thus need a helper on the C++ side, that will extract these bytes for us.\nFirst, the Rust side. We define a helper type\nByteSliceView\nwhich is a pointer and a length (the equivalent of a\nstd::string_view\nin C++ latest versions and\n&amp;[u8]\nin Rust), and our Rust function now takes an additional parameter, the\nname\n:\n#[repr(C)]\n// Akin to `&amp;[u8]`, for C.\npub struct ByteSliceView {\n    pub ptr: *const u8,\n    pub len: usize,\n}\n\n\n#[no_mangle]\npub extern &quot;C&quot; fn RUST_write_comment(\n    user: &amp;mut UserC,\n    comment: *const u8,\n    comment_len: usize,\n    name: ByteSliceView, // &lt;-- Additional parameter\n) {\n    let comment = unsafe { std::slice::from_raw_parts(comment, comment_len) };\n    let comment_str = unsafe { std::str::from_utf8_unchecked(comment) };\n\n    let name_slice = unsafe { std::slice::from_raw_parts(name.ptr, name.len) };\n    let name_str = unsafe { std::str::from_utf8_unchecked(name_slice) };\n\n    println!(\n        &quot;{} ({:x?}) says: {}&quot;,\n        name_str,\n        user.uuid.as_slice(),\n        comment_str\n    );\n\n    user.comments_count += 1;\n}\nWe re-run cbindgen, and now C++ has access to the\nByteSliceView\ntype. We thus write a helper to convert a\nstd::string\nto this type, and pass the additional parameter to the Rust function (we also define a trivial\nget_name()\ngetter for\nUser\nsince\nname\nis still private):\n// Path: user.cpp\n\nByteSliceView get_std_string_pointer_and_length(const std::string &amp;str) {\n  return {\n      .ptr = reinterpret_cast&lt;const uint8_t *&gt;(str.data()),\n      .len = str.size(),\n  };\n}\n\n// In main:\nint main() {\n    // [..]\n  RUST_write_comment(reinterpret_cast&lt;UserC *&gt;(&amp;alice),\n                     reinterpret_cast&lt;const uint8_t *&gt;(msg), sizeof(msg) - 1,\n                     get_std_string_pointer_and_length(alice.get_name()));\n}\nWe re-build, re-run, and lo and behold, the Rust implementation now prints the name:\nalice (69b7c41491ccfbd28c269ea4091652d) says: hello, world!\nComment count: 1\nalice ([69, b7, c4, 14, 9, 1c, cf, bd, 28, c2, 69, ea, 40, 91, 65, 2d]) says: hello, world!\nComment count: 2\nAlternatively, if we cannot or do not want to change the Rust signature, we can make the C++ helper\nget_std_string_pointer_and_length\nhave a C convention and take a void pointer, so that Rust will call the helper itself, at the cost of numerous casts in and out of\nvoid*\n.\nImproving the std::string situation\nInstead of modeling\nstd::string\nas an array of bytes whose size is platform-dependent, we could move this field to the end of the C++ class and remove it entirely from Rust (since it is unused there). This would break\nsizeof(User) == sizeof(UserC)\n, it would now be\nsizeof(User) - sizeof(std::string) == sizeof(UserC)\n. Thus, the layout would be exactly the same (until the last field which is fine) between C++ and Rust. However, it will be an ABI breakage, if external users depend on the exact layout of the C++ class, and C++ constructors will have to be adapted since they rely on the order of fields. This approach is basically the same as the\nflexible array member\nfeature in C.\nIf allocations are cheap, we could store the name as a pointer:\nstd::string * name;\non the C++ side, and on the Rust side, as a void pointer:\nname: *const std::ffi::c_void\n, since pointers have a guaranteed size on all platforms. That has the advantage that Rust can access the data in\nstd::string\n, by calling a C++ helper with a C calling convention. But some will dislike that a naked pointer is being used in C++.\nConclusion\nWe now have successfully re-written a C++ class method. This technique is great because the C++ class could have hundreds of methods, in a real codebase, and we can still rewrite them one at a time, without breaking or touching the others.\nThe big caveat is that: the more C++ specific features and standard types the class is using, the more difficult this technique is to apply, necessitating helpers to make conversions from one type to another, and/or numerous tedious casts. If the C++ class is basically a C struct only using C types, it will be very easy.\nStill, I have employed this technique at work a lot and I really enjoy its relative simplicity and incremental nature.\nIt can also be in theory automated, say with tree-sitter or libclang to operate on the C++ AST:\nAdd a compile-time assert in the C++ class constructor to ensure it is a \'standard layout class\' e.g.\nstatic_assert(std::is_standard_layout_v&lt;User&gt;);\n. If this fails, skip this class, it requires manual intervention.\nGenerate the equivalent Rust struct e.g. the struct\nUserC.\nFor each field of the C++ class/Rust struct, add an compile-time assert to make sure the layout is the same e.g.\nstatic_assert(sizeof(User) == sizeof(UserC)); static_assert(offsetof(User, name) == offsetof(UserC, name));\n. If this fails, bail.\nFor each C++ method, generate an (empty) equivalent Rust function. E.g.\nRUST_write_comment\n.\nA developer implements the Rust function. Or AI. Or something.\nFor each call site in C++, replace the C++ method call by a call to the Rust function. E.g.\nalice.write_comment(..);\nbecomes\nRUST_write_comment(alice, ..);\n.\nDelete the C++ methods that have been rewritten.\nAnd boom, project rewritten.\nAddendum: the full code\nThe full code\n// Path: user.cpp\n\n#include &quot;user-rs-lib.h&quot;\n#include &lt;cstdint&gt;\n#include &lt;cstdio&gt;\n#include &lt;cstring&gt;\n#include &lt;string&gt;\n\nextern &quot;C&quot; ByteSliceView\nget_std_string_pointer_and_length(const std::string &amp;str) {\n  return {\n      .ptr = reinterpret_cast&lt;const uint8_t *&gt;(str.data()),\n      .len = str.size(),\n  };\n}\n\nclass User {\n  std::string name;\n  uint64_t comments_count;\n  uint8_t uuid[16];\n\npublic:\n  User(std::string name_) : name{name_}, comments_count{0} {\n    arc4random_buf(uuid, sizeof(uuid));\n\n    static_assert(std::is_standard_layout_v&lt;User&gt;);\n    static_assert(sizeof(std::string) == 32);\n    static_assert(sizeof(User) == sizeof(UserC));\n    static_assert(offsetof(User, name) == offsetof(UserC, name));\n    static_assert(offsetof(User, comments_count) ==\n                  offsetof(UserC, comments_count));\n    static_assert(offsetof(User, uuid) == offsetof(UserC, uuid));\n  }\n\n  void write_comment(const char *comment, size_t comment_len) {\n    printf(&quot;%s (&quot;, name.c_str());\n    for (size_t i = 0; i &lt; sizeof(uuid); i += 1) {\n      printf(&quot;%x&quot;, uuid[i]);\n    }\n    printf(&quot;) says: %.*s\\n&quot;, (int)comment_len, comment);\n    comments_count += 1;\n  }\n\n  uint64_t get_comment_count() { return comments_count; }\n\n  const std::string &amp;get_name() { return name; }\n};\n\nint main() {\n  User alice{&quot;alice&quot;};\n  const char msg[] = &quot;hello, world!&quot;;\n  alice.write_comment(msg, sizeof(msg) - 1);\n\n  printf(&quot;Comment count: %lu\\n&quot;, alice.get_comment_count());\n\n  RUST_write_comment(reinterpret_cast&lt;UserC *&gt;(&amp;alice),\n                     reinterpret_cast&lt;const uint8_t *&gt;(msg), sizeof(msg) - 1,\n                     get_std_string_pointer_and_length(alice.get_name()));\n  printf(&quot;Comment count: %lu\\n&quot;, alice.get_comment_count());\n}\n// Path: user-rs-lib.h\n\n#include &lt;cstdarg&gt;\n#include &lt;cstdint&gt;\n#include &lt;cstdlib&gt;\n#include &lt;ostream&gt;\n#include &lt;new&gt;\n\nstruct UserC {\n  uint8_t name[32];\n  uint64_t comments_count;\n  uint8_t uuid[16];\n};\n\nstruct ByteSliceView {\n  const uint8_t *ptr;\n  uintptr_t len;\n};\n\nextern &quot;C&quot; {\n\nvoid RUST_write_comment(UserC *user,\n                        const uint8_t *comment,\n                        uintptr_t comment_len,\n                        ByteSliceView name);\n\n} // extern &quot;C&quot;\n// Path: user-rs-lib/src/lib.rs\n\n#[repr(C)]\npub struct UserC {\n    pub name: [u8; 32],\n    pub comments_count: u64,\n    pub uuid: [u8; 16],\n}\n\n#[repr(C)]\n// Akin to `&amp;[u8]`, for C.\npub struct ByteSliceView {\n    pub ptr: *const u8,\n    pub len: usize,\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn RUST_write_comment(\n    user: &amp;mut UserC,\n    comment: *const u8,\n    comment_len: usize,\n    name: ByteSliceView,\n) {\n    let comment = unsafe { std::slice::from_raw_parts(comment, comment_len) };\n    let comment_str = unsafe { std::str::from_utf8_unchecked(comment) };\n\n    let name_slice = unsafe { std::slice::from_raw_parts(name.ptr, name.len) };\n    let name_str = unsafe { std::str::from_utf8_unchecked(name_slice) };\n\n    println!(\n        &quot;{} ({:x?}) says: {}&quot;,\n        name_str,\n        user.uuid.as_slice(),\n        comment_str\n    );\n\n    user.comments_count += 1;\n}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#1948100756-the-trick",
"#2877789738-example",
"#3377210712-accessing-std-string-from-rust",
"#3494226560-improving-the-std-string-situation",
"#3796851539-conclusion",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
857,1882,9340,12004,13144,14851,],
},
{
name:"tip_of_day_1.html",
text:"Tip of the day #1: Count lines of Rust code, ignoring tests\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-10-29\nTip of the day #1: Count lines of Rust code, ignoring tests\nRust\nTip of the day\nAwk\nTable of contents\nAddendum: exit\nI have a Rust codebase at work. The other day, I was wondering how many lines of code were in there. Whether you use\nwc -l ***.rs\nor a more fancy tool like\ntokei\n, there is an issue: this will count the source code\nas well as\ntests.\nThat\'s because in Rust and in some other languages, people write their tests in the same files as the implementation. Typically it looks like that:\n// src/foo.rs\n\nfn foo() { \n ...\n}\n\n#[cfg(test)]\nmod tests {\n    fn test_foo(){\n      ...\n    }\n\n    ...\n}\nBut I only want to know how big is the implementation. I don\'t care about the tests. And\nwc\nor\ntokei\nwill not show me that.\nSo I resorted to my trusty\nawk\n. Let\'s first count all lines, like\nwc\ndoes:\n$ awk \'{count += 1} END{print(count)}\' src/***.rs\n# Equivalent to:\n$ wc -l src/***/.rs\nOn my open-source Rust\nproject\n, this prints\n11485\n.\nAlright, now let\'s exclude the tests. When we encounter the line\nmod tests\n, we stop counting. Note that this name is just a convention, but that\'s one that followed pretty much universally in Rust code, and there is usually no more code after this section. Tweak the name if needed:\n$ awk \'/mod tests/{skip[FILENAME]=1}  !skip[FILENAME]{count += 1} END{print(count)}\'  src/***.rs\nAnd this prints in the same project:\n10057\n.\nLet\'s unpack it:\nWe maintain a hashtable called\nskip\nwhich is a mapping of the file name to whether or not we should skip the rest of this file. In AWK we do not need to initialize variables, we can use them right away and they are zero initialized. AWK also automatically stores the name of the current file in the global builtin variable\nFILENAME\n.\n/mod tests/\n: this pattern matches the line containing\nmod tests\n. The action for this line is to flag this file as \'skipped\', by setting the value in the map for this file to\n1\n(i.e.\ntrue\n).\n!skip[FILENAME]{count += 1}\n: If this line for the current file is not flagged as \'skipped\', we increment for each line, the global counter. Most people think that AWK can only use patterns as clauses before the action, but in fact it also supports boolean conditions, and both can be use together, e.g.:\n/foo/ &amp;&amp; !skip[FILENAME] {print(&quot;hello&quot;)}\nEND{print(count)}\n: we print the count at the very end.\nAnd that\'s it. AWK is always very nifty.\nAddendum: exit\nOriginally I implemented it wrongly, like this:\n$ awk \'/mod tests/{exit 0} {count += 1} END{print(count)}\'  src/***.rs\nIf we encounter tests, stop processing the file altogether, with the builtin statement\nexit\n(\ndocs\n).\nRunning this on the same Rust codebase prints:\n1038\nwhich is obviously wrong.\nWhy is it wrong then?\nWell, as I understand it, AWK processes all inputs files one by one, as if it was one big sequential file (it will still fill the builtin constant\nFILENAME\nthough, that\'s why the solution above works). Since there is no isolation between the processing each file (AWK does not spawn a subprocess for each file), it means we simply stop altogether at the first encountered test in any file.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#4091184562-addendum-exit",
],
title_text_offsets:[
2537,],
},
{
name:"tip_of_the_day_2.html",
text:"Tip of the day #2: A safer arena allocator\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-10-29\nTip of the day #2: A safer arena allocator\nC\nAllocator\nSafety\nTip of the day\nTable of contents\nThe standard arena\nThe bug\nThe solution\nVariations\nThe paranoid approach\nThe bucket per type approach\nSee also\nDiscussions:\n/r/programming\n,\n/r/cprogramming\nThe most transformative action you can do to dramatically improve your code in a programming language where you are in control of the memory is: to use arenas.\nMuch has been written about arenas (\n1\n,\n2\n). In short, it means grouping multiple allocations with the same lifetime in one batch that gets allocated and deallocated only once.\nAnother way to look at it, is that the allocations are append only. They never get freed during their \'life\'. The program is split into \'phases\'. Typically, each phase has its own arena, and when it reaches its end, the whole arena gets nuked from space along with all entities allocated from it. It\'s a great way to simplify the code, make it faster, and escape from the \'web of pointers\' hell.\nThe standard arena\nA typical arena looks like that:\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;unistd.h&gt;\n\ntypedef struct {\n  uint8_t *start;\n  uint8_t *end;\n} Arena;\n\nstatic Arena arena_make_from_virtual_mem(uint64_t size) {\n  uint8_t *alloc = mmap(nullptr, size, PROT_READ | PROT_WRITE,\n                   MAP_ANON | MAP_PRIVATE, -1, 0);\n  return (Arena){.start = alloc, .end = alloc + size};\n}\n\nstatic void *\narena_alloc(Arena *a, uint64_t size, uint64_t align, uint64_t count) {\n  const uint64_t padding = (-(uint64_t)a-&gt;start &amp; (align - 1));\n  const int64_t available = (int64_t)a-&gt;end - (int64_t)a-&gt;start - (int64_t)padding;\n\n  void *res = a-&gt;start + padding;\n\n  a-&gt;start += padding + count * size;\n\n  return memset(res, 0, count * size);\n}\n\nint main() {\n  Arena a = arena_make_from_virtual_mem(4096);\n}\nVery simple, just ask the OS to give us a region of virtual memory and off we go (on Windows, the system call is named differently but is equivalent).\nThe bug\nNow, since we use a system call directly, sanitizers and runtime checks from the libc allocator do not apply, since we bypass them completely. In a way, it is also a feature: it means that our program will behave exactly the same on all OSes, have the exact same memory layout, and use the exact same amount of memory. It does not depend on the libc or allocator.\nSo it turns out that I had a bug in my code: I allocated an array from the arena, and then accidentally wrote past the bounds of my array (so far, this sounds like a typical story from the C trenches).\nNormally, this would likely (depending on a few factors, like where in the arena was this allocation located, how big was it, and by how many bytes did the write go past the bounds, etc) write past the memory page that the OS gave us, thus triggering a\nSIGSEGV\n.\nHowever, in that instance, I got unlucky, because my code actually did something like that:\nint main() {\n  Arena a = arena_make_from_virtual_mem(4096);\n  Arena b = arena_make_from_virtual_mem(4096);\n\n  // Simulate writing past the arena:\n  a.start + 5000 = 42;\n}\nAnd...the program did not crash. The symptoms were very weird: data was subtly wrong in another place of the program, thus making it very difficult to troubleshoot. That\'s basically the nightmare scenario for any engineer. A crash would be so much easier.\nBut why?\nWell, we basically asked the OS to give us one page of virtual memory when creating the first arena. Right after, we asked for a second page. And most often than not, the OS gives us then a page right after the first page. So from the OS perspective, we allocated\n2 * 4096 = 8192\nbytes, and wrote in the middle, so all is good. We wanted to write into the first arena but instead wrote into the second one accidentally.\nThis behavior is however not consistent, running the programs many times will sometimes crash and sometimes not. It all depends if the memory pages for the different arenas are contiguous or not.\nThe solution\nSo how do we fix it? What I did was defense in depth:\nAdd asserts everywhere I could to check pre- and post-conditions. I believe that\'s how I discovered the bug in the first place, when one assert failed, even though it seemed impossible.\nReplace all direct array and pointer accesses with macros that check bounds (like most modern programming languages)\nTweak how the arena is created to make it safer. That\'s our tip of the day, so let\'s see it.\nThe idea is not new, most allocators do so in \'hardening\' mode: when the arena is created, we place a \'guard page\' right before and after the real allocation.\nWe mark these guard pages as neither readable nor writable, so any access will trigger a\nSIGSEGV\n, even though that\'s memory owned by our program.\nThat way, going slightly past the bounds of the real allocation in either direction, will result in a crash that\'s easy to diagnose.\nNote that this is a trade-off:\nIt will not catch all out-of-bounds accesses. We could get unlucky and accidentally hit the memory of another arena still. This is a protection that typically helps with off-by-one errors.\nIt\'s very lightweight: the OS only has to maintain an entry in a table, recording that the program owns the two additional pages (per arena). No actually physical memory will be dedicated for them. But, if there are millions of arenas, it could make a difference.\nIt\'s theoretically tunable: nothing prevents us from having larger guard \'regions\'. If we are paranoid, we could make the guard region 64 Gib before and after the real allocation of 4096 bytes, if we wish. That\'s the power of virtual memory.\nThe granularity is still the page (typically 4096 bytes, something larger). We cannot easily prevent out-of-bounds accesses within a page.\nThe original implementation at the beginning of the article did not have to bother with the size of a page. But this implementation has to, which slightly complicates the logic (but not by much).\nSo here it is:\nstatic Arena arena_make_from_virtual_mem(uint64_t size) {\n  uint64_t page_size = (uint64_t)sysconf(_SC_PAGE_SIZE);\n  uint64_t alloc_real_size = round_up_multiple_of(size, page_size);\n\n  // Page guard before + after.\n  uint64_t mmap_size = alloc_real_size + 2 * page_size;\n\n  uint8_t *alloc = mmap(nullptr, mmap_size, PROT_READ | PROT_WRITE,\n                   MAP_ANON | MAP_PRIVATE, -1, 0);\n\n  uint64_t page_guard_before = (uint64_t)alloc;\n\n  alloc += page_size;\n  uint64_t page_guard_after = (uint64_t)alloc + alloc_real_size;\n\n  mprotect((void *)page_guard_before, page_size, PROT_NONE);\n  mprotect((void *)page_guard_after, page_size, PROT_NONE);\n\n  return (Arena){.start = alloc, .end = alloc + size};\n}\nWe get the page size with POSIX\'s\nsysconf (3)\n. Again, that\'s required because we will use the system call\nmprotect\nto change the permissions on parts of the memory, and\nmprotect\nexpects a page-aligned memory range.\nSince an allocation is at least one page, even if the user asked for an arena of size\n1\n, we first round the user allocation size up, to the next page size. E.g. for a page size of\n4096\n:\n1 -&gt; 4096\n,\n4095 -&gt; 4096\n,\n4096 -&gt; 4096\n,\n4097 -&gt; 8192\n.\nThen, in one\nmmap\ncall, we allocate all the memory we need including the two guard pages. For a brief moment, all the memory is readable and writable. The very next thing we do is mark the first page and last page as neither readable nor writable. We then return the arena, and the user is none the wiser.\nWouldn\'t it be simpler to issue 3\nmmap\ncalls with the right permissions from the get go? Well, yes, but there is no guarantee that the OS would give us a contiguous region of memory across these 3 calls. On Linux, we can give hints, but still there is no guarantee. Remember, our program is one of many running concurrently, and could get interrupted for some time between these\nmmap\ncalls, the whole OS could go to sleep, etc. What we want is an atomic operation, thus, one\nmmap\ncall.\nNote, we can alternatively create the whole allocation as\nPROT_NONE\nand then mark the real (user-visible) allocation as\nPROT_READ | PROT_WRITE\n, that also works.\nSo that\'s it, a poor man Adress Sanitizer in a few lines of code.\nVariations\nThe paranoid approach\nIf we are really paranoid, we could change how the arena works, to make every allocation get a new, separate page from the OS. That means that creating the arena would do nothing, and allocating from the arena would do the real allocation. This approach is, to me, indistinguishable from a general purpose allocator a la\nmalloc\nfrom libc, just one that\'s very naive, and probably much slower.\nBut, if there is a pesky out-of-bound bug pestering you, that could be worth trying.\nThe bucket per type approach\nOn\nApple platforms\n, the libc allocator has a hardening mode that can be enabled at compile time. It stems from the realization that many security vulnerabilities rely on type confusion: The program thinks it is handling an entity of type\nX\n, but due to a logic bug, or the attacker meddling, or the allocator reusing freshly freed memory from another place in the program, it is actually of another type\nY\n. This results in an entity being in an \'impossible\' state which is great for an attacker. Also, reusing a previously allocated-then-freed object with a different type, without zero-initializing it, can leak secrets or information about the state of the program, to an attacker.\nThere\'s a whole class of attacks where the first step is to make the program allocate and free objects many times, of an attacker controlled size, so that the heap is in the right \'shape\', with a high statistical chance. Meaning, a few targeted objects are next to each other in the heap, for the attack to occur.\nSo, the mitigation is to place all allocations of the same type in one bucket (supposedly, it\'s a separate memory region with guard pages before and after). When an object of type\nX\nis allocated, then freed, and then the program allocates an object of type\nY\n, of roughly the same size, a typical allocator will reuse the memory of\nX\n. This Apple allocator would give memory from a separate bucket, from a completely different memory region.\nWhat I don\'t know, is whether or not there are runtime checks as well, for example when casting one object from one type to another e.g. from\nX\nto\nvoid*\n, back to\nX\n, with\nreinterpret_cast\nin C++. It seems that this allocator would have the information needed at runtime to do so, which could be an interesting feature.\nNow, having one bucket per type turns out to be too slow in reality, and consumes too much memory, according to Apple developers, so this allocator groups a handful a different types in one bucket. This is a typical trade-off between performance and security.\nStill, this is an interesting approach, and could be implemented in our context by having one arena store all entities of one type, i.e. one arena is one bucket.\nSee also\nAstute readers have also mentioned: using canaries in the available space in the arena to detect illegal accesses, putting the real data at the start or end of the page to catch out-of-bounds accesses respectively before and after the allocation, periodic checks for long-running applications, randomizing where the guard pages are placed relative to the allocation, running the tests a number of times to catch inconsistent behavior, and finally, teaching Address Sanitizer to be aware of our custom arena allocator so that it does these checks for us. That\'s super cool! See the linked discussions at the start.\nI wrote in the past about adding memory profiling an arena allocator:\nRoll your own memory profiling: it\'s actually not hard\n.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3570727127-the-standard-arena",
"#366874779-the-bug",
"#1807516660-the-solution",
"#2175727336-variations",
"#3293170840-the-paranoid-approach",
"#332247973-the-bucket-per-type-approach",
"#3625827200-see-also",
],
title_text_offsets:[
1131,2162,4143,8323,8334,8834,11047,],
},
{
name:"lessons_learned_from_a_successful_rust_rewrite.html",
text:"Lessons learned from a successful Rust rewrite\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-10-30\nLessons learned from a successful Rust rewrite\nRust\nC++\nRewrite\nTable of contents\nWhat worked well\nWhat did not work so well\nI am still chasing Undefined Behavior\nMiri does not always work and I still have to use Valgrind\nI am still chasing memory leaks\nCross-compilation does not always work\nCbindgen does not always work\nUnstable ABI\nNo support for custom memory allocators\nComplexity\nConclusion\nDiscussions:\n/r/rust\n,\n/r/programming\n,\nHN\n,\nlobsters\nI have written about my on-going rewrite-it-to-Rust effort at work:\n1\n,\n2\n,\n3\n. And now it\'s finished, meaning it\'s 100% Rust and 0% C++ - the public C API has not changed, just the implementation, one function at time until the end. Let\'s have a look back at what worked, what didn\'t, and what can be done about it.\nFor context, I have written projects in pure Rust before, so I won\'t mention all of the usual Rust complaints, like &quot;learning it is hard&quot;, they did not affect me during this project.\nWhat worked well\nThe rewrite was done incrementally, in a stop-and-go fashion. At some point, as I expected, we had to add brand new features while the rewrite was on-going and that was very smooth with this approach. Contrast this with the (wrong) approach of starting a new codebase from scratch in parallel, and then the feature has to be implemented twice.\nThe new code is much, much simpler and easier to reason about. It is roughly the same number of lines of code as the old C++ codebase, or slightly more. Some people think that equivalent Rust code will be much shorter (I have heard ratios of 1/2 or 2/3), but in my experience, it\'s not really the case. C++ can be incredibly verbose in some instances, but Rust as well. And the C++ code will often ignore some errors that the Rust compiler forces the developer to handle, which is a good thing, but also makes the codebase slightly bigger.\nUndergoing a rewrite, even a bug-for-bug one like ours, opens many new doors in terms of performance. For example, some fields in C++ were assumed to be of a dynamic size, but we realized that they were always 16 bytes according to business rules, so we stored them in an array of a fixed size, thus simplifying lots of code and reducing heap allocations. That\'s not strictly due to Rust, it\'s just that having this holistic view of the codebase yields many benefits.\nRelated to this: we delete lots and lots of dead code. I estimate that we removed perhaps a third or half of the whole C++ codebase because it was simply never used. Some of it were half-assed features some long-gone customer asked for, and some were simply never run or even worse, never even built (they were C++ files not even present in the CMake build system). I feel that modern programming languages such as Rust or Go are much more aggressive at flagging dead code and pestering the developer about it, which again, is a good thing.\nWe don\'t have to worry about out-of-bounds accesses and overflow/underflows with arithmetic. These were the main issues in the C++ code. Even if C++ containers have this\n.at()\nmethod to do bounds check, in my experience, most people do not use them. It\'s nice that this happens by default. And overflows/underflows checks are typically never addressed in C and C++ codebases.\nCross-compilation is pretty smooth, although not always, see next section.\nThe builtin test framework in Rust is very serviceable. All the ones I used in C++ were terrible and took so much time to even compile.\nRust is much more concerned with correctness than C++, so it sparked a lot of useful discussions. For example: oh, the Rust compiler is forcing me to check if this byte array is valid UTF8 when I try to convert it to a string. The old C++ code did no such check. Let\'s add this check.\nIt felt so good to remove all the CMake files. On all the C or C++ projects I worked on, I never felt that CMake was worth it and I always lost a lot of hours to coerce it into doing what I needed.\nWhat did not work so well\nThis section is surprisingly long and is the most interesting in my opinion. Did Rust hold its promises?\nI am still chasing Undefined Behavior\nDoing an incremental rewrite from C/C++ to Rust, we had to use a lot of raw pointers and\nunsafe{}\nblocks. And even when segregating these to the entry point of the library, they proved to be a big pain in the neck.\nAll the stringent rules of Rust still apply inside these blocks but the compiler just stops checking them for you, so you are on your own. As such, it\'s so easy to introduce Undefined Behavior. I honestly think from this experience that it is easier to inadvertently introduce Undefined Behavior in Rust than in C++, and it turn, it\'s easier in C++ than in C.\nThe main rule in Rust is:\nmultiple read-only pointers XOR one mutable pointer\nmultiple read-only reference XOR one mutable reference\n. That\'s what the borrow checker is always pestering you about.\nBut when using raw pointers, it\'s so easy to silently break, especially when porting C or C++ code as-is, which is mutation and pointer heavy:\nNote: Astute readers have pointed out that the issue in the snippet below is having multiple mutable references, not pointers, and that using the syntax\nlet a = &amp;raw mut x;\nin recent Rust versions, or\naddr_of_mut\nin older versions, avoids creating multiple mutable references.\nfn main() {\n    let mut x = 1;\n    unsafe {\n        let a: *mut usize = &amp;mut x;\n        let b: *mut usize = &amp;mut x;\n\n        *a = 2;\n        *b = 3;\n    }\n}\nYou might think that this code is dumb and obviously wrong, but in a big real codebase, this is not so easy to spot, especially when these operations are hidden inside helper functions or layers and layers of abstraction, as Rust loves to do.\ncargo run\nis perfectly content with the code above. The Rust compiler can and will silently assume that there is only one mutable pointer to\nx\n, and make optimizations, and generate machine code, based on that assumption, which this code breaks.\nThe only savior here is\nMiri\n:\n$ cargo +nightly-2024-09-01 miri r\nerror: Undefined Behavior: attempting a write access using &lt;2883&gt; at alloc1335[0x0], but that tag does not exist in the borrow stack for this location\n --&gt; src/main.rs:7:9\n  |\n7 |         *a = 2;\n  |         ^^^^^^\n  |         |\n  |         attempting a write access using &lt;2883&gt; at alloc1335[0x0], but that tag does not exist in the borrow stack for this location\n  |         this error occurs as part of an access at alloc1335[0x0..0x8]\n  |\n  [...]\n --&gt; src/main.rs:4:29\n  |\n4 |         let a: *mut usize = &amp;mut x;\n  |                             ^^^^^^\nhelp: &lt;2883&gt; was later invalidated at offsets [0x0..0x8] by a Unique retag\n --&gt; src/main.rs:5:29\n  |\n5 |         let b: *mut usize = &amp;mut x;\n  |                             ^^^^^^\n  [...]\nSo, what could have been a compile time error, is now a runtime error. Great. I hope you have 100% test coverage! Thank god there\'s Miri.\nIf you are writing\nunsafe{}\ncode without Miri checking it, or if you do so without absolutely having to, I think this is foolish. It will blow up in your face.\nMiri is awesome. But...\nMiri does not always work and I still have to use Valgrind\nI am not talking about some parts of Miri that are experimental. Or the fact that running code under Miri is excruciatingly slow. Or the fact that Miri only works in\nnightly\n.\nNo, I am talking about code that Miri cannot run, period:\n|\n471 |     let pkey_ctx = LcPtr::new(unsafe { EVP_PKEY_CTX_new_id(EVP_PKEY_EC, null_mut()) })?;\n    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ can\'t call foreign function `\u{2401}aws_lc_0_16_0_EVP_PKEY_CTX_new_id` on OS `linux`\n    |\n    = help: if this is a basic API commonly used on this target, please report an issue with Miri\n    = help: however, note that Miri does not aim to support every FFI function out there; for instance, we will not support APIs for things such as GUIs, scripting languages, or databases\nIf you are using a library that has parts written in C or assembly, which is usual for cryptography libraries, or video compression, etc, you are out of luck.\nSo we resorted to add a feature flag to split the codebase between parts that use this problematic library and parts that don\'t. And Miri only runs tests with the feature disabled.\nThat means that there is a lot of\nunsafe\ncode that is simply not being checked right now. Bummer.\nPerhaps there could be a fallback implementation for these libraries that\'s entirely implemented in software (and in pure Rust). But that\'s not really feasible for most libraries to maintain two implementations just for Rust developers.\nI resorted to run the problematic tests in\nvalgrind\n, like I used to do with pure C/C++ code. It does not detect many things that Miri would, for example having more than one mutable pointer to the same value, which is perfectly fine in C/C++/Assembly, but not in Rust.\nI am still chasing memory leaks\nOur library offers a C API, something like this:\nvoid* handle = MYLIB_init();\n\n// Do some stuff with the handle...\n\nMYLIB_release(handle);\nUnder the hood,\nMYLIB_init\nallocates some memory and\nMYLIB_release()\nfrees it. This is a very usual pattern in C libraries, e.g.\ncurl_easy_init()/curl_easy_cleanup()\n.\nSo immediately, you are thinking: well, it\'s easy to forget to call\nMYLIB_release\nin some code paths, and thus leak memory. And you\'d be right. So let\'s implement them to illustrate. We are good principled developers so we write a Rust test:\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_init() -&gt; *mut std::ffi::c_void {\n    let alloc = Box::leak(Box::new(1usize));\n\n    alloc as *mut usize as *mut std::ffi::c_void\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_do_stuff(_handle: *mut std::ffi::c_void) {\n    // Do some stuff.\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_release(handle: *mut std::ffi::c_void) {\n    let _ = unsafe { Box::from_raw(handle as *mut usize) };\n}\n\nfn main() {}\n\n#[cfg(test)]\nmod test {\n    #[test]\n    fn test_init_release() {\n        let x = super::MYLIB_init();\n\n        super::MYLIB_do_stuff(x);\n\n        super::MYLIB_release(x);\n    }\n}\nA Rust developer first instinct would be to use RAII by creating a wrapper object which implements\nDrop\nand automatically calls the cleanup function.\nHowever, we wanted to write our tests using the public C API of the library like a normal C application would, and it would not have access to this Rust feature.\nAlso, it can become unwieldy when there are tens of types that have an allocation/deallocation function. It\'s a lot of boilerplate!\nAnd often, there is complicated logic with lots of code paths, and we need to ensure that the cleanup is always called. In C, this is typically done with\ngoto\nto an\nend:\nlabel that always cleans up the resources. But Rust does not support this form of\ngoto\n.\nSo we solved it with the\ndefer\ncrate in Rust and implementing a\ndefer\nstatement in C++.\nHowever, the Rust borrow checker really does not like the\ndefer\npattern. Typically, a cleanup function will take as its argument as\n&amp;mut\nreference and that precludes the rest of the code to also store and use a second\n&amp;mut\nreference to the same value. So we could not always use\ndefer\non the Rust side.\nCross-compilation does not always work\nSame issue as with Miri, using libraries with a Rust API but with parts implemented in C or Assembly will make\ncargo build --target=...\nnot work out of the box. It won\'t affect everyone out there, and perhaps it can be worked around by providing a sysroot like in C or C++. But that\'s a bummer still. For example, I think Zig manages this situation smoothly for most targets, since it ships with a C compiler and standard library, whereas\ncargo\ndoes not.\nCbindgen does not always work\ncbindgen\nis a conventionally used tool to generate a C header from a Rust codebase. It mostly works, until it does not. I hit quite a number of limitations or bugs. I thought of contributing PRs, but I found for most of these issues, a stale open PR, so I didn\'t. Every time, I thought of dumping\ncbindgen\nand writing all of the C prototypes by hand. I think it would have been simpler in the end.\nAgain, as a comparison, I believe Zig has a builtin C header generation tool.\nUnstable ABI\nI talked about this point in my previous articles so I won\'t be too long. Basically, all the useful standard library types such as\nOption\nhave no stable ABI, so they have to be replicated manually with the\nrepr(C)\nannotation, so that they can be used from C or C++. This again is a bummer and creates friction. Note that I am equally annoyed at C++ ABI issues for the same reason.\nMany, many hours of hair pulling would be avoided if Rust and C++ adopted, like C, a\nstable ABI\n.\nNo support for custom memory allocators\nWith lots of C libraries, the user can provide its own allocator at runtime, which is often very useful. In Rust, the developer can only pick the global allocator at compile time. So we did not attempt to offer this feature in the library API.\nAdditionally, all of the aforementioned issues about cleaning up resources would have been instantly fixed by using an\narena allocator\n, which is not at all idiomatic in Rust and does not integrate with the standard library (even though there are crates for it). Again, Zig and Odin all support arenas natively, and it\'s trivial to implement and use them in C. I really longed for an arena while chasing subtle memory leaks.\nComplexity\nFrom the start, I decided I would not touch async Rust with a ten-foot pole, and I did not miss it at all, for this project.\nWhilst reading the docs for\nUnsafeCell\nfor the fourth time, and pondering whether I should use that or\nRefCell\n, while just having been burnt by the pitfalls of\nMaybeUninit\n, and asking myself if I need\nPin\n, I really asked myself what life choices had led me to this.\nPure Rust is already very complex, but add to it the whole layer that is mainly there to deal with FFI, and it really becomes a beast. Especially for new Rust learners.\nSome developers in our team straight declined to work on this codebase, mentioning the real or perceived Rust complexity.\nNow, I think that Rust is still mostly easier to learn than C++, but admittedly not by much, especially in this FFI heavy context.\nConclusion\nI am mostly satisfied with this Rust rewrite, but I was disappointed in some areas, and it overall took much more effort than I anticipated. Using Rust with a lot of C interop feels like using a completely different language than using pure Rust. There is much friction, many pitfalls, and many issues in C++, that Rust claims to have solved, that are in fact not really solved at all.\nI am deeply grateful to the developers of Rust, Miri, cbindgen, etc. They have done tremendous work. Still, the language and tooling, when doing lots of C FFI, feel immature, almost pre v1.0. If the ergonomics of\nunsafe\n(which are being worked and slightly improved in the recent versions), the standard library, the docs, the tooling, and the unstable ABI, all improve in the future, it could become a more pleasant experience.\nI think that all of these points have been felt by Microsoft and Google, and that\'s why they are investing real money in this area to improve things.\nIf you do not yet know Rust, I recommend for your first project to use pure Rust, and stay far away from the whole FFI topic.\nI initially considered using Zig or Odin for this rewrite, but I really did not want to use a pre v1.0 language for an enterprise production codebase (and I anticipated that it would be hard to convince other engineers and managers). Now, I am wondering if the experience would have really been worse than with Rust. Perhaps the Rust model is really at odds with the C model (or with the C++ model for that matter) and there is simply too much friction when using both together.\nIf I have to undertake a similar effort in the future, I think I would strongly consider going with Zig instead. We\'ll see. In any case, the next time someone say \'just rewrite it in Rust\', point them to this article, and ask them if that changed their mind ;)\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#1596753652-what-worked-well",
"#3041159231-what-did-not-work-so-well",
"#2006554032-i-am-still-chasing-undefined-behavior",
"#2694732638-miri-does-not-always-work-and-i-still-have-to-use-valgrind",
"#2584141995-i-am-still-chasing-memory-leaks",
"#1568320768-cross-compilation-does-not-always-work",
"#929959896-cbindgen-does-not-always-work",
"#3393406502-unstable-abi",
"#2235693709-no-support-for-custom-memory-allocators",
"#3763530832-complexity",
"#3796851539-conclusion",
],
title_text_offsets:[
1111,4091,4222,7277,9075,11399,11893,12399,12891,13600,14427,],
},
{
name:"tip_of_day_3.html",
text:"Tip of the day #3: Convert a CSV to a markdown or HTML table\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-10-31\nTip of the day #3: Convert a CSV to a markdown or HTML table\nMarkdown\nCsv\nAwk\nTip of the day\nThe other day at work, I found myself having to produce a human-readable table of all the direct dependencies in the project, for auditing purposes.\nThere is a\ntool\nfor Rust projects that outputs a TSV (meaning: a CSV where the separator is the tab character) of this data. That\'s great, but not really fit for consumption by a non-technical person.\nI just need to convert that to a human readable table in markdown or HTML, and voila!\nHere\'s the output of this tool in my open-source Rust\nproject\n:\n$ cargo license --all-features --avoid-build-deps --avoid-dev-deps --direct-deps-only --tsv\nname\tversion\tauthors\trepository\tlicense\tlicense_file\tdescription\nclap\t2.33.0\tKevin K. &lt;kbknapp@gmail.com&gt;\thttps://github.com/clap-rs/clap\tMIT\t\tA simple to use, efficient, and full-featured Command Line Argument Parser\nheck\t0.3.1\tWithout Boats &lt;woboats@gmail.com&gt;\thttps://github.com/withoutboats/heck\tApache-2.0 OR MIT\t\theck is a case conversion library.\nkotlin\t0.1.0\tPhilippe Gaultier &lt;philigaultier@gmail.com&gt;\t\t\t\t\nlog\t0.4.8\tThe Rust Project Developers\thttps://github.com/rust-lang/log\tApache-2.0 OR MIT\t\tA lightweight logging facade for Rust\npretty_env_logger\t0.3.1\tSean McArthur &lt;sean@seanmonstar&gt;\thttps://github.com/seanmonstar/pretty-env-logger\tApache-2.0 OR MIT\t\ta visually pretty env_logger\ntermcolor\t1.1.0\tAndrew Gallant &lt;jamslam@gmail.com&gt;\thttps://github.com/BurntSushi/termcolor\tMIT OR Unlicense\t\tA simple cross platform library for writing colored text to a terminal.\nNot really readable. We need to transform this data into a\nmarkdown table\n, something like that:\n| First Header  | Second Header |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n| Content Cell  | Content Cell  |\nTechnically, markdown tables are an extension to standard markdown (if there is such a thing), but they are very common and supported by all the major platforms e.g. Github, Azure, etc. So how do we do that?\nOnce again, I turn to the trusty AWK. It\'s always been there for me. And it\'s present on every UNIX system out of the box.\nAWK neatly handles all the \'decoding\' of the CSV format for us, we just need to output the right thing:\nGiven a line (which AWK calls \'record\'): output each field interleaved with the\n|\ncharacter\nOutput a delimiting line between the table headers and rows. The markdown table spec states that this delimiter should be at least 3\n-\ncharacters in each cell.\nAlignment is not a goal, it does not matter for a markdown parser. If you want to produce a pretty markdown table, it\'s easy to achieve, it simply makes the implementation a bit bigger\nHere\'s the full implementation (don\'t forget to mark the file executable). The shebang line instructs AWK to use the tab character\n\\t\nas the delimiter between fields:\n#!/usr/bin/env -S awk -F \'\\t\' -f\n\n{\n    printf(&quot;|&quot;);\n    for (i = 1; i &lt;= NF; i++) {\n        # Note: if a field contains the character `|`,\n        # it will mess up the table.\n        # In this case, we should replace this character\n        # by something else e.g. `,`:\n        gsub(/\\|/, &quot;,&quot;, $i);\n        printf(&quot; %s |&quot;, $i);\n    } \n    printf(&quot;\\n&quot;);\n} \n\nNR==1 { # Output the delimiting line\n    printf(&quot;|&quot;);\n    for(i = 1; i &lt;= NF; i++) {\n        printf(&quot; --- | &quot;);\n    }\n    printf(&quot;\\n&quot;);\n}\nThe first clause will execute for each line of the input.\nThe for loop then iterates over each field and outputs the right thing.\nThe second clause will execute only for the first line (\nNR\nis the line number).\nThe same line can trigger multiple clauses, here, the first line of the input will trigger both clauses, whilst the remaining lines will only trigger the first clause.\nSo let\'s run it!\n$ cargo license --all-features --avoid-build-deps --avoid-dev-deps --direct-deps-only --tsv | ./md-table.awk \n| name | version | authors | repository | license | license_file | description |\n| --- |  --- |  --- |  --- |  --- |  --- |  --- | \n| clap | 2.33.0 | Kevin K. &lt;kbknapp@gmail.com&gt; | https://github.com/clap-rs/clap | MIT |  | A simple to use, efficient, and full-featured Command Line Argument Parser |\n| heck | 0.3.1 | Without Boats &lt;woboats@gmail.com&gt; | https://github.com/withoutboats/heck | Apache-2.0 OR MIT |  | heck is a case conversion library. |\n| kotlin | 0.1.0 | Philippe Gaultier &lt;philigaultier@gmail.com&gt; |  |  |  |  |\n| log | 0.4.8 | The Rust Project Developers | https://github.com/rust-lang/log | Apache-2.0 OR MIT |  | A lightweight logging facade for Rust |\n| pretty_env_logger | 0.3.1 | Sean McArthur &lt;sean@seanmonstar&gt; | https://github.com/seanmonstar/pretty-env-logger | Apache-2.0 OR MIT |  | a visually pretty env_logger |\n| termcolor | 1.1.0 | Andrew Gallant &lt;jamslam@gmail.com&gt; | https://github.com/BurntSushi/termcolor | MIT OR Unlicense |  | A simple cross platform library for writing colored text to a terminal. |\nOk, it\'s hard to really know if that\'s correct or not. Let\'s pipe it into\ncmark-gfm\nto render this markdown table as HTML:\n$ cargo license --all-features --avoid-build-deps --avoid-dev-deps --direct-deps-only --tsv | ./md-table.awk | cmark-gfm -e table\nAnd voila:\nname\nversion\nauthors\nrepository\nlicense\nlicense_file\ndescription\nclap\n2.33.0\nKevin K.\nkbknapp@gmail.com\nhttps://github.com/clap-rs/clap\nMIT\nA simple to use, efficient, and full-featured Command Line Argument Parser\nheck\n0.3.1\nWithout Boats\nwoboats@gmail.com\nhttps://github.com/withoutboats/heck\nApache-2.0 OR MIT\nheck is a case conversion library.\nkotlin\n0.1.0\nPhilippe Gaultier\nphiligaultier@gmail.com\nlog\n0.4.8\nThe Rust Project Developers\nhttps://github.com/rust-lang/log\nApache-2.0 OR MIT\nA lightweight logging facade for Rust\npretty_env_logger\n0.3.1\nSean McArthur\nsean@seanmonstar\nhttps://github.com/seanmonstar/pretty-env-logger\nApache-2.0 OR MIT\na visually pretty env_logger\ntermcolor\n1.1.0\nAndrew Gallant\njamslam@gmail.com\nhttps://github.com/BurntSushi/termcolor\nMIT OR Unlicense\nA simple cross platform library for writing colored text to a terminal.\nAll in all, very little code. I have a feeling that I will use this approach a lot in the future for reporting or even inspecting data easily, for example from a database dump.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"perhaps_rust_needs_defer.html",
text:"Perhaps Rust needs &quot;defer&quot;\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-11-06\nPerhaps Rust needs \"defer\"\nRust\nC\nTable of contents\nSetting the stage\nFirst attempt at freeing the memory properly\nSecond attempt at freeing the memory properly\nThird attempt at freeing the memory properly\nDefer\nPossible solutions\nConclusion\nAddendum: One more gotcha\nOr, how FFI in Rust is a pain in the neck.\nDiscussions:\n/r/rust\n,\n/r/programming\n,\nHN\n,\nlobsters\nIn a previous article I\nmentioned\nthat we use the\ndefer\nidiom in Rust through a crate, but that it actually rarely gets past the borrow checker. Some comments were\nclaiming this issue does not exist\nsurprised and I did not have an example at hand.\nWell, today at work I hit this issue again so I thought I would document it. And the whole experience showcases well how working in Rust with lots of FFI interop feels like.\nSetting the stage\nSo, I have a Rust API like this:\n#[repr(C)]\npub struct Foo {\n    value: usize,\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_get_foos(out_foos: *mut *mut Foo, out_foos_count: &amp;mut usize) -&gt; i32 {\n    let res = vec![Foo { value: 42 }, Foo { value: 99 }];\n    *out_foos_count = res.len();\n    unsafe { *out_foos = res.leak().as_mut_ptr() };\n    0\n}\nIt allocates and returns an dynamically allocated array as a pointer and a length. Of course in reality,\nFoo\nhas many fields and the values are not known in advance but what happens is that we send messages to a Smartcard to ask it to send us a piece of data residing on it, and it replies with some encoded messages that our library decodes and returns to the user.\nI tell Cargo this is a static library:\n# Cargo.toml\n\n[lib]\ncrate-type = [&quot;staticlib&quot;]\nIt\'s a straightforward API, so I generate the corresponding C header with cbindgen:\n$ cbindgen -v src/lib.rs --lang=c -o mylib.h\nAnd I get:\n#include &lt;stdarg.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdlib.h&gt;\n\ntypedef struct Foo {\n  uintptr_t value;\n} Foo;\n\nint32_t MYLIB_get_foos(struct Foo **out_foos, uintptr_t *out_foos_count);\nI can now use it from C so:\n#include &quot;mylib.h&quot;\n#include &lt;assert.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main() {\n  Foo *foos = NULL;\n  size_t foos_count = 0;\n  assert(0 == MYLIB_get_foos(&amp;foos, &amp;foos_count));\n\n  for (size_t i = 0; i &lt; foos_count; i++) {\n    printf(&quot;%lu\\n&quot;, foos[i].value);\n  }\n\n  if (NULL != foos) {\n    free(foos);\n  }\n}\nI build it with all the warnings enabled, run it with sanitizers on, and/or in Valgrind, all good.\nThis code has a subtle mistake (can you spot it?), so keep on reading.\nIf we feel fancy (and non-portable), we can even automate the freeing of the memory in C with\n__attribute(cleanup)\n, like\ndefer\n(ominous sounds). But let\'s not, today. Let\'s focus on the Rust side.\nNow, we are principled developers who test their code (right?). So let\'s write a Rust test for it. We expect it to be exactly the same as the C code:\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_get_foos() {\n        let mut foos = std::ptr::null_mut();\n        let mut foos_count = 0;\n        assert_eq!(0, super::MYLIB_get_foos(&amp;mut foos, &amp;mut foos_count));\n    }\n}\nAnd it passes:\n$ cargo test\n...\nrunning 1 test\ntest tests::test_get_foos ... ok\n...\nOf course, we have not yet freed anything, so we expect Miri to complain, and it does:\n$ cargo +nightly miri test\n...\nerror: memory leaked: alloc59029 (Rust heap, size: 16, align: 8), allocated here:\n...\nNote that the standard test runner does not report memory leaks, unfortunately. If Miri does not work for a given use case, and we still want to check that there are no leaks, we have to reach for nightly sanitizers or Valgrind.\nFirst attempt at freeing the memory properly\nGreat, so let\'s free it at the end of the test, like C does, with\nfree\nfrom libc, which we add as a dependency:\n    #[test]\n    fn test_get_foos() {\n        ...\n\n        unsafe { libc::free(foos as *mut std::ffi::c_void) };\n    }\nThe test passes, great. Let\'s try with Miri:\n$ cargo +nightly miri test\n...\n error: Undefined Behavior: deallocating alloc59029, which is Rust heap memory, using C heap deallocation operation\n...\nHmm...ok...Well that\'s a bit weird, because what Rust does, when the\nVec\nis allocated, is to call out to\nmalloc\nfrom libc, as we can see with\nstrace\n:\n$ strace -k -v -e brk ./a.out\n...\nbrk(0x213c0000)                         = 0x213c0000\n &gt; /usr/lib64/libc.so.6(brk+0xb) [0x10fa9b]\n &gt; /usr/lib64/libc.so.6(__sbrk+0x6b) [0x118cab]\n &gt; /usr/lib64/libc.so.6(__default_morecore@GLIBC_2.2.5+0x15) [0xa5325]\n &gt; /usr/lib64/libc.so.6(sysmalloc+0x57b) [0xa637b]\n &gt; /usr/lib64/libc.so.6(_int_malloc+0xd39) [0xa7399]\n &gt; /usr/lib64/libc.so.6(tcache_init.part.0+0x36) [0xa7676]\n &gt; /usr/lib64/libc.so.6(__libc_malloc+0x125) [0xa7ef5]\n &gt; /home/pg/scratch/rust-blog2/a.out(alloc::alloc::alloc+0x6a) [0x4a145a]\n &gt; /home/pg/scratch/rust-blog2/a.out(alloc::alloc::Global::alloc_impl+0x140) [0x4a15a0]\n &gt; /home/pg/scratch/rust-blog2/a.out(alloc::alloc::exchange_malloc+0x3a) [0x4a139a]\n &gt; /home/pg/scratch/rust-blog2/a.out(MYLIB_get_foos+0x26) [0x407cc6]\n &gt; /home/pg/scratch/rust-blog2/a.out(main+0x2b) [0x407bfb]\nDepending on your system, the call stack and specific system call may vary. It depends on the libc implementation, but point being,\nmalloc\nfrom libc gets called by Rust.\nNote the irony that we do not need to have a third-party dependency on the\nlibc\ncrate to allocate with\nmalloc\n(being called under the hood), but we do need it, in order to deallocate the memory with\nfree\n. Perhaps it\'s by design. Anyway. Where was I.\nThe docs for\nVec\nindeed state:\nIn general, Vec\u{2019}s allocation details are very subtle \u{2014} if you intend to allocate memory using a Vec and use it for something else (either to pass to unsafe code, or to build your own memory-backed collection), be sure to deallocate this memory by using from_raw_parts to recover the Vec and then dropping it.\nBut a few sentences later it also says:\nThat is, the reported capacity is completely accurate, and can be relied on. It can even be used to manually free the memory allocated by a Vec if desired.\nSo now I am confused, am I allowed to\nfree()\nthe\nVec\n\'s pointer directly or not?\nBy the way, we also spot in the same docs that there was no way to correctly free the\nVec\nby calling\nfree()\non the pointer without knowing the capacity because:\nThe pointer will never be null, so this type is null-pointer-optimized. However, the pointer might not actually point to allocated memory.\nHmm, ok... So I guess the only way to not trigger Undefined Behavior on the C side when freeing, would be to keep the\ncapacity\nof the\nVec\naround and do:\nif (capacity &gt; 0) {\n    free(foos);\n  }\nLet\'s ignore for now that this will surprise every C developer out there that have been doing\nif (NULL != ptr) free(ptr)\nfor 50 years now.\nI also tried to investigate how\ndrop\nis implemented for\nVec\nto understand what\'s going on and I stopped at this function in\ncore/src/alloc/mod.rs\n:\nunsafe fn deallocate(&amp;self, ptr: NonNull&lt;u8&gt;, layout: Layout);\nNot sure where the implementation is located... Ok, let\'s move on.\nLet\'s stay on the safe side and assume that we ought to use\nVec::from_raw_parts\nand let the\nVec\nfree the memory when it gets dropped at the end of the scope. The only problem is: This function requires the pointer, the length,\nand the capacity\n. Wait, but we lost the capacity when we returned the pointer + length to the caller in\nMYLIB_get_foos()\n, and the caller\ndoes not care one bit about the capacity\n! It\'s irrelevant to them! At work, the mobile developers using our library rightfully asked: wait, what is this\ncap\nfield? Why do I care? What do I do with it? If you are used to manually managing your own memory, this is a very old concept, but if you are used to a Garbage Collector, it\'s very much new.\nSecond attempt at freeing the memory properly\nSo, let\'s first try to dodge the problem the\nhacky\nsimple way by pretending that the memory is allocated by a\nBox\n, which only needs the pointer, just like\nfree()\n:\n#[test]\n    fn test_get_foos() {\n        ...\n\n        unsafe {\n            let _ = Box::from_raw(foos);\n        }\n    }\nThat\'s I think the first instinct for a C developer. Whatever way the memory was heap allocated, be it with\nmalloc\n,\ncalloc\n,\nrealloc\n, be it for one struct or for a whole array, we want to free it with one call, passing it the base pointer. Let\'s ignore for a moment the docs that state that sometimes the pointer is heap-allocated and sometimes not.\nSo this Rust code builds. The test passes. And Miri is unhappy. I guess you know the drill by now:\n$ cargo +nightly miri test\n...\n incorrect layout on deallocation: alloc59029 has size 16 and alignment 8, but gave size 8 and alignment 8\n...\nLet\'s take a second to marvel at the fact that Rust, probably the programming language the most strict at compile time, the if-it-builds-it-runs-dude-I-swear language, seems to work at compile time and at run time, but only fails when run under an experimental analyzer that only works in nightly and does not support lots of FFI patterns, which is the place where you need Miri the most!\nThat\'s the power of Undefined Behavior and\nunsafe{}\n. Again: audit all of your\nunsafe\nblocks, and be very suspicious of any third-party code that uses\nunsafe\n. I think Rust developers on average do not realize the harm that it is very easy to inflict to your program by using\nunsafe\nunwisely even if everything seems fine.\nAnyways, I guess we have to refactor our whole C API to do it the Rust Way(tm)!\nThird attempt at freeing the memory properly\nSo, in our codebase at work, we have defined this type:\n/// Owning Array i.e. `Vec&lt;T&gt;` in Rust or `std::vector&lt;T&gt;` in C++.\n#[repr(C)]\npub struct OwningArrayC&lt;T&gt; {\n    pub data: *mut T,\n    pub len: usize,\n    pub cap: usize,\n}\nIt clearly signifies to the caller that they are in charge of freeing the memory, and also it carries the capacity of the\nVec\nwith it, so it\'s not lost.\nIn our project, this struct is used a lot. We also define a struct for non owning arrays (slices), etc.\nSo let\'s adapt the function, and also add a function in the API to free it for convenience:\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_get_foos(out_foos: &amp;mut OwningArrayC&lt;Foo&gt;) -&gt; i32 {\n    let res = vec![Foo { value: 42 }, Foo { value: 99 }];\n    let len = res.len();\n    let cap = res.capacity();\n\n    *out_foos = OwningArrayC {\n        data: res.leak().as_mut_ptr(),\n        len,\n        cap,\n    };\n    0\n}\n\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_free_foos(foos: &amp;mut OwningArrayC&lt;Foo&gt;) {\n    if foos.cap &gt; 0 {\n        unsafe {\n            let _ = Vec::from_raw_parts(foos.data, foos.len, foos.cap);\n        }\n    }\n}\nLet\'s also re-generate the C header, adapt the C code, rebuild it, communicate with the various projects that use our C API to make them adapt, etc...\nBack to the Rust test:\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_get_foos() {\n        let mut foos = crate::OwningArrayC {\n            data: std::ptr::null_mut(),\n            len: 0,\n            cap: 0,\n        };\n        assert_eq!(0, super::MYLIB_get_foos(&amp;mut foos));\n        println!(&quot;foos: {}&quot;, foos.len);\n        super::MYLIB_free_foos(&amp;mut foos);\n    }\n}\nAnd now, Miri is happy. Urgh. So, back to what we set out to do originally,\ndefer\n.\nDefer\nThe test is trivial right now but in real code, there are many code paths that sometimes allocate, sometimes not, with validation interleaved, and early returns, so we\'d really like if we could statically demonstrate that the memory is always correctly freed. To ourselves, to auditors, etc.\nOne example at work of such hairy code is: building a linked list (in Rust), fetching more from the network based on the content of the last node in the list, and appending the additional data to the linked list, until some flag is detected in the encoded data. Oh, and there is also validation of the incoming data, so you might have to return early with a partially constructed list which should be properly cleaned up.\nAnd there are many such examples like this, where the memory is often allocated/deallocated with a C API and it\'s not always possible to use RAII. So\ndefer\ncomes in handy.\nLet\'s use the\nscopeguard\ncrate which provides a\ndefer!\nmacro, in the test, to automatically free the memory:\n#[test]\n    fn test_get_foos() {\n        let mut foos = crate::OwningArrayC {\n            data: std::ptr::null_mut(),\n            len: 0,\n            cap: 0,\n        };\n        assert_eq!(0, super::MYLIB_get_foos(&amp;mut foos));\n        defer! {\n            super::MYLIB_free_foos(&amp;mut foos);\n        }\n\n        println!(&quot;foos: {}&quot;, foos.len);\n    }\nAnd we get a compile error:\n$ cargo test\nerror[E0502]: cannot borrow `foos.len` as immutable because it is also borrowed as mutable\n  --&gt; src/lib.rs:54:30\n   |\n50 | /         defer! {\n51 | |             super::MYLIB_free_foos(&amp;mut foos);\n   | |                                         ---- first borrow occurs due to use of `foos` in closure\n52 | |         }\n   | |_________- mutable borrow occurs here\n53 |\n54 |           println!(&quot;foos: {}&quot;, foos.len);\n   |                                ^^^^^^^^ immutable borrow occurs here\n55 |       }\n   |       - mutable borrow might be used here, when `_guard` is dropped and runs the `Drop` code for type `ScopeGuard`\n   |\nDum dum duuuum....Yes, we cannot use the\ndefer\nidiom here (or at least I did not find a way). In some cases it\'s possible, in lots of cases it\'s not. The borrow checker considers that the\ndefer\nblock holds an exclusive mutable reference and the rest of the code cannot use that reference in any way.\nDespite the fact, that the version without defer, and with defer, are semantically equivalent and the borrow checker is fine with the former and not with the latter.\nPossible solutions\nSo that is why I argue that Rust should get a\ndefer\nstatement in the language and the borrow checker should be made aware of this construct to allow this approach to take place.\nBut what can we do otherwise? Are there any alternatives?\nWe can be very careful and make sure we deallocate everything by hand in every code paths. Obviously that doesn\'t scale to team size, code complexity, etc. And it\'s unfortunate since using a defer-like approach in C with\n__attribute(cleanup)\nand in C++ by implementing our\nown\ndefer\nis trivial. And even Go which is garbage-collected has a first-class\ndefer\n. So not being able to do so in Rust is unfortunate.\nWe can use a goto-like approach, as a reader\nsuggested\nin a previous article, even though Rust does not have\ngoto\nper se:\nfn foo_init() -&gt; *mut () { &amp;mut () }\nfn foo_bar(_: *mut ()) -&gt; bool { false }\nfn foo_baz(_: *mut ()) -&gt; bool { true }\nfn foo_free(_: *mut ()) {}\n\nfn main() {\n  let f = foo_init();\n  \n  \'free: {\n    if foo_bar(f) {\n        break \'free;\n    }\n    \n    if foo_baz(f) {\n        break \'free;\n    }\n    \n    // ...\n  };\n  \n  foo_free(f);\n}\nIt\'s very nifty, but I am not sure I would enjoy reading and writing this kind of code, especially with multiple levels of nesting. Again, it does not scale very well. But it\'s something.\nWe can work-around the borrow-checker to still use\ndefer\nby refactoring our code to make it happy. Again, tedious and not always possible. One thing that possibly works is using handles (numerical ids) instead of pointers, so that they are\nCopy\nand the borrow checker does not see an issue with sharing/copying them. Like file descriptors work in Unix. The potential downside here is that it creates global state since some component has to bookkeep these handles and their mapping to the real pointer. But it\'s a\ncommon\npattern in gamedev.\nPerhaps the borrow checker can be improved upon without adding\ndefer\nto the language, \'just\' by making it smarter?\nWe can use arenas everywhere and sail away in the sunset, leaving all these nasty problems behind us\nRust can stabilize various nightly APIs and tools, like custom allocators and sanitizers, to make development simpler\nConclusion\nRust + FFI is nasty and has a lot of friction. I went at work through all these steps I went through in this article, and this happens a lot.\nThe crux of the issue is that there is a lot of knowledge to keep in our heads, lots of easy ways to shoot ourselves in the foot, and we have to reconcile what various tools tell us: even if the compiler is happy, the tests might not be. Even the tests are happy, Miri might not be. Even if we think we have done the right thing, we discover later, buried deep in the docs, that in fact, we didn\'t. It\'s definitely for experts only.\nThis should not be so hard! Won\'t somebody think of the\nchildren\nRust FFI users?\nEDIT: It\'s been\npointed\nout to me that there are two on-going internal discussions by the Rust developers about this topic to possibly reserve the\ndefer\nkeyword for future use and maybe one day add this facility to the language:\n1\n,\n2\n.\nAddendum: One more gotcha\nRust guarantees that the underlying pointer in\nVec\nis not null. And\nOwningArrayC\nmirrors\nVec\n, so it should be the same, right? Well consider this C code:\nint main() {\n    OwningArrayC_Foo foos = {0};\n    if (some_condition) {\n         MYLIB_get_foos(&amp;foos);\n    }\n\n    // `foos.data` is null here in some code paths.\n    MYLIB_free_foos(&amp;foos);\n}\nIn this case,\nMYLIB_free_foos\nactually can receive an argument with a null pointer (the\ndata\nfield), which would then trigger an assert inside\nVec::from_raw_parts\n. So we should check that in\nMY_LIB_free_foos\n:\n#[no_mangle]\npub extern &quot;C&quot; fn MYLIB_free_foos(foos: &amp;mut OwningArrayC&lt;Foo&gt;) {\n    if !foos.data.is_null() {\n        unsafe {\n            let _ = Vec::from_raw_parts(foos.data, foos.len, foos.cap);\n        }\n    }\n}\nIt might be a bit surprising to a pure Rust developer given the\nVec\nguarantees, but since the C side could pass anything, we must be defensive.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#3029713171-setting-the-stage",
"#1329431729-first-attempt-at-freeing-the-memory-properly",
"#3847667637-second-attempt-at-freeing-the-memory-properly",
"#2173130770-third-attempt-at-freeing-the-memory-properly",
"#1920616220-defer",
"#629489335-possible-solutions",
"#3796851539-conclusion",
"#1681326077-addendum-one-more-gotcha",
],
title_text_offsets:[
926,3792,7971,9687,11517,14033,16231,17135,],
},
{
name:"way_too_many_ways_to_wait_for_a_child_process_with_a_timeout.html",
text:"Way too many ways to wait on a child process with a timeout\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2024-11-10\nWay too many ways to wait on a child process with a timeout\nUnix\nSignals\nC\nLinux\nFreeBSD\nIllumos\nMacOS\nTable of contents\nWhat are we building?\nFirst way: old-school sigsuspend\nSecond way: sigtimedwait\nThird approach: Self-pipe trick\nA simpler self-pipe trick\nFourth approach: Linux\'s signalfd\nFifth approach: process descriptors\nSixth approach: MacOS\'s and BSD\'s kqueue\nA parenthesis: libkqueue\nAnother parenthesis: Solaris/illumos\'s ports\nSeventh approach: Linux\'s io_uring\nEigth approach: Threads\nNinth approach: Active polling.\nConclusion\nAddendum: The code\nWindows is not covered at all in this article.\nDiscussions:\n/r/programming\n,\nHN\n,\nLobsters\nI often need to launch a program in the terminal in a retry loop. Maybe because it\'s flaky, or because it tries to contact a remote service that is not available. A few scenarios:\nssh to a (re)starting machine.\npsql\nto a (re)starting database.\nEnsuring that a network service started fine with\nnetcat\n.\nFile system commands over NFS.\nIt\'s a common problem, so much so that there are two utilities that I usually reach for:\ntimeout\nfrom GNU coreutils, which launches a command with a timeout (useful if the command itself does not have a\n--timeout\noption).\neb\nwhich runs a command with a certain number of times with an exponential backoff. That\'s useful to avoid hammering a server with connection attempts for example.\nThis will all sound familiar to people who develop distributed systems: they have long known that this is\nbest practice\nto retry an operation:\nWith a timeout (either constant or adaptive).\nA bounded number of times e.g. 10.\nWith a waiting time between each retry, either a constant one or a increasing one e.g. with exponential backoff.\nWith jitter, although this point also seemed the least important since most of us use non real-time operating systems which introduce some jitter anytime we sleep or wait on something with a timeout. The AWS article makes a point that in highly contended systems, the jitter parameter is very important, but for the scope of this article I\'ll leave it out.\nThis is best practice in distributed systems, and we often need to do the same on the command line. But the two aforementioned tools only do that partially:\ntimeout\ndoes not retry.\neb\ndoes not have a timeout.\nSo let\'s implement our own that does both! As we\'ll see, it\'s much less straightforward, and thus more interesting, than I thought. It\'s a whirlwind tour through Unix deeps. If you\'re interested in systems programming, Operating Systems, multiplexed I/O, data races, weird historical APIs, and all the ways you can shoot yourself in the foot with just a few system calls, you\'re in the right place!\nWhat are we building?\nI call the tool we are building\nueb\nfor: micro exponential backoff. It does up to 10 retries, with a waiting period in between that starts at an arbitrary 128 ms and doubles every retry. The timeout for the subprocess is the same as the sleep time, so that it\'s adaptive and we give the subprocess a longer and longer time to finish successfully. These numbers would probably be exposed as command line options in a real polished program, but there\'s no time, what have to demo it:\n# This returns immediately since it succeeds on the first try.\n$ ueb true\n\n# This retries 10 times since the command always fails, waiting more and more time between each try, and finally returns the last exit code of the command (1).\n$ ueb false\n\n# This retries a few times (~ 4 times), until the waiting time exceeds the duration of the sub-program. It exits with `0` since from the POV of our program, the sub-program finally finished in its alloted time.\n$ ueb sleep 1\n\n\n# Run a program that prints the date and time, and exits with a random status code, to see how it works.\n$ ueb sh -c \'date --iso-8601=ns; export R=$(($RANDOM % 5)); echo $R; exit $R\'\n2024-11-10T15:48:49,499172093+01:00\n4\n2024-11-10T15:48:49,628818472+01:00\n3\n2024-11-10T15:48:49,886557676+01:00\n4\n2024-11-10T15:48:50,400199626+01:00\n3\n2024-11-10T15:48:51,425937132+01:00\n2\n2024-11-10T15:48:53,475565645+01:00\n2\n2024-11-10T15:48:57,573278508+01:00\n1\n2024-11-10T15:49:05,767338611+01:00\n0\n\n# Some more practical examples.\n$ ueb ssh &lt;some_ip&gt;\n$ ueb createdb my_great_database -h 0.0.0.0 -U postgres\nIf you want to monitor the retries and the sleeps, you can use\nstrace\nor\ndtrace\n:\n$ strace ueb sleep 1\nNote that the sub-command should be idempotent, otherwise we might create a given resource twice, or the command might have succeeded right after our timeout triggered but also right before we killed it, so our program thinks it timed out and thus needs to be retried. There is this small data race window, which is completely fine if the command is idempotent but will erroneously retry the command to the bitter end otherwise. There is also the case where the sub-command does stuff over the network for example creating a resource, it succeeds, but the ACK is never received due to network issues. The sub-command will think it failed and retry. Again, fairly standard stuff in distributed systems but I thought it was worth mentioning.\nSo how do we implement it?\nImmediately, we notice something: even though there are a bazillion ways to wait on a child process to finish (\nwait\n,\nwait3\n,\nwait4\n,\nwaitid\n,\nwaitpid\n), none of them take a timeout as an argument. This has sparked numerous questions online (\n1\n,\n2\n), with in my opinion unsatisfactory answers. So let\'s explore this rabbit hole.\nWe\'d like the pseudo-code to be something like:\nwait_ms := 128\n\nfor retry in 0..&lt;10:\n    child_pid := run_command_in_subprocess(cmd)\n\n    ret := wait_for_process_to_finish_with_timeout_ms(child_pid, wait_ms)\n    if (did_process_finish_successfully(ret)):\n        exit(0)\n        \n    // In case of a timeout, we need to kill the child process and retry.\n    kill(child_pid, SIGKILL)\n\n    // Reap zombie process to avoid a resource leak.\n    waitpid(child_pid)\n\n    sleep_ms(wait_ms);\n\n    wait_ms *= 2;\n\n// All retries exhausted, exit with an error code.\nexit(1)\nThere is a degenerate case where the give command to run is wrong (e.g. typo in the parameters) or the executable does not exist, and our program will happily retry it to the bitter end. But there is solace: this is bounded by the number of retries (10). That\'s why we do not retry forever.\nFirst way: old-school sigsuspend\nThat\'s how\ntimeout\nfrom coreutils\nimplements\nit. This is quite simple on paper:\nWe opt-in to receive a\nSIGCHLD\nsignal when the child processes finishes with:\nsignal(SIGCHLD, on_chld_signal)\nwhere\non_chld_signal\nis a function pointer we provide. Even if the signal handler does not do anything in this case.\nWe schedule a\nSIGALARM\nsignal with\nalarm\nor more preferably\nsetitimer\nwhich can take a duration in microseconds whereas\nalarm\ncan only handle seconds. There\'s also\ntimer_create/timer_settime\nwhich handles nanoseconds. It depends what the OS and hardware support.\nWe wait for either signal with\nsigsuspend\nwhich suspends the program until a given set of signals arrive.\nWe should not forget to\nwait\non the child process to avoid leaving zombie processes behind.\nThe reality is grimmer, looking through the\ntimeout\nimplementation:\nWe could have inherited any signal mask from our parent so we need to explicitly unblock the signals we are interested in.\nSignals can be sent to a process group we need to handle that case.\nWe have to avoid entering a \'signal loop\'.\nOur process can be implicitly multi-threaded due to some\ntimer_settime\nimplementations, therefore a\nSIGALRM\nsignal sent to a process group, can be result in the signal being sent multiple times to a process (I am directly quoting the code comments from the\ntimeout\nprogram here).\nWhen using\ntimer_create\n, we need to take care of cleaning it up with\ntimer_delete\n, lest we have a resource leak when retrying.\nThe signal handler may be called concurrently and we have to be aware of that.\nDepending on the timer implementation we chose, we are susceptible to clock adjustments for example going back. E.g.\nsetitimer\nonly offers the\nCLOCK_REALTIME\nclock option for counting time, which is just the wall clock. We\'d like something like\nCLOCK_MONOTONIC\nor\nCLOCK_MONOTONIC_RAW\n(the latter being Linux specific).\nSo... I don\'t\nlove\nthis approach:\nI find signals hard. It\'s basically a global\ngoto\nto a completely different location.\nA signal handler is forced to use global mutable state, which is better avoided if possible, and it does not play nice with threads.\nLots of functions are not \'signal-safe\', and that has led to security vulnerabilities in the past e.g. in\nssh\n. In short, non-atomic operations are not signal safe because they might be suspended in the middle, thus leaving an inconsistent state behind. Thus, we have to read documentation very carefully to ensure that we only call signal safe functions in our signal handler, and cherry on the cake, that varies from platform to platform, or even between libc versions on the same platform.\nSignals do not compose well with other Unix entities such as file descriptors and sockets. For example, we cannot\npoll\non signals. There are platform specific solutions though, keep on reading.\nDifferent signals have different default behaviors, and this gets inherited in child processes, so you cannot assume anything in your program and have to be very defensive. Who knows what the parent process, e.g. the shell, set as the signal mask? If you read through the whole implementation of the\ntimeout\nprogram, a lot of the code is dedicated to setting signal masks in the parent, forking, immediately changing the signal mask in the child and the parent, etc. Now, I believe modern Unices offer more control than\nfork()\nabout what signal mask the child should be created with, so maybe it got better. Still, it\'s a lot of stuff to know.\nThey are many libc functions and system calls relating to signals and that\'s a lot to learn. A non-exhaustive list e.g. on Linux:\nkill(1), alarm(2), kill(2), pause(2), sigaction(2), signalfd(2),  sigpending(2),  sigprocmask(2),   sigsuspend(2),  bsd_signal(3),  killpg(3),  raise(3),  siginterrupt(3), sigqueue(3), sigsetops(3), sigvec(3), sysv_signal(3), signal(7)\n. Oh wait, I forgot\nsigemptyset(3)\nand\nsigaddset(3)\n. And I\'m sure I forgot about a few!\nSo, let\'s stick with signals for a bit but simplify our current approach.\nSecond way: sigtimedwait\nWouldn\'t it be great if we could wait on a signal, say,\nSIGCHLD\n, with a timeout? Oh look, a system call that does exactly that\nand\nis standardized by POSIX 2001. Cool! I am not quite sure why the\ntimeout\nprogram does not use it, but we sure as hell can. My only guess would be that they want to support old Unices pre 2001, or non POSIX systems.\nAnyways, here\'s a very straightforward implementation:\n#define _GNU_SOURCE\n#include &lt;errno.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nvoid on_sigchld(int sig) { (void)sig; }\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n  signal(SIGCHLD, on_sigchld);\n\n  uint32_t wait_ms = 128;\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    sigset_t sigset = {0};\n    sigemptyset(&amp;sigset);\n    sigaddset(&amp;sigset, SIGCHLD);\n\n    siginfo_t siginfo = {0};\n\n    struct timespec timeout = {\n        .tv_sec = wait_ms / 1000,\n        .tv_nsec = (wait_ms % 1000) * 1000 * 1000,\n    };\n\n    int sig = sigtimedwait(&amp;sigset, &amp;siginfo, &amp;timeout);\n    if (-1 == sig &amp;&amp; EAGAIN != errno) { // Error\n      return errno;\n    }\n    if (-1 != sig) { // Child finished.\n      if (WIFEXITED(siginfo.si_status) &amp;&amp; 0 == WEXITSTATUS(siginfo.si_status)) {\n        return 0;\n      }\n    }\n\n    if (-1 == kill(child_pid, SIGKILL)) {\n      return errno;\n    }\n\n    if (-1 == wait(NULL)) {\n      return errno;\n    }\n\n    usleep(wait_ms * 1000);\n    wait_ms *= 2;\n  }\n  return 1;\n}\nI like this implementation. It\'s pretty easy to convince ourselves looking at the code that it is obviously correct, and that\'s a very important factor for me.\nWe still have to deal with signals though. Could we reduce their imprint on our code?\nThird approach: Self-pipe trick\nThis is a really nifty, quite well known\ntrick\nat this point, where we bridge the world of signals with the world of file descriptors with the\npipe(2)\nsystem call.\nUsually, pipes are a form of inter-process communication, and here we do not want to communicate with the child process (since it could be any program, and most programs do not get chatty with their parent process). What we do is: in the signal handler for\nSIGCHLD\n, we simply write (anything) to our own pipe. We know this is signal-safe so it\'s good.\nAnd you know what\'s cool with pipes? They are simply a file descriptor which we can\npoll\n. With a timeout. Nice! Here goes:\n#define _GNU_SOURCE\n#include &lt;errno.h&gt;\n#include &lt;poll.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nstatic int pipe_fd[2] = {0};\nvoid on_sigchld(int sig) {\n  (void)sig;\n  char dummy = 0;\n  write(pipe_fd[1], &amp;dummy, 1);\n}\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n\n  if (-1 == pipe(pipe_fd)) {\n    return errno;\n  }\n\n  signal(SIGCHLD, on_sigchld);\n\n  uint32_t wait_ms = 128;\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    struct pollfd poll_fd = {\n        .fd = pipe_fd[0],\n        .events = POLLIN,\n    };\n\n    // Wait for the child to finish with a timeout.\n    poll(&amp;poll_fd, 1, (int)wait_ms);\n\n    kill(child_pid, SIGKILL);\n    int status = 0;\n    wait(&amp;status);\n    if (WIFEXITED(status) &amp;&amp; 0 == WEXITSTATUS(status)) {\n      return 0;\n    }\n\n    char dummy = 0;\n    read(pipe_fd[0], &amp;dummy, 1);\n\n    usleep(wait_ms * 1000);\n    wait_ms *= 2;\n  }\n  return 1;\n}\nSo we still have one signal handler but the rest of our program does not deal with signals in any way (well, except to kill the child when the timeout triggers, but that\'s invisible).\nThere are a few catches with this implementation:\nContrary to\nsigtimedwait\n,\npoll\ndoes not give us the exit status of the child, we have to get it with\nwait\n. Which is fine.\nIn the case that the timeout fired, we\nkill\nthe child process. However, the child process, being forcefully ended, will result in a\nSIGCHLD\nsignal being sent to our program. Which will then trigger our signal handler, which will then write a value to the pipe. So we need to unconditionally read from the pipe after killing the child and before retrying. If we only read from the pipe if the child ended by itself, that will result in the pipe and the child process being desynced.\nIn some complex programs, we\'d have to use\nppoll\ninstead of\npoll\n.\nppoll\nprevents a set of signals from interrupting the polling. That\'s to avoid some data races (again, more data races!). Quoting from the man page for\npselect\nwhich is analogous to\nppoll\n:\nThe  reason  that pselect() is needed is that if one wants to wait for either a signal\nor for a file descriptor to become ready, then an atomic test  is  needed  to  prevent\nrace  conditions.  (Suppose the signal handler sets a global flag and returns.  Then a\ntest of this global flag followed by a call of select() could hang indefinitely if the\nsignal arrived just after the test but just before the call.  By  contrast,  pselect()\nallows one to first block signals, handle the signals that have come in, then call pselect()\nwith the desired sigmask, avoiding the race.)\nSo, this trick is clever, but wouldn\'t it be nice if we could avoid signals\nentirely\n?\nA simpler self-pipe trick\nAn astute reader\npointed out\nthat this trick can be simplified to not deal with signals at all and instead leverage two facts:\nA child inherits the open file descriptors of the parent (including the ones from a pipe)\nWhen a process exits, the OS automatically closes its file descriptors\nBehind the scenes, at the OS level, there is a reference count for a file descriptor shared by multiple processes. It gets decremented when doing\nclose(fd)\nor by a process terminating. When this count reaches 0, it is closed for real. And you know what system call can watch for a file descriptor closing? Good old\npoll\n!\nSo the improved approach is as follows:\nEach retry, we create a new pipe.\nWe fork.\nThe parent closes the write end pipe and the child closes the read end pipe. Effectively, the parent owns the read end and the child owns the write end.\nThe parent polls on the read end.\nWhen the child finishes, it automatically closes the write end which in turn triggers an event in\npoll\n.\nWe cleanup before retrying (if needed)\nSo in a way, it\'s not really a\nself\n-pipe, it\'s more precisely a pipe between the parent and the child, and nothing gets written or read, it\'s just used by the child to signal it\'s done when it closes its end. Which is a useful approach for many cases outside of our little program.\nHere is the code:\n#define _GNU_SOURCE\n#include &lt;errno.h&gt;\n#include &lt;poll.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n\n  uint32_t wait_ms = 128;\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int pipe_fd[2] = {0};\n    if (-1 == pipe(pipe_fd)) {\n      return errno;\n    }\n\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      // Close the read end of the pipe.\n      close(pipe_fd[0]);\n\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    // Close the write end of the pipe.\n    close(pipe_fd[1]);\n\n    struct pollfd poll_fd = {\n        .fd = pipe_fd[0],\n        .events = POLLHUP | POLLIN,\n    };\n\n    // Wait for the child to finish with a timeout.\n    poll(&amp;poll_fd, 1, (int)wait_ms);\n\n    kill(child_pid, SIGKILL);\n    int status = 0;\n    wait(&amp;status);\n    if (WIFEXITED(status) &amp;&amp; 0 == WEXITSTATUS(status)) {\n      return 0;\n    }\n\n    close(pipe_fd[0]);\n\n    usleep(wait_ms * 1000);\n    wait_ms *= 2;\n  }\n  return 1;\n}\nVoila, no signals and no global state!\nFourth approach: Linux\'s signalfd\nThis is a short one: on Linux, there is a system call that does exactly the same as the self-pipe trick: from a signal, it gives us a file descriptor that we can\npoll\n. So, we can entirely remove our pipe and signal handler and instead\npoll\nthe file descriptor that\nsignalfd\ngives us.\nCool, but also....Was it really necessary to introduce a system call for that? I guess the advantage is clarity.\nI would prefer extending\npoll\nto support things other than file descriptors, instead of converting everything a file descriptor to be able to use\npoll\n.\nOk, next!\nFifth approach: process descriptors\nRecommended reading about this topic:\n1\nand\n2\n.\nIn the recent years (starting with Linux 5.3 and FreeBSD 9), people realized that process identifiers (\npid\ns) have a number of problems:\nPIDs are recycled and the space is small, so collisions will happen. Typically, a process spawns a child process, some work happens, and then the parent decides to send a signal to the PID of the child. But it turns out that the child already terminated (unbeknownst to the parent) and another process took its place with the same PID. So now the parent is sending signals, or communicating with, a process that it thinks is its original child but is in fact something completely different. Chaos and security issues ensue. Now, in our very simple case, that would not really happen, but perhaps the root user is running our program, or, imagine that you are implementing the init process with PID 1, e.g. systemd: you can kill any process on the machine! Or think of the case of re-parenting a process. Or sending a certain PID to another process and they send a signal to it at some point in the future. It becomes hairy and it\'s a very real problem.\nData races are hard to escape (see the previous point).\nIt\'s easy to accidentally send a signal to all processes with\nkill(0, SIGKILL)\nor\nkill(-1, SIGKILL)\nif the developer has not checked that all previous operations succeeded. This is a classic mistake:\nint child_pid = fork();  // This fork fails and returns -1.\n... // (do not check that fork succeeded);\nkill(child_pid, SIGKILL); // Effectively: kill(-1, SIGKILL)\nAnd the kernel developers have worked hard to introduce a better concept: process descriptors, which are (almost) bog-standard file descriptors, like files or sockets. After all, that\'s what sparked our whole investigation: we wanted to use\npoll\nand it did not work on a PID. PIDs and signals do not compose well, but file descriptors do. Also, just like file descriptors, process descriptors are per-process. If I open a file with\nopen()\nand get the file descriptor\n3\n, it is scoped to my process. Another process can\nclose(3)\nand it will refer to their own file descriptor, and not affect my file descriptor. That\'s great, we get isolation, so bugs in our code do not affect other processes.\nSo, Linux and FreeBSD have introduced the same concepts but with slightly different APIs (unfortunately), and I have no idea about other OSes:\nA child process can be created with\nclone3(..., CLONE_PIDFD)\n(Linux) or\npdfork()\n(FreeBSD) which returns a process descriptor which is almost like a normal file descriptor. On Linux, a process descriptor can also be obtained from a PID with\npidfd_open(pid)\ne.g. after a normal\nfork\nwas done (but there is a risk of a data race in some cases!). Once we have the process descriptor, we do not need the PID anymore.\nWe wait on the process descriptor with\npoll(..., timeout)\n(or\nselect\n, or\nepoll\n, etc).\nWe kill the child process using the process descriptor with\npidfd_send_signal\n(Linux) or\nclose\n(FreeBSD) or\npdkill\n(FreeBSD).\nWe wait on the zombie child process again using the process descriptor to get its exit status.\nAnd voila, no signals! Isolation! Composability! (Almost) No PIDs in our program! Life can be nice sometimes. It\'s just unfortunate that there isn\'t a cross-platform API for that.\nHere\'s the Linux implementation:\n#define _GNU_SOURCE\n#include &lt;errno.h&gt;\n#include &lt;poll.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;sys/syscall.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n\n  uint32_t wait_ms = 128;\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    // Parent.\n\n    int child_fd = (int)syscall(SYS_pidfd_open, child_pid, 0);\n    if (-1 == child_fd) {\n      return errno;\n    }\n\n    struct pollfd poll_fd = {\n        .fd = child_fd,\n        .events = POLLHUP | POLLIN,\n    };\n    // Wait for the child to finish with a timeout.\n    if (-1 == poll(&amp;poll_fd, 1, (int)wait_ms)) {\n      return errno;\n    }\n\n    if (-1 == syscall(SYS_pidfd_send_signal, child_fd, SIGKILL, NULL, 0)) {\n      return errno;\n    }\n\n    siginfo_t siginfo = {0};\n    // Get exit status of child &amp; reap zombie.\n    if (-1 == waitid(P_PIDFD, (id_t)child_fd, &amp;siginfo, WEXITED)) {\n      return errno;\n    }\n\n    if (WIFEXITED(siginfo.si_status) &amp;&amp; 0 == WEXITSTATUS(siginfo.si_status)) {\n      return 0;\n    }\n\n    wait_ms *= 2;\n    usleep(wait_ms * 1000);\n\n    close(child_fd);\n  }\n}\nA small note: To\npoll\na process descriptor, Linux wants us to use\nPOLLIN\nwhereas FreeBSD wants us to use\nPOLLHUP\n. So we use\nPOLLHUP | POLLIN\nsince there are no side-effects to use both.\nAnother small note: a process descriptor, just like a file descriptor, takes up resources on the kernel side and we can reach some system limits (or even the memory limit), so it\'s good practice to\nclose\nit as soon as possible to free up resources. For us, that\'s right before retrying. On FreeBSD, closing the process descriptor also kills the process, so it\'s very short, just one system call. On Linux, we need to do both.\nSixth approach: MacOS\'s and BSD\'s kqueue\nIt feels like cheating, but MacOS and the BSDs have had\nkqueue\nfor decades which works out of the box with PIDs. It\'s a bit similar to\npoll\nor\nepoll\non Linux:\n#include &lt;errno.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;sys/event.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n\n  uint32_t wait_ms = 128;\n  int queue = kqueuex(KQUEUE_CLOEXEC);\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    struct kevent change_list = {\n        .ident = child_pid,\n        .filter = EVFILT_PROC,\n        .fflags = NOTE_EXIT,\n        .flags = EV_ADD | EV_CLEAR,\n    };\n\n    struct kevent event_list = {0};\n\n    struct timespec timeout = {\n        .tv_sec = wait_ms / 1000,\n        .tv_nsec = (wait_ms % 1000) * 1000 * 1000,\n    };\n\n    int ret = kevent(queue, &amp;change_list, 1, &amp;event_list, 1, &amp;timeout);\n    if (-1 == ret) { // Error\n      return errno;\n    }\n    if (1 == ret) { // Child finished.\n      int status = 0;\n      if (-1 == wait(&amp;status)) {\n        return errno;\n      }\n      if (WIFEXITED(status) &amp;&amp; 0 == WEXITSTATUS(status)) {\n        return 0;\n      }\n    }\n\n    kill(child_pid, SIGKILL);\n    wait(NULL);\n\n    change_list = (struct kevent){\n        .ident = child_pid,\n        .filter = EVFILT_PROC,\n        .fflags = NOTE_EXIT,\n        .flags = EV_DELETE,\n    };\n    kevent(queue, &amp;change_list, 1, NULL, 0, NULL);\n\n    usleep(wait_ms * 1000);\n    wait_ms *= 2;\n  }\n  return 1;\n}\nThe only surprising thing, perhaps, is that a\nkqueue\nis stateful, so once the child process exited by itself or was killed, we have to remove the watcher on its PID, since the next time we spawn a child process, the PID will very likely be different.\nkqueue\noffers the flag\nEV_ONESHOT\n, which automatically deletes the event from the queue once it has been consumed by us. However, it would not help in all cases: if the timeout triggers, no event was consumed, and we have to kill the child process, which creates an event in the queue! So we have to always consume/delete the event from the queue right before we retry, with a second\nkevent\ncall. That\'s the same situation as with the self-pipe approach where we unconditionally\nread\nfrom the pipe to \'clear\' it before retrying.\nI love that\nkqueue\nworks with every kind of Unix entity: file descriptor, pipes, PIDs, Vnodes, sockets, etc. Even signals! However, I am not sure that I love its statefulness. I find the\npoll\nAPI simpler, since it\'s stateless. But perhaps this behavior is necessary for some corner cases or for performance to avoid the linear scanning that\npoll\nentails? It\'s interesting to observe that Linux\'s\nepoll\nwent the same route as\nkqueue\nwith a similar API, however,\nepoll\ncan only watch plain file descriptors.\nA parenthesis: libkqueue\nkqueue\nis only for MacOS and BSDs....Or is it?\nThere is this library,\nlibkqueue\n, that acts as a compatibility layer to be able to use\nkqueue\non all major operating systems, mainly Windows, Linux, and even Solaris/illumos!\nSo...How do they do it then? How can we, on an OS like Linux, watch a PID with the\nkqueue\nAPI, when the OS does not support that functionality (neither with\npoll\nor\nepoll\n)? Well, the solution is actually very simple:\nOn Linux 5.3+, they use\npidfd_open\n+\npoll/epoll\n. Hey, we just did that a few sections above!\nOn older versions of Linux, they handle the signals, like GNU\'s\ntimeout\n. It has a number of known shortcomings which is testament to the hardships of using signals. To just quote one piece:\nBecause the Linux kernel coalesces SIGCHLD (and other signals), the only way to reliably determine if a monitored process has exited, is to loop through all PIDs registered by any kqueue when we receive a SIGCHLD. This involves many calls to waitid(2) and may have a negative performance impact.\nAnother parenthesis: Solaris/illumos\'s ports\nSo, if it was not enough that each major OS has its own way to watch many different kinds of entities (Windows has its own thing called\nI/O completion ports\n, MacOS &amp; BSDs have\nkqueue\n, Linux has\nepoll\n), Solaris/illumos shows up and says: Watch me do my own thing. Well actually I do not know the chronology, they might in fact have been first, and some illumos kernel developers (namely Brian Cantrill in the fabulous\nCantrillogy\n) have admitted that it would have been better for everyone if they also had adopted\nkqueue\n.\nAnyways, their own system is called\nport\n(or is it ports?) and it looks so similar to\nkqueue\nit\'s almost painful. And weirdly, they support all the different kinds of entities that\nkqueue\nsupports\nexcept\nPIDs! And I am not sure that they support process descriptors either e.g.\npidfd_open\n. However, they have an extensive compatibility layer for Linux so perhaps they do there.\nEDIT: illumos has\nPctlfd\nwhich seems to give a file descriptor for a given process, and this file descriptor could then be used\nport_create\nor\npoll\n.\nSeventh approach: Linux\'s io_uring\nio_uring\nis the last candidate to enter the already packed ring (eh) of different-yet-similar ways to do \'I/O multiplexing\', meaning to wait with a timeout on various kinds of entities to do interesting \'stuff\'. We queue a system call e.g.\nwait\n, as well as a timeout, and we wait for either to complete. If\nwait\ncompleted first and the exit status is a success, we exit. Otherwise, we retry. Familiar stuff at this point.\nio_uring\nessentially makes every system call asynchronous with a uniform API. That\'s exactly what we want!\nio_uring\nonly exposes\nwaitid\nand only in very recent versions, which is completely fine.\nIncidentally, this approach is exactly what\nliburing\ndoes in a\nunit test\n.\nAlternatively, we can only queue the\nwaitid\nand use\nio_uring_wait_cqe_timeout\nto mimick\npoll(..., timeout)\n:\n#define _DEFAULT_SOURCE\n#include &lt;liburing.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char *argv[]) {\n  (void)argc;\n\n  struct io_uring ring = {0};\n  if (io_uring_queue_init(2, &amp;ring,\n                          IORING_SETUP_SINGLE_ISSUER |\n                              IORING_SETUP_DEFER_TASKRUN) &lt; 0) {\n    return 1;\n  }\n\n  uint32_t wait_ms = 128;\n\n  for (int retry = 0; retry &lt; 10; retry += 1) {\n    int child_pid = fork();\n    if (-1 == child_pid) {\n      return errno;\n    }\n\n    if (0 == child_pid) { // Child\n      argv += 1;\n      if (-1 == execvp(argv[0], argv)) {\n        return errno;\n      }\n      __builtin_unreachable();\n    }\n\n    struct io_uring_sqe *sqe = NULL;\n\n    // Queue `waitid`.\n    sqe = io_uring_get_sqe(&amp;ring);\n    siginfo_t si = {0};\n    io_uring_prep_waitid(sqe, P_PID, (id_t)child_pid, &amp;si, WEXITED, 0);\n    sqe-&gt;user_data = 1;\n\n    io_uring_submit(&amp;ring);\n\n    struct __kernel_timespec ts = {\n        .tv_sec = wait_ms / 1000,\n        .tv_nsec = (wait_ms % 1000) * 1000 * 1000,\n    };\n    struct io_uring_cqe *cqe = NULL;\n\n    int ret = io_uring_wait_cqe_timeout(&amp;ring, &amp;cqe, &amp;ts);\n\n    // If child exited successfully: the end.\n    if (ret == 0 &amp;&amp; cqe-&gt;res &gt;= 0 &amp;&amp; cqe-&gt;user_data == 1 &amp;&amp;\n        WIFEXITED(si.si_status) &amp;&amp; 0 == WEXITSTATUS(si.si_status)) {\n      return 0;\n    }\n    if (ret == 0) {\n      io_uring_cqe_seen(&amp;ring, cqe);\n    } else {\n      kill(child_pid, SIGKILL);\n      // Drain the CQE.\n      ret = io_uring_wait_cqe(&amp;ring, &amp;cqe);\n      io_uring_cqe_seen(&amp;ring, cqe);\n    }\n\n    wait(NULL);\n\n    wait_ms *= 2;\n    usleep(wait_ms * 1000);\n  }\n  return 1;\n}\nThe only difficulty here is in case of timeout: we kill the child directly, and we need to consume and discard the\nwaitid\nentry in the completion queue. Just like\nkqueue\n.\nOne caveat for io_uring: it\'s only supported on modern kernels (5.1+).\nAnother caveat: some cloud providers e.g. Google Cloud disable\nio_uring\ndue to security concerns when running untrusted code. So it\'s not ubiquitous.\nEigth approach: Threads\nReaders have\npointed out\nthat threads are also a solution, albeit a suboptimal one. Here\'s the approach:\nSpawn a thread, it will be in charge of spawning the child process, storing the child PID in a global thread-safe variable (e.g. protected by a mutex). It then\nwait\ns on the child in a blocking way.\nIf the child exits,\nwait\nwill return the status, which is also written in a global thread-safe variable, and the thread ends.\nIn the main thread, wait on the other thread with a timeout, e.g. with\npthread_timedjoin_np\n.\nIf the child did not exit successfully, this is the same as usual: kill, wait, sleep, and retry.\nIf the threads library supports returning a value from a thread, like\npthread\nor C11 threads do, that could be used to return the exit status of the child to simplify the code a bit.\nAlso, we could make the thread spawning logic a bit more efficient by not spawning a new thread for each retry, if we wanted to. Instead, we communicate with the other thread with a queue or such to instruct it to spawn the child again. It\'s more complex though.\nNow, this approach works but is kind of cumbersome (as noted by the readers), because threads interact in surprising ways with signals (yay, another thing to watch out for!) so we may have to set up signal masks to block/ignore some, and we must take care of not introducing data-races due to the global variables.\nUnless the problem is embarassingly parallel and the threads share nothing (e.g.: dividing an array into pieces and each thread gets its own piece to work on), I am reminded of the adage: &quot;You had two problems. You reach out for X. You now have 3 problems&quot;. And threads are often the X.\nStill, it\'s a useful tool in the toolbox.\nNinth approach: Active polling.\nThat\'s looping in user code with micro-sleeping to actively poll on the child status in a non-blocking way, for example using\nwait(..., WNOHANG)\n. Unless you have a very bizzare use case and you know what you are doing, please do not do this. This is unnecessary, bad for power consumption, and all we achieve is noticing late that the child ended. This approach is just here for completeness.\nConclusion\nI find signals and spawning child process to be the hardest parts of Unix. Evidently this is not a rare opinion, looking at the development in these areas: process descriptors, the various expansions to the venerable\nfork\nwith\nvfork\n,\nclone\n,\nclone3\n,\nclone6\n, a bazillion different ways to do I/O multiplexing, etc.\nSo what\'s the best approach then in a complex program? Let\'s recap:\nIf you need maximum portability and are a Unix wizard, you can use\nsigsuspend\n.\nIf you are not afraid of signals, want a simpler API that still widely supported, and the use case is very specific (like ours), you can use\nsigtimedwait\n.\nIf you favor correctness and work with recent Linux and FreeBSD versions, you can use process descriptors with shims to get the same API on both OSes. That\'s probably my favorite option if it\'s applicable.\nIf you only care about MacOS and BSDs (or accept to use\nlibkqueue\non Linux), you can use\nkqueue\nbecause it works out of the box with PIDs, you avoid signals completely, and it\'s used in all the big libraries out of there e.g.\nlibuv\n.\nIf you only care about bleeding edge Linux, are already using\nio_uring\nin your code, and are bold enough to add\nwait\nsupport to\nio_uring\n, you can use\nio_uring\n(once you have merged it in mainline Linux!).\nIf you only care about Linux and are afraid of using\nio_uring\n, you can use\nsignalfd\n+\npoll\n.\nI often look at complex code and think: what are the chances that this is correct? What are the chances that I missed something? Is there a way to make it simplistic that it is obviously correct? And how can I limit the blast of a bug I wrote? Will I understand this code in 3 months? When dealing with signals, I was constantly finding weird corner cases and timing issues leading to data races. You would not believe how many times I got my system completely frozen while writing this article, because I accidentally fork-bombed myself or simply forgot to reap zombie processes.\nAnd to be fair to the OS developers that have to implement them: I do not think they did a bad job! I am sure it\'s super hard to implement! It\'s just that the whole concept and the available APIs are very easy to misuse. It\'s a good illustration of how a good API, the right abstraction, can enable great programs, and a poor API, the wrong abstraction, can be the root cause of various bugs in many programs for decades.\nAnd OS developers have noticed and are working on new, better abstractions!\nProcess descriptors seem to me so straightforward, so obviously correct, that I would definitely favor them over signals. They simply remove entire classes of bugs. If these are not available to me, I would perhaps use\nkqueue\ninstead (with\nlibkqueue\nemulation when necessary), because it means my program can be extended easily to watch for over types of entities and I like that the API is very straightforward: one call to create the queue and one call to use it.\nFinally, I regret that there is so much fragmentation across all operating systems. Perhaps\nio_uring\nwill become more than a Linuxism and spread to Windows, MacOS, the BSDs, and illumos in the future?\nAddendum: The code\nThe code is available\nhere\n. It does not have any dependencies except libc (well, and libkqueue for\nkqueue.c\n). All of these programs are in the worst case 27 KiB in size, with debug symbols enabled and linking statically to musl. They do not allocate any memory themselves.\nFor comparison,\neb\nhas 24 dependencies and is 1.2 MiB! That\'s roughly 50x times more.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#785223571-what-are-we-building",
"#1028185512-first-way-old-school-sigsuspend",
"#3926643734-second-way-sigtimedwait",
"#184214679-third-approach-self-pipe-trick",
"#848676761-a-simpler-self-pipe-trick",
"#3012560712-fourth-approach-linux-s-signalfd",
"#4269605744-fifth-approach-process-descriptors",
"#4073477733-sixth-approach-macos-s-and-bsd-s-kqueue",
"#1021934944-a-parenthesis-libkqueue",
"#2516997340-another-parenthesis-solaris-illumos-s-ports",
"#210343823-seventh-approach-linux-s-io-uring",
"#3235889612-eigth-approach-threads",
"#2864348830-ninth-approach-active-polling",
"#3796851539-conclusion",
"#164672758-addendum-the-code",
],
title_text_offsets:[
2836,6475,10498,12518,16173,18742,19337,24695,27774,28821,29925,32894,34639,35065,38183,],
},
{
name:"the_missing_cross_platform_os_api_for_timers.html",
text:"The missing cross-platform OS API for timers\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-02\nThe missing cross-platform OS API for timers\nUnix\nSignals\nC\nLinux\nFreeBSD\nIllumos\nMacOS\nWindows\nOpenBSD\nNetBSD\nTimers\nTable of contents\nWindows: SetTimer\nReaders suggestions: CreateWaitableTimer, CreateThreadpoolTimer, CreateTimerQueueTimer\nPOSIX: timer_create, timer_settime\nLinux: timerfd_create, timerfd_settime\nBSD: kqueue/kevent\nIllumos: port_create\nmacOS: dispatch_source_create\nLinux: io_uring\nAll OSes: timers fully implemented in userspace\nConclusion\nDiscussions:\n/r/programming\n,\nHN\nMost serious programs will need to trigger some action at a delayed point in time, often repeatedly: set timeouts, clean up temporary files or entries in the database, send keep-alives, garbage-collect unused entities, etc. All while doing some work in the meantime. A blocking\nsleep\nwon\'t cut it! For example, JavaScript has\nsetTimeout\n. But how does it work under the hood? How does each OS handle that?\nLately, I have found myself in need of doing just that, repeatedly sending a keep-alive over the network to many remote peers, in C. My program has an event loop, a la NodeJS or Redis. It is doing lots of file I/O, network I/O, and handling timers, all in a single thread, in a non-blocking way.\nAnd I wanted to do all that in a cross-platform way. And to my surprise, I could not find a (sane) libc function or syscall to create a timer, and that is the same on all Unices!\nEach Unix variant had its own weird way to do it, as I discovered. I am used to Windows being the odd kid in its corner doing its thing, but usually, Unices (thanks to POSIX) agree on a simple API to do something. There\'s the elephant in the room, of course, with epoll/kqueue/event ports...Which is such a pain that numerous libraries have sprung up to paper over the differences and offer The\nOne API To Rule Them All\n: libuv, libev, libevent, etc. So, are timers the same painful ordeal?\nWell, let\'s take a tour of all the OS APIs to handle them.\nWindows: SetTimer\nThis will be brief because I do not develop on Windows. The official documentation mentions the\nSetTimer\nfunction from Win32 and you pass it a timeout and a callback. Alternatively, since Windows applications come with a built-in event queue, an event of type\nWM_TIMER\ngets emitted and can be consumed from the queue. Simple, and it composes with other OS events, I like it.\nReaders suggestions: CreateWaitableTimer, CreateThreadpoolTimer, CreateTimerQueueTimer\nReaders with experience with\nSetTimer\nhave pointed out that\nSetTimer\nhas flaws:\nAn invisible window must be created to get a message queue, which is opt-in.\nThe parameter size is limited which can be an issue.\nThe event\nWM_TIMER\nis low-priority so any other events, say mouse events, will take precedence.\nWorry not, there are alternatives (and again, I mention them in passing as someone who does not develop on Windows):\nCreateThreadpoolTimer\nwhich works with the threadpool every Win32 process gets by default\nCreateWaitableTimer\ndoes not need a window, and can be shared between processes to do inter-process synchronization. Which is pretty nifty. And a timer created by this function can be referred by name.\nPOSIX: timer_create, timer_settime\nPOSIX has one API for timers, and it sucks. A timer is created with\ntimer_create\n, which does initially nothing, and the timer is started with a timeout using\ntimer_settime\n. When the timeout is reached, a signal is sent to the program. And that\'s the issue. Signals are\nvery\nproblematic, as seen in my\nprevious article\n:\nThey do not compose with other OS primitives. This forces numerous syscalls to have a normal version and a signal-aware version that can block some signals for its duration:\npoll/ppoll\n,\nselect/pselect\n, etc.\nThey are affected by the signal mask of the parent (e.g.: the shell, the service runner, etc)\nThey behave confusingly with child processes. Normally, a signal mask is inherited by the child. But some signal-triggering APIs (e.g.:\ntimer_settime\n)  explicitly prevent child processes from inheriting their signals. I guess we\'ll have to read the fine prints in the man page!\nIt\'s hard to write complex programs with signals in mind due to their global nature. Code of our own, or in a library we use, could block some signals for some period of time, unbeknownst to us. Or simply modify the signal mask of the process, so we can never assume that the signal mask has a given value.\nA signal handler has to use global variables, there is no way to pass it a pointer to some data.\nMost functions are not async-signal-safe and should not be used from within a signal handler but no compiler warns about that and most example code is wrong. This is exacerbated by the fact that a given function may be async-signal safe on some OS but not on another. Or for some version of this OS but not for another version. This has caused real\nsecurity vulnerabilities\nin the past.\nI\'ll just quote here the Linux man page for\ntimer_create\n:\n/* Note: calling printf() from a signal handler is not safe\n  (and should not be done in production programs), since\n  printf() is not async-signal-safe; see signal-safety(7).\n  Nevertheless, we use printf() here [...]. */\nEnough said.\nAnd this is really tricky to get right. For example,\nmalloc\nis not async-signal-safe. By the way, you have to go out of your way to find this out, because the man page (at least on my system) does not mention anything about signals or async safety.\nWell, you think, let\'s just remember to not use\nmalloc\nin signal handlers! Done! Feeling confident, we happen to call\nqsort\nin our signal handler. Should be fine, right? We just sort some data in-place... Well, we just introduced a security vulnerability!\nThat\'s because in glibc, the innocent looking\nqsort\ncalls\nmalloc\nunder the hood! (And that was, in the past, the cause of\nqsort\nsegfaulting, which I find hilarious):\nto our great surprise, we discovered\nthat the glibc\'s qsort() is not, in fact, a quick sort by default, but a\nmerge sort (in stdlib/msort.c).\n[...]\nBut merge sort suffers from one\nmajor drawback: it does not sort in-place -- it malloc()ates a copy of\nthe array of elements to be sorted.\nSo...let\'s accept that writing signal handlers correctly is not feasible for us mere mortals. Many people have concluded the same in the past and have created better OS APIs that do not involve signals at all. Let\'s look into that.\nLinux: timerfd_create, timerfd_settime\nSo, we all heard the saying: In Unix, everything is a file. So, what if a timer was also a file (descriptor)? And we could ask the OS to notify our program whenever there is data to read (i.e.: when our timer triggers), like with a file or a socket?\nThat\'s the whole idea behind\ntimerfd_create\nand\ntimerfd_settime\n. We create a timer, we get a file descriptor back.\nIn the previous article, we saw that Linux added similar APIs for signals with\nsignalfd\nand processes with\npidfd_open\n, so there is a consistent effort to indeed make everything a file.\nThat means that using the venerable\npoll(2)\n, we can wait on an array of very diverse things: sockets, files, signals, timers, processes, pipes, etc. This is great! That\'s simple (one API for all OS entities) and composable (handling an additional OS entity does not force our program to undergo big changes, and we can wait on diverse OS entities using the same API).\nLet\'s see it in action by creating 10 timers and waiting for them to trigger:\n#include &lt;assert.h&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/epoll.h&gt;\n#include &lt;sys/timerfd.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\n  int queue = epoll_create(1 /* Ignored */);\n  assert(-1 != queue);\n\n  int res = 0;\n\n  for (int i = 0; i &lt; 10; i++) {\n    res = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK);\n    assert(-1 != res);\n\n    int fd = res;\n    struct itimerspec ts = {.it_value.tv_nsec = i * 50 * 1000 * 1000};\n    res = timerfd_settime(fd, 0, &amp;ts, NULL);\n    assert(-1 != res);\n\n    struct epoll_event ev = {\n        .events = EPOLLIN,\n        .data.fd = fd,\n    };\n    res = epoll_ctl(queue, EPOLL_CTL_ADD, fd, &amp;ev);\n    assert(-1 != res);\n  }\n\n  int timeout_ms = 1000;\n\n  struct epoll_event events[10] = {0};\n  int events_len = 10;\n\n  for (;;) {\n    res = epoll_wait(queue, events, events_len, timeout_ms);\n    assert(-1 != res);\n\n    if (0 == res) { // The end.\n      return 0;\n    }\n\n    for (int i = 0; i &lt; res; i++) {\n      struct epoll_event event = events[i];\n      if (event.events &amp; EPOLLIN) {\n        struct timespec now = {0};\n        clock_gettime(CLOCK_REALTIME, &amp;now);\n        printf(&quot;[%ld.%03ld] timer %d triggered\\n&quot;, now.tv_sec,\n               now.tv_nsec / 1000 / 1000, event.data.fd);\n        close(event.data.fd);\n      }\n    }\n  }\n}\nAnd it prints:\n[1738530944.233] timer 5 triggered\n[1738530944.283] timer 6 triggered\n[1738530944.333] timer 7 triggered\n[1738530944.383] timer 8 triggered\n[1738530944.433] timer 9 triggered\n[1738530944.483] timer 10 triggered\n[1738530944.533] timer 11 triggered\n[1738530944.583] timer 12 triggered\n[1738530944.633] timer 13 triggered\nThe only gotcha, which is mentioned by the man page, is that we need to remember to\nread(2)\nfrom the timer whenever it triggers. That only matters for repeating timers (also sometimes called interval timers).\nThere\'s even an additional benefit with this API: thanks to\nProcFS\n, timers appear on the file system under\n/proc/&lt;pid&gt;/fd/\n, so troubleshooting is a bit easier.\nHowever, it\'s unfortunate that this is a Linux-only API...or is it really?\nFreeBSD has it\ntoo\n:\nThe timerfd facility was\toriginally ported to FreeBSD\'s Linux  compatibility  layer  [...] in FreeBSD 12.0.\nIt  was\trevised\t and  adapted  to   be\t native\t  [...] in FreeBSD 14.0.\nIllumos has it\ntoo\n.\nNetBSD has it\ntoo\n:\nThe timerfd interface first appeared in NetBSD 10.  It is compatible with\nthe timerfd interface that appeared in Linux 2.6.25.\nOpenBSD does not seem to have it.\nmacOS does not seem to have it.\nSo, pretty good, but not ubiquitous. The search continues.\nBSD: kqueue/kevent\nkqueue\nmight be my favorite OS API: it can watch any OS entity for changes with just one call. Even timers! As it is often the case for BSD-borne APIs, they are well designed and well documented. The man page says:\nEVFILT_TIMER   Establishes an arbitrary timer identified by ident.\nThat\'s great, we do not even have to use various APIs to  create the timer, set the time, read from the timer, etc. We do not even have to destroy the timer ourselves, thanks to the\nEV_ONESHOT\nflag.\nLet\'s see it in action:\n#include &lt;assert.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/event.h&gt;\n#include &lt;sys/time.h&gt;\n\nint main() {\n  int queue = kqueue();\n  assert(-1 != queue);\n\n  int res = 0;\n\n  struct kevent changelist[10] = {0};\n  for (int i = 0; i &lt; 10; i++) {\n    changelist[i] = (struct kevent){\n        .ident = i + 1,\n        .flags = EV_ADD | EV_ONESHOT,\n        .data = i * 50,\n        .filter = EVFILT_TIMER,\n        .fflags = NOTE_MSECONDS,\n    };\n  }\n\n  res = kevent(queue, changelist, 10, NULL, 0, 0);\n  assert(-1 != res);\n\n  struct kevent eventlist[10] = {0};\n  struct timespec timeout = {.tv_sec = 1};\n  for (;;) {\n    res = kevent(queue, NULL, 0, eventlist, 10, &amp;timeout);\n    assert(-1 != res);\n\n    if (0 == res) { // The end.\n      return 0;\n    }\n\n    for (int i = 0; i &lt; res; i++) {\n      struct kevent event = eventlist[i];\n      if (event.filter &amp; EVFILT_TIMER) {\n        struct timespec now = {0};\n        clock_gettime(CLOCK_REALTIME, &amp;now);\n        printf(&quot;[%ld.%03ld] timer %ld triggered\\n&quot;, now.tv_sec,\n               now.tv_nsec / 1000 / 1000, event.ident);\n      }\n    }\n  }\n}\nAnd it prints:\n[1738380963.984] timer 1 triggered\n[1738380964.034] timer 2 triggered\n[1738380964.084] timer 3 triggered\n[1738380964.134] timer 4 triggered\n[1738380964.184] timer 5 triggered\n[1738380964.234] timer 6 triggered\n[1738380964.284] timer 7 triggered\n[1738380964.334] timer 8 triggered\n[1738380964.384] timer 9 triggered\n[1738380964.434] timer 10 triggered\nWhat about the portability?\nFreeBSD has it\nNetBSD has it\nOpenBSD has it\nmacOS has it\nA past version of this section mentioned that this was not implemented on macOS. This used to be the case way back in the day, but an astute reader pointed out that Apple added this functionality at some point around macOS 10.9 (circa 2013).\nGreat news, and thanks, nice reader!\nIllumos: port_create\nSo, Illumos (in)famously has its own API for multiplexing events from disjoint sources, that is different from\nkqueue\n, and some Illumos developers have publicly stated they now wished they had adopted\nkqueue\nback in the day.\nAnyways, similarly to kqueue, their API (\nport_create\n) also supports timers! From the\nman page\n:\nPORT_SOURCE_TIMER events represent one or more timer expirations for a\ngiven timer.  A timer is associated with a port by specifying SIGEV_PORT\nas its notification mechanism.\nInterestingly, the timer is created using the POSIX API that normally triggers a signal upon timer expiration, but thanks to\nport_create\n, the signal is instead turned into an event ports notification, as if it was a file descriptor. I think it\'s pretty clever, because that means that historical code creating timers need not be modified. In other words, it makes the POSIX API sane by circumventing signals and integrating it into a more modern facility to make it composable with other OS entities.\nmacOS: dispatch_source_create\nApple developers, in their infinite wisdom, decided to support\nkqueue\nbut not kqueue timers, and invented their own thing instead.\nIt\'s called\ndispatch_source_create\nand it supports timers with\nDISPATCH_SOURCE_TYPE_TIMER\n.\nI do not currently have access to an Apple computer so I have not tried it. All I know is that\nGrand Central Dispatch/libdispatch\nis an effort to have applications have an event queue and thread pool managed for them by the OS. It\'s more of a task system, actually. All of this seems to me somewhat redundant with\nkqueue\n(which, on Apple platforms, came first!), but I am not an Apple engineer.\nlibdispatch\nhas technically been ported to many platforms but I suppose this is just like\nlibkqueue\non Linux: it exposes the familiar API, but under the hood, it translates all calls to the OS-specific API, so for all intents and purposes, this syscall is macOS specific (well, and iOS, tvOS, IpadOS, etc, but let\'s group them all into a \'macOS\' bucket).\nLinux: io_uring\nio_uring\nis a fascinating Linux-only approach to essentially make every blocking system call... non-blocking. A syscall is enqueued into a ring buffer shared between userspace and the kernel, as a \'request\', and at some point in time, a \'response\' is enqueued by the kernel into a separate ring buffer that our program can read. It\'s simple, it\'s composable, it\'s great.\nAt the beginning I said that a blocking \'sleep\' was not enough, because our program cannot do any work while sleeping.\nio_uring\nrenders this moot: we can (conceptually) enqueue a sleep, do some work, for example enqueue other syscalls, and whenever our sleep finishes, we can dequeue it from the second ring buffer, and voila: we just implemented a timer.\nIt\'s so simple it\'s brilliant! Sadly, it\'s Linux only, only for recent-ish kernels, and some cloud providers disable this facility.\nLet\'s see it in action:\n#include &lt;assert.h&gt;\n#include &lt;liburing.h&gt;\n#include &lt;liburing/io_uring.h&gt;\n#include &lt;stdio.h&gt;\n\nint main() {\n  struct io_uring ring = {0};\n  if (io_uring_queue_init(10, &amp;ring, IORING_SETUP_SINGLE_ISSUER) &lt; 0) {\n    return 1;\n  }\n\n  // Queue `sleep`.\n  struct io_uring_sqe *sqe = NULL;\n  for (int i = 1; i &lt;= 10; i++) {\n    sqe = io_uring_get_sqe(&amp;ring);\n    struct __kernel_timespec ts = {.tv_nsec = i * 50 * 1000 * 1000};\n    io_uring_prep_timeout(sqe, &amp;ts, 1, IORING_TIMEOUT_ETIME_SUCCESS);\n    sqe-&gt;user_data = i;\n    assert(1 == io_uring_submit(&amp;ring));\n  }\n\n  for (int i = 0; i &lt; 10; i++) {\n    struct io_uring_cqe *cqe = NULL;\n\n    int ret = io_uring_wait_cqe(&amp;ring, &amp;cqe);\n    assert(0 == ret);\n    assert(-ETIME == cqe-&gt;res);\n\n    struct timespec now = {0};\n    clock_gettime(CLOCK_REALTIME, &amp;now);\n    printf(&quot;[%ld.%03ld] timer %lld triggered\\n&quot;, now.tv_sec,\n           now.tv_nsec / 1000 / 1000, cqe-&gt;user_data);\n    io_uring_cqe_seen(&amp;ring, cqe);\n  }\n}\nAnd it outputs:\n[1738532785.771] timer 1 triggered\n[1738532785.821] timer 2 triggered\n[1738532785.871] timer 3 triggered\n[1738532785.921] timer 4 triggered\n[1738532785.971] timer 5 triggered\n[1738532786.021] timer 6 triggered\n[1738532786.071] timer 7 triggered\n[1738532786.121] timer 8 triggered\n[1738532786.171] timer 9 triggered\n[1738532786.221] timer 10 triggered\nAll OSes: timers fully implemented in userspace\nFrustrated by my research, not having found one sane API that exists on all Unices, I wondered: How does\nlibuv\n, the C library powering all of the asynchronous I/O for NodeJS, do it? I knew they support\ntimers\n. And they support all OSes, even the most obscure ones like AIX. Surely, they have found the best OS API!\nLet\'s make a super simple C program using libuv timers (loosely adapted from their test suite):\n#include &lt;assert.h&gt;\n#include &lt;uv.h&gt;\n\nstatic void once_cb(uv_timer_t *handle) {\n  printf(&quot;timer %#x triggered\\n&quot;, handle);\n}\n\nint main() {\n  uv_timer_t once_timers[10] = {0};\n  int r = 0;\n\n  /* Start 10 timers. */\n  for (int i = 0; i &lt; 10; i++) {\n    r = uv_timer_init(uv_default_loop(), &amp;once_timers[i]);\n    assert(0 == r);\n    r = uv_timer_start(&amp;once_timers[i], once_cb, i * i * 50, 0);\n    assert(0 == r);\n  }\n\n  uv_run(uv_default_loop(), UV_RUN_DEFAULT);\n}\nWe create 10 timers with increasing durations, and run the event loop. When a timer triggers, our callback is called by\nlibuv\n.\nOf course, in a real program, we would also do real work while the timers run, e.g. network I/O.\nLet\'s compile our program and look at what syscalls are being done (here I am on Linux but we\'ll soon seen it does not matter at all):\n$ cc uv-timers.c -luv\n$ strace ./a.out\n[...]\nepoll_pwait(3, [], 1024, 49, NULL, 8)   = 0\nwrite(1, &quot;timer 0x27432398 triggered\\n&quot;, 27timer 0x27432398 triggered\n) = 27\nepoll_pwait(3, [], 1024, 149, NULL, 8)  = 0\nwrite(1, &quot;timer 0x27432430 triggered\\n&quot;, 27timer 0x27432430 triggered\n) = 27\nepoll_pwait(3, [], 1024, 249, NULL, 8)  = 0\nwrite(1, &quot;timer 0x274324c8 triggered\\n&quot;, 27timer 0x274324c8 triggered\n) = 27\nepoll_pwait(3, [], 1024, 349, NULL, 8)  = 0\nwrite(1, &quot;timer 0x27432560 triggered\\n&quot;, 27timer 0x27432560 triggered\n) = 27\n[...]\nHuh, no call to\ntimerfd_create\nor something like this, just...\nepoll_pwait\nwhich is basically just\nepoll_wait\n, which is basically just a faster\npoll\n. And no events, just a timeout... So... are\nlibuv\ntimers fully implemented in userspace?\nI was at this moment reminded of a\nsentence\nI had read from a Illumos man page:\ntimerfd is a Linux-borne facility for creating POSIX timers and receiving\ntheir subsequent events via a file descriptor.  The facility itself is\narguably unnecessary: portable code can [...] use the timeout value\npresent in poll(2) [...].\nSo, what\nlibuv\ndoes is quite simple in fact:\nWhen a timer is created, it is added to an efficient data structure. It\'s a\nmin-heap\n, i.e. a binary tree that is easy to implement and is designed to get the smallest element in a set quickly. It is typically used to implement priority queues, which is what this bookkeeping of user-space timers really is.\nA typical event loop tick first gets the current time from the OS. Then, it computes the timeout to pass to poll/epoll/kqueue/etc.  If there are no active timers, it\'s easy, there is no timeout (that means that the program will block indefinitely until some I/O happens).\nIf there are active timers, get the \'smallest\' one, meaning: the first that would trigger. The OS timeout is thus\nnow - timer.value\n.\nWhenever a timer expires, it is removed from the min-heap. Simple, (relatively) efficient. The only caveat is that\nepoll\nonly offers a millisecond precision for the timeout parameter so that\'s also the precision of\nlibuv\ntimers.\nThis approach is reminiscent of this part from the\nman page\nof\nselect\n(which is basically\npoll\nwith more limitations):\nEmulating usleep(3)\nBefore the advent of usleep(3), some code employed a call to\nselect() with all three sets empty, nfds zero, and a non-NULL\ntimeout as a fairly portable way to sleep with subsecond\nprecision.\nThat way, we can \'sleep\' while we also do meaningful work, for example network I/O. If some I/O completes before a timer triggers, we\'ll get notified by the OS and we can react to it. Then, during the next event loop tick, we\'ll compute a shorter timeout than the first one (since some time elapsed).\nIf no I/O happens at all, the OS will wake us up when our timeout is elapsed.\nIn short, we have multiplexed multiple timers using one system call (and a min-heap to remember what timers are on-going and when will the next one trigger).\nAddendum\n: A reader has pointed out that\nWebkit\ndoes exactly the same.\nConclusion\nWriting cross-platform C code typically means writing two code paths: one for Windows and one for Unix. But for multiplexed I/O, and for timers, each Unix has its own idea of what\'s the Right Way(tm).\nTo sum up:\nOS API\nWindows\nmacOS\nLinux\nFreeBSD\nNetBSD\nOpenBSD\nIllumos\nSetTimer\n\u{2713}\nPOSIX timers\n1\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\ntimerfd\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\nkevent timer\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\nport_create timer\n\u{2713}\ndispatch_source_create\n\u{2713}\nio_uring sleep\n2\n\u{2713}\nUserspace timers\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\n\u{2713}\nFor performant multiplexed I/O, that means that we have to have a code path for each OS (using\nepoll\non Linux,\nkqueue\non macOS and BSDs, event ports on Illumos, I/O completion ports on Windows).\nFor timers, it seems that the easiest approach is to implement them fully in userspace, as long as we have an efficient data structure to manage them.\nDo not recommend using in non-trivial programs.\n\u{21a9}\nNot always enabled.\n\u{21a9}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2371048346-windows-settimer",
"#84588324-readers-suggestions-createwaitabletimer-createthreadpooltimer-createtimerqueuetimer",
"#1405764248-posix-timer-create-timer-settime",
"#1096776765-linux-timerfd-create-timerfd-settime",
"#288104383-bsd-kqueue-kevent",
"#1016060147-illumos-port-create",
"#4005145368-macos-dispatch-source-create",
"#2940717762-linux-io-uring",
"#2425088119-all-oses-timers-fully-implemented-in-userspace",
"#3796851539-conclusion",
],
title_text_offsets:[
2071,2464,3266,6481,10143,12525,13547,14550,16861,21237,],
},
{
name:"tip_of_the_day_4.html",
text:"Tip of the day #4: Type annotations on Rust match patterns\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-11\nTip of the day #4: Type annotations on Rust match patterns\nRust\nTip of the day\nDiscussions:\n/r/rust\nToday at work I was adding error logs to our Rust codebase and I hit an interesting case. I had a match pattern, and the compiler asked me to add type annotations to a branch of the pattern, because it could not infer by itself the right type.\nfn decode_foo(input: &amp;[u8]) -&gt; Result&lt;(&amp;[u8], [u8; 33]), Error&gt; {\n    if input.len() &lt; 33 {\n        return Err(Error::InvalidData);\n    }\n\n    let (left, right) = input.split_at(33);\n    let value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err) =&gt; {\n            let err_s = err.to_string(); // &lt;= Here is the compilation error.\n            eprintln!(&quot;failed to decode data, wrong length: {}&quot;, err_s);\n            return Err(Error::InvalidData);\n        }\n    };\n\n    Ok((right, value))\n}\nerror[E0282]: type annotations needed\n  --&gt; src/main.rs:14:25\n   |\n14 |             let err_s = err.to_string();\n   |                         ^^^ cannot infer type\nThis function parses a slice of bytes, and on error, logs the error. The real code is of course more complex but I could reduce the error to this minimal code.\nSo I tried to add type annotations the usual Rust way:\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err: TryFromSliceError) =&gt; {\n            // [...]\n        }\nWhich leads to this nice error:\nerror: expected one of `)`, `,`, `@`, or `|`, found `:`\n  --&gt; src/main.rs:15:16\n   |\n15 |         Err(err: TryFromSliceError) =&gt; {\n   |                ^ expected one of `)`, `,`, `@`, or `|`\nIf you\'re feeling smart, thinking, \'Well that\'s because you did not use\ninspect_err\nor\nmap_err\n!\'. Well they suffer from the exact same problem: a type annotation is needed. However, since they use a lambda, the intuitive type annotation, like the one I tried, works. But not for\nmatch\n.\nAlright, so after some\nsearching around\n, I came up with this mouthful of a syntax:\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err::&lt;_, TryFromSliceError&gt;(err) =&gt; {\n            // [...]\n        }\nWhich works! And the same syntax can be applied to the\nOk\nbranch (per the link above) if needed. Note that this is a partial type annotation: we only care about the\nErr\npart of the\nResult\ntype.\nThat was a TIL for me. It\'s a bit of a weird syntax here. It\'s usually the syntax for type annotations on methods (more on that in a second).\nYou can be even more verbose by mentioning the whole type, if you want to:\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Result::&lt;_, TryFromSliceError&gt;::Err(err) =&gt; {\nAnyways, there\'s a much better way to solve this issue. We can simply  annotate the resulting variable outside of the whole match pattern, so that\nrustc\nknows which\ntry_into\nmethod we are using:\nlet value: [u8; 33] = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err) =&gt; {\n          // [...]\n        }\nOr alternatively, as pointed out by a perceptive reader, annotate the\nerr\nvariable inside the body for the\nErr\nbranch:\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err) =&gt; {\n            let err: TryFromSliceError = err; // &lt;= Here.\n            let err_s = err.to_string();\n            eprintln!(&quot;failed to decode data, wrong length: {}&quot;, err_s);\n            return Err(Error::InvalidData);\n        }\n    };\nAnother reader had a different idea: use a match binding, which mentions the error type explicitly (that only works if the error type is a struct):\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err @ TryFromSliceError { .. }) =&gt; {\nPretty succinct! This reader mentions this\nPR\nto expand this to all types, but that the general feedback is that the \'intuitive\' syntax\nErr(err: Bar) =&gt; {\nshould be possible instead.\nYet another approach that works is to annotate the\ntry_into()\nfunction with the type, but I find it even noisier than annotating the\nErr\nbranch:\nlet value = match TryInto::&lt;[u8; 33]&gt;::try_into(left) {\n        Ok(v) =&gt; v,\n        Err(err) =&gt; {\n          // [...]\n        }\nAstute readers will think at this point that all of this is unnecessary: let\'s just have the\nmagic traits(tm)\ndo their wizardry. We do not convert the error to a string, we simply let\neprintln!\ncall\nerr.fmt()\nunder the hood, since\nTryFromSliceError\nimplements the\nDisplay\ntrait (which is why we could convert it to a\nString\nwith\n.to_string()\n):\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err(err) =&gt; {\n            eprintln!(&quot;failed to decode data, wrong length: {}&quot;, err);\n            return Err(Error::InvalidData);\n        }\n    };\nThat works but in my case I really needed to convert the error to a\nString\n, to be able to pass it to C, which does not know anything about fancy traits.\nI find this issue interesting because it encapsulates well the joy and pain of writing Rust: match patterns are really handy, but they sometimes lead to weird syntax not found elsewhere in the Rust language (maybe due to the OCaml heritage?). Type inference is nice but sometimes the compiler/language server fails at inferring things you\'d think they should really be able to infer. Traits and\ninto/try_into\nare found everywhere in Rust code, but it\'s hard to know what type is being converted to what, especially when these are chained several times without any type annotation whatsoever.\nBy the way, here\'s a tip I heard some time ago: if you want to know the real type of a variable that\'s obscured by type inference, just add a type annotation that\'s obviously wrong, and the compiler will show the correct type. That\'s how I pinpointed the\nTryFromSliceError\ntype. Let\'s add a bogus\nbool\ntype annotation:\nlet value = match left.try_into() {\n        Ok(v) =&gt; v,\n        Err::&lt;_, bool&gt;(err) =&gt; {\n          // [...]\n        }\nAnd the compiler helpfully gives us the type:\nerror[E0271]: type mismatch resolving `&lt;[u8; 33] as TryFrom&lt;&amp;[u8]&gt;&gt;::Error == bool`\n  --&gt; src/main.rs:11:28\n   |\n11 |     let value = match left.try_into() {\n   |                            ^^^^^^^^ expected `bool`, found `TryFromSliceError`\nSo...it\ndoes\nactually know the type of\nerr\n... You naughty compiler, playing games with me! It reminds me of this picture:\nCoffee or tea?\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"addressing_cgo_pains_one_at_a_time.html",
text:"Addressing CGO pains, one at a time\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-14\nAddressing CGO pains, one at a time\nGo\nC\nRust\nZig\nDocker\nCross-compilation\nMusl\nTable of contents\nCGO does not have unions\nSlices vs Strings\nTest a C function in Go tests\nThe Go compiler does not detect changes\nFalse positive warnings\nWhite space is significant\nDebug Go and C/Rust\nStrace, bpftrace\nCross-compile\nConclusion\nAddendum: the full code\nRust? Go? Cgo!\nI maintain a Go codebase at work which does most of its work through a Rust library that exposes a C API. So they interact via Cgo, Go\'s FFI mechanism. And it works!\nAlso, Cgo has many weird limitations and surprises. Fortunately, over the two years or so I have been working in this project, I have (re-)discovered solutions for most of these issues. Let\'s go through them, and hopefully the next time you use Cgo, you\'ll have a smooth experience.\nFrom Go\'s perspective, Rust is invisible, the C library looks like a pure C library (and indeed it used to be 100% C++ before it got incrementally rewritten to Rust). So I will use C snippets in this article, because that\'s what the public C header of the library looks like, and not everybody knows Rust, but most people know a C-like language. But worry not, I will still talk at lengths about Rust in the last section.\nLet\'s create a sample app:\n.\n\u{251c}\u{2500}\u{2500} app\n\u{2502}\u{a0}\u{a0} \u{2514}\u{2500}\u{2500} app.go\n\u{251c}\u{2500}\u{2500} c\n\u{2502}\u{a0}\u{a0} \u{251c}\u{2500}\u{2500} api.c\n\u{2502}\u{a0}\u{a0} \u{251c}\u{2500}\u{2500} api.h\n\u{2502}\u{a0}\u{a0} \u{251c}\u{2500}\u{2500} api.o\n\u{2502}\u{a0}\u{a0} \u{251c}\u{2500}\u{2500} libapi.a\n\u{2502}\u{a0}\u{a0} \u{2514}\u{2500}\u{2500} Makefile\n\u{251c}\u{2500}\u{2500} go.mod\n\u{2514}\u{2500}\u{2500} main.go\nThe C code is in the\nc\ndirectory, we build a static library\nlibapi.a\nfrom it. The public header file is\napi.h\n.\nThe Go code then links this library.\nThe full code can be found at the end of this article.\nCGO does not have unions\nThis is known to Go developers: Go does not have tagged unions, also called sum types, algebraic data types, etc. But C, and Rust, do have them, and Go needs to generate Go types for each C type, so that we can use them! So what does it do? Let\'s have a look.\nSo, here is a (very useful) C tagged union:\n// c/api.h\n\n#pragma once\n#include &lt;stdint.h&gt;\n\ntypedef struct {\n  char *data;\n  uint64_t len;\n} String;\n\ntypedef enum {\n  ANIMAL_KIND_DOG,\n  ANIMAL_KIND_CAT,\n} AnimalKind;\n\ntypedef struct {\n  AnimalKind kind;\n  union {\n    String cat_name;   // Only for `ANIMAL_KIND_CAT`.\n    uint16_t dog_tail; // Only for `ANIMAL_KIND_DOG`.\n  };\n} Animal;\n\nAnimal animal_make_dog();\n\nAnimal animal_make_cat();\n\nvoid animal_print(Animal *animal);\nThe C implementation is straightforward:\n// c/api.c\n\n#include &quot;api.h&quot;\n#include &lt;assert.h&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;stdio.h&gt;\n\nAnimal animal_make_dog() {\n  return (Animal){\n      .kind = ANIMAL_KIND_DOG,\n      .dog_tail = 42,\n  };\n}\n\nAnimal animal_make_cat() {\n  return (Animal){\n      .kind = ANIMAL_KIND_CAT,\n      .cat_name =\n          {\n              .data = &quot;kitty&quot;,\n              .len = 5,\n          },\n  };\n}\n\nvoid animal_print(Animal *animal) {\n  switch (animal-&gt;kind) {\n  case ANIMAL_KIND_DOG:\n    printf(&quot;Dog: %&quot; PRIu16 &quot;\\n&quot;, animal-&gt;dog_tail);\n    break;\n  case ANIMAL_KIND_CAT:\n    printf(&quot;Cat: %.*s\\n&quot;, (int)animal-&gt;cat_name.len, animal-&gt;cat_name.data);\n    break;\n  default:\n    assert(0 &amp;&amp; &quot;unreachable&quot;);\n  }\n}\nAnd here\'s how we use it in Go:\n// app/app.go\n\npackage app\n\n// #cgo CFLAGS: -g -O2 -I${SRCDIR}/../c/\n// #cgo LDFLAGS: ${SRCDIR}/../c/libapi.a\n// #include &lt;api.h&gt;\nimport &quot;C&quot;\nimport &quot;fmt&quot;\n\nfunc DoStuff() {\n\tdog := C.animal_make_dog()\n\tC.animal_print(&amp;dog)\n\n\tcat := C.animal_make_cat()\n\tC.animal_print(&amp;cat)\n}\nSo far, so good. Let\'s run it (our\nmain.go\nsimply calls\napp.DoStuff()\n):\n$ go run .\nDog: 42\nCat: kitty\nGreat!\nNow, let\'s say we want to access the fields of the C tagged union. We can to have some logic based on whether our cat\'s name is greater than a limit, say 255? What does the Go struct look like for\nAnimal\n?\ntype _Ctype_struct___0 struct {\n\tkind\t_Ctype_AnimalKind\n\t_\t[4]byte\n\tanon0\t[16]byte\n}\nSo it\'s a struct with a\nkind\nfield, so far so good. Then comes 4 bytes of padding, as expected (the C struct also has them). But then, we only see 16 opaque bytes. The size is correct: the C union is the size of its largest member which is 16 bytes long (\nString\n). But then, how do we access\nString.len\n?\nHere\'s the very tedious way, by hand:\n// app/app.go\nfunc DoStuff() {\n    // [...]\n\n\tcat_ptr := unsafe.Pointer(&amp;cat)\n\tcat_name_ptr := unsafe.Add(cat_ptr, 8)\n\tcat_name_len_ptr := unsafe.Add(cat_name_ptr, 8)\n\tfmt.Println(*(*C.uint64_t)(cat_name_len_ptr))\n}\nAnd we get:\n$ go run .\nDog: 42\nCat: kitty\n5\nOk, we are a C compiler now. Back to computing fields offsets by hand! I sure hope you do not forget about alignment! And keep the offsets in sync with the C struct when its layout changes!\nWell we all agree this sucks, but that\'s all what the\nunsafe\npackage offers. Cherry on the cake, every pointer in this code has the same type:\nunsafe.Pointer\n, even though the first one really is a\nAnimal*\n, the second one is a\nString*\n, and the third one is a\nuint64_t*\n. Not great.\nSo the solution is: treat C unions as opaque values in Go, and only access them with C functions (essentially, getters and setters):\n// c/api.h\n\nuint16_t animal_dog_get_tail(Animal *animal);\n\nString animal_cat_get_name(Animal *animal);\n// c/api.c\n\nuint16_t animal_dog_get_tail(Animal *animal) {\n  assert(ANIMAL_KIND_DOG == animal-&gt;kind);\n  return animal-&gt;dog_tail;\n}\n\nString animal_cat_get_name(Animal *animal) {\n  assert(ANIMAL_KIND_CAT == animal-&gt;kind);\n  return animal-&gt;cat_name;\n}\nAnd now we have a sane Go code:\n// app/app.go\nfunc DoStuff() {\n    // [...]\n\n\tcat_name := C.animal_cat_get_name(&amp;cat)\n\tfmt.Println(cat_name.len)\n}\nAnd as a bonus, whenever the layout of\nAnimal\nchanges, for example the order of fields gets changed, or a new field gets added which changes the alignment and thus the padding (here it\'s not the case because the alignment is already 8 which is the maximum, but in other cases it could happen), the C code gets recompiled, it does the right thing automatically, and everything works as expected.\nMy recommendation:\nnever role-play as a compiler, just use getters and setters for unions and let the C compiler do the dirty work.\nMy ask to the Go team:\nmention the approach with getters and setters in the docs. The only thing the\ndocs\nhave to say about unions right now is:\nAs Go doesn\'t have support for C\'s union type in the general case, C\'s union types are represented as a Go byte array with the same length\n. And I don\'t expect Go to have (tagged) unions anytime soon, so that\'s the best we can do.\nSlices vs Strings\nQuick Go trivia question: what\'s the difference between\n[]byte\n(a slice of bytes) and\nstring\n(which is a slice of bytes underneath)?\n...\nThe former is mutable while the latter is immutable.\nYes, I might have learned that while writing this article.\nAnyways, converting C slices (pointer + length) to Go is straightforward using the\nunsafe\npackage in modern Go (it used to be much hairier in older Go versions):\n// app/app.go\nfunc DoStuff() {\n    // [...]\n\n\tcat_name := C.animal_cat_get_name(&amp;cat)\n\tslice := unsafe.Slice(cat_name.data, cat_name.len)\n\tstr := unsafe.String((*byte)(unsafe.Pointer(cat_name.data)), cat_name.len)\n\n\tfmt.Println(slice)\n\tfmt.Println(str)\n}\nAnd it does what we expect:\n$ go run .\nDog: 42\nCat: kitty\n[107 105 116 116 121]\nkitty\nOk, but just reading them is boring, let\'s try to mutate them. First, we need to allocate a fresh string in C, otherwise the string constant will be located in the read-only part of the executable, mapped to read-only page, and we will segfault when trying to mutate it. So we modify\nanimal_make_cat\n:\n// c/api.c\n\nAnimal animal_make_cat() {\n  return (Animal){\n      .kind = ANIMAL_KIND_CAT,\n      .cat_name =\n          {\n              .data = strdup(&quot;kitty&quot;), // &lt;= Heap allocation here.\n              .len = 5,\n          },\n  };\n}\nLet\'s mutate all the things!\n// app/app.go\nfunc DoStuff() {\n    // [...]\n\n\tslice[0] -= 32 // Poor man\'s uppercase.\n\tfmt.Println(slice)\n\tfmt.Println(str)\n}\nAnd we get the additional output:\n[75 105 116 116 121]\nKitty\nBut wait, this is undefined behavior! The string\ndid\nget mutated! The Go compiler generates code based on the assumption that strings are immutable, so our program\nmay\nbreak in very unexpected ways.\nThe docs for\nunsafe.String\nstate:\nSince Go strings are immutable, the bytes passed to String\nmust not be modified as long as the returned string value exists.\nMaybe the runtime Cgo checks will detect it?\n$ GODEBUG=cgocheck=1 go run .\n[...]\n[75 105 116 116 121]\nKitty\n# Works fine!\n\n$ GOEXPERIMENT=cgocheck2 go run . \n[...]\n[75 105 116 116 121]\nKitty\n# Works fine!\nNope... so what can we do about it? In my real-life program I have almost no strings to deal with, but some programs will.\nMy recommendation:\nIn Go, do not use\nunsafe.String\n, just use\nunsafe.Slice\nand accept that it\'s mutable everywhere in the program\nIf you really want to use\nunsafe.String\n, make sure that the string data returned by the C code is immutable,\nenforced by the OS\n, so either:\nIt\'s a constant string placed in the read-only segment\nThe string data is allocated in its own virtual memory page and the page permissions are changed to read-only before returning the pointer to Go\nIn C, do not expose string data directly to Go, only expose opaque values (\nvoid*\n), and mutations are only done by calling a C function. That way, the Go caller simply cannot use\nunsafe.String\n(I guess they could with lots of casts, but that\'s not in the realm of a\nhonest mistake\nanymore).\nMy ask to the Go team:\nattempt to develop more advanced checks to detect this issue at runtime.\nTest a C function in Go tests\nWe are principled programmers who write tests. Let\'s write a test to ensure that\nanimal_make_dog()\ndoes indeed create a dog, i.e. the kind is\nANIMAL_KIND_DOG\n:\n// app/app_test.go\n\npackage app\n\nimport &quot;testing&quot;\nimport &quot;C&quot;\n\nfunc TestAnimalMakeDog(t *testing.T) {\n\tdog := C.animal_make_dog()\n\t_ = dog\n}\nLet\'s run it:\n$ go test ./app/\nuse of cgo in test app_test.go not supported\nAh... yeah this is a\nknown limitation\n:\n_test.go files can\u{2019}t use cgo.\n.\nSolution: wrap the C function in a Go one.\n// app/app.go\n\nfunc AnimalDogKind() int {\n\treturn C.ANIMAL_KIND_DOG\n}\n\nfunc AnimalMakeDog() C.Animal {\n\treturn C.animal_make_dog()\n}\nAnd we now have a passing Go test:\n// app/app_test.go\n\npackage app\n\nimport &quot;testing&quot;\n\nfunc TestAnimalMakeDog(t *testing.T) {\n\tdog := AnimalMakeDog()\n\tif int(dog.kind) != AnimalDogKind() {\n\t\tpanic(&quot;wrong kind&quot;)\n\t}\n}\n$ go test ./app/ -count=1 -v\n=== RUN   TestAnimalMakeDog\n--- PASS: TestAnimalMakeDog (0.00s)\nPASS\nok  \tcgo/app\t0.003s\nSo... that works, and also: that\'s annoying boilerplate that no one wants to have to write. And if you\'re feeling smug, thinking your favorite LLM will do the right thing for you, I can tell you I tried and the LLM generated the wrong thing, with the test trying to use Cgo directly.\nMy recommendation:\nTest the C code in C directly (or Rust, or whatever language it is)\nThere is some glue code sometimes that is only useful to the Go codebase, and that\'s written in C. In that case wrap each C utility function in a Go one and write a Go test, hopefully it\'s not that much.\nMy ask to the Go team:\nlet\'s allow the use of Cgo in tests.\nThe Go compiler does not detect changes\nPeople are used to say: Go builds so fast! And yes, it\'s not a slow compiler, but if you have ever built the Go compiler from scratch, you will have noticed it takes a significant amount of time still. What Go is really good at, is caching: it\'s really smart at detecting what changed, and only rebuilding that. And that\'s great! Until it isn\'t.\nSometimes, changes to the Cgo build flags, or to the\n.a\nlibrary, were not detected by Go. I could not really reproduce these issues reliably, but they do happen.\nSolution: force a clean build with\ngo build -a\n.\nFalse positive warnings\nSometimes we need to run some C code once at startup, when the package gets initialized:\n// app/app.go\n\npackage app\n\n// #cgo CFLAGS: -g -O2 -I${SRCDIR}/../c/\n// #cgo LDFLAGS: ${SRCDIR}/../c/libapi.a\n// #include &lt;api.h&gt;\n// void initial_setup();\nimport &quot;C&quot;\n\nfunc init() {\n\tC.initial_setup()\n}\n\n\n[...]\nAnd the C function\ninitial_setup\nis defined in a second file in the same Go package (this is not strictly necessary but it will turn out to be useful to showcase something later):\n// app/cfuncs.go\n\npackage app\n\n/*\nvoid initial_setup(){\n    // Do some useful stuff.\n}\n*/\nimport &quot;C&quot;\nYes, we can write C code directly in Go files. Inside comments. Not, it\'s not weird at all.\nWe build, everything is fine:\n$ go build .\nSince we are serious programmers, we want to enable C warnings, right? Let\'s add\n-Wall\nto the\nCFLAGS\n:\n// app/app.go\n\n[...]\n// #cgo CFLAGS: -Wall -g -O2 -I${SRCDIR}/../c/    &lt;= We add -Wall\n[...]\nWe re-build, and get this nice error:\n$ go build .\n# cgo/app\ncgo-gcc-prolog: In function \u{2018}_cgo_13d20cc583d0_Cfunc_initial_setup\u{2019}:\ncgo-gcc-prolog:78:49: warning: unused variable \u{2018}_cgo_a\u{2019} [-Wunused-variable]\nWait, we do not have\nany\nvariable in\ninitial_setup\n, how come a variable is unused?\nSome searching around turns up this\nGithub issue\nwhere the official recommendation is: do not use\n-Wall\n, it creates false positives. Ok.\nMy recommendation:\nWrite C code in C files and enable all the warnings you want.\nMy ask to the Go team:\nLet\'s please fix the false positives and allow people to enable some basic warnings.\n-Wall\nis the bare minimum!\nWhite space is significant\nLet\'s go back to the\napp/cfuncs.go\nwe just created that builds fine:\npackage app\n\n/*\nvoid initial_setup(){}\n*/\nimport &quot;C&quot;\nLet\'s add one empty line near the end:\npackage app\n\n/*\nvoid initial_setup(){}\n*/\n\nimport &quot;C&quot;\nLet\'s build:\n$ go build .\n# cgo\n/home/pg/Downloads/go/pkg/tool/linux_amd64/link: running gcc failed: exit status 1\n/usr/bin/gcc -m64 -o $WORK/b001/exe/a.out -Wl,--export-dynamic-symbol=_cgo_panic -Wl,--export-dynamic-symbol=_cgo_topofstack -Wl,--export-dynamic-symbol=crosscall2 -Wl,--compress-debug-sections=zlib /tmp/go-link-2748897775/go.o /tmp/go-link-2748897775/000000.o /tmp/go-link-2748897775/000001.o /tmp/go-link-2748897775/000002.o /tmp/go-link-2748897775/000003.o /tmp/go-link-2748897775/000004.o /tmp/go-link-2748897775/000005.o /tmp/go-link-2748897775/000006.o /tmp/go-link-2748897775/000007.o /tmp/go-link-2748897775/000008.o /tmp/go-link-2748897775/000009.o /tmp/go-link-2748897775/000010.o /tmp/go-link-2748897775/000011.o /tmp/go-link-2748897775/000012.o /tmp/go-link-2748897775/000013.o /tmp/go-link-2748897775/000014.o /tmp/go-link-2748897775/000015.o /tmp/go-link-2748897775/000016.o -O2 -g /home/pg/scratch/cgo/app/../c/libapi.a -O2 -g -lpthread -no-pie\n/usr/bin/ld: /tmp/go-link-2748897775/000001.o: in function `_cgo_f1a74d84225f_Cfunc_initial_setup\':\n/tmp/go-build/cgo-gcc-prolog:80:(.text+0x53): undefined reference to `initial_setup\'\ncollect2: error: ld returned 1 exit status\nOk... not much to say here.\nHere\'s another example. We add a comment about not using\n-Wall\n:\n// app/app.go\n\npackage app\n\n// NOTE: Do not use -Wall.\n// #cgo CFLAGS: -g -O2 -I${SRCDIR}/../c/\n// #cgo LDFLAGS: ${SRCDIR}/../c/libapi.a\n// #include &lt;api.h&gt;\n// void initial_setup();\nimport &quot;C&quot;\n\n[...]\nWe rebuild, and boom:\n$ go build .\n# cgo/app\napp/app.go:3:6: error: expected \'=\', \',\', \';\', \'asm\' or \'__attribute__\' before \':\' token\n    3 | // NOTE: Do not use -Wall.\n      |      ^\nThat\'s because when seeing a\n#cgo\ndirective in the comments, the Go compiler parses what it recognizes, passes the rest to the C compiler, which chokes on it.\nSolution: insert a blank line between the comment and the\n#cgo\ndirective to avoid that:\n// app/app.go\n\npackage app\n\n// NOTE: Do not use -Wall.\n\n// #cgo CFLAGS: -g -O2 -I${SRCDIR}/../c/\n// #cgo LDFLAGS: ${SRCDIR}/../c/libapi.a\n// #include &lt;api.h&gt;\n// void initial_setup();\nimport &quot;C&quot;\n\n[...]\nMy recommendation:\nIf you get a hairy and weird error, compare the white space with official code examples.\nMy ask to the Go team:\nCan we please fix this? Or at least document it? There is zero mention of this pitfall anywhere, as far as I can see.\nDebug Go and C/Rust\nIt\'s very simple, you have two exclusive choices:\nUse a C/Rust debugger (e.g gdb, lldb, etc), which does not understand the Go calling convention so you can see the C/Rust call stack, but it ends at the Cgo FFI boundary, or\nUse a Go debugger (e.g. delve) which does not (really) understand the C/Rust calling convention so you can see the Go stack, but it ends at the Cgo FFI boundary\nLet\'s see it for ourselves:\n$ gdb ./cgo\n(gdb) break animal_print\nBreakpoint 1 at 0x469b6c\n(gdb) run\n[...]\nThread 1 &quot;cgo&quot; hit Breakpoint 1, 0x0000000000469b6c in animal_print ()\n(gdb) backtrace\n#0  0x0000000000469b6c in animal_print ()\n#1  0x0000000000464644 in runtime.asmcgocall () at /home/pg/Downloads/go/src/runtime/asm_amd64.s:923\n#2  0x000000c0000061c0 in ?? ()\n#3  0x0000000000462a0a in runtime.systemstack () at /home/pg/Downloads/go/src/runtime/asm_amd64.s:514\n#4  0x00007fffffffe228 in ?? ()\n#5  0x0000000000466f3f in runtime.newproc (fn=0x46288f &lt;runtime.rt0_go+303&gt;) at &lt;autogenerated&gt;:1\n#6  0x0000000000462905 in runtime.mstart () at /home/pg/Downloads/go/src/runtime/asm_amd64.s:395\n#7  0x000000000046288f in runtime.rt0_go () at /home/pg/Downloads/go/src/runtime/asm_amd64.s:358\n#8  0x0000000000000001 in ?? ()\n#9  0x00007fffffffe388 in ?? ()\n#10 0x00007fffffffe340 in ?? ()\n#11 0x0000000000000001 in ?? ()\n#12 0x00007fffffffe388 in ?? ()\n#13 0x00007ffff7db1248 in __libc_start_call_main (main=0x300000002, argc=192, argv=0x43a3c5 &lt;runtime.reentersyscall+165&gt;) at ../sysdeps/nptl/libc_start_call_main.h:58\nBacktrace stopped: previous frame inner to this frame (corrupt stack?)\nWhere is\napp.DoStuff\n? Where is\nmain\n? Probably around frames 8-13 in the\ncorrupt stack\n...\nNow with\ndelve\n:\n$ go build   -gcflags=all=&quot;-N -l&quot;\n$ dlv exec ./cgo\n(dlv) b animal_print\nCommand failed: could not find function C.animal_print\n\n(dlv) b app.DoStuff\nBreakpoint 1 set at 0x471f2a for cgo/app.DoStuff() ./app/app.go:23\n(dlv) c\n&gt; [Breakpoint 1] cgo/app.DoStuff() ./app/app.go:23 (hits goroutine(1):1 total:1) (PC: 0x471f2a)\n    18:\t\n    19:\tfunc AnimalMakeDog() C.Animal {\n    20:\t\treturn C.animal_make_dog()\n    21:\t}\n    22:\t\n=&gt;  23:\tfunc DoStuff() {\n    24:\t\tdog := C.animal_make_dog()\n    25:\t\tC.animal_print(&amp;dog)\n    26:\t\n    27:\t}\n(dlv) s\n&gt; cgo/app.DoStuff() ./app/app.go:24 (PC: 0x471f2e)\n    19:\tfunc AnimalMakeDog() C.Animal {\n    20:\t\treturn C.animal_make_dog()\n    21:\t}\n    22:\t\n    23:\tfunc DoStuff() {\n=&gt;  24:\t\tdog := C.animal_make_dog()\n    25:\t\tC.animal_print(&amp;dog)\n    26:\t\n    27:\t}\n(dlv) \n&gt; cgo/app._Cfunc_animal_make_dog() _cgo_gotypes.go:79 (PC: 0x471d93)\n(dlv) \n&gt; cgo/app._Cfunc_animal_make_dog() _cgo_gotypes.go:80 (PC: 0x471dab)\n(dlv) \n&gt; cgo/app._Cfunc_animal_make_dog() _cgo_gotypes.go:81 (PC: 0x471dd3)\n(dlv) \n&gt; cgo/app._Cfunc_animal_make_dog() _cgo_gotypes.go:83 (PC: 0x471de4)\n(dlv) \n&gt; cgo/app.DoStuff() ./app/app.go:24 (PC: 0x471f45)\nValues returned:\n\tr1: cgo/app._Ctype_struct___0 {\n\t\tkind: 0,\n\t\t_: [4]uint8 [0,0,0,0],\n\t\tanon0: [16]uint8 [42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],}\n\n    19:\tfunc AnimalMakeDog() C.Animal {\n    20:\t\treturn C.animal_make_dog()\n    21:\t}\n    22:\t\n    23:\tfunc DoStuff() {\n=&gt;  24:\t\tdog := C.animal_make_dog()\n    25:\t\tC.animal_print(&amp;dog)\n    26:\t\n    27:\t}\n(dlv) \n&gt; cgo/app.DoStuff() ./app/app.go:25 (PC: 0x471f67)\n    20:\t\treturn C.animal_make_dog()\n    21:\t}\n    22:\t\n    23:\tfunc DoStuff() {\n    24:\t\tdog := C.animal_make_dog()\n=&gt;  25:\t\tC.animal_print(&amp;dog)\n    26:\t\n    27:\t}\n(dlv) \n&gt; cgo/app.DoStuff() ./app/app.go:25 (PC: 0x471f67)\n    20:\t\treturn C.animal_make_dog()\n    21:\t}\n    22:\t\n    23:\tfunc DoStuff() {\n    24:\t\tdog := C.animal_make_dog()\n=&gt;  25:\t\tC.animal_print(&amp;dog)\n    26:\t\n    27:\t}\n(dlv) s\n&gt; cgo/app._Cfunc_animal_print() _cgo_gotypes.go:91 (PC: 0x471e13)\n(dlv) s\n&gt; cgo/app._Cfunc_animal_print() _cgo_gotypes.go:92 (PC: 0x471e17)\n(dlv) stack\n0  0x0000000000471e17 in cgo/app._Cfunc_animal_print\n   at _cgo_gotypes.go:92\n1  0x0000000000471f75 in cgo/app.DoStuff\n   at ./app/app.go:25\n2  0x000000000047228f in main.main\n   at ./main.go:6\n3  0x0000000000437a07 in runtime.main\n   at /home/pg/Downloads/go/src/runtime/proc.go:272\n4  0x000000000046c301 in runtime.goexit\n   at /home/pg/Downloads/go/src/runtime/asm_amd64.s:1700\nSo the Go debugger does not understand C/Rust debugging information, so as soon as we are inside a C/Rust function, it cannot show anything useful, but it can still kind of understand the call stack...Urgh.\nAnd the\ndocs\nacknowledge that:\nGDB does not understand Go programs well. The stack management, threading, and runtime contain aspects that differ enough from the execution model GDB expects that they can confuse the debugger and cause incorrect results even when the program is compiled with gccgo. As a consequence, although GDB can be useful in some situations (e.g., debugging Cgo code, or debugging the runtime itself), it is not a reliable debugger for Go programs, particularly heavily concurrent ones. Moreover, it is not a priority for the Go project to address these issues, which are difficult.\nAnd it\'s not an issue of missing debugging information, I compiled the C code with\n-g\n, or\n-g3\n.\nThis point is close to being a deal-breaker for me. Debugging is really important! A language/tech stack is IMHO only as good as we developers can understand and troubleshoot production applications. Can\'t debug, can\'t pinpoint where the bug is? Not sure if that program is worth much.\nMy recommendation:\n: Have both debuggers at hand and locate where the problem is: is it on the Go side or on the C/Rust side? Then use the right debugger to inspect local variables and such. Yes, it\'s a pity. I guess you can try to build Go code with Gccgo, perhaps gdb understands the full call stack then? My approach was to insert logs everywhere in the code, both Go and Rust, with logs. Not ideal. It\'s a bit too close to \'printf debugging\' to my taste.\nMy ask for the Go team:\n: Well, ideally both debuggers would work fully with CGO. But since this issue is known for years...I don\'t have much hope.\nStrace, bpftrace\nIt\'s the same issue manifesting in a different way: it\'s not just debuggers than do not understand the call stack, it\'s also\nstrace\n:\n$ strace -k -e write ./cgo\n--- SIGURG {si_signo=SIGURG, si_code=SI_TKILL, si_pid=438876, si_uid=1000} ---\n &gt; /usr/lib64/libc.so.6(pthread_sigmask@GLIBC_2.2.5+0x48) [0x783b8]\n &gt; /home/pg/scratch/cgo/cgo(_cgo_sys_thread_start+0x7e) [0x4727ee]\n &gt; /home/pg/scratch/cgo/cgo(runtime.asmcgocall.abi0+0x9c) [0x46c01c]\nwrite(1, &quot;Dog: 42\\n&quot;, 8Dog: 42\n)                = 8\n &gt; /usr/lib64/libc.so.6(__write+0x4d) [0xe853d]\n &gt; /usr/lib64/libc.so.6(_IO_file_write@@GLIBC_2.2.5+0x34) [0x68fa4]\n &gt; /usr/lib64/libc.so.6(new_do_write+0x5c) [0x6711c]\n &gt; /usr/lib64/libc.so.6(_IO_do_write@@GLIBC_2.2.5+0x20) [0x67fb0]\n &gt; /usr/lib64/libc.so.6(_IO_file_overflow@@GLIBC_2.2.5+0x11a) [0x6852a]\n &gt; /usr/lib64/libc.so.6(_IO_default_xsputn+0x74) [0x6a624]\n &gt; /usr/lib64/libc.so.6(_IO_file_xsputn@@GLIBC_2.2.5+0x117) [0x69127]\n &gt; /usr/lib64/libc.so.6(__printf_buffer_flush_to_file+0xc8) [0x36448]\n &gt; /usr/lib64/libc.so.6(__printf_buffer_to_file_done+0x1b) [0x3650b]\n &gt; /usr/lib64/libc.so.6(__vfprintf_internal+0xaa) [0x41bea]\n &gt; /usr/lib64/libc.so.6(printf+0xb2) [0x35bf2]\n &gt; /home/pg/scratch/cgo/cgo(animal_print+0x38) [0x472da0]\n &gt; /home/pg/scratch/cgo/cgo(runtime.asmcgocall.abi0+0x63) [0x46bfe3]\n &gt; No DWARF information found\n+++ exited with 0 +++\nSame as gdb, the call stack stops at the Cgo FFI boundary.\nBut surprisingly,\nbpftrace\nseems to work:\n$ sudo bpftrace -e \'uprobe:./cgo:animal_print {print(ustack(perf, 64))}\' -c ./cgo\nAttaching 1 probe...\nDog: 42\n\n\t472d68 animal_print+0 (./cgo)\n\t46bfe4 runtime.asmcgocall.abi0+100 (./cgo)\n\t46361f runtime.cgocall+127 (./cgo)\n\t471e3f cgo/app._Cfunc_animal_print.abi0+63 (./cgo)\n\t471f75 cgo/app.DoStuff+85 (./cgo)\n\t47228f main.main+15 (./cgo)\n\t437a07 runtime.main+583 (./cgo)\n\t46c301 runtime.goexit.abi0+1 (./cgo)\nSo, let\'s use\nbpftrace\n, I guess.\nCross-compile\nSo picture me, building my Go program (a web service) using Cgo. Locally, it builds very quickly, due to Rust and Go caching.\nNow, time to build in Docker to be able to test my changes:\n$ time docker build [...]\n[...]\nTotal execution time 101.664413146\nThat\'s in seconds. Every. Single. Time. Urgh.\nThe issue is that little to no caching is being leveraged by either compiler. Dependencies are fetched from the internet, and essentially, a clean release build is performed. That takes a looong time. Past developers tried to fix this by volume mounting host directories inside Docker but apparently, they missed a few.\nThat\'s why I am convinced that Docker is not meant to build stuff. Only to run stuff. I have seen the same problem with C++ codebases being built in Docker, with Rust codebases being built in Docker, etc. Even with JavaScript/Typescript codebases built in docker (these were for some reason often the slowest to build). In the worst cases it would take over an hour to build, and developers resorted to duplicate the deployment setup to be able to run (and thus test) the app locally, completely bypassing Docker.\nI think the original intent to do a clean build inside Docker was because developers feared that the local environment was somehow tainted and/or that the compiler would mess up with the caching and result in a borked build. And that was the case I believe, with most C/C++ codebase relying on globally installed libraries built how-knows-how. But modern compilers are, from my perspective, really good at identifying changes, correctly caching what did not change, and rebuilding with the correct build flags, what does need to be rebuilt. And developers have improved on the Bill Of Material side. Much work has been done on existing tools to get reproducible builds. New tools have emerged, like Nix, that focus on controlled reproducible builds.\nSo in my opinion, the ideal Docker build process is: a single static executable is built locally, relying on caching of previous builds (or possibly in CI, remote intermediate artifacts). Then, it is copied inside the image which, again ideally, for security purposes, is very bare bone. The dockerfile can look like this:\nFROM gcr.io/distroless/static:nonroot\nUSER nonroot\nWORKDIR /home/nonroot\n\nCOPY --chown=nonroot:nonroot app.exe .\n\nCMD [&quot;/home/nonroot/app.exe&quot;]\nIt\'s fast, simple, secure. But, to make it work, regardless of the host, we need to cross-compile.\nGo is praised for its uncomplicated cross-compiling support. But this goes out of the window when Cgo is enabled. Let\'s try:\n$ GOOS=linux GOARCH=arm go build  .\ncgo/app: build constraints exclude all Go files in /home/pg/scratch/cgo/app\nIt fails. But fortunately, Go still supports cross-compiling with Cgo as long as we provide it with a cross-compiler.\nAfter some experimentation, my favorite way is to use\nZig\nfor that. That way it works the same way for people using macOS, Linux, be it on ARM, on x86_64, etc. And it makes it trivial to build native Docker images for ARM without changing the whole build system or installing additional tools.\nThe work on Zig is fantastic, please consider supporting them!\nSo, how does it look like? Let\'s assume we want to target\nx86_64-linux-musl\n, built statically, since we use a distroless image that does not come with a libc. The benefit is that our service looks like any other Go service without Cgo.\nWe could also target a specific glibc version and deploy on a LTS version of Ubuntu, Debian, etc. Zig supports that.\nFirst, we cross-compile our C code:\n$ CC=&quot;zig cc --target=x86_64-linux-musl&quot; make -C ./c\nOr, bring your own cross-compiler, you don\'t have to use Zig:\n$ CC=musl-gcc make -C ./c\nIf we have Rust code, we do instead:\n$ rustup target add x86_64-unknown-linux-musl\n$ cargo build --release --all-features --target=x86_64-unknown-linux-musl\nThen we build our Go code using the Zig C compiler. I put the non cross-compiling build commands just before for comparison:\n$ go build .\n$ file cgo\ncgo: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=9d5da9b6a211c5635a83e4a8a346ff605f7b6e3b, for GNU/Linux 3.2.0, with debug_info, not stripped\n\n$ CGO_ENABLED=1 CC=\'zig cc --target=x86_64-linux-musl -static\' GOOS=linux GOARCH=amd64 go build .\n$ file cgo\ncgo: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, Go BuildID=gTeiH1YL9FSvJJ2euuGd/P0s07MkwoQlcaBA6EXDD/NOYPaeKuxUZ0cnLxfpC9/YeAu_C7s53nGjPEKZDYI, with debug_info, not stripped\nTa dam!\nTime to build a native ARM image? No problem:\n$ CC=&quot;zig cc --target=aarch64-linux-musl&quot; make -C ./c\n$ CGO_ENABLED=1 CC=\'zig cc --target=aarch64-linux-musl -static\' GOOS=linux GOARCH=arm64 go build .\n$ file ./cgo\n./cgo: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, Go BuildID=QRDa72MrAj44K3mt54PK/_aJwgCwTO37mKpnfElWN/0TEmGFNLMEZCx3Zv_PKs/lgDlIHFQ6-LxhCOsdhQI, with debug_info, not stripped\nIf you\'ve done\nany\nwork with cross-compilation, you know that this is magic. It\'s supposed to take weeks to make it work, dammit!\nNote: Rust code typically needs libunwind for printing a backtrace, so it needs to be cross-compiled and linked as well. But no worries, Zig has you covered, it ships with libunwind sources and will, just like with musl, build it for your target, and cache the results! Just add\n-lunwind\nto the\nzig cc\ninvocation, and voila.\nOh, and what about the speed now? Here is a full Docker build with my real-life program (Rust + Go):\n$ make docker-build\nExecuted in    1.47 secs\nThat time includes\ncargo build --release\n,\ngo build\n, and\ndocker build\n. Most of the time is spent copying the giant executable (around 72 MiB!) into the Docker image since neither Rust nor Go are particularly good at producing small executables.\nSo, we went from ~100s to ~1s, roughly a 100x improvement. Pretty pretty good if you ask me.\nMy recommendation:\n: Never build in Docker if you can avoid it. Build locally and copy the one static executable into the Docker image.\nMy ask for the Go team\n: None actually, they have done an amazing job on the build system to support this use-case, and on the documentation.\nConclusion\nCgo is rocky, but there are no real blocking issues, apart from the debugging pain point, mostly lots of small pains. Half the cure is being aware of the ailment, as the saying goes. So armed with this knowledge, I wish you god speed with your Cgo projects!\nAddendum: the full code\nThe full code\nc/Makefile:\nlibapi.a: api.o\n\t$(AR) -rcs libapi.a api.o\n\napi.o: api.c\n\t$(CC) $(CFLAGS) api.c -c\nc/api.c:\n#include &quot;api.h&quot;\n#include &lt;assert.h&gt;\n#include &lt;inttypes.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n\nAnimal animal_make_dog() {\n  return (Animal){\n      .kind = ANIMAL_KIND_DOG,\n      .dog_tail = 42,\n  };\n}\n\nAnimal animal_make_cat() {\n  return (Animal){\n      .kind = ANIMAL_KIND_CAT,\n      .cat_name =\n          {\n              .data = strdup(&quot;kitty&quot;),\n              .len = 5,\n          },\n  };\n}\n\nvoid animal_print(Animal *animal) {\n  switch (animal-&gt;kind) {\n  case ANIMAL_KIND_DOG:\n    printf(&quot;Dog: %&quot; PRIu16 &quot;\\n&quot;, animal-&gt;dog_tail);\n    break;\n  case ANIMAL_KIND_CAT:\n    printf(&quot;Cat: %.*s\\n&quot;, (int)animal-&gt;cat_name.len, animal-&gt;cat_name.data);\n    break;\n  default:\n    assert(0 &amp;&amp; &quot;unreachable&quot;);\n  }\n}\n\nuint16_t animal_dog_get_tail(Animal *animal) {\n  assert(ANIMAL_KIND_DOG == animal-&gt;kind);\n  return animal-&gt;dog_tail;\n}\n\nString animal_cat_get_name(Animal *animal) {\n  assert(ANIMAL_KIND_CAT == animal-&gt;kind);\n  return animal-&gt;cat_name;\n}\nc/api.h:\n#pragma once\n#include &lt;stdint.h&gt;\n\ntypedef struct {\n  char *data;\n  uint64_t len;\n} String;\n\ntypedef enum {\n  ANIMAL_KIND_DOG,\n  ANIMAL_KIND_CAT,\n} AnimalKind;\n\ntypedef struct {\n  AnimalKind kind;\n  union {\n    String cat_name;   // Only for `ANIMAL_KIND_CAT`.\n    uint16_t dog_tail; // Only for `ANIMAL_KIND_DOG`.\n  };\n} Animal;\n\nAnimal animal_make_dog();\n\nAnimal animal_make_cat();\n\nvoid animal_print(Animal *animal);\n\nuint16_t animal_dog_get_tail(Animal *animal);\n\nString animal_cat_get_name(Animal *animal);\napp/app.go:\npackage app\n\n// NOTE: Do not use -Wall.\n\n// #cgo CFLAGS: -g -O2 -I${SRCDIR}/../c/\n// #cgo LDFLAGS: ${SRCDIR}/../c/libapi.a\n// #include &lt;api.h&gt;\n// void initial_setup();\nimport &quot;C&quot;\n\nfunc init() {\n\tC.initial_setup()\n}\n\nfunc AnimalDogKind() int {\n\treturn C.ANIMAL_KIND_DOG\n}\n\nfunc AnimalMakeDog() C.Animal {\n\treturn C.animal_make_dog()\n}\n\nfunc DoStuff() {\n\tdog := C.animal_make_dog()\n\tC.animal_print(&amp;dog)\n\n}\napp/app_test.go:\npackage app\n\nimport &quot;testing&quot;\n\nfunc TestAnimalMakeDog(t *testing.T) {\n\tdog := AnimalMakeDog()\n\tif int(dog.kind) != AnimalDogKind() {\n\t\tpanic(&quot;wrong kind&quot;)\n\t}\n}\napp/cfuncs.go:\npackage app\n\n/*\nvoid initial_setup(){}\n*/\nimport &quot;C&quot;\nmain.go:\npackage main\n\nimport &quot;cgo/app&quot;\n\nfunc main() {\n\tapp.DoStuff()\n}\ngo.mod:\nmodule cgo\n\ngo 1.23.1\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2500525419-cgo-does-not-have-unions",
"#1510699236-slices-vs-strings",
"#1045507796-test-a-c-function-in-go-tests",
"#1377417454-the-go-compiler-does-not-detect-changes",
"#1226423581-false-positive-warnings",
"#716190716-white-space-is-significant",
"#1161538398-debug-go-and-c-rust",
"#1317537828-strace-bpftrace",
"#1705429708-cross-compile",
"#3796851539-conclusion",
"#1512890027-addendum-the-full-code",
],
title_text_offsets:[
1817,6788,9869,11533,12130,13746,16417,22525,24505,30735,31004,],
},
{
name:"making_my_debug_build_run_100_times_faster.html",
text:"Making my debug build run 100x faster so that it is finally usable\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-18\nMaking my debug build run 100x faster so that it is finally usable\nC\nSIMD\nSHA1\nTorrent\nOptimization\nx86_64\nTable of contents\nWhy is it a problem at all and how did it come to be?\nNon-SIMD implementation\nExplanation\nThe code\nResults\nPossible optimizations\nSIMD (SSE) implementation\nExplanation\nThe code\nResults\nIntel SHA extension implementation\nExplanations\nThe code\nResults\nOpenSSL hand crafted assembly implementation\nAdditional improvements\nConclusion\nSIMD and dedicated silicon to the rescue.\nDiscussions:\n/r/C_Programming\n,\nHN\nI am writing a torrent application, to download and serve torrent files, in C, because it\'s fun. A torrent download is made of thousands of pieces of the same size, typically a few hundred KiB to a few MiB.  At start-up, the program reads the downloaded file from disk piece by piece, computes the\nSHA1\nhash of the piece, and marks this piece as downloaded if the actual hash is indeed the expected hash. We get from the\n.torrent\nfile the expected hash of each piece.\nWhen we have not downloaded anything yet, the file is completely empty (but still of the right size - we use\nftruncate(2)\nto size it properly even if empty from the get go), and nearly every piece has the wrong hash. Some pieces will accidentally have the right hash, since they are all zeroes in the file we are downloading - good news then, with this approach we do not even have to download them at all!. If we continue an interrupted download (for example the computer restarted), some pieces will have the right hash, and some not. When the download is complete, all pieces will have the correct hash. That way, we know what what pieces we need to download, if any.\nI read that some torrent clients prefer to skip this verification at startup because they persist their state in a separate file (perhaps a Sqlite database), each time a new piece is downloaded (and its hash is verified). However I favor doing a from scratch verification at startup for a few reasons, over the \'state file\' approach:\nWe might have crashed in the middle of a previous download, before updating the state file, and the persisted state is out-of-sync with the download\nThere may have been data corruption at the disk level (not everybody runs ZFS and can detect that!)\nWe can continue a partial download started with a different torrent client - no need for format interoperability. The downloaded file is the source of truth.\nSome other program might have corrupted/modified the download, unbeknownst to us and our state file\nFor this reason I do not have a state file at all. It\'s simpler and a whole class of out-of-sync issues disappears.\nSo I have this big\nNetBSD image\ntorrent that I primarily test with (by the way, thank you NetBSD maintainers for that!). It\'s not that big:\n$ du -h ./NetBSD-9.4-amd64.iso \n485M\t./NetBSD-9.4-amd64.iso\nBut when I build my code in debug mode (no optimizations) with Address Sanitizer, to detect various issues early, startup takes\n20 to 30 seconds\n(hashing at roughly ~\n18 KiB/s\n)! That\'s unbearable, especially when working in the debugger and inspecting some code that runs after the startup. We\'d like to finish this verification under 1 second ideally. And making it fast is important, because until it finishes, we do not know which pieces we need to download so that blocks everything.\nLet\'s see how we can speed it up.\nWhy is it a problem at all and how did it come to be?\nIt\'s important to note that in my case, to reduce third-party dependencies, the SHA1 code is vendored in the source tree and comes from OpenBSD. It is plain C code, not using SIMD or such. It\'s good because I can read it and understand it.\nI entertained depending on OpenSSL or such, but it feels wasteful to pull in such a huge amount of code just for SHA1. And building OpenSSL ourselves, to tweak the build flags, means depending on Perl (and Go, in the case of aws-lc), and a lot of stuff. And now I need to pick between OpenSSL, LibreSSL, BoringSSL, aws-lc, etc. And upgrade it when the weekly security vulnerability gets announced. I don\'t want any of it, if I can help it. Also I want to understand from top to bottom what code I depend on.\nFor a while, due to this slowness, I simply gave up using a debug build, instead I use minimal optimizations (\n-O1\n) with Address Sanitizer. It was much faster, but lots of functions and variables got optimized away, and the debugging experience was thus sub par. I needed to make my debug + Address Sanitizer build viable.  The debug build without Address Sanitizer is much faster: the startup \'only\' takes around 2 seconds. But Address Sanitizer is very valuable, I want to be able to use it! And 2 seconds is still too long. Reducing the iteration cycle is often the deciding factor for software quality in my experience.\nWhat\'s vexing is that from first principles, we know it could/should be much, much faster:\n$ hyperfine --shell=none --warmup 3 \'sha1sum ./NetBSD-9.4-amd64.iso\'\nBenchmark 1: sha1sum ./NetBSD-9.4-amd64.iso\n  Time (mean \u{b1} \u{3c3}):     297.7 ms \u{b1}   3.2 ms    [User: 235.8 ms, System: 60.9 ms]\n  Range (min \u{2026} max):   293.7 ms \u{2026} 304.2 ms    10 runs\nGranted, computing the hash for the whole file should be slightly faster than computing the hash for N pieces, because the final step for SHA1 is about padding the data to make it 64 bytes aligned and extracting the digest value from the state computed so far with some bit operations. But still, it\'s a marginal difference.\nWhy is it so slow then? I can see on CPU profiles that the SHA1 function takes all of the startup time:\nThe SHA1 code is simplistic, it does not use any SIMD or intrinsics directly. And that\'s fine, because when it\'s compiled with optimizations on, the compiler does a pretty good job at optimizing, and it\'s really fast, around ~300 ms. But the issue is that this code is working one byte at a time. And Address Sanitizer, with its nice runtime and bounds checks, makes each memory access\nvery\nexpensive. So we basically have just written a worst-case stress-test for Address Sanitizer.\nLet\'s first review the simple SIMD-less C version to understand the baseline.\nNon-SIMD implementation\nTo isolate the issue, I have created a simple benchmark program. It reads the\n.torrent\nfile, and the download file, in my case the\n.iso\nNetBSD image. Every piece gets hashed and this gets compared with the expected value (a SHA1 hash, or digest, is 20 bytes long). To simplify this example, I skip the decoding of the\n.torrent\nfile, and hard-code the piece length, as well as where exactly in the file are the expected hashes. The only difficulty is that the last piece might be shorter than the others so we need to compute its exact length to avoid going out of bounds:\n#include &lt;fcntl.h&gt;\n#include &lt;inttypes.h&gt;\n#include &quot;sha1_sw.c&quot;\n#include &lt;stdbool.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;unistd.h&gt;\n\nstatic bool is_piece_valid(uint8_t *piece, uint64_t piece_len,\n                           uint8_t digest_expected[20]) {\n  SHA_CTX ctx = {0};\n  SHA1_Init(&amp;ctx);\n\n  SHA1_Update(&amp;ctx, piece, piece_len);\n\n  uint8_t digest_actual[20] = {0};\n  SHA1_Final(digest_actual, &amp;ctx);\n\n  return !memcmp(digest_actual, digest_expected, 20);\n}\n\nint main(int argc, char *argv[]) {\n  if (3 != argc) {\n    return 1;\n  }\n\n  int file_download = open(argv[1], O_RDONLY, 0600);\n  if (!file_download) {\n    return 1;\n  }\n\n  struct stat st_download = {0};\n  if (-1 == fstat(file_download, &amp;st_download)) {\n    return 1;\n  }\n  size_t file_download_size = (size_t)st_download.st_size;\n\n  uint8_t *file_download_data = mmap(NULL, file_download_size, PROT_READ,\n                                     MAP_FILE | MAP_PRIVATE, file_download, 0);\n  if (!file_download_data) {\n    return 1;\n  }\n\n  int file_torrent = open(argv[2], O_RDONLY, 0600);\n  if (!file_torrent) {\n    return 1;\n  }\n\n  struct stat st_torrent = {0};\n  if (-1 == fstat(file_torrent, &amp;st_torrent)) {\n    return 1;\n  }\n  size_t file_torrent_size = (size_t)st_torrent.st_size;\n\n  uint8_t *file_torrent_data = mmap(NULL, file_torrent_size, PROT_READ,\n                                    MAP_FILE | MAP_PRIVATE, file_torrent, 0);\n  if (!file_torrent_data) {\n    return 1;\n  }\n  // HACK\n  // The piece hashes begin at offset 237 in the file.\n  uint64_t file_torrent_data_offset = 237;\n  file_torrent_data += file_torrent_data_offset;\n  // The last character in the file must be ignored because it\'s the bencode dictionary closing character \'e\'.\n  file_torrent_size -= file_torrent_data_offset - 1;\n\n  uint64_t piece_length = 262144;\n  uint64_t pieces_count = file_download_size / piece_length +\n                          ((0 == file_download_size % piece_length) ? 0 : 1);\n  for (uint64_t i = 0; i &lt; pieces_count; i++) {\n    uint8_t *data = file_download_data + i * piece_length;\n    uint64_t piece_length_real = ((i + 1) == pieces_count)\n                                     ? (file_download_size - i * piece_length)\n                                     : piece_length;\n    uint8_t *digest_expected = file_torrent_data + i * 20;\n\n    if (!is_piece_valid(data, piece_length_real, digest_expected)) {\n      return 1;\n    }\n  }\n}\nExplanation\nIn Intel words, what is SHA1?\nSHA-1 produces a 160 bit (20 byte) hash value (digest), taking as an input a sequence of 1 or more 512 bit (64 byte) data blocks. The original source data also requires some padding according to the standard. The data is treated as an array of big-endian 32-bit values. Processing each of the 64-byte input blocks consists of 80 iterations also known as rounds.\nIn this implementation:\nState initialization is done with\nSHA1_Init\n: the state is an array of 5\nuint32_t\n, set to magic values defined by the standard.\nProcessing is done with\nSHA1_Update\n: processing works on chunks of 64 bytes. The result of the processing of a chunk is that the state is updated to new values. Incoming data is buffered into the current chunk until it reaches 64 bytes, and that\'s when the real computation kicks in with\nSHA1_Transform\n. This API allows for reading and hashing data in a streaming fashion by repeatedly calling\nSHA1_Update\n.\nPadding and finalization is done with\nSHA1_Final\n: the last chunk is padded to 64 bytes if it is too short, processed, and the digest (the final 20 bytes we are after) is the current state, after endianness conversion.\nThe SHA1 algorithm and some implementations support architectures where 1 byte is\nnot\n8 bits. But knowing that 1 byte\nis indeed\n8 bits on our architecture unlocks a ton of performance as we\'ll see.\nSHA1 expects data in big-endian but nearly all CPU nowadays are little-endian so we need to swap the bytes when loading the input data to do SHA1 computations, and back when storing the intermediate results (the SHA1 state). It is done here with lots of clever bit tricks, one\nuint32_t\nat a time.\nThe main loop operating on the 64 bytes chunk is unrolled, which avoids having conditionals in the middle of the loop, which might tank performance due to mispredicted branches. The algorithm lends itself to that really well:\nfor i from 0 to 79\n          if 0 \u{2264} i \u{2264} 19 then\n            [..]\n          else if 20 \u{2264} i \u{2264} 39\n            [..]\n          else if 40 \u{2264} i \u{2264} 59\n            [..]\n          else if 60 \u{2264} i \u{2264} 79\n            [..]\nSo it\'s trivial to unroll each section. We\'ll see that every implementation does the unrolling.\nThe code\nNon-SIMD SHA1\n// sha1_sw.c\n\n/*\t$OpenBSD: sha1.c,v 1.27 2019/06/07 22:56:36 dtucker Exp $\t*/\n\n/*\n * SHA-1 in C\n * By Steve Reid &lt;steve@edmweb.com&gt;\n * 100% Public Domain\n *\n * Test Vectors (from FIPS PUB 180-1)\n * &quot;abc&quot;\n *   A9993E36 4706816A BA3E2571 7850C26C 9CD0D89D\n * &quot;abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq&quot;\n *   84983E44 1C3BD26E BAAE4AA1 F95129E5 E54670F1\n * A million repetitions of &quot;a&quot;\n *   34AA973C D4C4DAA4 F61EEB2B DBAD2731 6534016F\n */\n\n#include &lt;inttypes.h&gt;\n#include &lt;string.h&gt;\n\n#define SHA1_BLOCK_LENGTH 64\n#define SHA1_DIGEST_LENGTH 20\n#define SHA1_DIGEST_STRING_LENGTH (SHA1_DIGEST_LENGTH * 2 + 1)\n\ntypedef struct {\n  uint32_t state[5];\n  uint64_t count;\n  uint8_t buffer[SHA1_BLOCK_LENGTH];\n} SHA1_CTX;\n#define rol(value, bits) (((value) &lt;&lt; (bits)) | ((value) &gt;&gt; (32 - (bits))))\n\n/*\n * blk0() and blk() perform the initial expand.\n * I got the idea of expanding during the round function from SSLeay\n */\n#define blk0(i)                                                                \\\n  (block-&gt;l[i] = (rol(block-&gt;l[i], 24) &amp; 0xFF00FF00) |                         \\\n                 (rol(block-&gt;l[i], 8) &amp; 0x00FF00FF))\n#define blk(i)                                                                 \\\n  (block-&gt;l[i &amp; 15] = rol(block-&gt;l[(i + 13) &amp; 15] ^ block-&gt;l[(i + 8) &amp; 15] ^   \\\n                              block-&gt;l[(i + 2) &amp; 15] ^ block-&gt;l[i &amp; 15],       \\\n                          1))\n\n/*\n * (R0+R1), R2, R3, R4 are the different operations (rounds) used in SHA1\n */\n#define R0(v, w, x, y, z, i)                                                   \\\n  z += ((w &amp; (x ^ y)) ^ y) + blk0(i) + 0x5A827999 + rol(v, 5);                 \\\n  w = rol(w, 30);\n#define R1(v, w, x, y, z, i)                                                   \\\n  z += ((w &amp; (x ^ y)) ^ y) + blk(i) + 0x5A827999 + rol(v, 5);                  \\\n  w = rol(w, 30);\n#define R2(v, w, x, y, z, i)                                                   \\\n  z += (w ^ x ^ y) + blk(i) + 0x6ED9EBA1 + rol(v, 5);                          \\\n  w = rol(w, 30);\n#define R3(v, w, x, y, z, i)                                                   \\\n  z += (((w | x) &amp; y) | (w &amp; x)) + blk(i) + 0x8F1BBCDC + rol(v, 5);            \\\n  w = rol(w, 30);\n#define R4(v, w, x, y, z, i)                                                   \\\n  z += (w ^ x ^ y) + blk(i) + 0xCA62C1D6 + rol(v, 5);                          \\\n  w = rol(w, 30);\n\ntypedef union {\n  uint8_t c[64];\n  uint32_t l[16];\n} CHAR64LONG16;\n\n/*\n * Hash a single 512-bit block. This is the core of the algorithm.\n */\nvoid SHA1Transform(uint32_t state[5], const uint8_t buffer[SHA1_BLOCK_LENGTH]) {\n  uint32_t a, b, c, d, e;\n  uint8_t workspace[SHA1_BLOCK_LENGTH];\n  CHAR64LONG16 *block = (CHAR64LONG16 *)workspace;\n\n  (void)memcpy(block, buffer, SHA1_BLOCK_LENGTH);\n\n  /* Copy context-&gt;state[] to working vars */\n  a = state[0];\n  b = state[1];\n  c = state[2];\n  d = state[3];\n  e = state[4];\n\n  /* 4 rounds of 20 operations each. Loop unrolled. */\n  R0(a, b, c, d, e, 0);\n  R0(e, a, b, c, d, 1);\n  R0(d, e, a, b, c, 2);\n  R0(c, d, e, a, b, 3);\n  R0(b, c, d, e, a, 4);\n  R0(a, b, c, d, e, 5);\n  R0(e, a, b, c, d, 6);\n  R0(d, e, a, b, c, 7);\n  R0(c, d, e, a, b, 8);\n  R0(b, c, d, e, a, 9);\n  R0(a, b, c, d, e, 10);\n  R0(e, a, b, c, d, 11);\n  R0(d, e, a, b, c, 12);\n  R0(c, d, e, a, b, 13);\n  R0(b, c, d, e, a, 14);\n  R0(a, b, c, d, e, 15);\n  R1(e, a, b, c, d, 16);\n  R1(d, e, a, b, c, 17);\n  R1(c, d, e, a, b, 18);\n  R1(b, c, d, e, a, 19);\n  R2(a, b, c, d, e, 20);\n  R2(e, a, b, c, d, 21);\n  R2(d, e, a, b, c, 22);\n  R2(c, d, e, a, b, 23);\n  R2(b, c, d, e, a, 24);\n  R2(a, b, c, d, e, 25);\n  R2(e, a, b, c, d, 26);\n  R2(d, e, a, b, c, 27);\n  R2(c, d, e, a, b, 28);\n  R2(b, c, d, e, a, 29);\n  R2(a, b, c, d, e, 30);\n  R2(e, a, b, c, d, 31);\n  R2(d, e, a, b, c, 32);\n  R2(c, d, e, a, b, 33);\n  R2(b, c, d, e, a, 34);\n  R2(a, b, c, d, e, 35);\n  R2(e, a, b, c, d, 36);\n  R2(d, e, a, b, c, 37);\n  R2(c, d, e, a, b, 38);\n  R2(b, c, d, e, a, 39);\n  R3(a, b, c, d, e, 40);\n  R3(e, a, b, c, d, 41);\n  R3(d, e, a, b, c, 42);\n  R3(c, d, e, a, b, 43);\n  R3(b, c, d, e, a, 44);\n  R3(a, b, c, d, e, 45);\n  R3(e, a, b, c, d, 46);\n  R3(d, e, a, b, c, 47);\n  R3(c, d, e, a, b, 48);\n  R3(b, c, d, e, a, 49);\n  R3(a, b, c, d, e, 50);\n  R3(e, a, b, c, d, 51);\n  R3(d, e, a, b, c, 52);\n  R3(c, d, e, a, b, 53);\n  R3(b, c, d, e, a, 54);\n  R3(a, b, c, d, e, 55);\n  R3(e, a, b, c, d, 56);\n  R3(d, e, a, b, c, 57);\n  R3(c, d, e, a, b, 58);\n  R3(b, c, d, e, a, 59);\n  R4(a, b, c, d, e, 60);\n  R4(e, a, b, c, d, 61);\n  R4(d, e, a, b, c, 62);\n  R4(c, d, e, a, b, 63);\n  R4(b, c, d, e, a, 64);\n  R4(a, b, c, d, e, 65);\n  R4(e, a, b, c, d, 66);\n  R4(d, e, a, b, c, 67);\n  R4(c, d, e, a, b, 68);\n  R4(b, c, d, e, a, 69);\n  R4(a, b, c, d, e, 70);\n  R4(e, a, b, c, d, 71);\n  R4(d, e, a, b, c, 72);\n  R4(c, d, e, a, b, 73);\n  R4(b, c, d, e, a, 74);\n  R4(a, b, c, d, e, 75);\n  R4(e, a, b, c, d, 76);\n  R4(d, e, a, b, c, 77);\n  R4(c, d, e, a, b, 78);\n  R4(b, c, d, e, a, 79);\n\n  /* Add the working vars back into context.state[] */\n  state[0] += a;\n  state[1] += b;\n  state[2] += c;\n  state[3] += d;\n  state[4] += e;\n\n  /* Wipe variables */\n  a = b = c = d = e = 0;\n}\n\n/*\n * SHA1Init - Initialize new context\n */\nvoid SHA1Init(SHA1_CTX *context) {\n\n  /* SHA1 initialization constants */\n  context-&gt;count = 0;\n  context-&gt;state[0] = 0x67452301;\n  context-&gt;state[1] = 0xEFCDAB89;\n  context-&gt;state[2] = 0x98BADCFE;\n  context-&gt;state[3] = 0x10325476;\n  context-&gt;state[4] = 0xC3D2E1F0;\n}\n\n/*\n * Run your data through this.\n */\nvoid SHA1Update(SHA1_CTX *context, const uint8_t *data, size_t len) {\n  size_t i, j;\n\n  j = (size_t)((context-&gt;count &gt;&gt; 3) &amp; 63);\n  context-&gt;count += ((uint64_t)len &lt;&lt; 3);\n  if ((j + len) &gt; 63) {\n    (void)memcpy(&amp;context-&gt;buffer[j], data, (i = 64 - j));\n    SHA1Transform(context-&gt;state, context-&gt;buffer);\n    for (; i + 63 &lt; len; i += 64)\n      SHA1Transform(context-&gt;state, (uint8_t *)&amp;data[i]);\n    j = 0;\n  } else {\n    i = 0;\n  }\n  (void)memcpy(&amp;context-&gt;buffer[j], &amp;data[i], len - i);\n}\n\n/*\n * Add padding and return the message digest.\n */\nvoid SHA1Pad(SHA1_CTX *context) {\n  uint8_t finalcount[8];\n  size_t i;\n\n  for (i = 0; i &lt; 8; i++) {\n    finalcount[i] = (uint8_t)((context-&gt;count &gt;&gt; ((7 - (i &amp; 7)) * 8)) &amp;\n                              255); /* Endian independent */\n  }\n  SHA1Update(context, (uint8_t *)&quot;\\200&quot;, 1);\n  while ((context-&gt;count &amp; 504) != 448)\n    SHA1Update(context, (uint8_t *)&quot;\\0&quot;, 1);\n  SHA1Update(context, finalcount, 8); /* Should cause a SHA1Transform() */\n}\n\nvoid SHA1Final(uint8_t digest[SHA1_DIGEST_LENGTH], SHA1_CTX *context) {\n  size_t i;\n\n  SHA1Pad(context);\n  for (i = 0; i &lt; SHA1_DIGEST_LENGTH; i++) {\n    digest[i] =\n        (uint8_t)((context-&gt;state[i &gt;&gt; 2] &gt;&gt; ((3 - (i &amp; 3)) * 8)) &amp; 255);\n  }\n  explicit_bzero(context, sizeof(*context));\n}\nThe\nSHA1_xxx\nfunctions are lifted from\nOpenBSD\n(there are similar variants, e.g. from\nSqlite\n, etc - they are all nearly identical)\nResults\nWhen compiled in non-optimized mode with Address Sanitizer, we get this timing:\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):     26.312 s \u{b1}  0.734 s    [User: 26.164 s, System: 0.066 s]\n  Range (min \u{2026} max):   25.366 s \u{2026} 27.780 s    10 runs\nThis is consistent with our real-life torrent program.\nI experimented with doing a\nread\nsyscall for each piece (that\'s what\nsha1sum\ndoes) versus using\nmmap\n, and there was no difference; additionally the system time is nothing compared to user time, so I/O is not the limiting factor - SHA1 computation is, as confirmed by the CPU profile.\nPossible optimizations\nSo what can we do about it?\nWe can build the SHA1 code separately with optimizations on, always (and potentially without Address Sanitizer). That\'s a bit annoying, because I currently do a Unity build meaning there is only one compilation unit. So having suddenly multiple compilation units with different build flags makes the build system more complex. And clang has\nannotations\nto\nlower\nthe optimization level for one function but not to\nraise\nit.\nWe can compute the hash of each piece in parallel for example in a thread pool, since each piece is independent. That works and that\'s what\nlibtorrent did/does\n, but that assumes that the target computer has cores to spare, and it creates some complexity:\nWe need to implement a thread pool (spawning a new thread for each piece will not perform well) and pick a reasonable thread pool size given the number of cores, in a cross-platform way\nWe need a M:N scheduling logic to compute the hash of M pieces on N threads. It could be a work-stealing queue where each thread picks the next item when its finished with its piece, or we read the whole file in memory and split the data in equal parts for each thread to plow through (but beware that the data for each thread must be aligned with the piece size!)\nWe would have high contention: in the real program, right after we checked the actual hash against the expected hash, we update a bitfield to remember which piece is valid or not. Every thread would contend on this (probably more so with the work-stealing approach than with the \'split in equal parts\' approach where we could avoid locking and contention entirely).\nWe can implement SHA1 with SIMD. That way, it\'s much faster regardless of the build level. Essentially, we do not rely on the compiler auto-vectorization that only occurs at higher optimization levels, we do it directly. It has the nice advantage that we have guaranteed performance even when using a different compiler, or an older compiler that cannot do auto-vectorization properly, or if a new compiler version comes along and auto-vectorization broke for this code. Since it uses lots of heuristics, this may happen.\nSo let\'s do SIMD and learn cool new stuff! The nice thing about it is that we can always in the future\nalso\ncompute hashes in parallel, as well as use SIMD; the two approaches compose well together. I am reminded of an old adage:\nYou can\'t have multiple cores until you\'ve shown you can use one efficiently.\nSIMD (SSE) implementation\nThis\nis an implementation from the early 2000s in the public domain. Yes, SSE, which is the first widespread SIMD instruction set, is from the nineties to early 2000s. More than 25 years ago! There\'s basically no reason to write SIMD-less code for performance sensitive code for a SIMD-friendly problem - every CPU we care about has SIMD! Well, we have two write separate implementations for x64 and ARM, and there were lots of additions to SSE over the years, that\'s the downside.\nIntel references this implementation on their\nwebsite\n. According to Intel, it was fundamental work at the time and influenced them. It\'s also not the fastest SSE implementation, the very article from Intel is about some performance enhancements they found for this code, but it has the advantage that if you have a processor from 2004 or after, it works, and it\'s simple.\nExplanation\nI really am a SIMD beginner but I found a few interesting nuggets of wisdom here:\nJust like the SIMD-less implementation, the loops are unrolled\nGoing from little-endian to big-endian (or back) is done with a SIMD shuffle. The way it works is by providing a bit mask that indicates which bits to copy from the source to the destination, and where to place them:\n// `0x1b` == `0b0001_1011`.\n  // Will result in:\n  // [31:0] == [127:96] (due to bits [1:0] being `11`).\n  // [63:32] == [95:64] (due to bits [3:2] being `10`).\n  // [95:64] == [63:32] (due to bits [5:4] being `01`).\n  // [127:96] == [31:0] (due to bits [7:6] being `00`).\n  // I.e.: Transform state to big-endian.\n  ABCD = _mm_shuffle_epi32(ABCD, 0x1B);\nIt\'s nifty because we can copy the data in and out of SIMD registers, while also doing the endianness conversion, in one operation that typically compiles down to one assembly instruction. And this approach also works from a SIMD register to another SIMD register or inside the same register.\nTypical SIMD code processes the data in groups of N bytes at a time, and the few excess bytes at the end use the normal SIMD-less code path. Here, we have to deal with an additional grouping: SHA1 processes data in chunks of 64 bytes and the last chunk is padded to be 64 bytes if it is too short. Hence, for the last short chunk we use the SIMD-less code path. We could try to be clever about doing the padding, and re-using the SIMD code path for this last chunk, since 64 bytes is a nice round number that is SIMD friendly, but this last chunk is not going to really make a difference in practice when we are dealing with megabytes or gigabytes of data.\nThe code\nSHA1 with SSE\ntypedef union {\n  uint32_t u32[4];\n  __m128i u128;\n} v4si __attribute__((aligned(16)));\n\nstatic const v4si K00_19 = {\n    .u32 = {0x5a827999, 0x5a827999, 0x5a827999, 0x5a827999}};\nstatic const v4si K20_39 = {\n    .u32 = {0x6ed9eba1, 0x6ed9eba1, 0x6ed9eba1, 0x6ed9eba1}};\nstatic const v4si K40_59 = {\n    .u32 = {0x8f1bbcdc, 0x8f1bbcdc, 0x8f1bbcdc, 0x8f1bbcdc}};\nstatic const v4si K60_79 = {\n    .u32 = {0xca62c1d6, 0xca62c1d6, 0xca62c1d6, 0xca62c1d6}};\n\n#define UNALIGNED 1\n#if UNALIGNED\n#define load(p) _mm_loadu_si128(p)\n#else\n#define load(p) (*p)\n#endif\n\n/*\n        the first 16 bytes only need byte swapping\n\n        prepared points to 4x uint32_t, 16-byte aligned\n\n        W points to the 4 dwords which need preparing --\n        and is overwritten with the swapped bytes\n*/\n#define prep00_15(prep, W)                                                     \\\n  do {                                                                         \\\n    __m128i r1, r2;                                                            \\\n                                                                               \\\n    r1 = (W);                                                                  \\\n    if (1) {                                                                   \\\n      r1 = _mm_shufflehi_epi16(r1, _MM_SHUFFLE(2, 3, 0, 1));                   \\\n      r1 = _mm_shufflelo_epi16(r1, _MM_SHUFFLE(2, 3, 0, 1));                   \\\n      r2 = _mm_slli_epi16(r1, 8);                                              \\\n      r1 = _mm_srli_epi16(r1, 8);                                              \\\n      r1 = _mm_or_si128(r1, r2);                                               \\\n      (W) = r1;                                                                \\\n    }                                                                          \\\n    (prep).u128 = _mm_add_epi32(K00_19.u128, r1);                              \\\n  } while (0)\n\n/*\n        for each multiple of 4, t, we want to calculate this:\n\n        W[t+0] = rol(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16], 1);\n        W[t+1] = rol(W[t-2] ^ W[t-7] ^ W[t-13] ^ W[t-15], 1);\n        W[t+2] = rol(W[t-1] ^ W[t-6] ^ W[t-12] ^ W[t-14], 1);\n        W[t+3] = rol(W[t]   ^ W[t-5] ^ W[t-11] ^ W[t-13], 1);\n\n        we\'ll actually calculate this:\n\n        W[t+0] = rol(W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16], 1);\n        W[t+1] = rol(W[t-2] ^ W[t-7] ^ W[t-13] ^ W[t-15], 1);\n        W[t+2] = rol(W[t-1] ^ W[t-6] ^ W[t-12] ^ W[t-14], 1);\n        W[t+3] = rol(  0    ^ W[t-5] ^ W[t-11] ^ W[t-13], 1);\n        W[t+3] ^= rol(W[t+0], 1);\n\n        the parameters are:\n\n        W0 = &amp;W[t-16];\n        W1 = &amp;W[t-12];\n        W2 = &amp;W[t- 8];\n        W3 = &amp;W[t- 4];\n\n        and on output:\n                prepared = W0 + K\n                W0 = W[t]..W[t+3]\n*/\n\n/* note that there is a step here where i want to do a rol by 1, which\n * normally would look like this:\n *\n * r1 = psrld r0,$31\n * r0 = pslld r0,$1\n * r0 = por r0,r1\n *\n * but instead i do this:\n *\n * r1 = pcmpltd r0,zero\n * r0 = paddd r0,r0\n * r0 = psub r0,r1\n *\n * because pcmpltd and paddd are availabe in both MMX units on\n * efficeon, pentium-m, and opteron but shifts are available in\n * only one unit.\n */\n#define prep(prep, XW0, XW1, XW2, XW3, K)                                      \\\n  do {                                                                         \\\n    __m128i r0, r1, r2, r3;                                                    \\\n                                                                               \\\n    /* load W[t-4] 16-byte aligned, and shift */                               \\\n    r3 = _mm_srli_si128((XW3), 4);                                             \\\n    r0 = (XW0);                                                                \\\n    /* get high 64-bits of XW0 into low 64-bits */                             \\\n    r1 = _mm_shuffle_epi32((XW0), _MM_SHUFFLE(1, 0, 3, 2));                    \\\n    /* load high 64-bits of r1 */                                              \\\n    r1 = _mm_unpacklo_epi64(r1, (XW1));                                        \\\n    r2 = (XW2);                                                                \\\n                                                                               \\\n    r0 = _mm_xor_si128(r1, r0);                                                \\\n    r2 = _mm_xor_si128(r3, r2);                                                \\\n    r0 = _mm_xor_si128(r2, r0);                                                \\\n    /* unrotated W[t]..W[t+2] in r0 ... still need W[t+3] */                   \\\n                                                                               \\\n    r2 = _mm_slli_si128(r0, 12);                                               \\\n    r1 = _mm_cmplt_epi32(r0, _mm_setzero_si128());                             \\\n    r0 = _mm_add_epi32(r0, r0); /* shift left by 1 */                          \\\n    r0 = _mm_sub_epi32(r0, r1); /* r0 has W[t]..W[t+2] */                      \\\n                                                                               \\\n    r3 = _mm_srli_epi32(r2, 30);                                               \\\n    r2 = _mm_slli_epi32(r2, 2);                                                \\\n                                                                               \\\n    r0 = _mm_xor_si128(r0, r3);                                                \\\n    r0 = _mm_xor_si128(r0, r2); /* r0 now has W[t+3] */                        \\\n                                                                               \\\n    (XW0) = r0;                                                                \\\n    (prep).u128 = _mm_add_epi32(r0, (K).u128);                                 \\\n  } while (0)\n\nstatic inline uint32_t f00_19(uint32_t x, uint32_t y, uint32_t z) {\n  /* FIPS 180-2 says this: (x &amp; y) ^ (~x &amp; z)\n   * but we can calculate it in fewer steps.\n   */\n  return ((y ^ z) &amp; x) ^ z;\n}\n\nstatic inline uint32_t f20_39(uint32_t x, uint32_t y, uint32_t z) {\n  return (x ^ z) ^ y;\n}\n\nstatic inline uint32_t f40_59(uint32_t x, uint32_t y, uint32_t z) {\n  /* FIPS 180-2 says this: (x &amp; y) ^ (x &amp; z) ^ (y &amp; z)\n   * but we can calculate it in fewer steps.\n   */\n  return (x &amp; z) | ((x | z) &amp; y);\n}\n\nstatic inline uint32_t f60_79(uint32_t x, uint32_t y, uint32_t z) {\n  return f20_39(x, y, z);\n}\n\n#define step(nn_mm, xa, xb, xc, xd, xe, xt, input)                             \\\n  do {                                                                         \\\n    (xt) = (input) + f##nn_mm((xb), (xc), (xd));                               \\\n    (xb) = rol((xb), 30);                                                      \\\n    (xt) += ((xe) + rol((xa), 5));                                             \\\n  } while (0)\n\n[[maybe_unused]]\nstatic void sha1_sse_step(uint32_t *restrict H, const uint32_t *restrict inputu,\n                          size_t num_steps) {\n  const __m128i *restrict input = (const __m128i *)inputu;\n  __m128i W0, W1, W2, W3;\n  v4si prep0, prep1, prep2;\n  uint32_t a, b, c, d, e, t;\n\n  a = H[0];\n  b = H[1];\n  c = H[2];\n  d = H[3];\n  e = H[4];\n\n  /* i\'ve tried arranging the SSE2 code to be 4, 8, 12, and 16\n   * steps ahead of the integer code.  12 steps ahead seems\n   * to produce the best performance. -dean\n   */\n  W0 = load(&amp;input[0]);\n  prep00_15(prep0, W0); /* prepare for 00 through 03 */\n  W1 = load(&amp;input[1]);\n  prep00_15(prep1, W1); /* prepare for 04 through 07 */\n  W2 = load(&amp;input[2]);\n  prep00_15(prep2, W2); /* prepare for 08 through 11 */\n  for (;;) {\n    W3 = load(&amp;input[3]);\n    step(00_19, a, b, c, d, e, t, prep0.u32[0]); /* 00 */\n    step(00_19, t, a, b, c, d, e, prep0.u32[1]); /* 01 */\n    step(00_19, e, t, a, b, c, d, prep0.u32[2]); /* 02 */\n    step(00_19, d, e, t, a, b, c, prep0.u32[3]); /* 03 */\n    prep00_15(prep0, W3);\n    step(00_19, c, d, e, t, a, b, prep1.u32[0]); /* 04 */\n    step(00_19, b, c, d, e, t, a, prep1.u32[1]); /* 05 */\n    step(00_19, a, b, c, d, e, t, prep1.u32[2]); /* 06 */\n    step(00_19, t, a, b, c, d, e, prep1.u32[3]); /* 07 */\n    prep(prep1, W0, W1, W2, W3, K00_19);         /* prepare for 16 through 19 */\n    step(00_19, e, t, a, b, c, d, prep2.u32[0]); /* 08 */\n    step(00_19, d, e, t, a, b, c, prep2.u32[1]); /* 09 */\n    step(00_19, c, d, e, t, a, b, prep2.u32[2]); /* 10 */\n    step(00_19, b, c, d, e, t, a, prep2.u32[3]); /* 11 */\n    prep(prep2, W1, W2, W3, W0, K20_39);         /* prepare for 20 through 23 */\n    step(00_19, a, b, c, d, e, t, prep0.u32[0]); /* 12 */\n    step(00_19, t, a, b, c, d, e, prep0.u32[1]); /* 13 */\n    step(00_19, e, t, a, b, c, d, prep0.u32[2]); /* 14 */\n    step(00_19, d, e, t, a, b, c, prep0.u32[3]); /* 15 */\n    prep(prep0, W2, W3, W0, W1, K20_39);\n    step(00_19, c, d, e, t, a, b, prep1.u32[0]); /* 16 */\n    step(00_19, b, c, d, e, t, a, prep1.u32[1]); /* 17 */\n    step(00_19, a, b, c, d, e, t, prep1.u32[2]); /* 18 */\n    step(00_19, t, a, b, c, d, e, prep1.u32[3]); /* 19 */\n\n    prep(prep1, W3, W0, W1, W2, K20_39);\n    step(20_39, e, t, a, b, c, d, prep2.u32[0]); /* 20 */\n    step(20_39, d, e, t, a, b, c, prep2.u32[1]); /* 21 */\n    step(20_39, c, d, e, t, a, b, prep2.u32[2]); /* 22 */\n    step(20_39, b, c, d, e, t, a, prep2.u32[3]); /* 23 */\n    prep(prep2, W0, W1, W2, W3, K20_39);\n    step(20_39, a, b, c, d, e, t, prep0.u32[0]); /* 24 */\n    step(20_39, t, a, b, c, d, e, prep0.u32[1]); /* 25 */\n    step(20_39, e, t, a, b, c, d, prep0.u32[2]); /* 26 */\n    step(20_39, d, e, t, a, b, c, prep0.u32[3]); /* 27 */\n    prep(prep0, W1, W2, W3, W0, K20_39);\n    step(20_39, c, d, e, t, a, b, prep1.u32[0]); /* 28 */\n    step(20_39, b, c, d, e, t, a, prep1.u32[1]); /* 29 */\n    step(20_39, a, b, c, d, e, t, prep1.u32[2]); /* 30 */\n    step(20_39, t, a, b, c, d, e, prep1.u32[3]); /* 31 */\n    prep(prep1, W2, W3, W0, W1, K40_59);\n    step(20_39, e, t, a, b, c, d, prep2.u32[0]); /* 32 */\n    step(20_39, d, e, t, a, b, c, prep2.u32[1]); /* 33 */\n    step(20_39, c, d, e, t, a, b, prep2.u32[2]); /* 34 */\n    step(20_39, b, c, d, e, t, a, prep2.u32[3]); /* 35 */\n    prep(prep2, W3, W0, W1, W2, K40_59);\n    step(20_39, a, b, c, d, e, t, prep0.u32[0]); /* 36 */\n    step(20_39, t, a, b, c, d, e, prep0.u32[1]); /* 37 */\n    step(20_39, e, t, a, b, c, d, prep0.u32[2]); /* 38 */\n    step(20_39, d, e, t, a, b, c, prep0.u32[3]); /* 39 */\n\n    prep(prep0, W0, W1, W2, W3, K40_59);\n    step(40_59, c, d, e, t, a, b, prep1.u32[0]); /* 40 */\n    step(40_59, b, c, d, e, t, a, prep1.u32[1]); /* 41 */\n    step(40_59, a, b, c, d, e, t, prep1.u32[2]); /* 42 */\n    step(40_59, t, a, b, c, d, e, prep1.u32[3]); /* 43 */\n    prep(prep1, W1, W2, W3, W0, K40_59);\n    step(40_59, e, t, a, b, c, d, prep2.u32[0]); /* 44 */\n    step(40_59, d, e, t, a, b, c, prep2.u32[1]); /* 45 */\n    step(40_59, c, d, e, t, a, b, prep2.u32[2]); /* 46 */\n    step(40_59, b, c, d, e, t, a, prep2.u32[3]); /* 47 */\n    prep(prep2, W2, W3, W0, W1, K40_59);\n    step(40_59, a, b, c, d, e, t, prep0.u32[0]); /* 48 */\n    step(40_59, t, a, b, c, d, e, prep0.u32[1]); /* 49 */\n    step(40_59, e, t, a, b, c, d, prep0.u32[2]); /* 50 */\n    step(40_59, d, e, t, a, b, c, prep0.u32[3]); /* 51 */\n    prep(prep0, W3, W0, W1, W2, K60_79);\n    step(40_59, c, d, e, t, a, b, prep1.u32[0]); /* 52 */\n    step(40_59, b, c, d, e, t, a, prep1.u32[1]); /* 53 */\n    step(40_59, a, b, c, d, e, t, prep1.u32[2]); /* 54 */\n    step(40_59, t, a, b, c, d, e, prep1.u32[3]); /* 55 */\n    prep(prep1, W0, W1, W2, W3, K60_79);\n    step(40_59, e, t, a, b, c, d, prep2.u32[0]); /* 56 */\n    step(40_59, d, e, t, a, b, c, prep2.u32[1]); /* 57 */\n    step(40_59, c, d, e, t, a, b, prep2.u32[2]); /* 58 */\n    step(40_59, b, c, d, e, t, a, prep2.u32[3]); /* 59 */\n\n    prep(prep2, W1, W2, W3, W0, K60_79);\n    step(60_79, a, b, c, d, e, t, prep0.u32[0]); /* 60 */\n    step(60_79, t, a, b, c, d, e, prep0.u32[1]); /* 61 */\n    step(60_79, e, t, a, b, c, d, prep0.u32[2]); /* 62 */\n    step(60_79, d, e, t, a, b, c, prep0.u32[3]); /* 63 */\n    prep(prep0, W2, W3, W0, W1, K60_79);\n    step(60_79, c, d, e, t, a, b, prep1.u32[0]); /* 64 */\n    step(60_79, b, c, d, e, t, a, prep1.u32[1]); /* 65 */\n    step(60_79, a, b, c, d, e, t, prep1.u32[2]); /* 66 */\n    step(60_79, t, a, b, c, d, e, prep1.u32[3]); /* 67 */\n    prep(prep1, W3, W0, W1, W2, K60_79);\n    step(60_79, e, t, a, b, c, d, prep2.u32[0]); /* 68 */\n    step(60_79, d, e, t, a, b, c, prep2.u32[1]); /* 69 */\n    step(60_79, c, d, e, t, a, b, prep2.u32[2]); /* 70 */\n    step(60_79, b, c, d, e, t, a, prep2.u32[3]); /* 71 */\n\n    --num_steps;\n    if (num_steps == 0)\n      break;\n\n    input += 4;\n    W0 = load(&amp;input[0]);\n    prep00_15(prep2, W0); /* prepare for next 00 through 03 */\n    W1 = load(&amp;input[1]);\n    step(60_79, a, b, c, d, e, t, prep0.u32[0]); /* 72 */\n    step(60_79, t, a, b, c, d, e, prep0.u32[1]); /* 73 */\n    step(60_79, e, t, a, b, c, d, prep0.u32[2]); /* 74 */\n    step(60_79, d, e, t, a, b, c, prep0.u32[3]); /* 75 */\n    prep0 = prep2;        /* top of loop expects this in prep0 */\n    prep00_15(prep2, W1); /* prepare for next 04 through 07 */\n    W2 = load(&amp;input[2]);\n    step(60_79, c, d, e, t, a, b, prep1.u32[0]); /* 76 */\n    step(60_79, b, c, d, e, t, a, prep1.u32[1]); /* 77 */\n    step(60_79, a, b, c, d, e, t, prep1.u32[2]); /* 78 */\n    step(60_79, t, a, b, c, d, e, prep1.u32[3]); /* 79 */\n    prep1 = prep2;        /* top of loop expects this in prep1 */\n    prep00_15(prep2, W2); /* prepare for next 08 through 11 */\n    /* e, t, a, b, c, d */\n    H[0] += e;\n    H[1] += t;\n    H[2] += a;\n    H[3] += b;\n    H[4] += c;\n\n    a = H[0];\n    b = H[1];\n    c = H[2];\n    d = H[3];\n    e = H[4];\n  }\n  /* no more input to prepare */\n  step(60_79, a, b, c, d, e, t, prep0.u32[0]); /* 72 */\n  step(60_79, t, a, b, c, d, e, prep0.u32[1]); /* 73 */\n  step(60_79, e, t, a, b, c, d, prep0.u32[2]); /* 74 */\n  step(60_79, d, e, t, a, b, c, prep0.u32[3]); /* 75 */\n  /* no more input to prepare */\n  step(60_79, c, d, e, t, a, b, prep1.u32[0]); /* 76 */\n  step(60_79, b, c, d, e, t, a, prep1.u32[1]); /* 77 */\n  step(60_79, a, b, c, d, e, t, prep1.u32[2]); /* 78 */\n  step(60_79, t, a, b, c, d, e, prep1.u32[3]); /* 79 */\n  /* e, t, a, b, c, d */\n  H[0] += e;\n  H[1] += t;\n  H[2] += a;\n  H[3] += b;\n  H[4] += c;\n}\nOur\nis_piece_valid\nfunction now becomes:\nstatic bool is_piece_valid(uint8_t *piece, uint64_t piece_len,\n                           uint8_t digest_expected[20]) {\n  SHA1_CTX ctx = {0};\n  SHA1Init(&amp;ctx);\n\n  // Process as many SHA1 64 bytes chunks as possible.\n  uint64_t len_rounded_down = (piece_len / 64) * 64;\n  uint64_t rem = piece_len % 64;\n  uint64_t steps = len_rounded_down / 64;\n  sha1_sse_step(ctx.state, piece, steps);\n\n  // Process the excess.\n  memcpy(ctx.buffer, piece + len_rounded_down, rem);\n\n  // `count` is in bits: multiple the number of bytes by 8.\n  ctx.count = piece_len * 8;\n\n  uint8_t digest_actual[20] = {0};\n  SHA1Final(digest_actual, &amp;ctx);\n\n  return !memcmp(digest_actual, digest_expected, 20);\n}\nResults\nSo predictably, since we now process 4\nuint32_t\nat a time instead of one, we observe roughly a 4x speed-up (still in debug + Address Sanitizer mode):\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):      8.093 s \u{b1}  0.272 s    [User: 8.010 s, System: 0.060 s]\n  Range (min \u{2026} max):    7.784 s \u{2026}  8.684 s    10 runs\nThat\'s better but still not great. We could apply the tweaks suggested by Intel, but that probably would not give us the order of magnitude improvement we need. They cite x1.2 to x1.5 improvements in their article. We need more.\nSo... did you know that in all likelihood, your CPU has dedicated silicon to accelerate SHA1 computations? Let\'s use that! We paid for it, we get to use it!\nIntel SHA extension implementation\nDespite the \'Intel\' name, Intel as well as AMD CPUs have been shipping with this\nextension\n, since around 2016-2017. It adds a few SIMD instructions dedicated to compute SHA1 (and SHA256, and other variants). Note that ARM also has an equivalent (albeit incompatible, of course) extension so the same can be done there.\nThere is an irony here, because 2017 is also the year where the first SHA1 public collision was published, which incited many developers to move away from SHA1...\nThe advantage is that the structure of the code can remain the same: we still are using 128 bits SIMD registers, still computing SHA1 chunks of 64 bytes at a time. It\'s just that a few operations get faster and the code is generally shorter and clearer, and the main part is branchless.\nThe implementation is a pure work of art, and comes from this\nGithub repository\n. I have commented lots of it for clarity.\nExplanations\nThe unit of work here is still 128 bits (or 4\nuint32_t\n). Unfortunately, the SHA1 state that we are continuously updating, and from which the final digest is extracted, is\n5\nuint32_t\n. So we are in a pickle since it does not fit neatly in one SIMD register.  Thus, we have to do one SIMD operation on the first 4\nuint32_t\n, named\nABCD\n, and another one with the last\nuint32_t\n, named\nE\n. So this second operation is a bit wasteful: our 128 bits only contain 1/4 of useful data, and our CPU does computations on a bunch of zeroes which will be thrown away. But there is no other way: SIMD uses a different set of registers from the standard ones. We want to stay in SIMD land as much as possible, that\'s where the performance is.\nEndianness conversion is done with one SIMD instruction, same as before (so 4\nuint32_t\nat a time).\nThe SHA Intel extension provides 4 operations:\nsha1rnds4\nto compute the next\nABCD\nstate\nsha1nexte\n: to compute the next\nE\nstate (remember,\nE\nis alone in its 128 bits register)\nsha1msg1\nand\nsha1msg2\n: they perform the SHA1 computations solely based on the input data\nThus we alternate between SHA1 computations with\nsha1msg1/sha1msg2\n, and state calculations with\nsha1rnds4/sha1nexte\n, always 4\nuint32_t\nat a time.\nWhat\'s a &quot;SHA computation&quot;? It\'s basically a recombination, or shuffling, of its input. For example,\nsha1msg1\nin pseudo-code does:\nW0 &lt;- SRC1[127:96] ;\n  W1 &lt;- SRC1[95:64] ;\n  W2 &lt;- SRC1[63: 32] ;\n  W3 &lt;- SRC1[31: 0] ;\n  W4 &lt;- SRC2[127:96] ;\n  W5 &lt;- SRC2[95:64] ;\n  DEST[127:96] &lt;- W2 XOR W0;\n  DEST[95:64] &lt;- W3 XOR W1;\n  DEST[63:32] &lt;- W4 XOR W2;\n  DEST[31:0] &lt;- W5 XOR W3;\nThe first 16 rounds, we do that on the input data (i.e. the download file). But for the remaining rounds (SHA1 does 80 rounds for a 64 byte chunk), the input is computations from previous rounds.\nsha1msg2\ndoes slightly different computations but still very similar.\nThe code\nSHA1 with the Intel SHA extension\n// Process as many 64 bytes chunks as possible.\n[[maybe_unused]]\nstatic void sha1_sha_ext(uint32_t state[5], const uint8_t data[],\n                         uint32_t length) {\n  __m128i ABCD, ABCD_SAVE, E0, E0_SAVE, E1;\n  __m128i MSG0, MSG1, MSG2, MSG3;\n  const __m128i MASK =\n      // As 16 u8: `0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15`.\n      _mm_set_epi64x(0x0001020304050607ULL, 0x08090a0b0c0d0e0fULL);\n\n  /* Load initial values */\n  ABCD = _mm_loadu_si128((const __m128i *)(void *)state);\n  E0 = _mm_set_epi32((int)state[4], 0, 0, 0);\n\n  // Transform state to big-endian.\n  ABCD = _mm_shuffle_epi32(ABCD, 0x1B);\n\n  while (length &gt;= 64) {\n    /* Save current state  */\n    ABCD_SAVE = ABCD;\n    E0_SAVE = E0;\n\n    /* Rounds 0-3 */\n    // Load `data[0:16]`.\n    MSG0 = _mm_loadu_si128((const __m128i *)(void *)(data + 0));\n\n    // Convert MSG0 to big-endian.\n    MSG0 = _mm_shuffle_epi8(MSG0, MASK);\n    // E0 += MSG0\n    E0 = _mm_add_epi32(E0, MSG0);\n    E1 = ABCD;\n    //  Perform 4 rounds of SHA1 operation.\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 0);\n\n    /* Rounds 4-7 */\n    // Load `data[16:32]`.\n    MSG1 = _mm_loadu_si128((const __m128i *)(void *)(data + 16));\n    // Convert to big-endian.\n    MSG1 = _mm_shuffle_epi8(MSG1, MASK);\n    // Compute the SHA1 state variable E after 4 rounds.\n    // It is added to the source operand (`E1`).\n    E1 = _mm_sha1nexte_epu32(E1, MSG1);\n    E0 = ABCD;\n\n    //  Perform 4 rounds of SHA1 operation.\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 0);\n    // Perform the intermediate calculation for the next four SHA1 message dwords (128 bits).\n    MSG0 = _mm_sha1msg1_epu32(MSG0, MSG1);\n\n    /* Rounds 8-11 */\n    // Load `data[32:48]`.\n    MSG2 = _mm_loadu_si128((const __m128i *)(void *)(data + 32));\n    // Convert to big-endian.\n    MSG2 = _mm_shuffle_epi8(MSG2, MASK);\n    // Compute the SHA1 state variable E after 4 rounds.\n    E0 = _mm_sha1nexte_epu32(E0, MSG2);\n    E1 = ABCD;\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 0);\n    MSG1 = _mm_sha1msg1_epu32(MSG1, MSG2);\n    MSG0 = _mm_xor_si128(MSG0, MSG2);\n\n    /* Rounds 12-15 */\n    // Load `data[48:64]`.\n    MSG3 = _mm_loadu_si128((const __m128i *)(void *)(data + 48));\n    // Convert to big-endian.\n    MSG3 = _mm_shuffle_epi8(MSG3, MASK);\n    // Compute the SHA1 state variable E after 4 rounds.\n    E1 = _mm_sha1nexte_epu32(E1, MSG3);\n    E0 = ABCD;\n    // Perform a final calculation for the next four SHA1 message dwords.\n    MSG0 = _mm_sha1msg2_epu32(MSG0, MSG3);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 0);\n    MSG2 = _mm_sha1msg1_epu32(MSG2, MSG3);\n    MSG1 = _mm_xor_si128(MSG1, MSG3);\n\n    /* Rounds 16-19 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG0);\n    E1 = ABCD;\n    MSG1 = _mm_sha1msg2_epu32(MSG1, MSG0);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 0);\n    MSG3 = _mm_sha1msg1_epu32(MSG3, MSG0);\n    MSG2 = _mm_xor_si128(MSG2, MSG0);\n\n    /* Rounds 20-23 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG1);\n    E0 = ABCD;\n    MSG2 = _mm_sha1msg2_epu32(MSG2, MSG1);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 1);\n    MSG0 = _mm_sha1msg1_epu32(MSG0, MSG1);\n    MSG3 = _mm_xor_si128(MSG3, MSG1);\n\n    /* Rounds 24-27 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG2);\n    E1 = ABCD;\n    MSG3 = _mm_sha1msg2_epu32(MSG3, MSG2);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 1);\n    MSG1 = _mm_sha1msg1_epu32(MSG1, MSG2);\n    MSG0 = _mm_xor_si128(MSG0, MSG2);\n\n    /* Rounds 28-31 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG3);\n    E0 = ABCD;\n    MSG0 = _mm_sha1msg2_epu32(MSG0, MSG3);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 1);\n    MSG2 = _mm_sha1msg1_epu32(MSG2, MSG3);\n    MSG1 = _mm_xor_si128(MSG1, MSG3);\n\n    /* Rounds 32-35 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG0);\n    E1 = ABCD;\n    MSG1 = _mm_sha1msg2_epu32(MSG1, MSG0);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 1);\n    MSG3 = _mm_sha1msg1_epu32(MSG3, MSG0);\n    MSG2 = _mm_xor_si128(MSG2, MSG0);\n\n    /* Rounds 36-39 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG1);\n    E0 = ABCD;\n    MSG2 = _mm_sha1msg2_epu32(MSG2, MSG1);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 1);\n    MSG0 = _mm_sha1msg1_epu32(MSG0, MSG1);\n    MSG3 = _mm_xor_si128(MSG3, MSG1);\n\n    /* Rounds 40-43 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG2);\n    E1 = ABCD;\n    MSG3 = _mm_sha1msg2_epu32(MSG3, MSG2);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 2);\n    MSG1 = _mm_sha1msg1_epu32(MSG1, MSG2);\n    MSG0 = _mm_xor_si128(MSG0, MSG2);\n\n    /* Rounds 44-47 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG3);\n    E0 = ABCD;\n    MSG0 = _mm_sha1msg2_epu32(MSG0, MSG3);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 2);\n    MSG2 = _mm_sha1msg1_epu32(MSG2, MSG3);\n    MSG1 = _mm_xor_si128(MSG1, MSG3);\n\n    /* Rounds 48-51 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG0);\n    E1 = ABCD;\n    MSG1 = _mm_sha1msg2_epu32(MSG1, MSG0);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 2);\n    MSG3 = _mm_sha1msg1_epu32(MSG3, MSG0);\n    MSG2 = _mm_xor_si128(MSG2, MSG0);\n\n    /* Rounds 52-55 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG1);\n    E0 = ABCD;\n    MSG2 = _mm_sha1msg2_epu32(MSG2, MSG1);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 2);\n    MSG0 = _mm_sha1msg1_epu32(MSG0, MSG1);\n    MSG3 = _mm_xor_si128(MSG3, MSG1);\n\n    /* Rounds 56-59 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG2);\n    E1 = ABCD;\n    MSG3 = _mm_sha1msg2_epu32(MSG3, MSG2);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 2);\n    MSG1 = _mm_sha1msg1_epu32(MSG1, MSG2);\n    MSG0 = _mm_xor_si128(MSG0, MSG2);\n\n    /* Rounds 60-63 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG3);\n    E0 = ABCD;\n    MSG0 = _mm_sha1msg2_epu32(MSG0, MSG3);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 3);\n    MSG2 = _mm_sha1msg1_epu32(MSG2, MSG3);\n    MSG1 = _mm_xor_si128(MSG1, MSG3);\n\n    /* Rounds 64-67 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG0);\n    E1 = ABCD;\n    MSG1 = _mm_sha1msg2_epu32(MSG1, MSG0);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 3);\n    MSG3 = _mm_sha1msg1_epu32(MSG3, MSG0);\n    MSG2 = _mm_xor_si128(MSG2, MSG0);\n\n    /* Rounds 68-71 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG1);\n    E0 = ABCD;\n    MSG2 = _mm_sha1msg2_epu32(MSG2, MSG1);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 3);\n    MSG3 = _mm_xor_si128(MSG3, MSG1);\n\n    /* Rounds 72-75 */\n    E0 = _mm_sha1nexte_epu32(E0, MSG2);\n    E1 = ABCD;\n    MSG3 = _mm_sha1msg2_epu32(MSG3, MSG2);\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E0, 3);\n\n    /* Rounds 76-79 */\n    E1 = _mm_sha1nexte_epu32(E1, MSG3);\n    E0 = ABCD;\n    ABCD = (__m128i)_mm_sha1rnds4_epu32(ABCD, E1, 3);\n\n    /* Combine state */\n    E0 = _mm_sha1nexte_epu32(E0, E0_SAVE);\n    // ABCD += ABCD_SAVE\n    ABCD = _mm_add_epi32(ABCD, ABCD_SAVE);\n\n    data += 64;\n    length -= 64;\n  }\n\n  /* Save state */\n  // Convert back to little-endian.\n  ABCD = _mm_shuffle_epi32(ABCD, 0x1B);\n  _mm_storeu_si128((__m128i *)(void *)state, ABCD);\n  // Convert back to little-endian.\n  state[4] = (uint32_t)_mm_extract_epi32(E0, 3);\n}\nOur\nis_piece_valid\nfunction is practically identical to the last section:\nstatic bool is_piece_valid(uint8_t *piece, uint64_t piece_len,\n                           uint8_t digest_expected[20]) {\n  SHA1_CTX ctx = {0};\n  SHA1Init(&amp;ctx);\n\n  // Process as many SHA1 64 bytes chunks as possible.\n  uint64_t len_rounded_down = (piece_len / 64) * 64;\n  uint64_t rem = piece_len % 64;\n  sha1_sha_ext(ctx.state, piece, (uint32_t)len_rounded_down);\n\n  memcpy(ctx.buffer, piece + len_rounded_down, rem);\n\n  ctx.count = piece_len * 8;\n\n  uint8_t digest_actual[20] = {0};\n  SHA1Final(digest_actual, &amp;ctx);\n\n  return !memcmp(digest_actual, digest_expected, 20);\n}\nResults\nHow fast?\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):     866.9 ms \u{b1}  17.4 ms    [User: 809.6 ms, System: 54.4 ms]\n  Range (min \u{2026} max):   839.7 ms \u{2026} 901.4 ms    10 runs\nNow that\'s what I\'m talking about, ~\n571 MiB/s\n. Around a 10x speed-up compared to the basic SSE implementation! And now we are running under a second. Also the variability is much reduced which is nice.\nWhat about a release build (without Address Sanitizer), for comparison?\nThis is the SIMD-less version with\n-O2 -march=native\n, benefiting from some auto-vectorization:\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):     617.8 ms \u{b1}  20.9 ms    [User: 573.6 ms, System: 42.2 ms]\n  Range (min \u{2026} max):   598.7 ms \u{2026} 669.1 ms    10 runs\nThat\'s ~\n802 Mib/s\n.\nAnd this is the code using the SHA extension, again with\n-O2 -march=native\n:\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):     281.2 ms \u{b1}   5.4 ms    [User: 240.6 ms, System: 39.6 ms]\n  Range (min \u{2026} max):   276.1 ms \u{2026} 294.3 ms    10 runs\nThat\'s ~\n1.8 Gib/s\n.\nUnsurprisingly, when inspecting the generated assembly code for the SIMD-less version, the auto-vectorization is\nvery\nlimited and does not use the SHA extension (compilers are smart, but not\nthat\nsmart).\nAs such, it\'s still very impressive that it reaches such a high performance. My guess is that the compiler does a good job at analyzing data dependencies and reordering statements to maximize utilization. Also, SHA1 does a lot of bit rotation, and the compiler makes heavy use of the\nror\n,\nrol\n, and\nshr\ninstructions to do just that instead of doing multiple naive bit operations like in the unoptimized code.\nThe version using the SHA extension performs very well, be it in debug + Address Sanitizer mode, or release mode.\nAlso, in both versions, as the SHA1 code got much faster, we start to see on the CPU profile\nmmap\nshow up, as confirmed by the\nsystem time\npart becoming a fifth of the whole runtime.\nThat means that we are starting to be limited by I/O. Which is good!  Using\nhdparm\nto measure my disk performance, I get:\nTiming buffered disk reads: 6518 MB in  3.00 seconds = 2171.34 MB/sec\nSince our benchmark first warms up a few times, we know that the file data is in the cache, so\nbuffered disk reads\nseems like a good metric to go by. Thus, our program performance is near the disk I/O limit for cached reads. Sounds pretty good to me!\nI tried to give the OS some hints to improve a bit on that front with\nmadvise(file_download_data, file_download_size, MADV_SEQUENTIAL | MADV_WILLNEED)\n, but it did not have any impact on the timings.\nOpenSSL hand crafted assembly implementation\nThe whole point of this article is to do SHA1 computations from scratch and avoid dependencies. Let\'s see how OpenSSL (in this case,\naws-lc\nbut I don\'t believe they changed that part at all) fares out of curiosity.\n$ hyperfine --warmup 3 \'./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\'\nBenchmark 1: ./a.out ./NetBSD-9.4-amd64.iso ~/Downloads/NetBSD-9.4-amd64.iso.torrent\n  Time (mean \u{b1} \u{3c3}):     281.5 ms \u{b1}   3.9 ms    [User: 245.7 ms, System: 35.1 ms]\n  Range (min \u{2026} max):   276.3 ms \u{2026} 288.9 ms    10 runs\nSo, the performance is essentially identical to our version. Pretty good.\nOpenSSL picks at runtime the best code path based on what features the CPU supports. Interestingly on my system, even when compiled with\n-march=native\n, it does not decide to use the SHA extension, and instead goes for hand-optimized SIMD. That\'s mind-blowing that this SIMD code performs as well that dedicated silicon, including the cycles spent on the runtime check. So props to the developers!\nI can see really low-level tricks like\nprefetcht0\nto ask for the prefetcher to cache some data ahead of time to reduce latency. And they mention they had help from some folks at Intel.\nAdditional improvements\nI have not talked about AVX2, AVX512, etc. These could be fun to implement and benchmark. If you are interested in this kind of thing, the OpenSSL project (and the various clones and forks) has a\nPerl script\nto generate assembly code to do SHA1 with various variants of SIMD and SHA extension. I think the numbers are pretty dated but it\'s a goldmine of information.\nOh, and I almost forgot: we can compute SHA1 on the\nGPU\n!\nConclusion\nThat was a fun deep dive about performance, SIMD, and a deprecated hash algorithm that is still in use in many applications (e.g. Git).\nWhat I have learned is that Address Sanitizer really likes SIMD code because it reduces significantly the runtime checks it has to do, and thus the performance impact is greatly reduced. It is often recommended to do fuzzing with Address Sanitizer on, so performance matters here.\nSIMD code is like a math puzzle, it\'s weird and fun. I\'m happy that I finally had my first real contact with it. It has the useful property to have a very stable performance across runs. I hope I did not get anything wrong in this article.\nAnd it\'s wild to see different implementations range from 30s to 300 ms (a factor of 100!) to do the same thing. Also, optimizers these days are god damn impressive.\nIf you want to learn more about SIMD, I recommend this\ntalk\nfrom the Titanfall developers at GDC where they explain how they use a lot of SIMD in their game engine, but also their thought process to go from a standard procedural code to a SIMD version:\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#2864684395-why-is-it-a-problem-at-all-and-how-did-it-come-to-be",
"#2923246873-non-simd-implementation",
"#1904669649-explanation",
"#1805512826-the-code",
"#2723950694-results",
"#458888313-possible-optimizations",
"#3812694471-simd-sse-implementation",
"#1057757599-explanation",
"#121025924-the-code",
"#226219880-results",
"#1053355703-intel-sha-extension-implementation",
"#281525890-explanations",
"#215954170-the-code",
"#4270897102-results",
"#121160688-openssl-hand-crafted-assembly-implementation",
"#2977180874-additional-improvements",
"#3796851539-conclusion",
],
title_text_offsets:[
3520,6283,9381,11606,18830,19581,22058,22939,24618,39649,40515,41443,43380,50992,54024,55264,55713,],
},
{
name:"tip_of_the_day_5.html",
text:"Tip of the day #5: Install Go tools with a specific version\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-18\nTip of the day #5: Install Go tools with a specific version\nGo\nTip of the day\nI had an issue with Go tools around versioning, and here\'s how I solved it. It could be useful to others. This was the error:\n$ staticcheck  ./...\n-: module requires at least go1.23.6, but Staticcheck was built with go1.23.1 (compile)\n$ go version\ngo version go1.23.6 linux/amd64\nIndeed the project was specifying\ngo 1.23.6\nin\ngo.mod\n.\nEven after removing the staticcheck binary and re-installing it I still had the same issue:\n$ which staticcheck\n/home/pg/go/bin/staticcheck\n$ rm /home/pg/go/bin/staticcheck\n$ which staticcheck\nwhich: no staticcheck \n$ go install honnef.co/go/tools/cmd/staticcheck@v0.5.1\n$ staticcheck  ./...\n-: module requires at least go1.23.6, but Staticcheck was built with go1.23.1 (compile)\nI even tried the\n-a\nflag for\ngo install\nto force a clean build (since\ngo install\nfetches the sources and builds them) to no avail.\nSolution:\nfollowing\nhttps://go.dev/doc/manage-install\n, I installed the specific version of Go I needed and used that to install the tool:\n$ go install golang.org/dl/go1.23.6@latest\n$ go1.23.6 download\n$ go1.23.6 install honnef.co/go/tools/cmd/staticcheck@v0.5.1\n$ staticcheck  -tags=integration_tests ./... # Works!\nThat was a TIL for me.\nNote that Go 1.24 supports the project listing tools directly in\ngo.mod\nwhich would probably solve this issue directly.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
],
title_text_offsets:[
],
},
{
name:"making_my_static_blog_generator_11_times_faster.html",
text:"Making my static blog generator &lt;del&gt;11&lt;/del&gt; 33 times faster\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-02-19\nMaking my static blog generator\n11\n33 times faster\nOptimization\nGit\nOdin\nFossil\nTable of contents\nThe investigation\nWhen there\'s one, there\'s many\nThe new approach\nThe new implementation\nFossil\nConclusion\nAddendum\nAddendum 2\nThis blog is statically generated from Markdown files. It used to be fast, but nowadays it\'s not:\n$ hyperfine --warmup 2 ./master.bin \nBenchmark 1: ./master.bin\n  Time (mean \u{b1} \u{3c3}):      1.873 s \u{b1}  0.053 s    [User: 1.351 s, System: 0.486 s]\n  Range (min \u{2026} max):    1.806 s \u{2026}  1.983 s    10 runs\n~ 2 seconds is not the end of the world, but it\'s just enough to be annoying when doing lots of edit-view cycles. Worse, it seemed to become slower and slower as I wrote more articles. So today I finally dedicated some time to tackle this problem.\nThe investigation\nIn the early days of this blog, there were only a few articles, and the build process was a simple Makefile, something like this (simplified):\n%.html: %.md header.html footer.html\n        cat header.html &gt;&gt; $@\n        pandoc --toc $&lt; &gt;&gt; $@\n        cat footer.html &gt;&gt; $@\nFor each markdown file, say\nwayland_from_scratch.md\n, we transform the markdown into HTML (at the time with\npandoc\n, which proved to be super slow, now with\ncmark\nwhich is extremely fast) and save that in the file\nwayland_from_scratch.html\n, with a HTML header prepended and footer appended.\nLater on, I added the publication date:\n%.html: %.md header.html footer.html\n        cat header.html &gt;&gt; $@\n        printf \'&lt;p id=&quot;publication_date&quot;&gt;Published on %s.&lt;/p&gt;\\n\' $$(git log --format=\'%as\' --reverse -- $&lt; | head -n1)  &gt;&gt; $@; fi\n        pandoc --toc $&lt; &gt;&gt; $@\n        cat footer.html &gt;&gt; $@\nThe publication date is the creation date, that is: the date of the first Git commit for this file. So we ask Git for the list of commits for this file (they are provided by default from newest to oldest, so we\n--reverse\nthe list), take the first one with\nhead\n, done. It\'s simple.\nNote: My initial approach was to get the creation and modification date from the file system, but it\'s incorrect, as soon as you work on more than one machine. The way Git works is that when you pull commits that created a file, it creates the file on the file system and does not try to hack the creation date. Thus the file creation date is the time of the Git pull, not the date of the commit that first created it.\nAs I added more and more features to this blog, like a list of article by tags, a home page that automatically lists all of the articles, a RSS feed, the \'last modified\' date for an article, etc, I outgrew the Makefile approach and wrote a small\nprogram\n(initially in Zig, then in\nOdin\n) to do all that. But the core approach remained:\nList all markdown files in the current directory (e.g.\nls *.md\n, the Makefile did that for us with\n%.md\n)\nFor each markdown file, sequentially:\nRun\ngit log article.md\nto get the date of the first and last commits for this file (respectively \'created at\' and \'modified at\')\nConvert the markdown content to HTML\nSave this HTML to\narticle.html\nFor long time, it was all good. It was single-threaded, but plenty fast. So I wrote more and more articles. But now it\'s too slow. Why? Let\'s profile it:\nYeah...I think it might be [git] [git] [git] [git] [git] [git] [git] [git]...\nAnother way to confirm this is with\nstrace\n:\n$ strace --summary-only ./src.bin\n% time     seconds  usecs/call     calls    errors syscall\n------ ----------- ----------- --------- --------- ----------------\n 94.85    0.479290        3928       122           waitid\n[...]\nSo ~\n95 %\nof the running time is spent waiting on a subprocess. It\'s mainly git - we also run\ncmark\nas a subprocess but it\'s really really fast. We could further investigate with\nstrace\nwhich process we are waiting on but the CPU profile already points the finger at Git and\ncmark\nis not even visible on it.\nAt this point it\'s important to mention that this program is a very simplistic static site generator: it is stateless and processes every markdown file in the repository one by one. You could say that it\'s a regression compared to the Makefile because\nmake\nhas built-in parallelism with\n-j\nand change detection. But in reality, change detection in make is primitive and I often want to reprocess everything because of a change that applies to every file. For example, I reword the\nDonate\nsection at the end of each article (wink wink), or the header, or the footer, etc.\nAlso, I really am fond of this \'pure function\' approach. There is no caching issue to debug, no complicated code to write, no data races, no async callbacks, etc.\nMy performance target was to process every file within 1s, or possibly even 0.5s.\nI could see a few options:\nDo not block on\ngit log\n. We can use a thread pool, or an\nasynchronous approach\nto spawn all the git processes at once, and wait for all of them to finish. But it\'s more complex.\nImplement caching so that only the changed markdown files get regenerated.\nMake\ngit log\nfaster somehow.\nThe last option was my preferred one because it did not force me to re-architect the whole program.\nNote that the other two options are sill on the table regardless of whether our experiment works out or not.\nWhen there\'s one, there\'s many\nMy intuition was to do a deep dive in the\ngit log\noptions, to see if I could instruct it to do less work. But then something struck me: we invoke\ngit log\nto get all commits for one markdown file (even though we only are interested in the first and last, but that\'s the only interface Git provides us as far as I know). What if we invoked it once\nfor all markdown files\n? Yes, the output might be a bit big... How big? Is it really faster? Let\'s measure!\nConceptually we can simply do\ngit log \'*.md\'\nand parse the output. We can refine that approach later with more options, but that\'s the gist of it:\n$ time git log \'*.md\' | wc -c\n191196\n\n________________________________________________________\nExecuted in   73.69 millis    fish           external\n   usr time   61.04 millis  738.00 micros   60.30 millis\n   sys time   15.95 millis  191.00 micros   15.76 millis\nSo it\'s much faster than doing it per file, and also it\'s entire output is ~ 186 KiB. And these numbers should grow very slowly because each new commit only adds 20-100 bytes to the output.\nLooks like we got our solution. There is one added benefit: we do not need to list all\n.md\nfiles in the directory at startup. Git gives us this information (in my case there are no markdown files\nnot\ntracked by Git).\nMike Acton and\nData Oriented Design\nare right once again:\nRule of thumb: When there is one, there is many.\n1\nOr: try to think in terms of arrays, not in terms of one isolated object at a time.\nThe new approach\nWe only want git to tell us, for each commit:\nThe date\nWhich files were affected\nHence we pass to\ngit log\n:\n--format=\'%aI\'\nto get the date in ISO format\n--name-status\nto know which files this commit added (\nA\n), modified (\nM\n), deleted (\nD\n), or renamed (\nR\n)\n--no-merges\nto skip merge commits since they do not directly affect any file\n--diff-filter=AMRD\nto only get commits that add/modify/delete/rename files. We are not interested in commits changing the permissions on a file, or modifying symbolic links, etc.\nWith these options we get even better numbers:\n$ time git log --format=\'%aI\' --name-status --no-merges --diff-filter=AMDR  -- \'*.md\' | wc -c\n77832\n\n________________________________________________________\nExecuted in  108.38 millis    fish           external\n   usr time   83.70 millis  231.00 micros   83.47 millis\n   sys time   27.99 millis  786.00 micros   27.20 millis\nThe output looks like this (I annotated each part along with the commit number):\n2024-11-05T15:43:44+01:00                                                            | [1] A commit starts with the date.\n                                                                                     | [1] Empty line\nM       how_to_rewrite_a_cpp_codebase_successfully.md                                | [1] A list of files affected by this commit.\nM       write_a_video_game_from_scratch_like_1987.md                                 | [1] Each starts with a letter describing the action.\nM       x11_x64.md                                                                   | [1] Here it\'s all modifications.\nM       you_inherited_a_legacy_cpp_codebase_now_what.md                              | [1]\n2025-02-02T22:54:23+01:00                                                            | [2] The second entry starts.\n                                                                                     | [2] \nR100    cross-platform-timers.md        the_missing_cross_platform_api_for_timers.md | [2] Rename with the (unneeded) confidence score.\n[...]                                                                                | Etc.\nParsing this commit log is tedious but not extremely difficult.\nWe maintain a map while inspecting each commit:\nmap&lt;Path, (creation_date, modification_date, tombstone)&gt;\n.\nIn case of a rename or delete, we set the\ntombstone\nto\ntrue\n. Why not remove the entry from the map directly? Well, we are inspecting the list of commits from newest to oldest.\nSo first we\'ll encounter the delete/rename commit for this file, and then later in the stream, a number of add/modify commits. When we are done, we need to remember that this markdown file should be ignored, otherwise, we\'ll try to open it, read it, and convert it to HTML, but we\'ll get a\nENOENT\nerror because it does not exist anymore on disk. We could avoid having this tombstone field and just bail on\nENOENT\n, that\'s a matter of taste I guess, but this field was useful to me to ensure that the parsing code is correct.\nAlternatively, we could pass\n--reverse\nto\ngit log\nand parse the commits in chronological order. When we see a delete/rename commit for a file, we can safely remove the entry from the map since no more commits about this file should show up after that.\nThe new implementation\nGitStat :: struct {\n\tcreation_date:     string,\n\tmodification_date: string,\n\tpath_rel:          string,\n}\n\nget_articles_creation_and_modification_date :: proc() -&gt; ([]GitStat, os2.Error) {\n\tfree_all(context.temp_allocator)\n\tdefer free_all(context.temp_allocator)\n\n\tstate, stdout_bin, stderr_bin, err := os2.process_exec(\n\t\t{\n\t\t\tcommand = []string {\n\t\t\t\t&quot;git&quot;,\n\t\t\t\t&quot;log&quot;,\n\t\t\t\t// Print the date in ISO format.\n\t\t\t\t&quot;--format=\'%aI\'&quot;,\n\t\t\t\t// Ignore merge commits since they do not carry useful information.\n\t\t\t\t&quot;--no-merges&quot;,\n\t\t\t\t// Only interested in creation, modification, renaming, deletion.\n\t\t\t\t&quot;--diff-filter=AMRD&quot;,\n\t\t\t\t// Show which modification took place:\n\t\t\t\t// A: added, M: modified, RXXX: renamed (with percentage score), etc.\n\t\t\t\t&quot;--name-status&quot;,\n\t\t\t\t&quot;*.md&quot;,\n\t\t\t},\n\t\t},\n\t\tcontext.temp_allocator,\n\t)\n\tif err != nil {\n\t\tfmt.eprintf(&quot;git failed: %d %v %s&quot;, state, err, string(stderr_bin))\n\t\tpanic(&quot;git failed&quot;)\n\t}\n\n\tstdout := strings.trim_space(string(stdout_bin))\n\tassert(stdout != &quot;&quot;)\n\n\tGitStatInternal :: struct {\n\t\tcreation_date:     string,\n\t\tmodification_date: string,\n\t\ttombstone:         bool,\n\t}\n\tstats_by_path := make(map[string]GitStatInternal, allocator = context.temp_allocator)\n\n\t// Sample git output:\n\t// 2024-10-31T16:09:02+01:00\n\t// \n\t// M       lessons_learned_from_a_successful_rust_rewrite.md\n\t// A       tip_of_day_3.md\n\t// 2025-02-18T08:07:55+01:00\n\t//\n\t// R100    sha.md  making_my_debug_build_run_100_times_faster.md\n\n\t// For each commit.\n\tfor {\n\t\t// Date\n\t\tdate: string\n\t\t{\n\t\t\tline := strings.split_lines_iterator(&amp;stdout) or_break\n\n\t\t\tassert(strings.starts_with(line, &quot;\'20&quot;))\n\t\t\tline_without_quotes := line[1:len(line) - 1]\n\t\t\tdate = strings.clone(strings.trim(line_without_quotes, &quot;\' \\n&quot;))\n\t\t}\n\n\t\t// Empty line\n\t\t{\n\t\t\t// Peek.\n\t\t\tline, ok := strings.split_lines_iterator(&amp;stdout)\n\t\t\tassert(ok)\n\t\t\tassert(line == &quot;&quot;)\n\t\t}\n\n\t\t// Files.\n\t\tfor {\n\t\t\t// Start of a new commit?\n\t\t\tif strings.starts_with(stdout, &quot;\'20&quot;) do break\n\n\t\t\tline := strings.split_lines_iterator(&amp;stdout) or_break\n\t\t\tassert(line != &quot;&quot;)\n\n\t\t\taction := line[0]\n\t\t\tassert(action == \'A\' || action == \'M\' || action == \'R\' || action == \'D\')\n\n\t\t\told_path: string\n\t\t\tnew_path: string\n\t\t\t{\n\t\t\t\t// Skip the \'action\' part.\n\t\t\t\t_, ok := strings.split_iterator(&amp;line, &quot;\\t&quot;)\n\t\t\t\tassert(ok)\n\n\t\t\t\told_path, ok = strings.split_iterator(&amp;line, &quot;\\t&quot;)\n\t\t\t\tassert(ok)\n\t\t\t\tassert(old_path != &quot;&quot;)\n\n\t\t\t\tif action == \'R\' { \t// Rename has two operands.\n\t\t\t\t\tnew_path, ok = strings.split_iterator(&amp;line, &quot;\\t&quot;)\n\t\t\t\t\tassert(ok)\n\t\t\t\t\tassert(new_path != &quot;&quot;)\n\t\t\t\t} else { \t// The others have only one.\n\t\t\t\t\tnew_path = old_path\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t_, v, inserted, err := map_entry(&amp;stats_by_path, new_path)\n\t\t\tassert(err == nil)\n\n\t\t\tif inserted {\n\t\t\t\tv.modification_date = date\n\t\t\t\tv.creation_date = date\n\t\t\t} else {\n\t\t\t\tassert(v.modification_date != &quot;&quot;)\n\t\t\t\t// Keep updating the creation date, when we reach the end of the commit log, it has the right value.\n\t\t\t\tv.creation_date = date\n\t\t\t}\n\n\n\t\t\t// We handle the action separately from the fact that this is the first commit we see for the path.\n\t\t\t// Because a file could have only one commit which is a rename.\n\t\t\t// Or its first commit is a rename but then there additional commits to modify it. \n\t\t\t// Case being: these two things are orthogonal.\n\n\t\t\tif action == \'R\' {\n\t\t\t\t// Mark the old path as \'deleted\'.\n\t\t\t\tstats_by_path[old_path] = GitStatInternal {\n\t\t\t\t\tmodification_date = date,\n\t\t\t\t\ttombstone         = true,\n\t\t\t\t}\n\n\t\t\t\t// The creation date of the new path is the date of the rename operation.\n\t\t\t\tv.creation_date = date\n\t\t\t}\n\t\t\tif action == \'D\' {\n\t\t\t\t// Mark as \'deleted\'.\n\t\t\t\tv.tombstone = true\n\t\t\t}\n\t\t}\n\t}\n\n\tgit_stats := make([dynamic]GitStat)\n\tfor k, v in stats_by_path {\n\t\tassert(k != &quot;&quot;)\n\t\tassert(v.creation_date != &quot;&quot;)\n\t\tassert(v.modification_date != &quot;&quot;)\n\t\tassert(v.creation_date &lt;= v.modification_date)\n\n\t\tif !v.tombstone {\n\t\t\tgit_stat := GitStat {\n\t\t\t\tpath_rel          = strings.clone(k),\n\t\t\t\tcreation_date     = strings.clone(v.creation_date),\n\t\t\t\tmodification_date = strings.clone(v.modification_date),\n\t\t\t}\n\t\t\tfmt.printf(&quot;%v\\n&quot;, git_stat)\n\t\t\tappend(&amp;git_stats, git_stat)\n\t\t}\n\t}\n\n\treturn git_stats[:], nil\n}\nA few things of interest:\nOdin has first class support for allocators so we allocate everything in this function with the temporary allocator. It is backed by an arena and emptied at the start and end of the function. Only the final result is allocated with the standard allocator. That way, even if Git starts spewing lots of data, as soon as we exit the function, all of that is gone, in one call, and the the program carries on with only the necessary data heap-allocated.\nIn this program, the main allocator and the temporary allocator are both arenas. The memory usage is a constant ~ 4 MiB, mainly located in the Odin standard library. The memory usage of my code is around ~ 65 KiB.\nA\nmap\nis a bit of an overkill for ~30 entries, but it\'s fine, and we expect the number of articles to grow\nWe can log the final result:\n[...]\nGitStat{creation_date = &quot;2020-09-07T20:49:20+02:00&quot;, modification_date = &quot;2024-11-04T09:24:17+01:00&quot;, path_rel = &quot;compile_ziglang_from_source_on_alpine_2020_9.md&quot;}\nGitStat{creation_date = &quot;2024-09-10T12:59:04+02:00&quot;, modification_date = &quot;2024-09-12T12:14:42+02:00&quot;, path_rel = &quot;odin_and_musl.md&quot;}\nGitStat{creation_date = &quot;2023-11-23T11:26:11+01:00&quot;, modification_date = &quot;2025-02-06T20:55:27+01:00&quot;, path_rel = &quot;roll_your_own_memory_profiling.md&quot;}\n[...]\nAlright, so how does our new implementation fare compared to the old one?\nFirst, we can confirm with\nstrace\nthat the time spent on waiting for subprocesses (mainly Git) shrinked:\n$ strace --summary-only ./src.bin\n% time     seconds  usecs/call     calls    errors syscall\n------ ----------- ----------- --------- --------- ----------------\n 56.59    0.043176         674        64           waitid\n [...]\nThen we benchmark:\n$ hyperfine --warmup 2 \'./src-main.bin\' \'./src.bin\'\nBenchmark 1: ./src-main.bin\n  Time (mean \u{b1} \u{3c3}):      1.773 s \u{b1}  0.022 s    [User: 1.267 s, System: 0.472 s]\n  Range (min \u{2026} max):    1.748 s \u{2026}  1.816 s    10 runs\n \nBenchmark 2: ./src.bin\n  Time (mean \u{b1} \u{3c3}):     158.7 ms \u{b1}   6.6 ms    [User: 128.4 ms, System: 133.7 ms]\n  Range (min \u{2026} max):   151.7 ms \u{2026} 175.6 ms    18 runs\n \nSummary\n  ./src.bin ran\n   11.17 \u{b1} 0.48 times faster than ./src-main.bin\nAround 11 times faster, and well within our ideal target of 500 ms ! And all we had to do was convert many\ngit log\ninvocations (one per markdown file) to just one.\nHere\'s the CPU profile now:\nOverall it\'s a pretty simple change, located in one function. Almost all of the complexity is due to parsing Git custom text output and skipping over irrelevant commits. We don\'t really have a choice either: that\'s all Git provides to query the commit log. The alternatives are all worse:\nParse directly the Git object files - no thank you\nUse a library (e.g.\nlibgit2\n) and hope that it offers a saner interface to query the commit log\nI wonder if there is a better way...\nFossil\nfossil\nis an alternative version control system created by the same folks that created, and are still working on, SQLite. Naturally, a fossil repository is basically just one SQLite database file. That sounds very\nqueryable\n!\nLet\'s import our git repository into a Fossil repository and enter the SQLite prompt:\n$ git fast-export --all | fossil import --git new-repo.fossil\n$ file new-repo.fossil \nnew-repo.fossil: SQLite 3.x database (Fossil repository), [...]\n$ fossil sql -R new-repo.fossil\nThere are lots of tables in this database. We craft this query after a few trials and errors (don\'t know if it is optimal or not):\nsqlite&gt; .mode json\nsqlite&gt; SELECT \n            f.name as filename,\n            datetime(min(e.mtime)) as creation_date,\n            datetime(max(e.mtime)) as last_modified\n        FROM repository.filename f\n        JOIN repository.mlink m ON f.fnid = m.fnid\n        JOIN repository.event e ON m.mid = e.objid\n        WHERE filename LIKE \'%.md\'\n        GROUP BY f.name\n        ORDER BY f.name;\nWhich outputs what we want:\n[...]\n{&quot;filename&quot;:&quot;body_of_work.md&quot;,&quot;creation_date&quot;:&quot;2023-12-19 13:27:40&quot;,&quot;last_modified&quot;:&quot;2024-11-05 15:11:55&quot;},\n{&quot;filename&quot;:&quot;communicate_by_sharing_code.md&quot;,&quot;creation_date&quot;:&quot;2024-03-07 09:48:39&quot;,&quot;last_modified&quot;:&quot;2024-03-07 10:14:09&quot;},\n{&quot;filename&quot;:&quot;compile_ziglang_from_source_on_alpine_2020_9.md&quot;,&quot;creation_date&quot;:&quot;2020-09-07 18:49:20&quot;,&quot;last_modified&quot;:&quot;2024-11-04 08:24:17&quot;},\n[...]\nNote that this does not filter out deleted/removed files yet. I\'m sure that it can be done by tweaking the query a bit, but there\'s not time! We need to benchmark!\n$ hyperfine --shell=none \'fossil sql -R new-repo.fossil &quot;SELECT [...]&quot;\'\nBenchmark 1: fossil sql -R new-repo.fossil &quot;[...]&quot;\n  Time (mean \u{b1} \u{3c3}):       3.0 ms \u{b1}   0.5 ms    [User: 1.5 ms, System: 1.4 ms]\n  Range (min \u{2026} max):     2.2 ms \u{2026}   5.6 ms    776 runs\nDamn that\'s fast.\nI do not use Fossil, but I eye it from time to time - generally when I need to extract some piece of information from Git and I discover it does not let me, or when I see the Gitlab bill  my (ex-) company pays, or when the Jira page takes more than 10 seconds to load... yeah, Fossil is the complete package, with issues, forums, a web UI, a timeline, a wiki, a chat... it has it all!\nBut the golden ticket idea is really to store everything inside SQLite. Suddenly, we can query anything! And there is no weird parsing needed - SQLite supports various export formats and (some? all?) fossil commands support the\n--sql\noption to show you which SQL query they use to get the information. After all, the only thing the\nfossil\ncommand line does in this case, is craft a SQL query and run int on the SQLite database.\nIt\'s quite magical to me that I can within a few seconds import my 6 years-long git repository into a SQLite database and start querying it, and the performance is great.\nNow I am not\nquite\nready yet to move to Fossil, and the import is a one time thing as far as I know, so it is not a viable option for the problem at hand as long as git is the source of truth. But still, while I was trying to tackle\ngit log\ninto submission, I was thinking the whole time: why can\'t I do an arbitrary query of git data? Generally, the more generic approach is slower than the ad-hoc one, but here it\'s not even the case. Fossil is for this use case objectively more powerful, more generic,\nand\nfaster.\nConclusion\nThe issue was effectively a N+1 query problem. We issued a separate \'query\' (in this case,\ngit log\n) for each markdown file, in a sequential blocking fashion. This approach worked until it didn\'t because the number of entities (i.e. articles, and commits) grew over time.\nThe solution is instead to do only one query for all entities. It may return a bit more data that we need, but that\'s much faster, and scales better, than the original version.\nIt\'s obvious in retrospect but it\'s easy to let it happen when the \'codebase\' (a big word for only one file that started as a basic Makefile) is a few years old, it\'s only looked at briefly from time to time, and the initial implementation did not really allow for the correct approach - who wants to parse the\ngit log\noutput in the Makefile language?\nFurthermore, the initial approach was fine because it only looked at the creation date, so we could do\ngit log --reverse article.md | head -n1\nwhich is faster than sifting through the whole commit log for this file. However, as it is always the case, requirements (again, a big word for: my taste concerning what should my personal blog look like) change and the modification date now had to also be extracted from git. This forced us, with the current Git functionality, to scan through the whole commit log, for each file, which became too slow.\nAs Mike Acton and Data Oriented Design state:\nDifferent problems require different solutions.\n2\nAnd:\nIf you have different data, you have a different problem.\n3\nIt also does not help that any querying in Git is ad-hoc and outputs a weird text format that we have to tediously parse. Please everyone, let\'s add the option to output structured data in our command line programs, damn it! String programming is no fun at all - that\'s why I moved away from concatenating the output of shell commands in a Makefile, to a real programming language, to do the static generation.\nAll in all, I am pleased with my solution - I can now see any edit materialize\ninstantly\n. It\'s a bit funny that my previous article was about SIMD and inspecting assembly instructions, while this issue is so obvious and high-level in retrospect.\nTo the next 5 years of blogging, till I need to revisit the performance of this function!\nAddendum\nRunning\ngit gc\nand\ngit prune\nalso helps because all unreachable objects are removed, so git has to do less work scanning and parsing them on disk.\nHaving done that, we get almost twice as fast:\n$ hyperfine --shell=none --warmup 2 \'./src.bin\'\nBenchmark 1: ./src.bin\n  Time (mean \u{b1} \u{3c3}):      89.7 ms \u{b1}   2.6 ms    [User: 63.6 ms, System: 59.5 ms]\n  Range (min \u{2026} max):    85.0 ms \u{2026}  94.3 ms    31 runs\nBut we have to remember to run it frequently or set up a periodic job that does it for us.\nThat\'s a ~21x speed-up from the original time.\nAddendum 2\nSince spawning the\ncmark\nprocess, having\ncmark\nparsing the command line options, over and over, is still taking a good chunk of the time, we can switch to using\nlibcmark\ndirectly. This is something I wanted to do anyway to extract a table of content, etc from the markdown. Since the running time is getting lower and lower, we add\n--shell=none\nand increase the warm-up to reduce statistical outliers:\n$ hyperfine --shell=none --warmup 10 ./src.bin\nBenchmark 1: ./src.bin\n  Time (mean \u{b1} \u{3c3}):      55.4 ms \u{b1}   1.5 ms    [User: 49.0 ms, System: 35.0 ms]\n  Range (min \u{2026} max):    53.1 ms \u{2026}  61.0 ms    55 runs\nIn fine\n: a x33 speed-up from the original time.\nCppCon 2014: Mike Acton &quot;Data-Oriented Design and C++&quot;\n\u{21a9}\nCppCon 2014: Mike Acton &quot;Data-Oriented Design and C++&quot;\n\u{21a9}\nCppCon 2014: Mike Acton &quot;Data-Oriented Design and C++&quot;\n\u{21a9}\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#1071142523-the-investigation",
"#3047915491-when-there-s-one-there-s-many",
"#2709289763-the-new-approach",
"#3854930553-the-new-implementation",
"#3898000878-fossil",
"#3796851539-conclusion",
"#4016320828-addendum",
"#2077345490-addendum-2",
],
title_text_offsets:[
950,5423,6918,10179,17560,21148,23417,23969,],
},
{
name:"tip_of_the_day_6.html",
text:"Tip of the day #6: Use Bpftrace to estimate how much memory an in-memory cache will use\nPhilippe Gaultier\nBody of work\nTags\n          Resume\n\u{23f4} Back to all articles\nPublished on 2025-03-12\nTip of the day #6: Use Bpftrace to estimate how much memory an in-memory cache will use\nGo\nTip of the day\nBpftrace\nTable of contents\nContext\nBpftrace\nAddendum: Function arguments in bpftrace\nContext\nI have a Go service that has an in-memory LRU (Least Recently Used) cache to speed up some things.\nHere I am, writing documentation for this service, and it happens that you can specify in its configuration the maximum number of cache entries.\nThat\'s useful to limit the overall memory usage. Obviously this value is directly related to the Kubernetes memory limit for this deployment.\nBut then I am wondering: what value should the docs recommend for this configuration field? A 1000 entries, 10 000? One factor is how many distinct entries do we expect, but another is:\nHow big is a cache entry\n?\nAn entry in the cache in this case is a slice of bytes (a blob) so it\'s not statically possible to determine, just looking at the code, how much memory it will consume.\nThis distribution of entry sizes is however easy to uncover: all entries in the cache are inserted by one callback. It happens to be a Go function that is passed to a C library (via CGO) but this trick works with any language. This function takes as argument a slice of bytes to be inserted in the cache. So, add a log in this callback, print the slice length, process all the relevant logs, compute some statistics, and done? Or, add a custom Prometheus metric, deploy, done?\nWell... why modify the source code when we don\'t have too? Let\'s use\nbpftrace\nto determine the distribution of entry sizes\nat runtime\non the unmodified program! In the past I have used\ndtrace\non macOS/FreeBSD which is similar and the direct inspiration for\nbpftrace\n. I find\ndtrace\nmore powerful in some regards - although\nbpftrace\nhas support for loops whereas\ndtrace\ndoes not. Point being, the\nbpftrace\nincantation can be adapted for\ndtrace\npretty easily. Both of these tools are essential workhorses of exploratory programming and troubleshooting.\nBpftrace\nSo, the plan is: I run the tests under\nbpftrace\n, collect a histogram of the slice of bytes to be inserted in the cache, and voila!\nWe can also run the real service with a load test to generate traffic, or simply wait for real traffic to come - all of that works, and\ndtrace\n/\nbpftrace\nare designed to inspect production programs without the risk of crashing them, or adversely impacting the system. The\nbpftrace\nincantation will be the same in all of these cases, only the binary (or process id) will change.\nHere, my function to insert a slice of bytes in the cache is called\ncache_insert\n, the executable is called\nitest.test\n, and the length of the slice of bytes happens to be passed as the third function argument. Arguments are zero-indexed so that means\narg2\n:\n$ sudo bpftrace -e \'uprobe:./itest.test:cache_insert {@bytes=lhist(arg2, 0 , 16384, 128)}\' -c \'./itest.test -test.count=1\'\nlhist\ncreates a linear histogram with the minimum value here being\n0\n, the maximum value\n16384\nand the bucket size\n128\n. I used the\nhist\nfunction initially which uses a power-of-two bucket size but my values were all in one big bucket so that was a bit imprecise. Still a good first approximation. But we can get a better estimate by using a small bucket size with\nlhist\n.\nbpftrace\nprints the histogram by default at the end:\n@bytes: \n[512, 640)            96 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|\nSo all slices of bytes have their length between\n512\nand\n640\nin this case, all in one bucket.\nAlternatively, we can point\nbpftrace\nat the Go function instead of the C function:\nfunc (c Cache) Insert(ctx context.Context, key [32]byte, value []byte, expiryDate time.Time) error { [...] }\nWe are interested in\nlen(value)\nwhich happens to be accessible in\narg5\n:\n$ sudo bpftrace -e \'uprobe:./itest.test:/path/to/my/pkg/Cache.Insert {@bytes=lhist(arg5, 0 , 16384, 128)}\' -c \'./itest.test -test.count=1\'\nand we get the same output.\nNote that we are doing very basic runtime inspection in this case, but we could also for example look at the hit rate of cache lookups, how much time inserting a new entry takes, etc.\nbpftrace\nand\ndtrace\nare really designed to be lightweight swiss-army knives.\nAddendum: Function arguments in bpftrace\nbpftrace\nreads neither debug information nor C headers by default so all function arguments are register sized, i.e. 64 bits on x86_64.\nbpftrace\ndoes not even know how many arguments the function accepts!\nMy function signature is (simplified):\nstruct ByteSliceView {\n    uint8_t* data;\n    size_t len;\n}\n\nvoid cache_insert(const uint8_t *key, struct ByteSliceView value, [...]);\nThe value of interest is\nvalue.len\n. So initially I tried to access it in\nbpftrace\nusing\narg1.len\n, however it did not work. Here is an excerpt from the documentation:\nFunction arguments are available through the argN for register args. Arguments passed on stack are available using the stack pointer, e.g. $stack_arg0 = (int64)reg(&quot;sp&quot;) + 16. Whether arguments passed on stack or in a register depends on the architecture and the number or arguments used, e.g. on x86_64 the first 6 non-floating point arguments are passed in registers and all following arguments are passed on the stack. Note that floating point arguments are typically passed in special registers which don\u{2019}t count as argN arguments which can cause confusion\nSo, it\'s a mess ...\nI fired up\ngdb\nand printed registers directly when the\ncache_insert\nfunction is entered. I discovered by doing\ninfo registers\nthat (on my machine, with this compiler and build flags, yada yada yada), the\nrdx\nregister contains\nvalue.len\n. I.e. the compiler unpacks\nvalue\nwhich is a struct of two fields, into\narg1\n(i.e. the\nrsi\nregister) and\narg2\n(i.e. the\nrdx\nregister).\nThus, this call:\ncache_insert(foo, bar)\ngets transformed by the compiler into\ncache_insert(foo, bar.data, bar.len)\n, and the third function argument (aka\narg2\n) is our length.\n\u{23f4} Back to all articles\nIf you enjoy what you\'re reading, you want to support me, and can afford it:\nSupport me\n. That allows me to write more cool articles!\n    This blog is\nopen-source\n!\n    If you find a problem, please open a Github issue.\n    The content of this blog as well as the code snippets are under the\nBSD-3 License\nwhich I also usually use for all my personal projects. It\'s basically free for every use but you have to mention me as the original author.\n",
titles:[
"#2166136261-",
"#132857161-context",
"#3714754269-bpftrace",
"#3450441466-addendum-function-arguments-in-bpftrace",
],
title_text_offsets:[
381,2185,4388,],
},
],
};
export default { raw_index };