<!--
This file has been auto-generated by main.c/main.bin from a markdown file of the same name.
Do not edit it by hand.
-->
<!DOCTYPE html>
<html>
<head>
<title>Roll your own memory profiling: it&#39;s actually not hard</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link type="application/atom+xml" href="/blog/feed.xml" rel="self">
<link rel="shortcut icon" type="image/ico" href="/blog/favicon.ico">
<link rel="stylesheet" type="text/css" href="main.css">
<link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@11.8.0/styles/default.min.css">
<script src="highlight.min.js"></script>
<!-- From https://github.com/odin-lang/odin-lang.org/blob/6f48c2cfb094a42dffd34143884fa958bd9c0ba2/themes/odin/layouts/partials/head.html#L71 -->
<script src="x86asm.min.js" defer></script>
<script src="main.js" defer></script>
<script type="module" src="search_index.js" defer></script>
<script type="module" src="search.js" defer></script>
</head>
<body>

<div id="banner">
    <div id="name">
        <img id="me" src="me.jpeg">
        <span>Philippe Gaultier</span>
    </div>
    <input id="search" placeholder="üîé Search" autocomplete=off>
    <ul>
      <li> <a href="/blog/body_of_work.html">Body of work</a> </li>
      <li> <a href="/blog/articles-by-tag.html">Tags</a> </li>
      <li> <a href="https://github.com/gaultier/resume/raw/master/Philippe_Gaultier_resume_en.pdf">
          Resume
        </a> </li>

      <li> <a href="/blog/feed.xml">
        <svg viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path fill-rule="evenodd" clip-rule="evenodd" d="M5.5 3.5C4.39543 3.5 3.5 4.39543 3.5 5.5V18.5C3.5 19.6046 4.39543 20.5 5.5 20.5H18.5C19.6046 20.5 20.5 19.6046 20.5 18.5V5.5C20.5 4.39543 19.6046 3.5 18.5 3.5H5.5ZM7 19C8.10457 19 9 18.1046 9 17C9 15.8954 8.10457 15 7 15C5.89543 15 5 15.8954 5 17C5 18.1046 5.89543 19 7 19ZM6.14863 10.5052C6.14863 10.0379 6.52746 9.65906 6.99478 9.65906C7.95949 9.65906 8.91476 9.84908 9.80603 10.2183C10.6973 10.5874 11.5071 11.1285 12.1893 11.8107C12.8715 12.4929 13.4126 13.3027 13.7817 14.194C14.1509 15.0852 14.3409 16.0405 14.3409 17.0052C14.3409 17.4725 13.9621 17.8514 13.4948 17.8514C13.0275 17.8514 12.6486 17.4725 12.6486 17.0052C12.6486 16.2627 12.5024 15.5275 12.2183 14.8416C11.9341 14.1556 11.5177 13.5324 10.9927 13.0073C10.4676 12.4823 9.84437 12.0659 9.15842 11.7817C8.47246 11.4976 7.73726 11.3514 6.99478 11.3514C6.52746 11.3514 6.14863 10.9725 6.14863 10.5052ZM7 5.15385C6.53268 5.15385 6.15385 5.53268 6.15385 6C6.15385 6.46732 6.53268 6.84615 7 6.84615C8.33342 6.84615 9.65379 7.10879 10.8857 7.61907C12.1176 8.12935 13.237 8.87728 14.1799 9.82015C15.1227 10.763 15.8707 11.8824 16.3809 13.1143C16.8912 14.3462 17.1538 15.6666 17.1538 17C17.1538 17.4673 17.5327 17.8462 18 17.8462C18.4673 17.8462 18.8462 17.4673 18.8462 17C18.8462 15.4443 18.5397 13.9039 17.9444 12.4667C17.3491 11.0294 16.4765 9.72352 15.3765 8.6235C14.2765 7.52349 12.9706 6.65091 11.5333 6.05558C10.0961 5.46026 8.55566 5.15385 7 5.15385Z" fill="#000000"/>
        </svg>
        </a> </li>

      <li> <a href="https://www.linkedin.com/in/philippegaultier/">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" data-supported-dps="24x24" fill="currentColor" class="mercado-match" width="24" height="24" focusable="false">
              <path d="M20.5 2h-17A1.5 1.5 0 002 3.5v17A1.5 1.5 0 003.5 22h17a1.5 1.5 0 001.5-1.5v-17A1.5 1.5 0 0020.5 2zM8 19H5v-9h3zM6.5 8.25A1.75 1.75 0 118.3 6.5a1.78 1.78 0 01-1.8 1.75zM19 19h-3v-4.74c0-1.42-.6-1.93-1.38-1.93A1.74 1.74 0 0013 14.19a.66.66 0 000 .14V19h-3v-9h2.9v1.3a3.11 3.11 0 012.7-1.4c1.55 0 3.36.86 3.36 3.66z"/>
            </svg>
        </a> </li>
      <li> <a href="https://github.com/gaultier">
        <svg height="32" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="32" data-view-component="true" class="octicon octicon-mark-github v-align-middle">
          <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z"/>
        </svg>
        </a> </li>
      <li> <a href="https://hachyderm.io/@pg">
        <svg width="75" height="79" viewBox="0 0 75 79" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M73.8393 17.4898C72.6973 9.00165 65.2994 2.31235 56.5296 1.01614C55.05 0.797115 49.4441 0 36.4582 0H36.3612C23.3717 0 20.585 0.797115 19.1054 1.01614C10.5798 2.27644 2.79399 8.28712 0.904997 16.8758C-0.00358524 21.1056 -0.100549 25.7949 0.0682394 30.0965C0.308852 36.2651 0.355538 42.423 0.91577 48.5665C1.30307 52.6474 1.97872 56.6957 2.93763 60.6812C4.73325 68.042 12.0019 74.1676 19.1233 76.6666C26.7478 79.2728 34.9474 79.7055 42.8039 77.9162C43.6682 77.7151 44.5217 77.4817 45.3645 77.216C47.275 76.6092 49.5123 75.9305 51.1571 74.7385C51.1797 74.7217 51.1982 74.7001 51.2112 74.6753C51.2243 74.6504 51.2316 74.6229 51.2325 74.5948V68.6416C51.2321 68.6154 51.2259 68.5896 51.2142 68.5661C51.2025 68.5426 51.1858 68.522 51.1651 68.5058C51.1444 68.4896 51.1204 68.4783 51.0948 68.4726C51.0692 68.4669 51.0426 68.467 51.0171 68.4729C45.9835 69.675 40.8254 70.2777 35.6502 70.2682C26.7439 70.2682 24.3486 66.042 23.6626 64.2826C23.1113 62.762 22.7612 61.1759 22.6212 59.5646C22.6197 59.5375 22.6247 59.5105 22.6357 59.4857C22.6466 59.4609 22.6633 59.4391 22.6843 59.422C22.7053 59.4048 22.73 59.3929 22.7565 59.3871C22.783 59.3813 22.8104 59.3818 22.8367 59.3886C27.7864 60.5826 32.8604 61.1853 37.9522 61.1839C39.1768 61.1839 40.3978 61.1839 41.6224 61.1516C46.7435 61.008 52.1411 60.7459 57.1796 59.7621C57.3053 59.7369 57.431 59.7154 57.5387 59.6831C65.4861 58.157 73.0493 53.3672 73.8178 41.2381C73.8465 40.7606 73.9184 36.2364 73.9184 35.7409C73.9219 34.0569 74.4606 23.7949 73.8393 17.4898Z" fill="url(#paint0_linear_549_34)"/>
        <path d="M61.2484 27.0263V48.114H52.8916V27.6475C52.8916 23.3388 51.096 21.1413 47.4437 21.1413C43.4287 21.1413 41.4177 23.7409 41.4177 28.8755V40.0782H33.1111V28.8755C33.1111 23.7409 31.0965 21.1413 27.0815 21.1413C23.4507 21.1413 21.6371 23.3388 21.6371 27.6475V48.114H13.2839V27.0263C13.2839 22.7176 14.384 19.2946 16.5843 16.7572C18.8539 14.2258 21.8311 12.926 25.5264 12.926C29.8036 12.926 33.0357 14.5705 35.1905 17.8559L37.2698 21.346L39.3527 17.8559C41.5074 14.5705 44.7395 12.926 49.0095 12.926C52.7013 12.926 55.6784 14.2258 57.9553 16.7572C60.1531 19.2922 61.2508 22.7152 61.2484 27.0263Z" fill="white"/>
        <defs>
        <linearGradient id="paint0_linear_549_34" x1="37.0692" y1="0" x2="37.0692" y2="79" gradientUnits="userSpaceOnUse">
        <stop stop-color="#6364FF"/>
        <stop offset="1" stop-color="#563ACC"/>
        </linearGradient>
        </defs>
        </svg>
        </a> </li>
      <li> <a href="https://bsky.app/profile/pgaultier.bsky.social">
        <svg fill="none" viewBox="0 0 64 57" width="32" style="width: 32px; height: 28.5px;"><path fill="#0085ff" d="M13.873 3.805C21.21 9.332 29.103 20.537 32 26.55v15.882c0-.338-.13.044-.41.867-1.512 4.456-7.418 21.847-20.923 7.944-7.111-7.32-3.819-14.64 9.125-16.85-7.405 1.264-15.73-.825-18.014-9.015C1.12 23.022 0 8.51 0 6.55 0-3.268 8.579-.182 13.873 3.805ZM50.127 3.805C42.79 9.332 34.897 20.537 32 26.55v15.882c0-.338.13.044.41.867 1.512 4.456 7.418 21.847 20.923 7.944 7.111-7.32 3.819-14.64-9.125-16.85 7.405 1.264 15.73-.825 18.014-9.015C62.88 23.022 64 8.51 64 6.55c0-9.818-8.578-6.732-13.873-2.745Z"/></svg>
        </a> </li>
    </ul>
</div>
<div id="search-matches" hidden>
</div>
<div id="pseudo-body">

<div class="article-prelude">
  <p><a href="/blog"> ‚è¥ Back to all articles</a></p>

  <p class="publication-date">Published on 2023-11-23</p>
</div>
<div class="article-title">
<h1>Roll your own memory profiling: it's actually not hard</h1>
  <div class="tags"> <a href="/blog/articles-by-tag.html#c" class="tag">C</a> <a href="/blog/articles-by-tag.html#allocator" class="tag">Allocator</a> <a href="/blog/articles-by-tag.html#profiling" class="tag">Profiling</a> <a href="/blog/articles-by-tag.html#pprof" class="tag">Pprof</a> <a href="/blog/articles-by-tag.html#linux" class="tag">Linux</a></div>
  </div>
 <strong>Table of contents</strong>
<ul>

  <li>
    <a href="#1714161565-pprof">Pprof</a>
  </li>

  <li>
    <a href="#3080183899-the-text-format">The text format</a>
  </li>

  <li>
    <a href="#3162870509-generating-a-pprof-profile">Generating a pprof profile</a>
  </li>

  <li>
    <a href="#2279041372-variations-and-limitations">Variations and limitations</a>
  </li>

  <li>
    <a href="#3437344394-alternatives">Alternatives</a>
  </li>

  <li>
    <a href="#3796851539-conclusion">Conclusion</a>
  </li>

  <li>
    <a href="#1512890027-addendum-the-full-code">Addendum: the full code</a>
  </li>
</ul>

<p><em>Discussions: <a href="https://old.reddit.com/r/C_Programming/comments/182rnqw/roll_your_own_memory_profiling_its_actually_not/">/r/c_programming</a></em></p>
<p><em>Or: An exploration of the <a href="https://github.com/gperftools/gperftools">pprof</a> memory profiler and its textual format for fun an profit.</em></p>
<p>Say that you are using a programming language where memory is manually managed, and you have decided to use a custom allocator for one reason or another, for example an arena allocator, and are wondering:</p>
<ul>
<li>How do I track every allocation, recording how many bytes were allocated and what was the call stack at that time?</li>
<li>How much memory is my program using, and what is the peak use?</li>
<li>How much memory does my program free? Is it all of it (are there leaks)?</li>
<li>Which line of code in my function is allocating, and how much?</li>
<li>I want a flamegraph showing allocations by function</li>
</ul>
<p>What to do? Mainstream allocators such as <code>tcmalloc</code> and <code>jemalloc</code> can provide us this information but we have lost this ability by using our own!</p>
<p>Well, it turns out that this can all be achieved very simply without adding dependencies to your application, in ~100 lines of code (including lots of comments). I'll show one way and then explore other possibilities. And here are the results we are working towards:</p>
<p><img src="mem_prof1.png" alt="1" />
<em>Profiling the memory usage of my <a href="https://github.com/gaultier/micro-kotlin">micro-kotlin</a> project.</em></p>
<p><img src="mem_prof2.png" alt="2" />
<em>Showing which lines of code are allocating in a function.</em></p>
<p><img src="mem_prof3.png" alt="3" />
<em>A flamegraph based on the previous data.</em></p>
<p>The only requirement to make it all work is to be able to run a bit of code on each allocation.</p>
<p>Another good reason to do this, is when the system's <code>malloc</code> comes with some form of memory profiling which is not suitable for your needs and you want something different/better/the same on every platform.</p>
<blockquote>
<p>If you spot an error, please open a <a href="https://github.com/gaultier/blog">Github issue</a>!</p>
</blockquote>
<h2 id="1714161565-pprof">
  <a class="title" href="#1714161565-pprof">Pprof</a>
  <a class="hash-anchor" href="#1714161565-pprof" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<p>Here is the plan:</p>
<ol>
<li>Each time there is an allocation in our program, we record information about it in an array.</li>
<li>At the end of the program (or upon receiving a signal, a special TCP packet, whatever), we dump the information in the (original) <a href="https://github.com/gperftools/gperftools">pprof</a> format, which is basically just a text file with one line per allocation (more details on that in a bit).</li>
<li>We can then use the (original) <code>pprof</code> which is just a <a href="https://github.com/gperftools/gperftools/blob/master/src/pprof">giant Perl script</a> which will extract interesting information and most importantly symbolize (meaning: transform memory addresses into line/column/function/file information).</li>
</ol>
<p>I will showcase this approach with C code using an arena allocator. The full code can be found in my project <a href="https://github.com/gaultier/micro-kotlin/blob/pprof-original/str.h#L320">micro-kotlin</a>. But this can be done in any language since the <code>pprof</code> text format is so simple! Also, using arenas, we do not bother to free anything so the memory profiling part is even simpler.</p>
<blockquote>
<p>The original <code>pprof</code> written in Perl is not to be confused with the rewritten <a href="https://github.com/google/pprof">pprof</a> in Go which offers a superset of the features of the original but based on a completely different and incompatible file format (protobuf)!</p>
</blockquote>
<h2 id="3080183899-the-text-format">
  <a class="title" href="#3080183899-the-text-format">The text format</a>
  <a class="hash-anchor" href="#3080183899-the-text-format" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<p>Here is the text format we want to generate:</p>
<pre><code class="language-text">heap profile:    &lt;in use objects sum&gt;:  &lt;in use bytes sum&gt; [   &lt;space objects sum&gt;:  &lt;space bytes sum&gt;] @ heapprofile
&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]
&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]
&lt;in use objects&gt;: &lt;in use bytes&gt; [&lt;space objects&gt;: &lt;space bytes&gt;] @ &lt;rip1&gt; &lt;rip2&gt; &lt;rip3&gt; [...]
                                                                             
MAPPED_LIBRARIES:
[...]
</code></pre>
<p>The first line is a header identifying that this is a heap profile (contrary to a CPU profile which <code>pprof</code> can also analyze, which uses a different, binary, format) and gives for each of the four fields we will record, their sum.</p>
<p>Then comes one line per entry. Each entry has these four fields that the header just gave us a sum of:</p>
<ul>
<li><code>in use objects</code>: How many objects are 'live' i.e. in use on the heap at the time of the allocation. Allocating increases its value, freeing decreases it.</li>
<li><code>in use bytes</code>: How many bytes are 'live' i.e. in use on the heap at the time of the allocation. Allocating increases its value, freeing decreases it.</li>
<li><code>space objects</code>: How many objects have been allocated since the start of the program. It is not affected by freeing memory, it only increases.</li>
<li><code>space bytes</code>: How many bytes have been allocated since the start of the program. It is not affected by freeing memory, it only increases.</li>
</ul>
<p>So when we allocate an object e.g. <code>new(Foo)</code> in C++:</p>
<ul>
<li><code>in use objects</code> and <code>space objects</code> increment by 1</li>
<li><code>in use bytes</code> and <code>space bytes</code> increment by <code>sizeof(Foo)</code></li>
</ul>
<p>When we allocate an array of N elements of type <code>Foo</code>:</p>
<ul>
<li><code>in use objects</code> and <code>space objects</code> increment by N</li>
<li><code>in use bytes</code> and <code>space bytes</code> increment by <code>N * sizeof(Foo)</code></li>
</ul>
<p>When we free an object:</p>
<ul>
<li><code>in use objects</code> decrements by 1</li>
<li><code>in use bytes</code> decrements by <code>sizeof(Foo)</code></li>
</ul>
<p>When we free an array of N elements of type <code>Foo</code>:</p>
<ul>
<li><code>in use objects</code> decrements by N</li>
<li><code>in use bytes</code> decrements by <code>N * sizeof(Foo)</code></li>
</ul>
<p>These 4 dimensions are really useful to spot memory leaks (<code>in use objects</code> and <code>in use bytes</code> increase over time), peak memory usage (<code>space bytes</code>), whether we are doing many small allocations versus a few big allocations, etc.
<code>pprof</code> also supports sampling and we could supply a sampling rate here optionally but we want to track each and every allocation so we do not bother with that.</p>
<p>Each entry (i.e. line) ends with the call stack which is a space-separated list of addresses. We'll see that it is easy to get that information without resorting to external libraries such as <code>libunwind</code> by simply walking the stack, a topic I touched on in a previous <a href="/blog/x11_x64.html#a-stack-primer">article</a>.</p>
<p>Very importantly, multiple allocation records with the same stack must be merged together into one, summing their values. In that sense, each line conceptually an entry in a hashmap where the key is the call stack (the part of the right of the <code>@</code> character) and the value is a 4-tuple: <code>(u64, u64, u64, u64)</code> (the part on the left of the <code>@</code> character).</p>
<p>The text file ends with a trailer which is crucial for symbolication (to transform memory addresses into source code locations), which on Linux is trivial to get: This is just a copy of the file <code>/proc/self/maps</code>. It lists of the loaded libraries and at which address they are.</p>
<p>I have not implemented it myself but a quick internet search shows that the other major operating systems have a similar capability, named differently:</p>
<ul>
<li>Windows: <code>VirtualQuery</code></li>
<li>macOS: <code>mach_vm_region_info</code></li>
<li>FreeBSD: <code>procstat_getvmmap</code></li>
</ul>
<p>Here is a small example:</p>
<pre><code class="language-c">#include &lt;stdlib.h&gt;

void b(int n) { malloc(n); }

void a(int n) {
  malloc(n);
  b(n);
}

int main() {
  for (int i = 0; i &lt; 2; i++)
    a(2);

  b(3);
}
</code></pre>
<p>Leveraging <code>tcmalloc</code>, this program will generate a heap profile:</p>
<pre><code class="language-sh">$ cc /tmp/test_alloc.c -ltcmalloc  -g3
$ HEAPPROFILE=/tmp/heapprof ./a.out
Starting tracking the heap
Dumping heap profile to /tmp/heapprof.0001.heap (Exiting, 11 bytes in use)
</code></pre>
<p><em>This is just an example to showcase the format, we will from this point on use our own code to generate this text format.</em></p>
<pre><code class="language-text">heap profile:      5:       11 [     5:       11] @ heapprofile
     2:        4 [     2:        4] @ 0x558e804cc165 0x558e804cc18e 0x558e804cc1b0 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085
     2:        4 [     2:        4] @ 0x558e804cc184 0x558e804cc1b0 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085
     1:        3 [     1:        3] @ 0x558e804cc165 0x558e804cc1c4 0x7f452a4daa90 0x7f452a4dab49 0x558e804cc085

MAPPED_LIBRARIES:
558e804cb000-558e804cc000 r--p 00000000 00:00 183128      /tmp/a.out
558e804cc000-558e804cd000 r-xp 00001000 00:00 183128      /tmp/a.out
558e804cd000-558e804ce000 r--p 00002000 00:00 183128      /tmp/a.out
558e804ce000-558e804cf000 r--p 00002000 00:00 183128      /tmp/a.out
558e804cf000-558e804d0000 rw-p 00003000 00:00 183128      /tmp/a.out
558e814b7000-558e81db8000 rw-p 00000000 00:00 0           [heap]
7f4529e7e000-7f452a112000 rw-p 00000000 00:00 0           
7f452a112000-7f452a115000 r--p 00000000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1
7f452a115000-7f452a136000 r-xp 00003000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1
7f452a136000-7f452a142000 r--p 00024000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1
7f452a142000-7f452a143000 r--p 00030000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1
7f452a143000-7f452a144000 rw-p 00031000 00:00 678524      /usr/lib/x86_64-linux-gnu/liblzma.so.5.4.1
7f452a144000-7f452a152000 r--p 00000000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6
7f452a152000-7f452a1d0000 r-xp 0000e000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6
7f452a1d0000-7f452a22b000 r--p 0008c000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6
7f452a22b000-7f452a22c000 r--p 000e6000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6
7f452a22c000-7f452a22d000 rw-p 000e7000 00:00 668348      /usr/lib/x86_64-linux-gnu/libm.so.6
7f452a22d000-7f452a22f000 rw-p 00000000 00:00 0           
7f452a22f000-7f452a2cb000 r--p 00000000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32
7f452a2cb000-7f452a3fc000 r-xp 0009c000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32
7f452a3fc000-7f452a489000 r--p 001cd000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32
7f452a489000-7f452a494000 r--p 0025a000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32
7f452a494000-7f452a497000 rw-p 00265000 00:00 678806      /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.32
7f452a497000-7f452a49b000 rw-p 00000000 00:00 0           
7f452a49b000-7f452a49e000 r--p 00000000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1
7f452a49e000-7f452a4a8000 r-xp 00003000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1
7f452a4a8000-7f452a4ab000 r--p 0000d000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1
7f452a4ab000-7f452a4ac000 r--p 0000f000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1
7f452a4ac000-7f452a4ad000 rw-p 00010000 00:00 702044      /usr/lib/x86_64-linux-gnu/libunwind.so.8.0.1
7f452a4ad000-7f452a4b7000 rw-p 00000000 00:00 0           
7f452a4b7000-7f452a4d9000 r--p 00000000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6
7f452a4d9000-7f452a651000 r-xp 00022000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6
7f452a651000-7f452a6a9000 r--p 0019a000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6
7f452a6a9000-7f452a6ad000 r--p 001f1000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6
7f452a6ad000-7f452a6af000 rw-p 001f5000 00:00 668342      /usr/lib/x86_64-linux-gnu/libc.so.6
7f452a6af000-7f452a6bc000 rw-p 00000000 00:00 0           
7f452a6bc000-7f452a6bf000 r--p 00000000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1
7f452a6bf000-7f452a6da000 r-xp 00003000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1
7f452a6da000-7f452a6de000 r--p 0001e000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1
7f452a6de000-7f452a6df000 r--p 00021000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1
7f452a6df000-7f452a6e0000 rw-p 00022000 00:00 677590      /usr/lib/x86_64-linux-gnu/libgcc_s.so.1
7f452a6e0000-7f452a6f3000 r--p 00000000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9
7f452a6f3000-7f452a719000 r-xp 00013000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9
7f452a719000-7f452a729000 r--p 00039000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9
7f452a729000-7f452a72a000 r--p 00048000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9
7f452a72a000-7f452a72b000 rw-p 00049000 00:00 182678      /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9
7f452a72b000-7f452a8e1000 rw-p 00000000 00:00 0           
7f452a8e4000-7f452a8f8000 rw-p 00000000 00:00 0           
7f452a8f8000-7f452a8f9000 r--p 00000000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
7f452a8f9000-7f452a921000 r-xp 00001000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
7f452a921000-7f452a92b000 r--p 00029000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
7f452a92b000-7f452a92d000 r--p 00033000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
7f452a92d000-7f452a92f000 rw-p 00035000 00:00 668336      /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2
7fff91a4d000-7fff91a6e000 rw-p 00000000 00:00 0           [stack]
7fff91b3f000-7fff91b43000 r--p 00000000 00:00 0           [vvar]
7fff91b43000-7fff91b45000 r-xp 00000000 00:00 0           [vdso]
ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0           [vsyscall]
</code></pre>
<p>We see that at the end of the program, we have (looking at the first line):</p>
<ul>
<li>5 objects in use</li>
<li>11 bytes in use</li>
<li>5 objects allocated in total</li>
<li>11 bytes allocated in total</li>
</ul>
<p>Since we never freed any memory, the <code>in use</code> counters are the same as the <code>space</code> counters.</p>
<p>We have 3 unique call stacks that allocate, in the same order as they appear in the text file (although order does not matter for <code>pprof</code>):</p>
<ul>
<li><code>b</code> &lt;- <code>a</code> &lt;- <code>main</code></li>
<li><code>a</code> &lt;- <code>main</code></li>
<li><code>b</code> &lt;- <code>main</code></li>
</ul>
<p>Since our program is a Position Independant Executable (PIE), the loader picks a random address for where to load our program in virtual memory. Consequently, addresses collected from within our program have this offset added to them and this offset is different every run. Thankfully, the <code>MAPPED_LIBRARIES</code> section lists address ranges (the first column of each line in that section) for each library that gets loaded.</p>
<p>As such, <code>pprof</code> only needs to find for each address the relevant range, subtract the start of the range from this address, and it has the real address in our executable. It then runs <code>addr2line</code> or similar to get the code location.</p>
<p>Finally we can use <code>pprof</code> to extract human-readable information from this text file:</p>
<pre><code class="language-sh">$ pprof --text ./a.out ./heapprof.0001.heap
Using local file ./a.out.
Using local file /tmp/heapprof.0001.heap.
Total: 0.0 MB
     0.0  63.6%  63.6%      0.0  63.6% b
     0.0  36.4% 100.0%      0.0  72.7% a
     0.0   0.0% 100.0%      0.0 100.0% __libc_start_call_main
     0.0   0.0% 100.0%      0.0 100.0% __libc_start_main_impl
     0.0   0.0% 100.0%      0.0 100.0% _start
     0.0   0.0% 100.0%      0.0 100.0% main
</code></pre>
<h2 id="3162870509-generating-a-pprof-profile">
  <a class="title" href="#3162870509-generating-a-pprof-profile">Generating a pprof profile</a>
  <a class="hash-anchor" href="#3162870509-generating-a-pprof-profile" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<p>Let's start with a very simple arena (directly based on <a href="https://nullprogram.com/blog/2023/09/27/">https://nullprogram.com/blog/2023/09/27/</a>) and show how it is used:</p>
<pre><code class="language-c">#define _GNU_SOURCE
#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;unistd.h&gt;


typedef struct {
  u8 *start;
  u8 *end;
} arena_t;

static void * arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {
  pg_assert(a-&gt;start &lt;= a-&gt;end);
  pg_assert(align == 1 || align == 2 || align == 4 || align == 8);

  size_t available = a-&gt;end - a-&gt;start;
  size_t padding = -(size_t)a-&gt;start &amp; (align - 1);

  size_t offset = padding + size * count;
  if (available &lt; offset) {
    fprintf(stderr,
            &quot;Out of memory: available=%lu &quot;
            &quot;allocation_size=%lu\n&quot;,
            available, offset);
    abort();
  }

  uint8_t *res = a-&gt;start + padding;

  a-&gt;start += offset;

  return (void *)res;
}
</code></pre>
<p>Now, we are ready to add memory profiling to our simple allocator.</p>
<p>First, we model a record with the 4 counters and the call stack:</p>
<pre><code class="language-c">typedef struct {
  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;
  uint64_t *call_stack;
  uint64_t call_stack_len;
} mem_record_t;
</code></pre>
<p>Then, the profile, which contains the 4 counters as a sum and an array of records.</p>
<p>An arena now has an (optional) pointer to a memory profile:</p>
<pre><code class="language-c">typedef struct mem_profile_t mem_profile_t;
typedef struct {
  uint8_t *start;
  uint8_t *end;
  mem_profile_t* profile;
} arena_t;

struct mem_profile_t {
  mem_record_t *records;
  uint64_t records_len;
  uint64_t records_cap;
  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;
  arena_t arena;
};
</code></pre>
<p>Note that the memory profile needs to allocate to store this metadata and as such needs an arena. Which makes these two structures cyclic!</p>
<p>The way we solve it is:</p>
<ol>
<li>We create an small arena dedicated to the memory profiling and this arena does <em>not</em> have a memory profile attached (otherwise we would end up in a infinite recursion, and we are not interested in profiling the memory usage of the memory profiler anyway; its memory usage is capped by the size of its dedicated arena).</li>
<li>We create the memory profile using this arena.</li>
<li>We create the main arena for our program to use and attach the profile to it.</li>
</ol>
<pre><code class="language-c">static arena_t arena_new(uint64_t cap, mem_profile_t *profile) {
  uint8_t *mem = mmap(NULL, cap, PROT_READ | PROT_WRITE,
                      MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);

  arena_t arena = {
      .profile = profile,
      .start = mem,
      .end = mem + cap,
  };
  return arena;
}

int main(){
  arena_t mem_profile_arena = arena_new(1 &lt;&lt; 16, NULL);
  mem_profile_t mem_profile = {.arena = mem_profile_arena};

  arena_t arena = arena_new(1 &lt;&lt; 22, &amp;mem_profile);
}
</code></pre>
<p>Now, in <code>arena_alloc</code>, if there is a non-NULL memory profile, we record the allocation just before returning the freshly allocated pointer:</p>
<pre><code class="language-c">static void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {
  [...]

  if (a-&gt;profile) {
    mem_profile_record_alloc(a-&gt;profile, count, offset);
  }

  return (void *)res;
}
</code></pre>
<p>We now have to implement <code>mem_profile_record_alloc</code> and exporting the profile to the text format, and we are done.</p>
<p>When recording an allocation, we need to capture the call stack, so we walk the stack upwards until we reach a frame address that is 0 or does not have the alignement of a pointer (8); at which point we know not to dereference it and go further.</p>
<p>This will break if we disable frame pointers when compiling (<code>-fomit-frame-pointer</code>) which is in my opinion always a bad idea. There are other ways to get a call stack fortunately but they all are more involved and potentially slower. Note that this approach probably only works on x86_64, no idea how ARM does that. Here is a <a href="https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/">deep dive</a> on getting a stack trace in different environments.</p>
<pre><code class="language-c">static uint8_t record_call_stack(uint64_t *dst, uint64_t cap) {
  uintptr_t *rbp = __builtin_frame_address(0);

  uint64_t len = 0;

  while (rbp != 0 &amp;&amp; ((uint64_t)rbp &amp; 7) == 0 &amp;&amp; *rbp != 0) {
    const uintptr_t rip = *(rbp + 1);
    rbp = (uintptr_t *)*rbp;

    // `rip` points to the return instruction in the caller, once this call is
    // done. But: We want the location of the call i.e. the `call xxx`
    // instruction, so we subtract one byte to point inside it, which is not
    // quite 'at' it, but good enough.
    dst[len++] = rip - 1;

    if (len &gt;= cap)
      return len;
  }
  return len;
}
</code></pre>
<p>Now we can record the allocation proper, upserting the new record into our existing list of records, trying to find an existing record with the same call stack.
That part is important to avoid having a huge profile and that's why <code>pprof</code> made this design decision.</p>
<p>The code is slightly lengthy because we need to roll our own arrays here in this minimal example, but in a real application you'd have your own array structure and helper functions, most likely:</p>
<pre><code class="language-c">static void mem_profile_record_alloc(mem_profile_t *profile,
                                     uint64_t objects_count,
                                     uint64_t bytes_count) {
  // Record the call stack by stack walking.
  uint64_t call_stack[64] = {0};
  uint64_t call_stack_len =
      record_call_stack(call_stack, sizeof(call_stack) / sizeof(call_stack[0]));

  // Update the sums.
  profile-&gt;alloc_objects += objects_count;
  profile-&gt;alloc_space += bytes_count;
  profile-&gt;in_use_objects += objects_count;
  profile-&gt;in_use_space += bytes_count;

  // Upsert the record.
  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {
    mem_record_t *r = &amp;profile-&gt;records[i];

    if (r-&gt;call_stack_len == call_stack_len &amp;&amp;
        memcmp(r-&gt;call_stack, call_stack, call_stack_len * sizeof(uint64_t)) ==
            0) {
      // Found an existing record, update it.
      r-&gt;alloc_objects += objects_count;
      r-&gt;alloc_space += bytes_count;
      r-&gt;in_use_objects += objects_count;
      r-&gt;in_use_space += bytes_count;
      return;
    }
  }

  // Not found, insert a new record
  mem_record_t record = {
      .alloc_objects = objects_count,
      .alloc_space = bytes_count,
      .in_use_objects = objects_count,
      .in_use_space = bytes_count,
  };
  record.call_stack = arena_alloc(&amp;profile-&gt;arena, sizeof(uint64_t),
                                  _Alignof(uint64_t), call_stack_len);
  memcpy(record.call_stack, call_stack, call_stack_len * sizeof(uint64_t));
  record.call_stack_len = call_stack_len;

  if (profile-&gt;records_len &gt;= profile-&gt;records_cap) {
    uint64_t new_cap = profile-&gt;records_cap * 2;
    // Grow the array.
    mem_record_t *new_records = arena_alloc(
        &amp;profile-&gt;arena, sizeof(mem_record_t), _Alignof(mem_record_t), new_cap);
    memcpy(new_records, profile-&gt;records,
           profile-&gt;records_len * sizeof(mem_record_t));
    profile-&gt;records_cap = new_cap;
    profile-&gt;records = new_records;
  }
  profile-&gt;records[profile-&gt;records_len++] = record;
}
</code></pre>
<p>Finally, we can dump this profile in the <code>pprof</code> textual representation:</p>
<pre><code class="language-c">static void mem_profile_write(mem_profile_t *profile, FILE *out) {
  fprintf(out, &quot;heap profile: %lu: %lu [     %lu:    %lu] @ heapprofile\n&quot;,
          profile-&gt;in_use_objects, profile-&gt;in_use_space,
          profile-&gt;alloc_objects, profile-&gt;alloc_space);

  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {
    mem_record_t r = profile-&gt;records[i];

    fprintf(out, &quot;%lu: %lu [%lu: %lu] @ &quot;, r.in_use_objects, r.in_use_space,
            r.alloc_objects, r.alloc_space);

    for (uint64_t j = 0; j &lt; r.call_stack_len; j++) {
      fprintf(out, &quot;%#lx &quot;, r.call_stack[j]);
    }
    fputc('\n', out);
  }

  fputs(&quot;\nMAPPED_LIBRARIES:\n&quot;, out);

  static uint8_t mem[4096] = {0};
  int fd = open(&quot;/proc/self/maps&quot;, O_RDONLY);
  assert(fd != -1);
  ssize_t read_bytes = read(fd, mem, sizeof(mem));
  assert(read_bytes != -1);
  close(fd);

  fwrite(mem, 1, read_bytes, out);

  fflush(out);
}
</code></pre>
<p>And we're done! Let's try it with our initial example (bumping the size of the allocations a bit because <code>pprof</code> ignores tiny allocations for readability - although this is configurable):</p>
<pre><code class="language-c">void b(int n, arena_t *arena) {
  arena_alloc(arena, sizeof(int), _Alignof(int), n);
}

void a(int n, arena_t *arena) {
  arena_alloc(arena, sizeof(int), _Alignof(int), n);
  b(n, arena);
}

int main() {
  [...]

  arena_t arena = arena_new(1 &lt;&lt; 28, &amp;mem_profile);

  for (int i = 0; i &lt; 2; i++)
    a(2 * 1024 * 1024, &amp;arena);

  b(3 * 1024 * 1024, &amp;arena);

  mem_profile_write(&amp;mem_profile, stderr);
}
</code></pre>
<pre><code class="language-sh">$ cc -g3 example.c
$ ./a.out 2&gt; heap.profile
$ pprof --web ./a.out heap.profile
</code></pre>
<p>And we see in our browser:</p>
<p><img src="mem_prof4.png" alt="Initial profile" /></p>
<p>And we can even generate a flamegraph for it leveraging the great <a href="https://github.com/brendangregg/FlameGraph">OG flamegraph project</a>:</p>
<pre><code class="language-sh">$ pprof --collapsed ./a.out heap.profile | flamegraph.pl &gt; out.svg
</code></pre>
<p><object data="mem_prof_flamegraph.svg" type="image/svg+xml"></object></p>
<h2 id="2279041372-variations-and-limitations">
  <a class="title" href="#2279041372-variations-and-limitations">Variations and limitations</a>
  <a class="hash-anchor" href="#2279041372-variations-and-limitations" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<ul>
<li>For this article we always do memory profiling and abort once the arena is full; but it does not have to be this way. Memory profiling could be enabled in a CLI program with a command line flag; if it is disabled we do not create a memory profile nor an arena for it. Or, it could be enabled/disabled dynamically, after a given amount of time, etc. It could also stop when its dedicated arena is full instead of aborting the whole program.</li>
<li>Sampling could be easily added to <code>mem_profile_record_alloc</code> to only record some records, say 1%</li>
<li>The current maximum call stack depth is 64, for brevity in the context of this article. We can store a bigger one by having a dynamically sized array or storing each address in a more compact format, e.g. varint instead of a fixed 8 bytes</li>
<li>Stack traces won't work across library calls that are compiled without frame pointers. To which I'd say: It's likely easier to compile all of the code you depend on with the build flags you require than try to come up with alternative ways to walk the stack. Your mileage may vary.</li>
<li>We use linear scanning to find an existing record with the same call stack. When having lots of records, it would be advantageous to use a binary search on a sorted array or perhaps a hashtable.</li>
</ul>
<h2 id="3437344394-alternatives">
  <a class="title" href="#3437344394-alternatives">Alternatives</a>
  <a class="hash-anchor" href="#3437344394-alternatives" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<p><code>pprof</code> (the Perl one) is not the only way to get this information.</p>
<p>It turns out that your browser comes with a built-in profiler and a nice one to use at that! And it has support for native allocations, stack traces and so forth. Another possibility is the new <code>pprof</code> (the Go one). They all have more features than the original <code>pprof</code> that are really handy, most notably:</p>
<ul>
<li>A built-in interactive flamegraph feature</li>
<li>Tracking the time at which an allocation happened, which can then be used to produce a flamechart representing allocations over time (for example to observe a memory leak increasing the memory usage over time, and discover where it comes from)</li>
</ul>
<p>To make use of these, our application needs to generate the information we gathered in the format the profiler expects, just like we did with <code>pprof</code>.</p>
<ul>
<li>Chrome expects a <a href="https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/preview">JSON file</a>, which I did not experiment with yet.</li>
<li>Firefox expects a <a href="https://github.com/firefox-devtools/profiler/blob/main/docs-developer/processed-profile-format.md">different JSON file</a>. A good starting point is <a href="https://github.com/mstange/samply">https://github.com/mstange/samply</a>. I experimented with it but dropped this avenue because of several frustrating aspects:
<ul>
<li>It is very JS-centric so much of the profile has to be filled with <code>null</code> values or explicitly saying that the each sample is not for JS.</li>
<li>All fields must be provided even if empty, including arrays. Failing to do so throws an obscure exception in the profiler, that has to be tracked in the browser debugger, which shows the minified JS profiler code, which is not fun (yes, the profiler is written mostly/entirely in JS). The consequence is that most of the profile file is made of lengthy arrays only containing <code>null</code> values. Thus, most of the code to generate it is boilerplate noise.</li>
<li>Memory traces are supported but it seems that a CPU trace is required for each memory trace which makes the profile even bigger, and harder to generate. Only providing memory samples shows nothing in the graphs.</li>
</ul>
</li>
<li>The new <code>pprof</code> (the Go version) expects a relatively simple gzipped <a href="https://github.com/google/pprof/tree/4ca4178f5c7ab3f10300f07dab7422ead8dc17bc/proto">protobuf file</a>, but that means adding code generation and a library dependency. I use this tool when writing Go quite often and it is helpful. It also supports adding labels to samples, for example we could label the allocations coming from different arenas differently to be able to distinguish them in the same profile.</li>
</ul>
<h2 id="3796851539-conclusion">
  <a class="title" href="#3796851539-conclusion">Conclusion</a>
  <a class="hash-anchor" href="#3796851539-conclusion" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<p>I like that one of the most common memory profilers uses a very simple text format that anyone can generate, and that's it's stand-alone. It's very UNIXy!</p>
<p>Nonetheless, I will in the future explore the other aforementioned profilers (probably the Chrome one because it seems the most straightforward) and I do not think it should be much additional work. It's nice to leverage the existing browser to avoid having to install a profiler.</p>
<p>After all, it's been <a href="https://technology.riotgames.com/news/profiling-real-world-performance-league">done before</a>!</p>
<h2 id="1512890027-addendum-the-full-code">
  <a class="title" href="#1512890027-addendum-the-full-code">Addendum: the full code</a>
  <a class="hash-anchor" href="#1512890027-addendum-the-full-code" aria-hidden="true" onclick="navigator.clipboard.writeText(this.href);"></a>
</h2>
<details>
  <summary>The full code</summary>
<pre><code class="language-c">#define _GNU_SOURCE
#include &lt;assert.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;unistd.h&gt;

typedef struct {
  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;
  uint64_t *call_stack;
  uint64_t call_stack_len;
} mem_record_t;

typedef struct mem_profile mem_profile_t;
typedef struct {
  uint8_t *start;
  uint8_t *end;
  mem_profile_t *profile;
} arena_t;

struct mem_profile {
  mem_record_t *records;
  uint64_t records_len;
  uint64_t records_cap;
  uint64_t in_use_space, in_use_objects, alloc_space, alloc_objects;
  arena_t arena;
};

static void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count);

static uint8_t record_call_stack(uint64_t *dst, uint64_t cap) {
  uintptr_t *rbp = __builtin_frame_address(0);

  uint64_t len = 0;

  while (rbp != 0 &amp;&amp; ((uint64_t)rbp &amp; 7) == 0 &amp;&amp; *rbp != 0) {
    const uintptr_t rip = *(rbp + 1);
    rbp = (uintptr_t *)*rbp;

    // `rip` points to the return instruction in the caller, once this call is
    // done. But: We want the location of the call i.e. the `call xxx`
    // instruction, so we subtract one byte to point inside it, which is not
    // quite 'at' it, but good enough.
    dst[len++] = rip - 1;

    if (len &gt;= cap)
      return len;
  }
  return len;
}
static void mem_profile_record_alloc(mem_profile_t *profile,
                                     uint64_t objects_count,
                                     uint64_t bytes_count) {
  // Record the call stack by stack walking.
  uint64_t call_stack[64] = {0};
  uint64_t call_stack_len =
      record_call_stack(call_stack, sizeof(call_stack) / sizeof(call_stack[0]));

  // Update the sums.
  profile-&gt;alloc_objects += objects_count;
  profile-&gt;alloc_space += bytes_count;
  profile-&gt;in_use_objects += objects_count;
  profile-&gt;in_use_space += bytes_count;

  // Upsert the record.
  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {
    mem_record_t *r = &amp;profile-&gt;records[i];

    if (r-&gt;call_stack_len == call_stack_len &amp;&amp;
        memcmp(r-&gt;call_stack, call_stack, call_stack_len * sizeof(uint64_t)) ==
            0) {
      // Found an existing record, update it.
      r-&gt;alloc_objects += objects_count;
      r-&gt;alloc_space += bytes_count;
      r-&gt;in_use_objects += objects_count;
      r-&gt;in_use_space += bytes_count;
      return;
    }
  }

  // Not found, insert a new record.
  mem_record_t record = {
      .alloc_objects = objects_count,
      .alloc_space = bytes_count,
      .in_use_objects = objects_count,
      .in_use_space = bytes_count,
  };
  record.call_stack = arena_alloc(&amp;profile-&gt;arena, sizeof(uint64_t),
                                  _Alignof(uint64_t), call_stack_len);
  memcpy(record.call_stack, call_stack, call_stack_len * sizeof(uint64_t));
  record.call_stack_len = call_stack_len;

  if (profile-&gt;records_len &gt;= profile-&gt;records_cap) {
    uint64_t new_cap = profile-&gt;records_cap * 2;
    // Grow the array.
    mem_record_t *new_records = arena_alloc(
        &amp;profile-&gt;arena, sizeof(mem_record_t), _Alignof(mem_record_t), new_cap);
    memcpy(new_records, profile-&gt;records,
           profile-&gt;records_len * sizeof(mem_record_t));
    profile-&gt;records_cap = new_cap;
    profile-&gt;records = new_records;
  }
  profile-&gt;records[profile-&gt;records_len++] = record;
}

static void mem_profile_write(mem_profile_t *profile, FILE *out) {
  fprintf(out, &quot;heap profile: %lu: %lu [     %lu:    %lu] @ heapprofile\n&quot;,
          profile-&gt;in_use_objects, profile-&gt;in_use_space,
          profile-&gt;alloc_objects, profile-&gt;alloc_space);

  for (uint64_t i = 0; i &lt; profile-&gt;records_len; i++) {
    mem_record_t r = profile-&gt;records[i];

    fprintf(out, &quot;%lu: %lu [%lu: %lu] @ &quot;, r.in_use_objects, r.in_use_space,
            r.alloc_objects, r.alloc_space);

    for (uint64_t j = 0; j &lt; r.call_stack_len; j++) {
      fprintf(out, &quot;%#lx &quot;, r.call_stack[j]);
    }
    fputc('\n', out);
  }

  fputs(&quot;\nMAPPED_LIBRARIES:\n&quot;, out);

  static uint8_t mem[4096] = {0};
  int fd = open(&quot;/proc/self/maps&quot;, O_RDONLY);
  assert(fd != -1);
  ssize_t read_bytes = read(fd, mem, sizeof(mem));
  assert(read_bytes != -1);
  close(fd);

  fwrite(mem, 1, read_bytes, out);

  fflush(out);
}

static void *arena_alloc(arena_t *a, size_t size, size_t align, size_t count) {
  size_t available = a-&gt;end - a-&gt;start;
  size_t padding = -(size_t)a-&gt;start &amp; (align - 1);

  size_t offset = padding + size * count;
  if (available &lt; offset) {
    fprintf(stderr,
            &quot;Out of memory: available=%lu &quot;
            &quot;allocation_size=%lu\n&quot;,
            available, offset);
    abort();
  }

  uint8_t *res = a-&gt;start + padding;

  a-&gt;start += offset;

  if (a-&gt;profile) {
    mem_profile_record_alloc(a-&gt;profile, count, offset);
  }

  return (void *)res;
}

static arena_t arena_new(uint64_t cap, mem_profile_t *profile) {
  uint8_t *mem = mmap(NULL, cap, PROT_READ | PROT_WRITE,
                      MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);

  arena_t arena = {
      .profile = profile,
      .start = mem,
      .end = mem + cap,
  };
  return arena;
}

void b(int n, arena_t *arena) {
  arena_alloc(arena, sizeof(int), _Alignof(int), n);
}

void a(int n, arena_t *arena) {
  arena_alloc(arena, sizeof(int), _Alignof(int), n);
  b(n, arena);
}

int main() {
  arena_t mem_profile_arena = arena_new(1 &lt;&lt; 16, NULL);
  mem_profile_t mem_profile = {
      .arena = mem_profile_arena,
      .records = arena_alloc(&amp;mem_profile_arena, sizeof(mem_record_t),
                             _Alignof(mem_record_t), 16),
      .records_cap = 16,
  };

  arena_t arena = arena_new(1 &lt;&lt; 28, &amp;mem_profile);

  for (int i = 0; i &lt; 2; i++)
    a(2 * 1024 * 1024, &amp;arena);

  b(3 * 1024 * 1024, &amp;arena);

  mem_profile_write(&amp;mem_profile, stderr);
}
</code></pre>
</details>
<p><a href="/blog"> ‚è¥ Back to all articles</a></p>

<blockquote id="donate">
  <p>If you enjoy what you're reading, you want to support me, and can afford it: <a href="https://paypal.me/philigaultier?country.x=DE&locale.x=en_US">Support me</a>. That allows me to write more cool articles!</p>

  <p>
    This blog is <a href="https://github.com/gaultier/blog">open-source</a>!
    If you find a problem, please open a Github issue.
    The content of this blog as well as the code snippets are under the <a href="https://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_(%22BSD_License_2.0%22,_%22Revised_BSD_License%22,_%22New_BSD_License%22,_or_%22Modified_BSD_License%22)">BSD-3 License</a> which I also usually use for all my personal projects. It's basically free for every use but you have to mention me as the original author.
  </p>
</blockquote>

</div>
</body>
</html>
